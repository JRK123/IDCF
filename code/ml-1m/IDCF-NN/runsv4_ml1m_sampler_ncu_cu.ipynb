{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we extract core-user and non core users modify the non core users and give to myncf such that its accuracy decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from scipy.sparse.linalg import svds\n",
    "import random \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as ss\n",
    "import pickle\n",
    "from sklearn.utils.extmath import randomized_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadData():\n",
    "    ml1m_dir = 'data/ratings.dat'\n",
    "    ml1m_rating = pd.read_csv(ml1m_dir, sep='::', header=None, names=['uid', 'mid', 'rating', 'timestamp'],  engine='python')\n",
    "    unique_uid = np.unique(np.array(ml1m_rating['uid'].tolist()))\n",
    "    unique_mid = np.unique(np.array(ml1m_rating['mid'].tolist()))\n",
    "    uid_dict = dict([(y,x) for x,y in enumerate(unique_uid)])\n",
    "    mid_dict = dict([(y,x) for x,y in enumerate(unique_mid)])\n",
    "    print('DICTIONARY PREPARED:')\n",
    "\n",
    "    # init user item dictionary:\n",
    "    \n",
    "    uid_list = ml1m_rating['uid'].tolist()\n",
    "    uid_list_len = len(uid_list)\n",
    "    mid_list = ml1m_rating['mid'].tolist()\n",
    "    mid_list_len = len(mid_list)\n",
    "    rating_list = ml1m_rating['rating'].tolist()\n",
    "    user_item_dict = {x:set() for x in range(len(unique_uid))}\n",
    "    item_user_dict = {x:set() for x in range(len(unique_mid))}\n",
    "    for i in range(uid_list_len):\n",
    "        uid_list[i] = uid_dict[uid_list[i]]\n",
    "        mid_list[i] = mid_dict[mid_list[i]]\n",
    "        # rating_list[i] = 1 # comment this line if you want to activate explicit ratings\n",
    "        user_item_dict[uid_list[i]].add(mid_list[i])\n",
    "        item_user_dict[mid_list[i]].add(uid_list[i])\n",
    "    tmp_df = pd.DataFrame({\"uid\":uid_list, \"mid\":mid_list, \"ratings\":rating_list})\n",
    "    # v = tmp_df.uid.value_counts()\n",
    "    # df = tmp_df[tmp_df.uid.isin(v.index[v.gt(30)])]\n",
    "### code to store less than 30 interactions:\n",
    "    # df_less_30 = tmp_df[tmp_df.uid.isin(v.index[v.le(30)])]\n",
    "    return tmp_df, len(np.unique(mid_list)), len(unique_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICTIONARY PREPARED:\n",
      "UNIQUE MIDS:  3706\n",
      "UNIQUE UIDS:  6040\n"
     ]
    }
   ],
   "source": [
    "# threshold = 30 #split the users into test and train by threshold number of interactions. if greater than threshold then all interactions of that user goes into train set.\n",
    "df, unique_mids, unique_uids = ReadData()\n",
    "# print(\"GREATER THAN 30:\\n\", df_gt_30)\n",
    "# print(\"LESS THAN 30: \\n\", df_le_30)\n",
    "# print(len(df_gt_30))\n",
    "# print(len(df_le_30))\n",
    "print(\"UNIQUE MIDS: \", unique_mids)\n",
    "print(\"UNIQUE UIDS: \", unique_uids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support_test_df = df_gt_30.groupby(\"uid\").tail(1)\n",
    "# # print(len(df_gt_30))\n",
    "# support_train_df = df_gt_30.drop(df_gt_30.groupby('uid').tail(1).index, inplace=False)\n",
    "# # print(\"#TEST INSTANCES: \" ,len(support_test_df))\n",
    "# # print(\"#TRAIN INSTANCES: \" ,len(support_train_df))\n",
    "# assert(len(df_gt_30)== len(support_test_df) + len(support_train_df))\n",
    "# # print(len(test_df))\n",
    "# # print(len(train_df))\n",
    "# query_test_df = df_le_30.groupby(\"uid\").tail(1)\n",
    "# query_train_df = df_le_30.drop(df_le_30.groupby('uid').tail(1).index, inplace=False)\n",
    "# assert(len(df_le_30)== len(query_test_df) + len(query_train_df))\n",
    "# dic_support_train_df_uid_mapping = dict([(y,x) for x,y in enumerate(np.unique(support_train_df['uid']))])\n",
    "# dic_support_train_df_uid_rmapping = dict([(x,y) for x,y in enumerate(np.unique(support_train_df['uid']))])\n",
    "# ### no need for mid mapping\n",
    "\n",
    "# uid_of_train_df = support_train_df['uid'].tolist()\n",
    "# for i in range(len(uid_of_train_df)):\n",
    "#     uid_of_train_df[i] = dic_support_train_df_uid_mapping[uid_of_train_df[i]]\n",
    "# # for index, row in train_df.iterrows():\n",
    "# #     train_df['uid'][index] = dic_train_df_uid_mapping[train_df['uid'][index]]\n",
    "# core_user_ko_input_train_df = pd.DataFrame({'uid':uid_of_train_df, 'mid':support_train_df['mid'], 'ratings':support_train_df['ratings']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ui_dic = {}    \n",
    "# for user in range(unique_uids):\n",
    "#     train_ui_dic[user] = []\n",
    "# for index,row in support_train_df.iterrows():\n",
    "#         train_ui_dic[row['uid']].append(row['mid'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- utility functions for CUR coreusers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractCoreUsers(dataframe, unique_user_len, unique_item_len, percent_core_user=0.40):\n",
    "    # print(\"# of rows in ml1m_ratings: \", len(dataframe))\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "    userItemMatrix = np.zeros(shape=(u_len, m_len))\n",
    "    # print(userItemMatrix)\n",
    "    \n",
    "    unique_uid = np.unique(np.array(dataframe['uid'].tolist()))\n",
    "    assert(u_len == len(unique_uid))\n",
    "    uid_dict = dict([(y,x) for x,y in enumerate(unique_uid)])\n",
    "    rev_uid_dict = dict([(x,y) for x,y in enumerate(unique_uid)])\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        userItemMatrix[row['uid']][row['mid']] = row['ratings']\n",
    "        # print(row['uid'], row['mid'])\n",
    "    print(\"USER ITEM MATRIX: \\n\", userItemMatrix)\n",
    "\n",
    "    df = pd.DataFrame(userItemMatrix)\n",
    "    cosineSimilarity = cosine_similarity(df)\n",
    "    print(\"SHAPE OF COSINE MATIX:\\n \", cosineSimilarity.shape)\n",
    "\n",
    "    listToStoreTopFiftyOfEveryUser = []\n",
    "    for i in range(0, cosineSimilarity.shape[0]):\n",
    "        idx = np.argpartition(cosineSimilarity[i], -50)[-50:]\n",
    "        listToStoreTopFiftyOfEveryUser.append(idx)\n",
    "    # print(\"Top fifty list: \\n\", listToStoreTopFiftyOfEveryUser)\n",
    "    # listToStoreTopFiftyOfEveryUser = np.array(listToStoreTopFiftyOfEveryUser)\n",
    "    flatten = np.concatenate(listToStoreTopFiftyOfEveryUser)\n",
    "    listToStoreTopFiftyOfEveryUser = flatten.ravel()\n",
    "\n",
    "    # print(\"List of top 50\", listToStoreTopFiftyOfEveryUser)\n",
    "    df = pd.DataFrame(listToStoreTopFiftyOfEveryUser)\n",
    "    allUserList = df.value_counts().index.tolist()\n",
    "    # print(\"ALL USERS LIST\", allUserList)\n",
    "    allUserList = list(sum(allUserList,()))\n",
    "    # print(\"ALL USERS LIST\", allUserList)\n",
    "    twentyPercentUserList = allUserList[:int(len(allUserList)*0.2)]\n",
    "    # print(\"TWENTY PERCENT USER:\", len(twentyPercentUserList))\n",
    "    # print(\"TWENTY PERCENT USER:\", (twentyPercentUserList))\n",
    "    \n",
    "    r_ind = twentyPercentUserList\n",
    "    len_r_ind = len(r_ind)\n",
    "    new_r_ind = [rev_uid_dict[r_ind[i]] for i in range(len_r_ind)]\n",
    "    cos_coreusers = dataframe.iloc[np.where(dataframe.uid.isin(new_r_ind))]\n",
    "    # coreusers = dataframe.iloc[np.where(dataframe.uid.isin(twentyPercentUserList))]\n",
    "    # coreusers.reset_index()\n",
    "    # print(\"CORE USERS:\\n\", coreusers)\n",
    "    return cos_coreusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MID = 27277 + 1\n",
    "def select_cols(mat, k, dup=False):\n",
    "    # prob 1d array of probabilities of all columns\n",
    "    prob = mat.T.dot(mat)\n",
    "    prob = np.array(np.diagonal(prob))\n",
    "    denom = np.abs(prob).sum(axis = 0)\n",
    "    prob = prob/denom\n",
    "\n",
    "    C = np.zeros((mat.shape[0], k))\n",
    "    ind_cols = np.arange(0, prob.size)\n",
    "    c_ind = []\n",
    "    i = 0\n",
    "    while(i < k):\n",
    "        rand_sel = np.random.choice(ind_cols, 1, p=prob)\n",
    "        if rand_sel in c_ind:\n",
    "            continue\n",
    "        c_ind.append(rand_sel[0])\n",
    "        C[:, i] = mat[:, rand_sel[0]]\n",
    "        i += 1\n",
    "        # C[:, i] = C[:, i]/np.sqrt(k*prob[rand_sel[0]])\n",
    "\n",
    "    return C, c_ind\n",
    "\n",
    "def select_rows(mat, k, dup=False):\n",
    "\n",
    "    prob = mat.dot(mat.T)\n",
    "    prob = np.array(np.diagonal(prob))\n",
    "    denom = np.abs(prob).sum(axis=0)\n",
    "    prob = prob/denom\n",
    "    print(prob)\n",
    "    r = np.zeros((k, mat.shape[1]))\n",
    "    ind_rows = np.arange(0, prob.size)\n",
    "    r_ind = []\n",
    "    i = 0\n",
    "    while(i < k):\n",
    "        # print(ind_rows)\n",
    "        rand_sel = np.random.choice(ind_rows, 1, p=prob)\n",
    "        if rand_sel in r_ind:\n",
    "            continue\n",
    "        r_ind.append(rand_sel[0])\n",
    "        r[i, :] = mat[rand_sel[0], :]\n",
    "        i += 1\n",
    "        # r[i, :] = r[i, :]/np.sqrt(k*prob[rand_sel[0]])\n",
    "    r_ind = np.array(r_ind)\n",
    "    return r, r_ind\n",
    "\n",
    "# def matIntersection(mat, c_ind, r_ind):\n",
    "    \n",
    "#     W = np.zeros((len(r_ind), len(c_ind)))\n",
    "#     for i in range(len(r_ind)):\n",
    "#         W[i] = mat[r_ind[i], c_ind]\n",
    "    \n",
    "#     return W\n",
    "\n",
    "# def pseudoInverse(W):\n",
    "#     # U = WP (W+)\n",
    "\n",
    "#     # W = X.Z.YT\n",
    "#     X, Z, YT = np.linalg.svd(W)\n",
    "    \n",
    "#     # W+ = Y.Z+.XT\n",
    "#     XT = X.T\n",
    "#     Y = YT.T\n",
    "#     # Z+ = reciprocal(Z)\n",
    "#     ZP = np.reciprocal(Z)\n",
    "#     ZP = sp.spdiags(ZP, 0, ZP.size, ZP.size)\n",
    "#     ZP = ZP@ZP\n",
    "    \n",
    "#     # W+ = Y.Z+.XT\n",
    "#     WP = Y@ZP\n",
    "#     WP = WP@XT\n",
    "\n",
    "#     return WP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CUR_ExtractCoreUsers(dataframe, unique_user_len, unique_item_len, percent_core_user=0.40):\n",
    "    # print(\"# of rows in ml1m_ratings: \", len(dataframe))\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "    \n",
    "    # print(userItemMatrix)\n",
    "\n",
    "    unique_uid = np.unique(np.array(dataframe['uid'].tolist()))\n",
    "    assert(u_len == len(unique_uid))\n",
    "    # print(\"UNIQUE UID:\", unique_uid)\n",
    "    uid_dict = dict([(y,x) for x,y in enumerate(unique_uid)])\n",
    "    rev_uid_dict = dict([(x,y) for x,y in enumerate(unique_uid)])\n",
    "\n",
    "    userItemMatrix = np.zeros(shape=(u_len, m_len))\n",
    "    for index, row in dataframe.iterrows():\n",
    "        userItemMatrix[uid_dict[row['uid']]][row['mid']] = row['ratings']\n",
    "        # print(row['uid'], row['mid'])\n",
    "    print(\"USER ITEM MATRIX: \\n\", userItemMatrix)\n",
    "\n",
    "    mat = userItemMatrix\n",
    "    print(\"MAT:\", mat)\n",
    "    print(mat.shape)\n",
    "    C, c_ind = select_cols(mat, int(u_len * percent_core_user)) ## getting 20% core users\n",
    "    r, r_ind= select_rows(mat, int(u_len * percent_core_user))\n",
    "    # print(\"r\", r)\n",
    "    # print(\"r_ind len\", len(r_ind))\n",
    "\n",
    "    len_r_ind = len(r_ind)\n",
    "    new_r_ind = [rev_uid_dict[r_ind[i]] for i in range(len_r_ind)]\n",
    "    cur_coreusers = dataframe.iloc[np.where(dataframe.uid.isin(new_r_ind))]\n",
    "    # # coreusers.reset_index()\n",
    "    # # print(\"CORE USERS:\\n\", coreusers)\n",
    "    return cur_coreusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomSampling(dataframe, unique_user_len, unique_item_len, percent_core_user=0.40):\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "\n",
    "    how_much_to_sample = int(percent_core_user * u_len)\n",
    "    indices = random.sample(range(u_len), how_much_to_sample)\n",
    "    cur_coreusers = dataframe.iloc[np.where(dataframe.uid.isin(indices))]\n",
    "    return cur_coreusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class largest_leveragescores_Sampler:\n",
    "    def __init__(self, A, k, Q,N):\n",
    "        \"\"\" Create largest k-leverage scores Sampler for the matrix :math:`A` for k-low rank apparoximation.\n",
    "        :param A: \n",
    "            Matrix :math:`A`.\n",
    "        :type A: \n",
    "            array_type\n",
    "        :param Q: \n",
    "            Matrix containig the right singular vectors of :math:`A`.\n",
    "        :type Q: \n",
    "            array_type\n",
    "        :param k: \n",
    "            The order of low rank apparoximation.\n",
    "        :type k: \n",
    "            int\n",
    "        :param N: \n",
    "            The dimension of subsampling (the number of columns) of A.\n",
    "        :type N: \n",
    "            int\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        # print(\"k is\", type(k))\n",
    "        self.Q = np.transpose(Q[0:k,:])\n",
    "        self.N = N\n",
    "        self.k = k\n",
    "        \n",
    "        self.sampling_list = []\n",
    "        self.lvs_array = self.Estimate_Leverage_Scores()\n",
    "    def Estimate_Leverage_Scores(self):\n",
    "        return 1/(self.k)*np.diag(np.dot(self.Q,self.Q.T))\n",
    "    def MultiRounds(self):\n",
    "        temp_list = list(reversed(np.argsort(self.lvs_array)))\n",
    "        sampled_indices_ = temp_list[0:self.k]\n",
    "        self.sampling_list = sampled_indices_\n",
    "        return sampled_indices_\n",
    "from scipy.sparse.linalg import svds\n",
    "def Extract_LLS(dataframe, unique_user_len, unique_item_len, percent_core_user=0.40):\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "    \n",
    "    # print(userItemMatrix)\n",
    "\n",
    "    unique_uid = np.unique(np.array(dataframe['uid'].tolist()))\n",
    "    assert(u_len == len(unique_uid))\n",
    "    # print(\"UNIQUE UID:\", unique_uid)\n",
    "    uid_dict = dict([(y,x) for x,y in enumerate(unique_uid)])\n",
    "    rev_uid_dict = dict([(x,y) for x,y in enumerate(unique_uid)])\n",
    "\n",
    "    userItemMatrix = np.zeros(shape=(u_len, m_len))\n",
    "    for index, row in dataframe.iterrows():\n",
    "        userItemMatrix[uid_dict[int(row['uid'])]][int(row['mid'])] = int(row['ratings'])\n",
    "        # print(row['uid'], row['mid'])\n",
    "    print(\"USER ITEM MATRIX: \\n\", userItemMatrix)\n",
    "    A = userItemMatrix.T\n",
    "    number_of_coreusers = int(u_len * percent_core_user)\n",
    "    print(number_of_coreusers)\n",
    "    u4, s4, Q = svds(A, k=number_of_coreusers)\n",
    "    lls = largest_leveragescores_Sampler(A, number_of_coreusers, Q, number_of_coreusers)\n",
    "    indx = lls.MultiRounds()\n",
    "    # indx = indx.\n",
    "    print(\"LENGTH OF INDEX:\", len(indx))\n",
    "    print(\"INDICES ARE:\", indx)\n",
    "    cur_coreusers = dataframe.iloc[np.where(dataframe.uid.isin(indx))]\n",
    "    # # coreusers.reset_index()\n",
    "    # # print(\"CORE USERS:\\n\", coreusers)\n",
    "    return cur_coreusers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cur decomposition from paper (https://www.pnas.org/doi/10.1073/pnas.0803205106) called optimal cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUR():\n",
    "    def __init__(self, k, eps, it=None, truncated=False):\n",
    "        self.k = k\n",
    "        print(\"K IS :\", self.k)\n",
    "        self.eps = eps\n",
    "        self.trunc = truncated \n",
    "        self.c = k * np.log(k) / eps**2 #expectation number of sampled columns\n",
    "        self.C, self.U, self.R = None, None, None #matrices of decomposition\n",
    "        self.pi_col, self.pi_row = None, None #leverage scores of corresponding columns/rows\n",
    "        self.col_indices = None\n",
    "        self.row_indices = None\n",
    "    \n",
    "    def column_select(self, A):\n",
    "        n = A.shape[1]\n",
    "        A = np.array(A.copy())\n",
    "        if self.trunc:\n",
    "            _, _, v_k = randomized_svd(A, self.k) #for very big matrices\n",
    "        else:\n",
    "            _, _, vh = np.linalg.svd(A, full_matrices=False)\n",
    "            v_k = vh[0:self.k, :]\n",
    "        \n",
    "        pi = 1 / self.k * np.sum(v_k**2, axis=0)\n",
    "        c_index = [np.random.choice(2, \n",
    "                        p=[1 - min(1, self.c * pi[i]), min(1, self.c * pi[i])]) for i in range(n)\n",
    "                  ]\n",
    "        c_index = np.nonzero(c_index)[0]\n",
    "        print(len(c_index))\n",
    "        C = A[:, c_index]\n",
    "        return C, c_index, pi\n",
    "\n",
    "    def run_CUR(self, A):\n",
    "        A = np.array(A.copy())\n",
    "        # self.C, self.col_indices, self.pi_col = self.column_select(A)\n",
    "        self.R, self.row_indices, self.pi_row = self.column_select(A.T)\n",
    "        # self.U = np.linalg.pinv(self.C) @ A @ np.linalg.pinv(self.R.T)\n",
    "        return self.row_indices\n",
    "def OPTIMAL_CUR_ExtractCoreUsers(dataframe, unique_user_len, unique_item_len):\n",
    "    # print(\"# of rows in ml1m_ratings: \", len(dataframe))\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "    userItemMatrix = np.zeros(shape=(u_len, m_len))\n",
    "    # print(userItemMatrix)\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        userItemMatrix[row['uid']][row['mid']] = row['ratings']\n",
    "        # print(row['uid'], row['mid'])\n",
    "    print(\"USER ITEM MATRIX: \\n\", userItemMatrix)\n",
    "\n",
    "    mat = userItemMatrix\n",
    "    print(\"MAT:\", mat)\n",
    "    print(mat.shape)\n",
    "    cur = CUR(k=int(u_len * 0.10), eps=0.5,)\n",
    "    # ids = np.argsort(cur.pi_col)[::-1][:5]\n",
    "    cur.run_CUR(mat)\n",
    "    cur_coreusers_idx = np.argsort(cur.pi_row)[::-1][:int(u_len * 0.10)]\n",
    "    cur_coreusers = dataframe.iloc[np.where(dataframe.uid.isin(cur_coreusers_idx))]\n",
    "    # print(len(cur_coreusers))\n",
    "    return cur_coreusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER LEN: 6040\n",
      "MOVIE LEN: 3706\n",
      "USER ITEM MATRIX: \n",
      " [[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 0.]]\n",
      "2416\n"
     ]
    }
   ],
   "source": [
    "# core_users = CUR_ExtractCoreUsers(core_user_ko_input_train_df, len(np.unique(uid_of_train_df)), unique_mids, percent_core_user=0.40)\n",
    "# sdf.to_csv('file_name.csv', index=False)\n",
    "# core_users = ExtractCoreUsers(core_user_ko_input_train_df, len(np.unique(uid_of_train_df)), unique_mids)\n",
    "# core_users = RandomSampling(core_user_ko_input_train_df, len(np.unique(uid_of_train_df)), unique_mids, percent_core_user=0.40)\n",
    "core_users = Extract_LLS(df, len(np.unique(df['uid'])), unique_mids, percent_core_user=0.40)\n",
    "support_user_list = np.unique(core_users['uid'])\n",
    "print(\"CORE USERS:\" ,core_users)\n",
    "print(\"NUMBER OF CORE USERS:\", len(support_user_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE SNIPPET FOR GETTING NESTED CORE USERS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER LEN: 2416\n",
      "MOVIE LEN: 3706\n",
      "USER ITEM MATRIX: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " [5. 5. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 0.]]\n",
      "MAT: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " [5. 5. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 0.]]\n",
      "(2416, 3706)\n",
      "[0.00020753 0.00020781 0.00066301 ... 0.00099564 0.00027636 0.0004537 ]\n",
      "1208\n",
      "NESTED CORE USERS:\n",
      "          uid   mid  ratings\n",
      "254        4  2775        4\n",
      "255        4  2140        4\n",
      "256        4  1087        5\n",
      "257        4    38        3\n",
      "258        4   279        2\n",
      "...      ...   ...      ...\n",
      "999720  6036  1008        4\n",
      "999721  6036  1014        4\n",
      "999722  6036  1017        3\n",
      "999723  6036   548        4\n",
      "999724  6036  1025        5\n",
      "\n",
      "[474791 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "core_users_nested = CUR_ExtractCoreUsers(core_users, len(np.unique(core_users['uid'])), unique_mids, percent_core_user=0.50)\n",
    "print(len(np.unique(core_users_nested['uid'])))\n",
    "print(\"NESTED CORE USERS:\\n\" ,core_users_nested)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CODE SNIPPET FOR GETTING NESTED CORE USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON CORE USERS:           uid   mid  ratings\n",
      "0           0  1104        5\n",
      "1           0   639        3\n",
      "2           0   853        3\n",
      "3           0  3177        4\n",
      "4           0  2162        5\n",
      "...       ...   ...      ...\n",
      "1000204  6039  1019        1\n",
      "1000205  6039  1022        5\n",
      "1000206  6039   548        5\n",
      "1000207  6039  1024        4\n",
      "1000208  6039  1025        4\n",
      "\n",
      "[525418 rows x 3 columns]\n",
      "CORE USERS:          uid   mid  ratings\n",
      "254        4  2775        4\n",
      "255        4  2140        4\n",
      "256        4  1087        5\n",
      "257        4    38        3\n",
      "258        4   279        2\n",
      "...      ...   ...      ...\n",
      "999720  6036  1008        4\n",
      "999721  6036  1014        4\n",
      "999722  6036  1017        3\n",
      "999723  6036   548        4\n",
      "999724  6036  1025        5\n",
      "\n",
      "[474791 rows x 3 columns]\n",
      "4832\n"
     ]
    }
   ],
   "source": [
    "core_users_index_list_nested = core_users_nested.index.to_list()\n",
    "non_core_user_index = (df.index.difference(core_users_nested.index))\n",
    "non_core_user_index = non_core_user_index.tolist()\n",
    "\n",
    "core_users_df_nested = df.loc[core_users_index_list_nested]\n",
    "non_core_user_df = df.loc[non_core_user_index]\n",
    "print(\"NON CORE USERS:\" ,non_core_user_df)\n",
    "print(\"CORE USERS:\", core_users_nested)\n",
    "print(len(np.unique(non_core_user_df['uid'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_of_core_users = np.unique(core_users_df_nested['uid']).tolist()\n",
    "uid_non_core_users = np.unique(non_core_user_df['uid']).tolist()\n",
    "import pickle\n",
    "with open(\"ml-1m_core_users_and_non_core_users_obj.pkl\", \"wb\") as f:\n",
    "    pickle.dump(uid_of_core_users, f)\n",
    "    pickle.dump(uid_non_core_users, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate original matrix for non core_user df:\n",
    "matrix = np.zeros((unique_uids, unique_mids))\n",
    "for index, row in non_core_user_df.iterrows():\n",
    "    matrix[int(row['uid'])][int(row['mid'])] = int(1)\n",
    "## write this numpy matrix to a file\n",
    "with open(\"ml-1m_non_core_user_numpy_matrix.pkl\", \"wb\") as f:\n",
    "    pickle.dump(matrix, f)\n",
    "    pickle.dump(unique_uids, f)\n",
    "    pickle.dump(unique_mids, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_test_df = core_users_df_nested.groupby(\"uid\").tail(1)\n",
    "# print(len(df_gt_30))\n",
    "support_train_df = core_users_df_nested.drop(core_users_df_nested.groupby('uid').tail(1).index, inplace=False)\n",
    "# print(\"#TEST INSTANCES: \" ,len(support_test_df))\n",
    "# print(\"#TRAIN INSTANCES: \" ,len(support_train_df))\n",
    "assert(len(core_users_df_nested) == len(support_test_df) + len(support_train_df))\n",
    "# print(len(test_df))\n",
    "# print(len(train_df))\n",
    "query_test_df = non_core_user_df.groupby(\"uid\").tail(1)\n",
    "query_train_df = non_core_user_df.drop(non_core_user_df.groupby('uid').tail(1).index, inplace=False)\n",
    "assert(len(non_core_user_df)== len(query_test_df) + len(query_train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ui_dic = {}    \n",
    "for user in range(unique_uids):\n",
    "    train_ui_dic[user] = []\n",
    "for index,row in support_train_df.iterrows():\n",
    "        train_ui_dic[row['uid']].append(row['mid'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CODE SNIPPET FOR GETTING NESTED CORE USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208\n",
      "SUPPORT TEST DF:          uid   mid  ratings\n",
      "451        4   683        4\n",
      "1199       9  1868        5\n",
      "1336      10  1152        4\n",
      "1939      16  2773        5\n",
      "2244      17  1154        5\n",
      "...      ...   ...      ...\n",
      "995572  6010  1865        5\n",
      "995719  6012   548        5\n",
      "996791  6015  3540        4\n",
      "997442  6022  1017        1\n",
      "999724  6036  1025        5\n",
      "\n",
      "[1208 rows x 3 columns]\n",
      "QUERY TEST DF:\n",
      "           uid   mid  ratings\n",
      "52          0  1154        4\n",
      "181         1  1155        5\n",
      "232         2  1900        4\n",
      "253         3  1148        5\n",
      "522         5    33        4\n",
      "...       ...   ...      ...\n",
      "998634   6034  1865        4\n",
      "999522   6035  1867        3\n",
      "999744   6037  1007        5\n",
      "999867   6038  1025        4\n",
      "1000208  6039  1025        4\n",
      "\n",
      "[4832 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "unique_uids_in_support_trian = np.unique(np.array(core_users_df_nested['uid']))\n",
    "unique_uids_in_query_trian = np.unique(query_train_df['uid'])\n",
    "print(len(unique_uids_in_support_trian))\n",
    "support_test_df = support_test_df.loc[support_test_df['uid'].isin(unique_uids_in_support_trian)]\n",
    "print(\"SUPPORT TEST DF:\" ,support_test_df)\n",
    "query_test_df = query_test_df\n",
    "print(\"QUERY TEST DF:\\n\", query_test_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CODE SNIPPET FOR GETTING NESTED CORE USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_train = []\n",
    "for index,row in core_users_df_nested.iterrows():\n",
    "    support_train.append([row['uid'], row['mid'], row['ratings']])\n",
    "query_train = []\n",
    "for index, row in query_train_df.iterrows():\n",
    "    query_train.append([row['uid'], row['mid'], row['ratings']])\n",
    "support_test = []\n",
    "for index, row in support_test_df.iterrows():\n",
    "    support_test.append([row['uid'], row['mid'], row['ratings']])\n",
    "query_test = []\n",
    "for index, row in query_test_df.iterrows():\n",
    "    query_test.append([row['uid'], row['mid'], row['ratings']])\n",
    "user_his_dic = {}\n",
    "for u in train_ui_dic.keys():\n",
    "    user_his_dic[u] = train_ui_dic[u]\n",
    "user_supp_list = np.unique(core_users_df_nested['uid']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"input_for_getting_query_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(support_train, f)\n",
    "    pickle.dump(query_train, f)\n",
    "    pickle.dump(support_test, f)\n",
    "    pickle.dump(query_test, f)\n",
    "    pickle.dump(user_supp_list, f)\n",
    "    pickle.dump(user_his_dic, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting embeddings for query users and which we will use to mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 474791/520586\n",
      "test set size: support/query 1208/4832\n",
      "Epoch 0 Step 441: Train 1.9116 Reg: 0.5788\n",
      "Test: 0.8034 MAE: 0.7135 RMSE: 0.8963\n",
      "Val: 0.8192 MAE: 0.7161 RMSE: 0.9051\n",
      "Epoch 1 Step 882: Train 0.8167 Reg: 0.4449\n",
      "Test: 0.8020 MAE: 0.7115 RMSE: 0.8956\n",
      "Val: 0.8153 MAE: 0.7145 RMSE: 0.9029\n",
      "Epoch 2 Step 1323: Train 0.8128 Reg: 0.3585\n",
      "Test: 0.7934 MAE: 0.7122 RMSE: 0.8907\n",
      "Val: 0.8087 MAE: 0.7108 RMSE: 0.8993\n",
      "Epoch 3 Step 1764: Train 0.8100 Reg: 0.3151\n",
      "Test: 0.7999 MAE: 0.7133 RMSE: 0.8943\n",
      "Val: 0.8075 MAE: 0.7120 RMSE: 0.8986\n",
      "Epoch 4 Step 2205: Train 0.8054 Reg: 0.2917\n",
      "Test: 0.8000 MAE: 0.7121 RMSE: 0.8944\n",
      "Val: 0.8054 MAE: 0.7104 RMSE: 0.8974\n",
      "Epoch 5 Step 2646: Train 0.7999 Reg: 0.2786\n",
      "Test: 0.7875 MAE: 0.7031 RMSE: 0.8874\n",
      "Val: 0.7976 MAE: 0.7039 RMSE: 0.8931\n",
      "Epoch 6 Step 3087: Train 0.7880 Reg: 0.2771\n",
      "Test: 0.7905 MAE: 0.7026 RMSE: 0.8891\n",
      "Val: 0.7856 MAE: 0.6989 RMSE: 0.8863\n",
      "Epoch 7 Step 3528: Train 0.7729 Reg: 0.2835\n",
      "Test: 0.7680 MAE: 0.6897 RMSE: 0.8764\n",
      "Val: 0.7706 MAE: 0.6894 RMSE: 0.8778\n",
      "Epoch 8 Step 3969: Train 0.7566 Reg: 0.2855\n",
      "Test: 0.7525 MAE: 0.6798 RMSE: 0.8675\n",
      "Val: 0.7552 MAE: 0.6833 RMSE: 0.8690\n",
      "Epoch 9 Step 4410: Train 0.7411 Reg: 0.2870\n",
      "Test: 0.7355 MAE: 0.6777 RMSE: 0.8576\n",
      "Val: 0.7466 MAE: 0.6790 RMSE: 0.8640\n",
      "Epoch 10 Step 4851: Train 0.7263 Reg: 0.2995\n",
      "Test: 0.7211 MAE: 0.6662 RMSE: 0.8492\n",
      "Val: 0.7297 MAE: 0.6700 RMSE: 0.8542\n",
      "Epoch 11 Step 5292: Train 0.7067 Reg: 0.3209\n",
      "Test: 0.7108 MAE: 0.6645 RMSE: 0.8431\n",
      "Val: 0.7224 MAE: 0.6668 RMSE: 0.8499\n",
      "Epoch 12 Step 5733: Train 0.6900 Reg: 0.3319\n",
      "Test: 0.6922 MAE: 0.6624 RMSE: 0.8320\n",
      "Val: 0.7155 MAE: 0.6636 RMSE: 0.8459\n",
      "Epoch 13 Step 6174: Train 0.6730 Reg: 0.3485\n",
      "Test: 0.6673 MAE: 0.6489 RMSE: 0.8169\n",
      "Val: 0.7127 MAE: 0.6642 RMSE: 0.8442\n",
      "Epoch 14 Step 6615: Train 0.6545 Reg: 0.3709\n",
      "Test: 0.6512 MAE: 0.6443 RMSE: 0.8070\n",
      "Val: 0.7070 MAE: 0.6579 RMSE: 0.8409\n",
      "Epoch 15 Step 7056: Train 0.6312 Reg: 0.4064\n",
      "Test: 0.6106 MAE: 0.6179 RMSE: 0.7814\n",
      "Val: 0.7024 MAE: 0.6540 RMSE: 0.8381\n",
      "Epoch 16 Step 7497: Train 0.6018 Reg: 0.4496\n",
      "Test: 0.5789 MAE: 0.5969 RMSE: 0.7609\n",
      "Val: 0.7036 MAE: 0.6529 RMSE: 0.8388\n",
      "Epoch 17 Step 7938: Train 0.5693 Reg: 0.4877\n",
      "Test: 0.5433 MAE: 0.5839 RMSE: 0.7371\n",
      "Val: 0.7113 MAE: 0.6575 RMSE: 0.8434\n",
      "Epoch 18 Step 8379: Train 0.5397 Reg: 0.5137\n",
      "Test: 0.5091 MAE: 0.5600 RMSE: 0.7135\n",
      "Val: 0.7238 MAE: 0.6592 RMSE: 0.8508\n",
      "Epoch 19 Step 8820: Train 0.5162 Reg: 0.5315\n",
      "Test: 0.4811 MAE: 0.5482 RMSE: 0.6936\n",
      "Val: 0.7347 MAE: 0.6644 RMSE: 0.8571\n",
      "Epoch 20 Step 9261: Train 0.4973 Reg: 0.5432\n",
      "Test: 0.4682 MAE: 0.5413 RMSE: 0.6843\n",
      "Val: 0.7471 MAE: 0.6685 RMSE: 0.8643\n",
      "Epoch 21 Step 9702: Train 0.4828 Reg: 0.5477\n",
      "Test: 0.4548 MAE: 0.5319 RMSE: 0.6744\n",
      "Val: 0.7581 MAE: 0.6745 RMSE: 0.8707\n",
      "Epoch 22 Step 10143: Train 0.4726 Reg: 0.5482\n",
      "Test: 0.4412 MAE: 0.5240 RMSE: 0.6643\n",
      "Val: 0.7676 MAE: 0.6769 RMSE: 0.8761\n",
      "Epoch 23 Step 10584: Train 0.4644 Reg: 0.5465\n",
      "Test: 0.4342 MAE: 0.5168 RMSE: 0.6589\n",
      "Val: 0.7780 MAE: 0.6818 RMSE: 0.8820\n",
      "Epoch 24 Step 11025: Train 0.4578 Reg: 0.5447\n",
      "Test: 0.4309 MAE: 0.5165 RMSE: 0.6564\n",
      "Val: 0.7847 MAE: 0.6842 RMSE: 0.8858\n",
      "Epoch 25 Step 11466: Train 0.4512 Reg: 0.5427\n",
      "Test: 0.4230 MAE: 0.5105 RMSE: 0.6504\n",
      "Val: 0.7936 MAE: 0.6863 RMSE: 0.8908\n",
      "Epoch 26 Step 11907: Train 0.4450 Reg: 0.5405\n",
      "Test: 0.4157 MAE: 0.5082 RMSE: 0.6448\n",
      "Val: 0.7994 MAE: 0.6882 RMSE: 0.8941\n",
      "Epoch 27 Step 12348: Train 0.4398 Reg: 0.5369\n",
      "Test: 0.4121 MAE: 0.5073 RMSE: 0.6420\n",
      "Val: 0.8078 MAE: 0.6914 RMSE: 0.8988\n",
      "Epoch 28 Step 12789: Train 0.4352 Reg: 0.5332\n",
      "Test: 0.4107 MAE: 0.5040 RMSE: 0.6408\n",
      "Val: 0.8126 MAE: 0.6931 RMSE: 0.9014\n",
      "Epoch 29 Step 13230: Train 0.4314 Reg: 0.5285\n",
      "Test: 0.4087 MAE: 0.5039 RMSE: 0.6393\n",
      "Val: 0.8193 MAE: 0.6959 RMSE: 0.9052\n",
      "Epoch 30 Step 13671: Train 0.4278 Reg: 0.5241\n",
      "Test: 0.4058 MAE: 0.4994 RMSE: 0.6370\n",
      "Val: 0.8265 MAE: 0.6976 RMSE: 0.9091\n",
      "Epoch 31 Step 14112: Train 0.4246 Reg: 0.5197\n",
      "Test: 0.3990 MAE: 0.4977 RMSE: 0.6316\n",
      "Val: 0.8313 MAE: 0.7003 RMSE: 0.9118\n",
      "Epoch 32 Step 14553: Train 0.4215 Reg: 0.5152\n",
      "Test: 0.4009 MAE: 0.4996 RMSE: 0.6331\n",
      "Val: 0.8364 MAE: 0.7022 RMSE: 0.9145\n",
      "Epoch 33 Step 14994: Train 0.4188 Reg: 0.5112\n",
      "Test: 0.3992 MAE: 0.4971 RMSE: 0.6318\n",
      "Val: 0.8410 MAE: 0.7037 RMSE: 0.9170\n",
      "Epoch 34 Step 15435: Train 0.4162 Reg: 0.5067\n",
      "Test: 0.3954 MAE: 0.4962 RMSE: 0.6288\n",
      "Val: 0.8469 MAE: 0.7060 RMSE: 0.9203\n",
      "Epoch 35 Step 15876: Train 0.4136 Reg: 0.5025\n",
      "Test: 0.3936 MAE: 0.4921 RMSE: 0.6274\n",
      "Val: 0.8506 MAE: 0.7063 RMSE: 0.9223\n",
      "Epoch 36 Step 16317: Train 0.4111 Reg: 0.4986\n",
      "Test: 0.3943 MAE: 0.4928 RMSE: 0.6280\n",
      "Val: 0.8549 MAE: 0.7083 RMSE: 0.9246\n",
      "Epoch 37 Step 16758: Train 0.4087 Reg: 0.4947\n",
      "Test: 0.3925 MAE: 0.4887 RMSE: 0.6265\n",
      "Val: 0.8593 MAE: 0.7089 RMSE: 0.9270\n",
      "Epoch 38 Step 17199: Train 0.4064 Reg: 0.4913\n",
      "Test: 0.3920 MAE: 0.4877 RMSE: 0.6261\n",
      "Val: 0.8623 MAE: 0.7104 RMSE: 0.9286\n",
      "Epoch 39 Step 17640: Train 0.4035 Reg: 0.4885\n",
      "Test: 0.3905 MAE: 0.4884 RMSE: 0.6249\n",
      "Val: 0.8695 MAE: 0.7140 RMSE: 0.9325\n",
      "Epoch 40 Step 18081: Train 0.4007 Reg: 0.4857\n",
      "Test: 0.3883 MAE: 0.4878 RMSE: 0.6231\n",
      "Val: 0.8727 MAE: 0.7146 RMSE: 0.9342\n",
      "Epoch 41 Step 18522: Train 0.3980 Reg: 0.4829\n",
      "Test: 0.3873 MAE: 0.4841 RMSE: 0.6223\n",
      "Val: 0.8760 MAE: 0.7155 RMSE: 0.9359\n",
      "Epoch 42 Step 18963: Train 0.3958 Reg: 0.4800\n",
      "Test: 0.3866 MAE: 0.4856 RMSE: 0.6217\n",
      "Val: 0.8814 MAE: 0.7187 RMSE: 0.9388\n",
      "Epoch 43 Step 19404: Train 0.3937 Reg: 0.4768\n",
      "Test: 0.3851 MAE: 0.4820 RMSE: 0.6206\n",
      "Val: 0.8834 MAE: 0.7182 RMSE: 0.9399\n",
      "Epoch 44 Step 19845: Train 0.3918 Reg: 0.4739\n",
      "Test: 0.3850 MAE: 0.4820 RMSE: 0.6204\n",
      "Val: 0.8868 MAE: 0.7195 RMSE: 0.9417\n",
      "Epoch 45 Step 20286: Train 0.3901 Reg: 0.4710\n",
      "Test: 0.3831 MAE: 0.4811 RMSE: 0.6189\n",
      "Val: 0.8903 MAE: 0.7207 RMSE: 0.9436\n",
      "Epoch 46 Step 20727: Train 0.3885 Reg: 0.4682\n",
      "Test: 0.3822 MAE: 0.4796 RMSE: 0.6182\n",
      "Val: 0.8938 MAE: 0.7217 RMSE: 0.9454\n",
      "Epoch 47 Step 21168: Train 0.3870 Reg: 0.4653\n",
      "Test: 0.3823 MAE: 0.4804 RMSE: 0.6183\n",
      "Val: 0.8980 MAE: 0.7237 RMSE: 0.9476\n",
      "Epoch 48 Step 21609: Train 0.3855 Reg: 0.4627\n",
      "Test: 0.3811 MAE: 0.4796 RMSE: 0.6173\n",
      "Val: 0.9007 MAE: 0.7247 RMSE: 0.9491\n",
      "Epoch 49 Step 22050: Train 0.3841 Reg: 0.4601\n",
      "Test: 0.3792 MAE: 0.4763 RMSE: 0.6158\n",
      "Val: 0.9016 MAE: 0.7245 RMSE: 0.9495\n",
      "Epoch 50 Step 22491: Train 0.3828 Reg: 0.4576\n",
      "Test: 0.3780 MAE: 0.4763 RMSE: 0.6149\n",
      "Val: 0.9052 MAE: 0.7260 RMSE: 0.9514\n",
      "Epoch 51 Step 22932: Train 0.3815 Reg: 0.4551\n",
      "Test: 0.3778 MAE: 0.4754 RMSE: 0.6147\n",
      "Val: 0.9088 MAE: 0.7271 RMSE: 0.9533\n",
      "Epoch 52 Step 23373: Train 0.3803 Reg: 0.4528\n",
      "Test: 0.3777 MAE: 0.4759 RMSE: 0.6146\n",
      "Val: 0.9110 MAE: 0.7281 RMSE: 0.9544\n",
      "Epoch 53 Step 23814: Train 0.3792 Reg: 0.4506\n",
      "Test: 0.3783 MAE: 0.4748 RMSE: 0.6151\n",
      "Val: 0.9128 MAE: 0.7282 RMSE: 0.9554\n",
      "Epoch 54 Step 24255: Train 0.3781 Reg: 0.4484\n",
      "Test: 0.3777 MAE: 0.4763 RMSE: 0.6146\n",
      "Val: 0.9163 MAE: 0.7301 RMSE: 0.9572\n",
      "Epoch 55 Step 24696: Train 0.3771 Reg: 0.4464\n",
      "Test: 0.3777 MAE: 0.4742 RMSE: 0.6146\n",
      "Val: 0.9170 MAE: 0.7298 RMSE: 0.9576\n",
      "Epoch 56 Step 25137: Train 0.3761 Reg: 0.4444\n",
      "Test: 0.3771 MAE: 0.4730 RMSE: 0.6141\n",
      "Val: 0.9180 MAE: 0.7299 RMSE: 0.9581\n",
      "Epoch 57 Step 25578: Train 0.3751 Reg: 0.4425\n",
      "Test: 0.3765 MAE: 0.4722 RMSE: 0.6136\n",
      "Val: 0.9205 MAE: 0.7307 RMSE: 0.9594\n",
      "Epoch 58 Step 26019: Train 0.3742 Reg: 0.4407\n",
      "Test: 0.3763 MAE: 0.4723 RMSE: 0.6134\n",
      "Val: 0.9224 MAE: 0.7316 RMSE: 0.9604\n",
      "Epoch 59 Step 26460: Train 0.3733 Reg: 0.4390\n",
      "Test: 0.3761 MAE: 0.4714 RMSE: 0.6133\n",
      "Val: 0.9239 MAE: 0.7319 RMSE: 0.9612\n",
      "Epoch 60 Step 26901: Train 0.3725 Reg: 0.4374\n",
      "Test: 0.3752 MAE: 0.4716 RMSE: 0.6125\n",
      "Val: 0.9255 MAE: 0.7326 RMSE: 0.9620\n",
      "Epoch 61 Step 27342: Train 0.3717 Reg: 0.4358\n",
      "Test: 0.3747 MAE: 0.4725 RMSE: 0.6121\n",
      "Val: 0.9280 MAE: 0.7338 RMSE: 0.9633\n",
      "Epoch 62 Step 27783: Train 0.3709 Reg: 0.4343\n",
      "Test: 0.3748 MAE: 0.4718 RMSE: 0.6122\n",
      "Val: 0.9294 MAE: 0.7341 RMSE: 0.9641\n",
      "Epoch 63 Step 28224: Train 0.3702 Reg: 0.4329\n",
      "Test: 0.3750 MAE: 0.4722 RMSE: 0.6124\n",
      "Val: 0.9305 MAE: 0.7345 RMSE: 0.9646\n",
      "Epoch 64 Step 28665: Train 0.3696 Reg: 0.4314\n",
      "Test: 0.3751 MAE: 0.4717 RMSE: 0.6125\n",
      "Val: 0.9315 MAE: 0.7349 RMSE: 0.9651\n",
      "Epoch 65 Step 29106: Train 0.3689 Reg: 0.4301\n",
      "Test: 0.3747 MAE: 0.4710 RMSE: 0.6121\n",
      "Val: 0.9322 MAE: 0.7349 RMSE: 0.9655\n",
      "Epoch 66 Step 29547: Train 0.3683 Reg: 0.4288\n",
      "Test: 0.3743 MAE: 0.4705 RMSE: 0.6118\n",
      "Val: 0.9339 MAE: 0.7355 RMSE: 0.9664\n",
      "Epoch 67 Step 29988: Train 0.3676 Reg: 0.4277\n",
      "Test: 0.3736 MAE: 0.4711 RMSE: 0.6113\n",
      "Val: 0.9362 MAE: 0.7366 RMSE: 0.9676\n",
      "Epoch 68 Step 30429: Train 0.3671 Reg: 0.4265\n",
      "Test: 0.3740 MAE: 0.4702 RMSE: 0.6115\n",
      "Val: 0.9364 MAE: 0.7363 RMSE: 0.9677\n",
      "Epoch 69 Step 30870: Train 0.3665 Reg: 0.4254\n",
      "Test: 0.3742 MAE: 0.4701 RMSE: 0.6117\n",
      "Val: 0.9373 MAE: 0.7366 RMSE: 0.9681\n",
      "Epoch 70 Step 31311: Train 0.3660 Reg: 0.4243\n",
      "Test: 0.3738 MAE: 0.4694 RMSE: 0.6114\n",
      "Val: 0.9385 MAE: 0.7368 RMSE: 0.9687\n",
      "Epoch 71 Step 31752: Train 0.3655 Reg: 0.4233\n",
      "Test: 0.3739 MAE: 0.4702 RMSE: 0.6115\n",
      "Val: 0.9392 MAE: 0.7373 RMSE: 0.9691\n",
      "Epoch 72 Step 32193: Train 0.3650 Reg: 0.4224\n",
      "Test: 0.3734 MAE: 0.4706 RMSE: 0.6111\n",
      "Val: 0.9403 MAE: 0.7379 RMSE: 0.9697\n",
      "Epoch 73 Step 32634: Train 0.3646 Reg: 0.4215\n",
      "Test: 0.3736 MAE: 0.4701 RMSE: 0.6112\n",
      "Val: 0.9414 MAE: 0.7381 RMSE: 0.9702\n",
      "Epoch 74 Step 33075: Train 0.3641 Reg: 0.4206\n",
      "Test: 0.3733 MAE: 0.4695 RMSE: 0.6110\n",
      "Val: 0.9419 MAE: 0.7382 RMSE: 0.9705\n",
      "Epoch 75 Step 33516: Train 0.3637 Reg: 0.4198\n",
      "Test: 0.3730 MAE: 0.4699 RMSE: 0.6108\n",
      "Val: 0.9436 MAE: 0.7390 RMSE: 0.9714\n",
      "Epoch 76 Step 33957: Train 0.3634 Reg: 0.4190\n",
      "Test: 0.3730 MAE: 0.4692 RMSE: 0.6107\n",
      "Val: 0.9436 MAE: 0.7388 RMSE: 0.9714\n",
      "Epoch 77 Step 34398: Train 0.3630 Reg: 0.4182\n",
      "Test: 0.3737 MAE: 0.4681 RMSE: 0.6113\n",
      "Val: 0.9438 MAE: 0.7383 RMSE: 0.9715\n",
      "Epoch 78 Step 34839: Train 0.3626 Reg: 0.4175\n",
      "Test: 0.3729 MAE: 0.4694 RMSE: 0.6106\n",
      "Val: 0.9451 MAE: 0.7393 RMSE: 0.9722\n",
      "Epoch 79 Step 35280: Train 0.3623 Reg: 0.4168\n",
      "Test: 0.3731 MAE: 0.4689 RMSE: 0.6108\n",
      "Val: 0.9455 MAE: 0.7393 RMSE: 0.9724\n",
      "Epoch 80 Step 35721: Train 0.3620 Reg: 0.4162\n",
      "Test: 0.3728 MAE: 0.4697 RMSE: 0.6106\n",
      "Val: 0.9467 MAE: 0.7400 RMSE: 0.9730\n",
      "Epoch 81 Step 36162: Train 0.3617 Reg: 0.4155\n",
      "Test: 0.3728 MAE: 0.4689 RMSE: 0.6106\n",
      "Val: 0.9467 MAE: 0.7398 RMSE: 0.9730\n",
      "Epoch 82 Step 36603: Train 0.3613 Reg: 0.4149\n",
      "Test: 0.3728 MAE: 0.4684 RMSE: 0.6105\n",
      "Val: 0.9469 MAE: 0.7397 RMSE: 0.9731\n",
      "Epoch 83 Step 37044: Train 0.3611 Reg: 0.4144\n",
      "Test: 0.3727 MAE: 0.4688 RMSE: 0.6105\n",
      "Val: 0.9479 MAE: 0.7401 RMSE: 0.9736\n",
      "Epoch 84 Step 37485: Train 0.3608 Reg: 0.4138\n",
      "Test: 0.3730 MAE: 0.4682 RMSE: 0.6107\n",
      "Val: 0.9481 MAE: 0.7400 RMSE: 0.9737\n",
      "Epoch 85 Step 37926: Train 0.3606 Reg: 0.4133\n",
      "Test: 0.3727 MAE: 0.4683 RMSE: 0.6105\n",
      "Val: 0.9487 MAE: 0.7403 RMSE: 0.9740\n",
      "Epoch 86 Step 38367: Train 0.3603 Reg: 0.4129\n",
      "Test: 0.3727 MAE: 0.4680 RMSE: 0.6105\n",
      "Val: 0.9491 MAE: 0.7404 RMSE: 0.9742\n",
      "Epoch 87 Step 38808: Train 0.3601 Reg: 0.4124\n",
      "Test: 0.3728 MAE: 0.4678 RMSE: 0.6106\n",
      "Val: 0.9494 MAE: 0.7404 RMSE: 0.9744\n",
      "Epoch 88 Step 39249: Train 0.3598 Reg: 0.4119\n",
      "Test: 0.3723 MAE: 0.4684 RMSE: 0.6102\n",
      "Val: 0.9503 MAE: 0.7409 RMSE: 0.9748\n",
      "Epoch 89 Step 39690: Train 0.3596 Reg: 0.4115\n",
      "Test: 0.3724 MAE: 0.4682 RMSE: 0.6103\n",
      "Val: 0.9505 MAE: 0.7409 RMSE: 0.9749\n",
      "Epoch 90 Step 40131: Train 0.3594 Reg: 0.4111\n",
      "Test: 0.3724 MAE: 0.4682 RMSE: 0.6103\n",
      "Val: 0.9509 MAE: 0.7411 RMSE: 0.9751\n",
      "Epoch 91 Step 40572: Train 0.3592 Reg: 0.4108\n",
      "Test: 0.3722 MAE: 0.4682 RMSE: 0.6101\n",
      "Val: 0.9513 MAE: 0.7412 RMSE: 0.9753\n",
      "Epoch 92 Step 41013: Train 0.3591 Reg: 0.4104\n",
      "Test: 0.3722 MAE: 0.4681 RMSE: 0.6101\n",
      "Val: 0.9515 MAE: 0.7413 RMSE: 0.9754\n",
      "Epoch 93 Step 41454: Train 0.3589 Reg: 0.4100\n",
      "Test: 0.3724 MAE: 0.4678 RMSE: 0.6102\n",
      "Val: 0.9517 MAE: 0.7412 RMSE: 0.9756\n",
      "Epoch 94 Step 41895: Train 0.3587 Reg: 0.4097\n",
      "Test: 0.3724 MAE: 0.4675 RMSE: 0.6103\n",
      "Val: 0.9519 MAE: 0.7412 RMSE: 0.9757\n",
      "Epoch 95 Step 42336: Train 0.3586 Reg: 0.4094\n",
      "Test: 0.3721 MAE: 0.4680 RMSE: 0.6100\n",
      "Val: 0.9526 MAE: 0.7417 RMSE: 0.9760\n",
      "Epoch 96 Step 42777: Train 0.3584 Reg: 0.4091\n",
      "Test: 0.3721 MAE: 0.4682 RMSE: 0.6100\n",
      "Val: 0.9530 MAE: 0.7419 RMSE: 0.9762\n",
      "Epoch 97 Step 43218: Train 0.3583 Reg: 0.4088\n",
      "Test: 0.3720 MAE: 0.4681 RMSE: 0.6099\n",
      "Val: 0.9532 MAE: 0.7419 RMSE: 0.9763\n",
      "Epoch 98 Step 43659: Train 0.3581 Reg: 0.4086\n",
      "Test: 0.3721 MAE: 0.4677 RMSE: 0.6100\n",
      "Val: 0.9532 MAE: 0.7418 RMSE: 0.9763\n",
      "Epoch 99 Step 44100: Train 0.3580 Reg: 0.4083\n",
      "Test: 0.3722 MAE: 0.4676 RMSE: 0.6101\n",
      "Val: 0.9533 MAE: 0.7418 RMSE: 0.9764\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 474791/520586\n",
      "test set size: support/query 1208/4832\n",
      "Epoch 0: TrainLoss 0.8951 RecLoss: 0.0000 (left: 2:52:46)\n",
      "TestLoss: 0.9403 MAE: 0.7658 RMSE: 0.9697\n",
      "ValLoss: 0.8556 MAE: 0.7312 RMSE: 0.9250\n",
      "Epoch 1: TrainLoss 0.8578 RecLoss: 0.0000 (left: 2:54:51)\n",
      "TestLoss: 0.9386 MAE: 0.7611 RMSE: 0.9688\n",
      "ValLoss: 0.8540 MAE: 0.7289 RMSE: 0.9241\n",
      "Epoch 2: TrainLoss 0.8581 RecLoss: 0.0000 (left: 2:51:42)\n",
      "TestLoss: 0.9349 MAE: 0.7608 RMSE: 0.9669\n",
      "ValLoss: 0.8521 MAE: 0.7291 RMSE: 0.9231\n",
      "Epoch 3: TrainLoss 0.8579 RecLoss: 0.0000 (left: 2:50:11)\n",
      "TestLoss: 0.9436 MAE: 0.7596 RMSE: 0.9714\n",
      "ValLoss: 0.8586 MAE: 0.7289 RMSE: 0.9266\n",
      "Epoch 4: TrainLoss 0.8563 RecLoss: 0.0000 (left: 2:56:15)\n",
      "TestLoss: 0.9467 MAE: 0.7600 RMSE: 0.9730\n",
      "ValLoss: 0.8590 MAE: 0.7281 RMSE: 0.9268\n",
      "Epoch 5: TrainLoss 0.8559 RecLoss: 0.0000 (left: 3:02:58)\n",
      "TestLoss: 0.9377 MAE: 0.7642 RMSE: 0.9683\n",
      "ValLoss: 0.8527 MAE: 0.7314 RMSE: 0.9234\n",
      "Epoch 6: TrainLoss 0.8547 RecLoss: 0.0000 (left: 3:03:03)\n",
      "TestLoss: 0.9346 MAE: 0.7638 RMSE: 0.9668\n",
      "ValLoss: 0.8512 MAE: 0.7319 RMSE: 0.9226\n",
      "Epoch 7: TrainLoss 0.8552 RecLoss: 0.0000 (left: 2:58:43)\n",
      "TestLoss: 0.9370 MAE: 0.7680 RMSE: 0.9680\n",
      "ValLoss: 0.8520 MAE: 0.7348 RMSE: 0.9230\n",
      "Epoch 8: TrainLoss 0.8533 RecLoss: 0.0000 (left: 2:54:42)\n",
      "TestLoss: 0.9423 MAE: 0.7592 RMSE: 0.9707\n",
      "ValLoss: 0.8543 MAE: 0.7270 RMSE: 0.9243\n",
      "Epoch 9: TrainLoss 0.8530 RecLoss: 0.0000 (left: 2:52:29)\n",
      "TestLoss: 0.9374 MAE: 0.7671 RMSE: 0.9682\n",
      "ValLoss: 0.8507 MAE: 0.7329 RMSE: 0.9223\n",
      "Epoch 10: TrainLoss 0.8537 RecLoss: 0.0000 (left: 2:49:42)\n",
      "TestLoss: 0.9377 MAE: 0.7678 RMSE: 0.9684\n",
      "ValLoss: 0.8522 MAE: 0.7337 RMSE: 0.9231\n",
      "Epoch 11: TrainLoss 0.8525 RecLoss: 0.0000 (left: 2:46:48)\n",
      "TestLoss: 0.9395 MAE: 0.7589 RMSE: 0.9693\n",
      "ValLoss: 0.8528 MAE: 0.7274 RMSE: 0.9234\n",
      "Epoch 12: TrainLoss 0.8526 RecLoss: 0.0000 (left: 2:44:05)\n",
      "TestLoss: 0.9361 MAE: 0.7652 RMSE: 0.9675\n",
      "ValLoss: 0.8503 MAE: 0.7322 RMSE: 0.9221\n",
      "Epoch 13: TrainLoss 0.8515 RecLoss: 0.0000 (left: 2:41:33)\n",
      "TestLoss: 0.9385 MAE: 0.7688 RMSE: 0.9688\n",
      "ValLoss: 0.8504 MAE: 0.7339 RMSE: 0.9222\n",
      "Epoch 14: TrainLoss 0.8512 RecLoss: 0.0000 (left: 2:39:06)\n",
      "TestLoss: 0.9390 MAE: 0.7688 RMSE: 0.9690\n",
      "ValLoss: 0.8502 MAE: 0.7342 RMSE: 0.9221\n",
      "Epoch 15: TrainLoss 0.8510 RecLoss: 0.0000 (left: 2:36:12)\n",
      "TestLoss: 0.9389 MAE: 0.7678 RMSE: 0.9690\n",
      "ValLoss: 0.8506 MAE: 0.7332 RMSE: 0.9223\n",
      "Epoch 16: TrainLoss 0.8506 RecLoss: 0.0000 (left: 2:33:43)\n",
      "TestLoss: 0.9359 MAE: 0.7608 RMSE: 0.9674\n",
      "ValLoss: 0.8479 MAE: 0.7279 RMSE: 0.9208\n",
      "Epoch 17: TrainLoss 0.8512 RecLoss: 0.0000 (left: 2:32:02)\n",
      "TestLoss: 0.9374 MAE: 0.7604 RMSE: 0.9682\n",
      "ValLoss: 0.8488 MAE: 0.7285 RMSE: 0.9213\n",
      "Epoch 18: TrainLoss 0.8500 RecLoss: 0.0000 (left: 2:31:19)\n",
      "TestLoss: 0.9380 MAE: 0.7601 RMSE: 0.9685\n",
      "ValLoss: 0.8477 MAE: 0.7273 RMSE: 0.9207\n",
      "Epoch 19: TrainLoss 0.8501 RecLoss: 0.0000 (left: 2:30:23)\n",
      "TestLoss: 0.9389 MAE: 0.7581 RMSE: 0.9690\n",
      "ValLoss: 0.8488 MAE: 0.7255 RMSE: 0.9213\n",
      "Epoch 20: TrainLoss 0.8492 RecLoss: 0.0000 (left: 2:29:34)\n",
      "TestLoss: 0.9375 MAE: 0.7592 RMSE: 0.9682\n",
      "ValLoss: 0.8474 MAE: 0.7264 RMSE: 0.9206\n",
      "Epoch 21: TrainLoss 0.8488 RecLoss: 0.0000 (left: 2:28:43)\n",
      "TestLoss: 0.9353 MAE: 0.7641 RMSE: 0.9671\n",
      "ValLoss: 0.8484 MAE: 0.7313 RMSE: 0.9211\n",
      "Epoch 22: TrainLoss 0.8487 RecLoss: 0.0000 (left: 2:29:01)\n",
      "TestLoss: 0.9364 MAE: 0.7635 RMSE: 0.9677\n",
      "ValLoss: 0.8462 MAE: 0.7288 RMSE: 0.9199\n",
      "Epoch 23: TrainLoss 0.8486 RecLoss: 0.0000 (left: 2:27:42)\n",
      "TestLoss: 0.9361 MAE: 0.7638 RMSE: 0.9675\n",
      "ValLoss: 0.8467 MAE: 0.7299 RMSE: 0.9202\n",
      "Epoch 24: TrainLoss 0.8483 RecLoss: 0.0000 (left: 2:26:17)\n",
      "TestLoss: 0.9356 MAE: 0.7624 RMSE: 0.9673\n",
      "ValLoss: 0.8473 MAE: 0.7286 RMSE: 0.9205\n",
      "Epoch 25: TrainLoss 0.8482 RecLoss: 0.0000 (left: 2:24:55)\n",
      "TestLoss: 0.9349 MAE: 0.7618 RMSE: 0.9669\n",
      "ValLoss: 0.8474 MAE: 0.7290 RMSE: 0.9205\n",
      "Epoch 26: TrainLoss 0.8476 RecLoss: 0.0000 (left: 2:23:24)\n",
      "TestLoss: 0.9359 MAE: 0.7616 RMSE: 0.9674\n",
      "ValLoss: 0.8457 MAE: 0.7279 RMSE: 0.9196\n",
      "Epoch 27: TrainLoss 0.8471 RecLoss: 0.0000 (left: 2:21:54)\n",
      "TestLoss: 0.9381 MAE: 0.7638 RMSE: 0.9685\n",
      "ValLoss: 0.8454 MAE: 0.7289 RMSE: 0.9194\n",
      "Epoch 28: TrainLoss 0.8473 RecLoss: 0.0000 (left: 2:20:21)\n",
      "TestLoss: 0.9352 MAE: 0.7622 RMSE: 0.9670\n",
      "ValLoss: 0.8463 MAE: 0.7288 RMSE: 0.9200\n",
      "Epoch 29: TrainLoss 0.8465 RecLoss: 0.0000 (left: 2:18:44)\n",
      "TestLoss: 0.9403 MAE: 0.7588 RMSE: 0.9697\n",
      "ValLoss: 0.8476 MAE: 0.7258 RMSE: 0.9206\n",
      "Epoch 30: TrainLoss 0.8472 RecLoss: 0.0000 (left: 2:17:06)\n",
      "TestLoss: 0.9329 MAE: 0.7596 RMSE: 0.9659\n",
      "ValLoss: 0.8465 MAE: 0.7270 RMSE: 0.9201\n",
      "Epoch 31: TrainLoss 0.8462 RecLoss: 0.0000 (left: 2:15:27)\n",
      "TestLoss: 0.9357 MAE: 0.7605 RMSE: 0.9673\n",
      "ValLoss: 0.8461 MAE: 0.7270 RMSE: 0.9198\n",
      "Epoch 32: TrainLoss 0.8463 RecLoss: 0.0000 (left: 2:13:58)\n",
      "TestLoss: 0.9399 MAE: 0.7578 RMSE: 0.9695\n",
      "ValLoss: 0.8485 MAE: 0.7250 RMSE: 0.9212\n",
      "Epoch 33: TrainLoss 0.8460 RecLoss: 0.0000 (left: 2:12:26)\n",
      "TestLoss: 0.9370 MAE: 0.7660 RMSE: 0.9680\n",
      "ValLoss: 0.8465 MAE: 0.7317 RMSE: 0.9201\n",
      "Epoch 34: TrainLoss 0.8458 RecLoss: 0.0000 (left: 2:10:57)\n",
      "TestLoss: 0.9361 MAE: 0.7590 RMSE: 0.9675\n",
      "ValLoss: 0.8457 MAE: 0.7258 RMSE: 0.9196\n",
      "Epoch 35: TrainLoss 0.8460 RecLoss: 0.0000 (left: 2:09:17)\n",
      "TestLoss: 0.9363 MAE: 0.7635 RMSE: 0.9676\n",
      "ValLoss: 0.8469 MAE: 0.7301 RMSE: 0.9203\n",
      "Epoch 36: TrainLoss 0.8453 RecLoss: 0.0000 (left: 2:07:35)\n",
      "TestLoss: 0.9366 MAE: 0.7601 RMSE: 0.9678\n",
      "ValLoss: 0.8463 MAE: 0.7266 RMSE: 0.9199\n",
      "Epoch 37: TrainLoss 0.8458 RecLoss: 0.0000 (left: 2:06:11)\n",
      "TestLoss: 0.9376 MAE: 0.7578 RMSE: 0.9683\n",
      "ValLoss: 0.8451 MAE: 0.7243 RMSE: 0.9193\n",
      "Epoch 38: TrainLoss 0.8452 RecLoss: 0.0000 (left: 2:04:44)\n",
      "TestLoss: 0.9367 MAE: 0.7630 RMSE: 0.9678\n",
      "ValLoss: 0.8450 MAE: 0.7287 RMSE: 0.9192\n",
      "Epoch 39: TrainLoss 0.8449 RecLoss: 0.0000 (left: 2:03:11)\n",
      "TestLoss: 0.9382 MAE: 0.7625 RMSE: 0.9686\n",
      "ValLoss: 0.8471 MAE: 0.7274 RMSE: 0.9204\n",
      "Epoch 40: TrainLoss 0.8449 RecLoss: 0.0000 (left: 2:01:34)\n",
      "TestLoss: 0.9356 MAE: 0.7621 RMSE: 0.9673\n",
      "ValLoss: 0.8447 MAE: 0.7281 RMSE: 0.9191\n",
      "Epoch 41: TrainLoss 0.8446 RecLoss: 0.0000 (left: 1:59:57)\n",
      "TestLoss: 0.9368 MAE: 0.7606 RMSE: 0.9679\n",
      "ValLoss: 0.8451 MAE: 0.7274 RMSE: 0.9193\n",
      "Epoch 42: TrainLoss 0.8445 RecLoss: 0.0000 (left: 1:58:16)\n",
      "TestLoss: 0.9348 MAE: 0.7642 RMSE: 0.9669\n",
      "ValLoss: 0.8453 MAE: 0.7296 RMSE: 0.9194\n",
      "Epoch 43: TrainLoss 0.8442 RecLoss: 0.0000 (left: 1:56:31)\n",
      "TestLoss: 0.9351 MAE: 0.7600 RMSE: 0.9670\n",
      "ValLoss: 0.8444 MAE: 0.7262 RMSE: 0.9189\n",
      "Epoch 44: TrainLoss 0.8444 RecLoss: 0.0000 (left: 1:54:47)\n",
      "TestLoss: 0.9369 MAE: 0.7597 RMSE: 0.9680\n",
      "ValLoss: 0.8451 MAE: 0.7247 RMSE: 0.9193\n",
      "Epoch 45: TrainLoss 0.8438 RecLoss: 0.0000 (left: 1:52:52)\n",
      "TestLoss: 0.9363 MAE: 0.7646 RMSE: 0.9676\n",
      "ValLoss: 0.8443 MAE: 0.7290 RMSE: 0.9189\n",
      "Epoch 46: TrainLoss 0.8438 RecLoss: 0.0000 (left: 1:51:06)\n",
      "TestLoss: 0.9340 MAE: 0.7589 RMSE: 0.9664\n",
      "ValLoss: 0.8444 MAE: 0.7259 RMSE: 0.9189\n",
      "Epoch 47: TrainLoss 0.8433 RecLoss: 0.0000 (left: 1:49:22)\n",
      "TestLoss: 0.9358 MAE: 0.7617 RMSE: 0.9674\n",
      "ValLoss: 0.8442 MAE: 0.7282 RMSE: 0.9188\n",
      "Epoch 48: TrainLoss 0.8436 RecLoss: 0.0000 (left: 1:47:16)\n",
      "TestLoss: 0.9327 MAE: 0.7607 RMSE: 0.9658\n",
      "ValLoss: 0.8450 MAE: 0.7274 RMSE: 0.9193\n",
      "Epoch 49: TrainLoss 0.8435 RecLoss: 0.0000 (left: 1:45:05)\n",
      "TestLoss: 0.9318 MAE: 0.7579 RMSE: 0.9653\n",
      "ValLoss: 0.8441 MAE: 0.7252 RMSE: 0.9187\n",
      "Epoch 50: TrainLoss 0.8435 RecLoss: 0.0000 (left: 1:42:53)\n",
      "TestLoss: 0.9346 MAE: 0.7606 RMSE: 0.9667\n",
      "ValLoss: 0.8445 MAE: 0.7268 RMSE: 0.9190\n",
      "Epoch 51: TrainLoss 0.8430 RecLoss: 0.0000 (left: 1:40:42)\n",
      "TestLoss: 0.9331 MAE: 0.7598 RMSE: 0.9660\n",
      "ValLoss: 0.8450 MAE: 0.7267 RMSE: 0.9192\n",
      "Epoch 52: TrainLoss 0.8430 RecLoss: 0.0000 (left: 1:38:40)\n",
      "TestLoss: 0.9350 MAE: 0.7616 RMSE: 0.9669\n",
      "ValLoss: 0.8448 MAE: 0.7275 RMSE: 0.9191\n",
      "Epoch 53: TrainLoss 0.8426 RecLoss: 0.0000 (left: 1:37:06)\n",
      "TestLoss: 0.9367 MAE: 0.7633 RMSE: 0.9678\n",
      "ValLoss: 0.8448 MAE: 0.7289 RMSE: 0.9191\n",
      "Epoch 54: TrainLoss 0.8428 RecLoss: 0.0000 (left: 1:35:32)\n",
      "TestLoss: 0.9319 MAE: 0.7599 RMSE: 0.9654\n",
      "ValLoss: 0.8436 MAE: 0.7267 RMSE: 0.9185\n",
      "Epoch 55: TrainLoss 0.8426 RecLoss: 0.0000 (left: 1:34:02)\n",
      "TestLoss: 0.9367 MAE: 0.7580 RMSE: 0.9678\n",
      "ValLoss: 0.8449 MAE: 0.7246 RMSE: 0.9192\n",
      "Epoch 56: TrainLoss 0.8426 RecLoss: 0.0000 (left: 1:32:18)\n",
      "TestLoss: 0.9349 MAE: 0.7584 RMSE: 0.9669\n",
      "ValLoss: 0.8435 MAE: 0.7252 RMSE: 0.9184\n",
      "Epoch 57: TrainLoss 0.8423 RecLoss: 0.0000 (left: 1:30:34)\n",
      "TestLoss: 0.9337 MAE: 0.7616 RMSE: 0.9663\n",
      "ValLoss: 0.8430 MAE: 0.7267 RMSE: 0.9181\n",
      "Epoch 58: TrainLoss 0.8421 RecLoss: 0.0000 (left: 1:28:31)\n",
      "TestLoss: 0.9367 MAE: 0.7617 RMSE: 0.9679\n",
      "ValLoss: 0.8440 MAE: 0.7267 RMSE: 0.9187\n",
      "Epoch 59: TrainLoss 0.8426 RecLoss: 0.0000 (left: 1:26:24)\n",
      "TestLoss: 0.9329 MAE: 0.7606 RMSE: 0.9659\n",
      "ValLoss: 0.8438 MAE: 0.7272 RMSE: 0.9186\n",
      "Epoch 60: TrainLoss 0.8421 RecLoss: 0.0000 (left: 1:24:19)\n",
      "TestLoss: 0.9349 MAE: 0.7573 RMSE: 0.9669\n",
      "ValLoss: 0.8455 MAE: 0.7246 RMSE: 0.9195\n",
      "Epoch 61: TrainLoss 0.8418 RecLoss: 0.0000 (left: 1:22:12)\n",
      "TestLoss: 0.9356 MAE: 0.7611 RMSE: 0.9673\n",
      "ValLoss: 0.8434 MAE: 0.7262 RMSE: 0.9184\n",
      "Epoch 62: TrainLoss 0.8420 RecLoss: 0.0000 (left: 1:20:06)\n",
      "TestLoss: 0.9410 MAE: 0.7567 RMSE: 0.9700\n",
      "ValLoss: 0.8514 MAE: 0.7243 RMSE: 0.9227\n",
      "Epoch 63: TrainLoss 0.8418 RecLoss: 0.0000 (left: 1:18:03)\n",
      "TestLoss: 0.9332 MAE: 0.7585 RMSE: 0.9660\n",
      "ValLoss: 0.8446 MAE: 0.7250 RMSE: 0.9190\n",
      "Epoch 64: TrainLoss 0.8416 RecLoss: 0.0000 (left: 1:16:03)\n",
      "TestLoss: 0.9360 MAE: 0.7669 RMSE: 0.9674\n",
      "ValLoss: 0.8459 MAE: 0.7319 RMSE: 0.9197\n",
      "Epoch 65: TrainLoss 0.8418 RecLoss: 0.0000 (left: 1:13:58)\n",
      "TestLoss: 0.9339 MAE: 0.7607 RMSE: 0.9664\n",
      "ValLoss: 0.8433 MAE: 0.7266 RMSE: 0.9183\n",
      "Epoch 66: TrainLoss 0.8412 RecLoss: 0.0000 (left: 1:11:52)\n",
      "TestLoss: 0.9343 MAE: 0.7635 RMSE: 0.9666\n",
      "ValLoss: 0.8438 MAE: 0.7281 RMSE: 0.9186\n",
      "Epoch 67: TrainLoss 0.8408 RecLoss: 0.0000 (left: 1:09:44)\n",
      "TestLoss: 0.9340 MAE: 0.7601 RMSE: 0.9665\n",
      "ValLoss: 0.8441 MAE: 0.7259 RMSE: 0.9188\n",
      "Epoch 68: TrainLoss 0.8411 RecLoss: 0.0000 (left: 1:07:36)\n",
      "TestLoss: 0.9368 MAE: 0.7624 RMSE: 0.9679\n",
      "ValLoss: 0.8436 MAE: 0.7281 RMSE: 0.9185\n",
      "Epoch 69: TrainLoss 0.8408 RecLoss: 0.0000 (left: 1:05:30)\n",
      "TestLoss: 0.9349 MAE: 0.7572 RMSE: 0.9669\n",
      "ValLoss: 0.8452 MAE: 0.7243 RMSE: 0.9194\n",
      "Epoch 70: TrainLoss 0.8406 RecLoss: 0.0000 (left: 1:03:22)\n",
      "TestLoss: 0.9330 MAE: 0.7609 RMSE: 0.9659\n",
      "ValLoss: 0.8435 MAE: 0.7271 RMSE: 0.9184\n",
      "Epoch 71: TrainLoss 0.8408 RecLoss: 0.0000 (left: 1:01:17)\n",
      "TestLoss: 0.9386 MAE: 0.7687 RMSE: 0.9688\n",
      "ValLoss: 0.8471 MAE: 0.7331 RMSE: 0.9204\n",
      "Epoch 72: TrainLoss 0.8408 RecLoss: 0.0000 (left: 0:59:14)\n",
      "TestLoss: 0.9352 MAE: 0.7607 RMSE: 0.9671\n",
      "ValLoss: 0.8447 MAE: 0.7264 RMSE: 0.9191\n",
      "Epoch 73: TrainLoss 0.8404 RecLoss: 0.0000 (left: 0:57:10)\n",
      "TestLoss: 0.9352 MAE: 0.7573 RMSE: 0.9671\n",
      "ValLoss: 0.8467 MAE: 0.7242 RMSE: 0.9202\n",
      "Epoch 74: TrainLoss 0.8404 RecLoss: 0.0000 (left: 0:55:17)\n",
      "TestLoss: 0.9355 MAE: 0.7647 RMSE: 0.9672\n",
      "ValLoss: 0.8448 MAE: 0.7295 RMSE: 0.9192\n",
      "Epoch 75: TrainLoss 0.8402 RecLoss: 0.0000 (left: 0:53:19)\n",
      "TestLoss: 0.9350 MAE: 0.7572 RMSE: 0.9669\n",
      "ValLoss: 0.8448 MAE: 0.7238 RMSE: 0.9191\n",
      "Epoch 76: TrainLoss 0.8401 RecLoss: 0.0000 (left: 0:51:22)\n",
      "TestLoss: 0.9331 MAE: 0.7589 RMSE: 0.9660\n",
      "ValLoss: 0.8432 MAE: 0.7254 RMSE: 0.9183\n",
      "Epoch 77: TrainLoss 0.8402 RecLoss: 0.0000 (left: 0:49:22)\n",
      "TestLoss: 0.9326 MAE: 0.7605 RMSE: 0.9657\n",
      "ValLoss: 0.8432 MAE: 0.7269 RMSE: 0.9183\n",
      "Epoch 78: TrainLoss 0.8399 RecLoss: 0.0000 (left: 0:47:22)\n",
      "TestLoss: 0.9324 MAE: 0.7592 RMSE: 0.9656\n",
      "ValLoss: 0.8438 MAE: 0.7247 RMSE: 0.9186\n",
      "Epoch 79: TrainLoss 0.8401 RecLoss: 0.0000 (left: 0:45:22)\n",
      "TestLoss: 0.9353 MAE: 0.7579 RMSE: 0.9671\n",
      "ValLoss: 0.8453 MAE: 0.7242 RMSE: 0.9194\n",
      "Epoch 80: TrainLoss 0.8397 RecLoss: 0.0000 (left: 0:43:14)\n",
      "TestLoss: 0.9348 MAE: 0.7604 RMSE: 0.9668\n",
      "ValLoss: 0.8436 MAE: 0.7264 RMSE: 0.9185\n",
      "Epoch 81: TrainLoss 0.8396 RecLoss: 0.0000 (left: 0:41:04)\n",
      "TestLoss: 0.9334 MAE: 0.7584 RMSE: 0.9661\n",
      "ValLoss: 0.8436 MAE: 0.7248 RMSE: 0.9185\n",
      "Epoch 82: TrainLoss 0.8398 RecLoss: 0.0000 (left: 0:38:53)\n",
      "TestLoss: 0.9338 MAE: 0.7633 RMSE: 0.9663\n",
      "ValLoss: 0.8441 MAE: 0.7287 RMSE: 0.9187\n",
      "Epoch 83: TrainLoss 0.8394 RecLoss: 0.0000 (left: 0:36:44)\n",
      "TestLoss: 0.9323 MAE: 0.7592 RMSE: 0.9655\n",
      "ValLoss: 0.8428 MAE: 0.7252 RMSE: 0.9180\n",
      "Epoch 84: TrainLoss 0.8394 RecLoss: 0.0000 (left: 0:34:34)\n",
      "TestLoss: 0.9365 MAE: 0.7558 RMSE: 0.9677\n",
      "ValLoss: 0.8465 MAE: 0.7233 RMSE: 0.9201\n",
      "Epoch 85: TrainLoss 0.8395 RecLoss: 0.0000 (left: 0:32:27)\n",
      "TestLoss: 0.9357 MAE: 0.7642 RMSE: 0.9673\n",
      "ValLoss: 0.8442 MAE: 0.7296 RMSE: 0.9188\n",
      "Epoch 86: TrainLoss 0.8393 RecLoss: 0.0000 (left: 0:30:20)\n",
      "TestLoss: 0.9353 MAE: 0.7624 RMSE: 0.9671\n",
      "ValLoss: 0.8436 MAE: 0.7280 RMSE: 0.9185\n",
      "Epoch 87: TrainLoss 0.8391 RecLoss: 0.0000 (left: 0:28:10)\n",
      "TestLoss: 0.9338 MAE: 0.7579 RMSE: 0.9663\n",
      "ValLoss: 0.8464 MAE: 0.7257 RMSE: 0.9200\n",
      "Epoch 88: TrainLoss 0.8394 RecLoss: 0.0000 (left: 0:26:02)\n",
      "TestLoss: 0.9348 MAE: 0.7577 RMSE: 0.9668\n",
      "ValLoss: 0.8440 MAE: 0.7249 RMSE: 0.9187\n",
      "Epoch 89: TrainLoss 0.8389 RecLoss: 0.0000 (left: 0:23:53)\n",
      "TestLoss: 0.9346 MAE: 0.7595 RMSE: 0.9667\n",
      "ValLoss: 0.8434 MAE: 0.7249 RMSE: 0.9184\n",
      "Epoch 90: TrainLoss 0.8389 RecLoss: 0.0000 (left: 0:21:43)\n",
      "TestLoss: 0.9342 MAE: 0.7605 RMSE: 0.9665\n",
      "ValLoss: 0.8425 MAE: 0.7259 RMSE: 0.9179\n",
      "Epoch 91: TrainLoss 0.8390 RecLoss: 0.0000 (left: 0:19:33)\n",
      "TestLoss: 0.9352 MAE: 0.7593 RMSE: 0.9670\n",
      "ValLoss: 0.8433 MAE: 0.7252 RMSE: 0.9183\n",
      "Epoch 92: TrainLoss 0.8386 RecLoss: 0.0000 (left: 0:17:23)\n",
      "TestLoss: 0.9329 MAE: 0.7593 RMSE: 0.9659\n",
      "ValLoss: 0.8428 MAE: 0.7261 RMSE: 0.9180\n",
      "Epoch 93: TrainLoss 0.8387 RecLoss: 0.0000 (left: 0:15:12)\n",
      "TestLoss: 0.9347 MAE: 0.7575 RMSE: 0.9668\n",
      "ValLoss: 0.8450 MAE: 0.7246 RMSE: 0.9192\n",
      "Epoch 94: TrainLoss 0.8383 RecLoss: 0.0000 (left: 0:13:01)\n",
      "TestLoss: 0.9361 MAE: 0.7574 RMSE: 0.9675\n",
      "ValLoss: 0.8442 MAE: 0.7238 RMSE: 0.9188\n",
      "Epoch 95: TrainLoss 0.8385 RecLoss: 0.0000 (left: 0:10:51)\n",
      "TestLoss: 0.9335 MAE: 0.7620 RMSE: 0.9662\n",
      "ValLoss: 0.8433 MAE: 0.7278 RMSE: 0.9183\n",
      "Epoch 96: TrainLoss 0.8386 RecLoss: 0.0000 (left: 0:08:41)\n",
      "TestLoss: 0.9334 MAE: 0.7615 RMSE: 0.9661\n",
      "ValLoss: 0.8431 MAE: 0.7272 RMSE: 0.9182\n",
      "Epoch 97: TrainLoss 0.8382 RecLoss: 0.0000 (left: 0:06:30)\n",
      "TestLoss: 0.9333 MAE: 0.7607 RMSE: 0.9661\n",
      "ValLoss: 0.8427 MAE: 0.7265 RMSE: 0.9180\n",
      "Epoch 98: TrainLoss 0.8382 RecLoss: 0.0000 (left: 0:04:20)\n",
      "TestLoss: 0.9351 MAE: 0.7639 RMSE: 0.9670\n",
      "ValLoss: 0.8440 MAE: 0.7289 RMSE: 0.9187\n",
      "Epoch 99: TrainLoss 0.8382 RecLoss: 0.0000 (left: 0:02:10)\n",
      "TestLoss: 0.9345 MAE: 0.7627 RMSE: 0.9667\n",
      "ValLoss: 0.8433 MAE: 0.7276 RMSE: 0.9183\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "# !python test-1m.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 474791/520586\n",
      "test set size: support/query 1208/4832\n",
      "CORE IS SELECTED:\n",
      "SIZE OF MODEL: torch.Size([6040, 32])\n",
      "SIZE OF MODEL: torch.Size([3706, 32])\n",
      "torch.Size([6040, 3706])\n",
      "MATRIX IS: tensor([[-4.7781e-06, -1.4933e-07,  4.3704e-07,  ...,  1.0380e-06,\n",
      "         -5.8563e-08,  3.3805e-06],\n",
      "        [ 7.1967e-07, -6.1768e-07,  6.8633e-07,  ..., -1.0391e-07,\n",
      "          2.4735e-07,  1.3059e-06],\n",
      "        [ 1.6817e-06, -4.0636e-07, -8.1827e-07,  ..., -9.3848e-07,\n",
      "          7.9961e-07,  1.6096e-06],\n",
      "        ...,\n",
      "        [ 8.2051e-07, -6.3332e-07,  3.9873e-06,  ..., -5.2738e-07,\n",
      "         -1.2242e-07,  1.2278e-06],\n",
      "        [ 3.7712e-07, -3.9467e-07, -7.3393e-07,  ...,  2.1585e-07,\n",
      "          2.7295e-07, -2.1748e-07],\n",
      "        [-9.6813e-06, -1.4478e-06, -8.5960e-07,  ..., -1.2186e-07,\n",
      "         -1.4770e-06,  1.8190e-06]], device='cuda:0')\n",
      "NUMPY MATRIX: [[-4.7781068e-06 -1.4932927e-07  4.3704074e-07 ...  1.0379686e-06\n",
      "  -5.8562659e-08  3.3804699e-06]\n",
      " [ 7.1967213e-07 -6.1767662e-07  6.8633386e-07 ... -1.0390653e-07\n",
      "   2.4735462e-07  1.3058589e-06]\n",
      " [ 1.6816816e-06 -4.0635646e-07 -8.1826897e-07 ... -9.3847882e-07\n",
      "   7.9961478e-07  1.6095709e-06]\n",
      " ...\n",
      " [ 8.2050576e-07 -6.3332249e-07  3.9873016e-06 ... -5.2738153e-07\n",
      "  -1.2242153e-07  1.2278322e-06]\n",
      " [ 3.7711666e-07 -3.9466880e-07 -7.3393329e-07 ...  2.1585228e-07\n",
      "   2.7295420e-07 -2.1747816e-07]\n",
      " [-9.6813010e-06 -1.4478466e-06 -8.5959960e-07 ... -1.2185528e-07\n",
      "  -1.4770458e-06  1.8189647e-06]]\n",
      "1208\n",
      "4832\n",
      "dimension of mul: (6040, 3706)\n",
      "HEKKI\n",
      "Traceback (most recent call last):\n",
      "  File \"test-1m.py\", line 245, in <module>\n",
      "    tweakMatrix(mul)\n",
      "  File \"test-1m.py\", line 237, in tweakMatrix\n",
      "    unique_mids = pickle.load(f)\n",
      "EOFError: Ran out of input\n"
     ]
    }
   ],
   "source": [
    "!python test-1m.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
