{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we extract core-user and non core users modify the non core users and give to myncf such that its accuracy decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from scipy.sparse.linalg import svds\n",
    "import random \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as ss\n",
    "import pickle\n",
    "from sklearn.utils.extmath import randomized_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadData():\n",
    "    ml1m_dir = 'data/ratings.dat'\n",
    "    ml1m_rating = pd.read_csv(ml1m_dir, sep='::', header=None, names=['uid', 'mid', 'rating', 'timestamp'],  engine='python')\n",
    "    unique_uid = np.unique(np.array(ml1m_rating['uid'].tolist()))\n",
    "    unique_mid = np.unique(np.array(ml1m_rating['mid'].tolist()))\n",
    "    uid_dict = dict([(y,x) for x,y in enumerate(unique_uid)])\n",
    "    mid_dict = dict([(y,x) for x,y in enumerate(unique_mid)])\n",
    "    print('DICTIONARY PREPARED:')\n",
    "\n",
    "    # init user item dictionary:\n",
    "    \n",
    "    uid_list = ml1m_rating['uid'].tolist()\n",
    "    uid_list_len = len(uid_list)\n",
    "    mid_list = ml1m_rating['mid'].tolist()\n",
    "    mid_list_len = len(mid_list)\n",
    "    rating_list = ml1m_rating['rating'].tolist()\n",
    "    user_item_dict = {x:set() for x in range(len(unique_uid))}\n",
    "    item_user_dict = {x:set() for x in range(len(unique_mid))}\n",
    "    for i in range(uid_list_len):\n",
    "        uid_list[i] = uid_dict[uid_list[i]]\n",
    "        mid_list[i] = mid_dict[mid_list[i]]\n",
    "        # rating_list[i] = 1 # comment this line if you want to activate explicit ratings\n",
    "        user_item_dict[uid_list[i]].add(mid_list[i])\n",
    "        item_user_dict[mid_list[i]].add(uid_list[i])\n",
    "    tmp_df = pd.DataFrame({\"uid\":uid_list, \"mid\":mid_list, \"ratings\":rating_list})\n",
    "    # v = tmp_df.uid.value_counts()\n",
    "    # df = tmp_df[tmp_df.uid.isin(v.index[v.gt(30)])]\n",
    "### code to store less than 30 interactions:\n",
    "    # df_less_30 = tmp_df[tmp_df.uid.isin(v.index[v.le(30)])]\n",
    "    return tmp_df, len(np.unique(mid_list)), len(unique_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICTIONARY PREPARED:\n",
      "UNIQUE MIDS:  3706\n",
      "UNIQUE UIDS:  6040\n"
     ]
    }
   ],
   "source": [
    "# threshold = 30 #split the users into test and train by threshold number of interactions. if greater than threshold then all interactions of that user goes into train set.\n",
    "df, unique_mids, unique_uids = ReadData()\n",
    "# print(\"GREATER THAN 30:\\n\", df_gt_30)\n",
    "# print(\"LESS THAN 30: \\n\", df_le_30)\n",
    "# print(len(df_gt_30))\n",
    "# print(len(df_le_30))\n",
    "print(\"UNIQUE MIDS: \", unique_mids)\n",
    "print(\"UNIQUE UIDS: \", unique_uids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support_test_df = df_gt_30.groupby(\"uid\").tail(1)\n",
    "# # print(len(df_gt_30))\n",
    "# support_train_df = df_gt_30.drop(df_gt_30.groupby('uid').tail(1).index, inplace=False)\n",
    "# # print(\"#TEST INSTANCES: \" ,len(support_test_df))\n",
    "# # print(\"#TRAIN INSTANCES: \" ,len(support_train_df))\n",
    "# assert(len(df_gt_30)== len(support_test_df) + len(support_train_df))\n",
    "# # print(len(test_df))\n",
    "# # print(len(train_df))\n",
    "# query_test_df = df_le_30.groupby(\"uid\").tail(1)\n",
    "# query_train_df = df_le_30.drop(df_le_30.groupby('uid').tail(1).index, inplace=False)\n",
    "# assert(len(df_le_30)== len(query_test_df) + len(query_train_df))\n",
    "# dic_support_train_df_uid_mapping = dict([(y,x) for x,y in enumerate(np.unique(support_train_df['uid']))])\n",
    "# dic_support_train_df_uid_rmapping = dict([(x,y) for x,y in enumerate(np.unique(support_train_df['uid']))])\n",
    "# ### no need for mid mapping\n",
    "\n",
    "# uid_of_train_df = support_train_df['uid'].tolist()\n",
    "# for i in range(len(uid_of_train_df)):\n",
    "#     uid_of_train_df[i] = dic_support_train_df_uid_mapping[uid_of_train_df[i]]\n",
    "# # for index, row in train_df.iterrows():\n",
    "# #     train_df['uid'][index] = dic_train_df_uid_mapping[train_df['uid'][index]]\n",
    "# core_user_ko_input_train_df = pd.DataFrame({'uid':uid_of_train_df, 'mid':support_train_df['mid'], 'ratings':support_train_df['ratings']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ui_dic = {}    \n",
    "# for user in range(unique_uids):\n",
    "#     train_ui_dic[user] = []\n",
    "# for index,row in support_train_df.iterrows():\n",
    "#         train_ui_dic[row['uid']].append(row['mid'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- utility functions for CUR coreusers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractCoreUsers(dataframe, unique_user_len, unique_item_len, percent_core_user=0.40):\n",
    "    # print(\"# of rows in ml1m_ratings: \", len(dataframe))\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "    userItemMatrix = np.zeros(shape=(u_len, m_len))\n",
    "    # print(userItemMatrix)\n",
    "    \n",
    "    unique_uid = np.unique(np.array(dataframe['uid'].tolist()))\n",
    "    assert(u_len == len(unique_uid))\n",
    "    uid_dict = dict([(y,x) for x,y in enumerate(unique_uid)])\n",
    "    rev_uid_dict = dict([(x,y) for x,y in enumerate(unique_uid)])\n",
    "    \n",
    "    for index, row in dataframe.iterrows():\n",
    "        userItemMatrix[row['uid']][row['mid']] = row['ratings']\n",
    "        # print(row['uid'], row['mid'])\n",
    "    print(\"USER ITEM MATRIX: \\n\", userItemMatrix)\n",
    "\n",
    "    df = pd.DataFrame(userItemMatrix)\n",
    "    cosineSimilarity = cosine_similarity(df)\n",
    "    print(\"SHAPE OF COSINE MATIX:\\n \", cosineSimilarity.shape)\n",
    "\n",
    "    listToStoreTopFiftyOfEveryUser = []\n",
    "    for i in range(0, cosineSimilarity.shape[0]):\n",
    "        idx = np.argpartition(cosineSimilarity[i], -50)[-50:]\n",
    "        listToStoreTopFiftyOfEveryUser.append(idx)\n",
    "    # print(\"Top fifty list: \\n\", listToStoreTopFiftyOfEveryUser)\n",
    "    # listToStoreTopFiftyOfEveryUser = np.array(listToStoreTopFiftyOfEveryUser)\n",
    "    flatten = np.concatenate(listToStoreTopFiftyOfEveryUser)\n",
    "    listToStoreTopFiftyOfEveryUser = flatten.ravel()\n",
    "\n",
    "    # print(\"List of top 50\", listToStoreTopFiftyOfEveryUser)\n",
    "    df = pd.DataFrame(listToStoreTopFiftyOfEveryUser)\n",
    "    allUserList = df.value_counts().index.tolist()\n",
    "    # print(\"ALL USERS LIST\", allUserList)\n",
    "    allUserList = list(sum(allUserList,()))\n",
    "    # print(\"ALL USERS LIST\", allUserList)\n",
    "    twentyPercentUserList = allUserList[:int(len(allUserList)*0.2)]\n",
    "    # print(\"TWENTY PERCENT USER:\", len(twentyPercentUserList))\n",
    "    # print(\"TWENTY PERCENT USER:\", (twentyPercentUserList))\n",
    "    \n",
    "    r_ind = twentyPercentUserList\n",
    "    len_r_ind = len(r_ind)\n",
    "    new_r_ind = [rev_uid_dict[r_ind[i]] for i in range(len_r_ind)]\n",
    "    cos_coreusers = dataframe.iloc[np.where(dataframe.uid.isin(new_r_ind))]\n",
    "    # coreusers = dataframe.iloc[np.where(dataframe.uid.isin(twentyPercentUserList))]\n",
    "    # coreusers.reset_index()\n",
    "    # print(\"CORE USERS:\\n\", coreusers)\n",
    "    return cos_coreusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MID = 27277 + 1\n",
    "def select_cols(mat, k, dup=False):\n",
    "    # prob 1d array of probabilities of all columns\n",
    "    prob = mat.T.dot(mat)\n",
    "    prob = np.array(np.diagonal(prob))\n",
    "    denom = np.abs(prob).sum(axis = 0)\n",
    "    prob = prob/denom\n",
    "\n",
    "    C = np.zeros((mat.shape[0], k))\n",
    "    ind_cols = np.arange(0, prob.size)\n",
    "    c_ind = []\n",
    "    i = 0\n",
    "    while(i < k):\n",
    "        rand_sel = np.random.choice(ind_cols, 1, p=prob)\n",
    "        if rand_sel in c_ind:\n",
    "            continue\n",
    "        c_ind.append(rand_sel[0])\n",
    "        C[:, i] = mat[:, rand_sel[0]]\n",
    "        i += 1\n",
    "        # C[:, i] = C[:, i]/np.sqrt(k*prob[rand_sel[0]])\n",
    "\n",
    "    return C, c_ind\n",
    "\n",
    "def select_rows(mat, k, dup=False):\n",
    "\n",
    "    prob = mat.dot(mat.T)\n",
    "    prob = np.array(np.diagonal(prob))\n",
    "    denom = np.abs(prob).sum(axis=0)\n",
    "    prob = prob/denom\n",
    "    print(prob)\n",
    "    r = np.zeros((k, mat.shape[1]))\n",
    "    ind_rows = np.arange(0, prob.size)\n",
    "    r_ind = []\n",
    "    i = 0\n",
    "    while(i < k):\n",
    "        # print(ind_rows)\n",
    "        rand_sel = np.random.choice(ind_rows, 1, p=prob)\n",
    "        if rand_sel in r_ind:\n",
    "            continue\n",
    "        r_ind.append(rand_sel[0])\n",
    "        r[i, :] = mat[rand_sel[0], :]\n",
    "        i += 1\n",
    "        # r[i, :] = r[i, :]/np.sqrt(k*prob[rand_sel[0]])\n",
    "    r_ind = np.array(r_ind)\n",
    "    return r, r_ind\n",
    "\n",
    "# def matIntersection(mat, c_ind, r_ind):\n",
    "    \n",
    "#     W = np.zeros((len(r_ind), len(c_ind)))\n",
    "#     for i in range(len(r_ind)):\n",
    "#         W[i] = mat[r_ind[i], c_ind]\n",
    "    \n",
    "#     return W\n",
    "\n",
    "# def pseudoInverse(W):\n",
    "#     # U = WP (W+)\n",
    "\n",
    "#     # W = X.Z.YT\n",
    "#     X, Z, YT = np.linalg.svd(W)\n",
    "    \n",
    "#     # W+ = Y.Z+.XT\n",
    "#     XT = X.T\n",
    "#     Y = YT.T\n",
    "#     # Z+ = reciprocal(Z)\n",
    "#     ZP = np.reciprocal(Z)\n",
    "#     ZP = sp.spdiags(ZP, 0, ZP.size, ZP.size)\n",
    "#     ZP = ZP@ZP\n",
    "    \n",
    "#     # W+ = Y.Z+.XT\n",
    "#     WP = Y@ZP\n",
    "#     WP = WP@XT\n",
    "\n",
    "#     return WP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CUR_ExtractCoreUsers(dataframe, unique_user_len, unique_item_len, percent_core_user=0.40):\n",
    "    # print(\"# of rows in ml1m_ratings: \", len(dataframe))\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "    \n",
    "    # print(userItemMatrix)\n",
    "\n",
    "    unique_uid = np.unique(np.array(dataframe['uid'].tolist()))\n",
    "    assert(u_len == len(unique_uid))\n",
    "    # print(\"UNIQUE UID:\", unique_uid)\n",
    "    uid_dict = dict([(y,x) for x,y in enumerate(unique_uid)])\n",
    "    rev_uid_dict = dict([(x,y) for x,y in enumerate(unique_uid)])\n",
    "\n",
    "    userItemMatrix = np.zeros(shape=(u_len, m_len))\n",
    "    for index, row in dataframe.iterrows():\n",
    "        userItemMatrix[uid_dict[row['uid']]][row['mid']] = row['ratings']\n",
    "        # print(row['uid'], row['mid'])\n",
    "    print(\"USER ITEM MATRIX: \\n\", userItemMatrix)\n",
    "\n",
    "    mat = userItemMatrix\n",
    "    print(\"MAT:\", mat)\n",
    "    print(mat.shape)\n",
    "    C, c_ind = select_cols(mat, int(u_len * percent_core_user)) ## getting 20% core users\n",
    "    r, r_ind= select_rows(mat, int(u_len * percent_core_user))\n",
    "    # print(\"r\", r)\n",
    "    # print(\"r_ind len\", len(r_ind))\n",
    "\n",
    "    len_r_ind = len(r_ind)\n",
    "    new_r_ind = [rev_uid_dict[r_ind[i]] for i in range(len_r_ind)]\n",
    "    cur_coreusers = dataframe.iloc[np.where(dataframe.uid.isin(new_r_ind))]\n",
    "    # # coreusers.reset_index()\n",
    "    # # print(\"CORE USERS:\\n\", coreusers)\n",
    "    return cur_coreusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomSampling(dataframe, unique_user_len, unique_item_len, percent_core_user=0.40):\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "\n",
    "    how_much_to_sample = int(percent_core_user * u_len)\n",
    "    indices = random.sample(range(u_len), how_much_to_sample)\n",
    "    cur_coreusers = dataframe.iloc[np.where(dataframe.uid.isin(indices))]\n",
    "    return cur_coreusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class largest_leveragescores_Sampler:\n",
    "    def __init__(self, A, k, Q,N):\n",
    "        \"\"\" Create largest k-leverage scores Sampler for the matrix :math:`A` for k-low rank apparoximation.\n",
    "        :param A: \n",
    "            Matrix :math:`A`.\n",
    "        :type A: \n",
    "            array_type\n",
    "        :param Q: \n",
    "            Matrix containig the right singular vectors of :math:`A`.\n",
    "        :type Q: \n",
    "            array_type\n",
    "        :param k: \n",
    "            The order of low rank apparoximation.\n",
    "        :type k: \n",
    "            int\n",
    "        :param N: \n",
    "            The dimension of subsampling (the number of columns) of A.\n",
    "        :type N: \n",
    "            int\n",
    "        \"\"\"\n",
    "        self.A = A\n",
    "        # print(\"k is\", type(k))\n",
    "        self.Q = np.transpose(Q[0:k,:])\n",
    "        self.N = N\n",
    "        self.k = k\n",
    "        \n",
    "        self.sampling_list = []\n",
    "        self.lvs_array = self.Estimate_Leverage_Scores()\n",
    "    def Estimate_Leverage_Scores(self):\n",
    "        return 1/(self.k)*np.diag(np.dot(self.Q,self.Q.T))\n",
    "    def MultiRounds(self):\n",
    "        temp_list = list(reversed(np.argsort(self.lvs_array)))\n",
    "        sampled_indices_ = temp_list[0:self.k]\n",
    "        self.sampling_list = sampled_indices_\n",
    "        return sampled_indices_\n",
    "from scipy.sparse.linalg import svds\n",
    "def Extract_LLS(dataframe, unique_user_len, unique_item_len, percent_core_user=0.40):\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "    \n",
    "    # print(userItemMatrix)\n",
    "\n",
    "    unique_uid = np.unique(np.array(dataframe['uid'].tolist()))\n",
    "    assert(u_len == len(unique_uid))\n",
    "    # print(\"UNIQUE UID:\", unique_uid)\n",
    "    uid_dict = dict([(y,x) for x,y in enumerate(unique_uid)])\n",
    "    rev_uid_dict = dict([(x,y) for x,y in enumerate(unique_uid)])\n",
    "\n",
    "    userItemMatrix = np.zeros(shape=(u_len, m_len))\n",
    "    for index, row in dataframe.iterrows():\n",
    "        userItemMatrix[uid_dict[int(row['uid'])]][int(row['mid'])] = int(row['ratings'])\n",
    "        # print(row['uid'], row['mid'])\n",
    "    print(\"USER ITEM MATRIX: \\n\", userItemMatrix)\n",
    "    A = userItemMatrix.T\n",
    "    number_of_coreusers = int(u_len * percent_core_user)\n",
    "    print(number_of_coreusers)\n",
    "    u4, s4, Q = svds(A, k=number_of_coreusers)\n",
    "    lls = largest_leveragescores_Sampler(A, number_of_coreusers, Q, number_of_coreusers)\n",
    "    indx = lls.MultiRounds()\n",
    "    # indx = indx.\n",
    "    print(\"LENGTH OF INDEX:\", len(indx))\n",
    "    print(\"INDICES ARE:\", indx)\n",
    "    cur_coreusers = dataframe.iloc[np.where(dataframe.uid.isin(indx))]\n",
    "    # # coreusers.reset_index()\n",
    "    # # print(\"CORE USERS:\\n\", coreusers)\n",
    "    return cur_coreusers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cur decomposition from paper (https://www.pnas.org/doi/10.1073/pnas.0803205106) called optimal cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUR():\n",
    "    def __init__(self, k, eps, it=None, truncated=False):\n",
    "        self.k = k\n",
    "        print(\"K IS :\", self.k)\n",
    "        self.eps = eps\n",
    "        self.trunc = truncated \n",
    "        self.c = k * np.log(k) / eps**2 #expectation number of sampled columns\n",
    "        self.C, self.U, self.R = None, None, None #matrices of decomposition\n",
    "        self.pi_col, self.pi_row = None, None #leverage scores of corresponding columns/rows\n",
    "        self.col_indices = None\n",
    "        self.row_indices = None\n",
    "    \n",
    "    def column_select(self, A):\n",
    "        n = A.shape[1]\n",
    "        A = np.array(A.copy())\n",
    "        if self.trunc:\n",
    "            _, _, v_k = randomized_svd(A, self.k) #for very big matrices\n",
    "        else:\n",
    "            _, _, vh = np.linalg.svd(A, full_matrices=False)\n",
    "            v_k = vh[0:self.k, :]\n",
    "        \n",
    "        pi = 1 / self.k * np.sum(v_k**2, axis=0)\n",
    "        c_index = [np.random.choice(2, \n",
    "                        p=[1 - min(1, self.c * pi[i]), min(1, self.c * pi[i])]) for i in range(n)\n",
    "                  ]\n",
    "        c_index = np.nonzero(c_index)[0]\n",
    "        print(len(c_index))\n",
    "        C = A[:, c_index]\n",
    "        return C, c_index, pi\n",
    "\n",
    "    def run_CUR(self, A):\n",
    "        A = np.array(A.copy())\n",
    "        # self.C, self.col_indices, self.pi_col = self.column_select(A)\n",
    "        self.R, self.row_indices, self.pi_row = self.column_select(A.T)\n",
    "        # self.U = np.linalg.pinv(self.C) @ A @ np.linalg.pinv(self.R.T)\n",
    "        return self.row_indices\n",
    "def OPTIMAL_CUR_ExtractCoreUsers(dataframe, unique_user_len, unique_item_len):\n",
    "    # print(\"# of rows in ml1m_ratings: \", len(dataframe))\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "    userItemMatrix = np.zeros(shape=(u_len, m_len))\n",
    "    # print(userItemMatrix)\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        userItemMatrix[row['uid']][row['mid']] = row['ratings']\n",
    "        # print(row['uid'], row['mid'])\n",
    "    print(\"USER ITEM MATRIX: \\n\", userItemMatrix)\n",
    "\n",
    "    mat = userItemMatrix\n",
    "    print(\"MAT:\", mat)\n",
    "    print(mat.shape)\n",
    "    cur = CUR(k=int(u_len * 0.10), eps=0.5,)\n",
    "    # ids = np.argsort(cur.pi_col)[::-1][:5]\n",
    "    cur.run_CUR(mat)\n",
    "    cur_coreusers_idx = np.argsort(cur.pi_row)[::-1][:int(u_len * 0.10)]\n",
    "    cur_coreusers = dataframe.iloc[np.where(dataframe.uid.isin(cur_coreusers_idx))]\n",
    "    # print(len(cur_coreusers))\n",
    "    return cur_coreusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER LEN: 6040\n",
      "MOVIE LEN: 3706\n",
      "USER ITEM MATRIX: \n",
      " [[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 0.]]\n",
      "2416\n",
      "LENGTH OF INDEX: 2416\n",
      "INDICES ARE: [4168, 4276, 1679, 3031, 1068, 3538, 194, 1469, 1241, 3840, 888, 1940, 1447, 3223, 2908, 1697, 849, 548, 5110, 4681, 4646, 3617, 1979, 1732, 5099, 3490, 423, 1014, 730, 2123, 1149, 677, 523, 351, 3291, 1284, 3066, 3390, 5830, 1180, 3841, 1644, 2062, 3833, 1273, 52, 1604, 4481, 1424, 1834, 751, 3984, 4447, 2115, 5332, 4047, 2506, 2985, 4818, 1740, 4343, 1265, 1670, 1811, 1763, 672, 2906, 6015, 5316, 5811, 6035, 186, 1223, 3884, 4770, 2776, 1087, 4084, 1297, 5953, 542, 4507, 2303, 1925, 4304, 4063, 3271, 1450, 3807, 1448, 5510, 5877, 5794, 1836, 4040, 868, 1896, 4020, 3822, 2792, 4053, 3828, 1146, 1316, 5045, 2819, 3625, 3704, 172, 4353, 3791, 4542, 549, 2528, 5393, 4410, 3366, 1757, 5754, 880, 4815, 215, 3162, 1748, 854, 330, 1634, 2877, 1736, 3823, 1000, 2856, 4509, 5963, 1067, 4801, 147, 1353, 1500, 3506, 2180, 1050, 3482, 5613, 4226, 5073, 234, 3820, 5386, 1163, 2452, 3525, 1752, 2859, 4424, 1675, 2236, 5947, 2840, 2017, 5674, 4496, 4386, 5311, 4284, 5762, 838, 5642, 1957, 5010, 1942, 3307, 4078, 3030, 1202, 4311, 1193, 698, 5219, 5604, 720, 3561, 508, 3517, 1446, 4317, 4446, 2961, 3939, 4578, 2912, 5328, 1646, 475, 3680, 5503, 3674, 4087, 5915, 1464, 4727, 4000, 61, 2014, 3883, 148, 1883, 2091, 122, 2072, 1018, 3327, 1598, 5836, 5853, 1296, 3216, 1716, 3028, 2202, 5162, 3475, 4731, 1747, 5748, 4421, 4374, 5076, 4088, 1136, 2076, 5635, 1139, 1124, 1879, 1119, 3518, 709, 5053, 4866, 224, 411, 3310, 277, 1777, 2108, 2029, 2664, 1283, 4160, 4237, 4807, 2933, 1726, 5521, 4724, 5681, 437, 318, 659, 4085, 3200, 3777, 3415, 4980, 4956, 481, 5529, 4385, 4407, 1016, 2915, 947, 3502, 1686, 5184, 2084, 5995, 1610, 3260, 3409, 1305, 1721, 1116, 3017, 5288, 2543, 4082, 5014, 1898, 1982, 5805, 5579, 530, 4903, 2736, 1638, 1382, 5427, 1864, 5255, 2087, 5492, 326, 4013, 2742, 5181, 910, 5549, 4636, 638, 4032, 4027, 3591, 5106, 3933, 3649, 3835, 1700, 1578, 1696, 5844, 2966, 3998, 1915, 4052, 3849, 5432, 4297, 713, 2339, 5721, 2809, 4999, 116, 1973, 2367, 5442, 1882, 2163, 5743, 3311, 3647, 5787, 4505, 5305, 1185, 3944, 5467, 517, 4138, 2278, 1674, 1612, 527, 2105, 3545, 1987, 3470, 1009, 1911, 654, 4567, 2752, 1888, 748, 150, 3843, 2230, 4783, 5538, 4978, 4672, 5249, 1302, 165, 2898, 1698, 5366, 691, 4015, 837, 4957, 1968, 4417, 201, 4939, 2333, 1586, 3575, 4927, 3589, 1140, 4185, 1263, 3915, 5879, 1919, 3181, 4789, 3300, 5004, 473, 1684, 4114, 3546, 2250, 5567, 410, 4155, 5264, 4674, 4534, 1745, 3284, 342, 3079, 3400, 4800, 198, 1708, 1355, 389, 4936, 628, 2540, 1321, 3726, 3511, 5462, 3768, 5626, 2167, 3715, 4652, 237, 2886, 5999, 4212, 4139, 5458, 4249, 1841, 587, 3996, 5758, 4504, 4344, 799, 1351, 3640, 5847, 4577, 5746, 1210, 135, 2152, 1835, 5516, 5566, 3209, 3319, 3012, 2015, 3682, 4932, 3584, 676, 983, 3468, 801, 3877, 1630, 5152, 4634, 3053, 5025, 2401, 1368, 1495, 3188, 9, 2608, 5304, 4278, 3815, 5603, 2229, 5268, 168, 2642, 1226, 1754, 1243, 3128, 2824, 3195, 1033, 4334, 5041, 5457, 4747, 4836, 460, 5779, 3364, 4887, 345, 1171, 4662, 965, 3139, 3117, 1278, 5141, 3806, 2187, 4584, 3767, 5069, 5491, 1657, 4472, 816, 5171, 3901, 4351, 1693, 1293, 1111, 918, 3962, 3401, 1758, 2853, 5318, 5272, 2871, 668, 292, 2564, 3313, 3474, 3829, 3298, 2591, 145, 6001, 1421, 3245, 1290, 3134, 5596, 3991, 5358, 1127, 307, 493, 1631, 1220, 769, 4111, 3755, 2040, 1666, 800, 3086, 1332, 956, 5620, 5102, 130, 933, 797, 5364, 5535, 5793, 5270, 5360, 5737, 3463, 3556, 4714, 2204, 1259, 1123, 160, 3043, 3025, 5183, 301, 4223, 2172, 5000, 3588, 3370, 4457, 4963, 25, 1775, 2418, 532, 2375, 5846, 2525, 1599, 4665, 2894, 4696, 1504, 4471, 3692, 3723, 2483, 2675, 934, 2582, 4267, 5688, 2037, 3520, 1118, 260, 2626, 5889, 752, 1483, 1779, 1100, 283, 3376, 5761, 5339, 4149, 2120, 2917, 600, 1049, 3258, 2292, 328, 876, 4093, 3602, 4387, 821, 5518, 2234, 2763, 3886, 5954, 1751, 5089, 3867, 5840, 3215, 4106, 4571, 3800, 3609, 3728, 589, 4403, 4822, 441, 1665, 3907, 3424, 354, 1172, 4341, 5880, 4123, 4206, 5107, 5980, 4383, 2025, 3429, 5683, 3964, 2680, 4125, 1394, 3498, 4725, 636, 3270, 1590, 5299, 3689, 715, 2382, 1711, 3417, 2488, 4606, 6006, 779, 3779, 2927, 5500, 3694, 4380, 3071, 174, 4083, 4488, 4592, 4679, 391, 5447, 936, 5363, 2775, 3226, 4574, 5823, 1585, 2580, 1924, 701, 6039, 3557, 1876, 5786, 5697, 1245, 5960, 3228, 4321, 4795, 5810, 2263, 974, 4501, 2539, 2495, 969, 3196, 3712, 5887, 244, 5599, 5716, 1583, 3734, 3461, 2445, 3687, 1272, 5971, 4522, 4947, 889, 3750, 2099, 3805, 3050, 4483, 1112, 3881, 367, 4790, 4949, 4309, 650, 4896, 4475, 3987, 3568, 4152, 872, 3179, 4048, 2154, 2257, 4994, 228, 2760, 3599, 156, 44, 453, 32, 5081, 3997, 3970, 5267, 2925, 3453, 2995, 1070, 5449, 3335, 6009, 4445, 4302, 1120, 1254, 1201, 5727, 4216, 1145, 5625, 74, 3759, 1058, 705, 845, 5348, 586, 4897, 5474, 4625, 1206, 1433, 1077, 4787, 2019, 371, 2780, 3080, 3411, 5433, 4336, 4166, 1961, 1264, 2435, 3753, 1893, 1003, 4490, 5575, 5861, 1267, 4971, 5522, 4878, 3941, 1691, 4590, 3457, 2900, 997, 5139, 2011, 2377, 3016, 2210, 4707, 3863, 3717, 3107, 3657, 5679, 3389, 2505, 5766, 5977, 3299, 4608, 4814, 4167, 2928, 4477, 4061, 35, 853, 5155, 1756, 1789, 309, 5760, 623, 4599, 2993, 776, 2194, 5301, 47, 2610, 4372, 646, 6012, 4844, 3142, 5926, 4242, 5633, 5753, 2165, 5344, 2895, 5312, 4335, 3170, 2607, 4495, 2456, 4931, 3761, 3992, 5481, 4182, 3956, 519, 2241, 3207, 2909, 1705, 4785, 4192, 2130, 203, 2620, 3127, 3703, 2171, 3379, 2633, 1403, 5396, 1488, 5554, 1907, 2224, 4868, 998, 3928, 1412, 516, 336, 267, 3190, 903, 1169, 1951, 1501, 3519, 4860, 4259, 839, 1627, 3081, 3573, 5989, 2128, 3092, 3549, 5112, 2023, 4466, 2058, 4469, 764, 4115, 3744, 5197, 192, 4257, 1625, 4516, 2287, 5511, 1376, 57, 5248, 3064, 2222, 5238, 3312, 5785, 4054, 2066, 4610, 222, 3157, 271, 2455, 5959, 6000, 452, 2663, 3708, 2009, 861, 3891, 5082, 565, 1860, 2536, 3279, 2723, 568, 407, 4561, 1099, 3345, 1850, 4753, 4006, 1344, 1217, 3824, 634, 3377, 3899, 4886, 191, 2071, 2155, 4286, 254, 4361, 2806, 3120, 1642, 5098, 5038, 4735, 952, 1606, 3620, 5525, 5581, 4041, 756, 909, 2773, 3676, 927, 3000, 2628, 3419, 1334, 3852, 5850, 2030, 4057, 5873, 4008, 5569, 1874, 1921, 1260, 5412, 3772, 4285, 2246, 302, 3668, 3476, 270, 1456, 5007, 734, 5652, 4479, 5666, 2699, 4004, 5937, 3150, 5083, 1881, 1342, 5851, 2063, 450, 4788, 5644, 2751, 5254, 3719, 4704, 5778, 1242, 1086, 3826, 1389, 5622, 2240, 3803, 2994, 337, 1240, 948, 726, 2627, 1555, 4523, 3651, 3422, 2270, 2825, 5017, 3578, 1713, 5196, 4828, 4764, 4406, 4684, 2097, 1523, 3393, 4950, 2589, 5046, 5657, 4749, 1361, 4301, 4506, 4378, 2147, 1844, 5084, 2623, 695, 5662, 5629, 4737, 4784, 1379, 823, 5157, 5547, 2951, 2046, 569, 5568, 5770, 986, 2258, 1076, 3623, 1219, 2637, 2503, 2144, 5791, 1388, 3109, 5411, 2887, 4955, 766, 4945, 1608, 451, 5973, 2453, 686, 2940, 2823, 5904, 5482, 132, 5593, 2184, 4773, 3832, 1313, 3770, 5542, 5090, 3355, 402, 4983, 3054, 763, 4489, 2231, 4268, 4456, 6024, 2640, 5226, 863, 2388, 2243, 1735, 5425, 4270, 5370, 2055, 4833, 91, 795, 89, 96, 5351, 1596, 3153, 5555, 3595, 313, 4654, 2281, 2737, 3610, 790, 5885, 3508, 2264, 5584, 414, 3634, 4728, 3926, 5663, 2884, 5130, 1021, 306, 5445, 5955, 1053, 4359, 5451, 5487, 5552, 4332, 4920, 3795, 3960, 3110, 1901, 2022, 1508, 3489, 1895, 5274, 5421, 284, 5508, 492, 197, 3427, 3745, 3095, 3857, 1929, 4214, 4595, 3678, 21, 5928, 829, 3503, 5233, 4525, 5389, 5123, 2437, 1227, 697, 5523, 1529, 3124, 2730, 4224, 474, 5136, 34, 1328, 1997, 2899, 3362, 332, 1766, 3197, 2413, 2690, 2221, 5956, 5322, 5343, 1299, 6002, 2104, 1682, 4579, 4280, 2379, 5377, 1983, 1251, 5572, 4958, 1339, 545, 928, 4376, 2207, 630, 4178, 4293, 4794, 3052, 2124, 4658, 100, 954, 4025, 2862, 299, 1183, 4121, 4482, 1028, 465, 2943, 857, 1545, 4559, 3988, 2262, 5340, 5037, 3690, 1623, 4604, 17, 2847, 4116, 1150, 2049, 5839, 3363, 365, 5224, 3486, 921, 5949, 5276, 5537, 5598, 3975, 5309, 2059, 2484, 385, 2669, 2185, 263, 5281, 3714, 5837, 2839, 4519, 4823, 962, 300, 5282, 3413, 5400, 557, 4883, 4530, 731, 3562, 4400, 5392, 4555, 5160, 138, 1802, 498, 5204, 1095, 3542, 1310, 2778, 5064, 3650, 2010, 4, 867, 3264, 1436, 5177, 620, 2749, 4405, 1805, 5060, 4362, 5732, 4327, 4657, 5531, 2945, 5058, 5649, 2101, 2096, 1347, 3166, 3388, 5658, 607, 5544, 3661, 2532, 2174, 16, 3769, 4429, 5515, 2496, 3473, 1218, 4619, 1138, 2302, 5034, 4644, 2322, 3966, 1346, 3688, 428, 1723, 5921, 4314, 743, 1061, 1419, 1425, 5774, 995, 4071, 3094, 5280, 3716, 1796, 5465, 4916, 5471, 926, 1398, 1167, 1056, 2135, 3326, 3444, 4219, 401, 3435, 2164, 1695, 4264, 3158, 3351, 5135, 320, 5095, 807, 6034, 1515, 241, 1085, 4451, 4252, 1551, 4733, 5429, 1819, 5653, 5574, 4288, 2817, 5222, 229, 5914, 740, 3402, 3472, 2173, 4820, 3074, 72, 535, 4778, 4487, 1270, 4550, 5648, 3846, 180, 4741, 3684, 1890, 1039, 5501, 5573, 3969, 4021, 3858, 3672, 3952, 5893, 5086, 3073, 3137, 4853, 3902, 1550, 551, 4510, 149, 325, 162, 1953, 4632, 1600, 5336, 1129, 3577, 3100, 1409, 2444, 2020, 304, 5111, 5055, 4556, 1032, 3252, 5857, 1490, 957, 4808, 2810, 1541, 2975, 4576, 4448, 5541, 4906, 4812, 480, 1215, 3619, 1855, 1878, 3500, 3560, 5446, 1406, 3006, 1057, 2851, 593, 5431, 1390, 4059, 5052, 1902, 4851, 2750, 18, 2053, 4898, 3038, 1560, 4077, 976, 5769, 1266, 2308, 4736, 1386, 2592, 675, 2089, 408, 1280, 4370, 5924, 2732, 5979, 1591, 2717, 3539, 2678, 4961, 4921, 5871, 3282, 2989, 2566, 3357, 1037, 5022, 4325, 2941, 4076, 5909, 1229, 890, 2109, 4342, 1938, 4102, 4520, 972, 4572, 3421, 4680, 5368, 305, 77, 2624, 5678, 22, 1052, 3671, 4389, 2634, 1795, 2166, 555, 5043, 1465, 3890, 898, 155, 5916, 2967, 1141, 204, 5767, 5985, 2352, 4455, 2394, 3303, 4363, 2682, 4140, 2846, 592, 4620, 708, 3614, 4089, 3930, 3929, 1730, 3510, 3957, 5039, 3859, 3789, 2477, 3587, 5895, 1015, 559, 3232, 2718, 1473, 4805, 4612, 2175, 2179, 2464, 3204, 4673, 1692, 1725, 4848, 3585, 1959, 784, 1903, 4905, 5717, 2785, 3945, 5277, 3082, 5751, 3412, 5891, 5113, 689, 1330, 1482, 2575, 1130, 688, 5286, 2872, 1287, 5614, 1659, 128, 550, 3259, 213, 3314, 2177, 5097, 1605, 3308, 5728, 4642, 1360, 3961, 4591, 2497, 4023, 3980, 582, 4889, 4260, 3241, 1181, 645, 3571, 390, 3242, 1967, 3265, 2218, 1108, 5715, 1793, 669, 2502, 2977, 3318, 209, 3399, 2160, 3112, 5824, 3512, 4193, 2070, 3480, 5676, 1298, 3340, 5285, 5656, 4982, 4830, 1471, 1649, 647, 858, 3731, 4117, 2771, 4952, 2001, 3756, 3003, 2965, 4888, 2410, 2667, 5001, 4864, 515, 3440, 4881, 514, 4170, 4459, 4049, 4211, 1271, 4241, 1615, 1420, 2831, 5221, 2397, 5534, 4565, 2692, 1568, 4220, 4435, 1801, 4655, 745, 2050, 395, 3681, 923, 1853, 3452, 2161, 2343, 590, 5375, 4031, 2673, 3792, 1395, 1286, 2888, 1417, 1324, 3725, 1208, 5899, 5293, 1253, 3664, 164, 272, 2996, 5654, 2245, 3590, 5252, 780, 2881, 2768, 4670, 5519, 7, 1300, 4186, 2041, 1799, 1672, 3977, 5595, 126, 2979, 3893, 1824, 4605, 1134, 2930, 3230, 1767, 4917, 5804, 2471, 831, 2879, 4355, 3834, 1502, 1072, 4130, 951, 5560, 3528, 177, 4203, 5020, 1222, 4290, 930, 694, 6022, 5765, 5428, 3023, 4781, 4984, 5764, 1687, 1356, 5637, 970, 711, 4979, 6004, 4513, 1936, 3111, 4854, 5808, 4993, 5245, 2467, 503, 58, 3383, 4767, 796, 4703, 3888, 787, 5583, 5323, 2795, 6036, 1496, 3085, 3344, 2143, 5757, 4126, 1900, 2655, 2232, 5941, 5948, 2565, 3686, 5048, 4650, 5346, 5564, 424, 4202, 2693, 4842, 2648, 3973, 2755, 2337, 5402, 2803, 5165, 5698, 4996, 2867, 3798, 1192, 3055, 3019, 4305, 444, 3352, 280, 4799, 5490, 1055, 2662, 5259, 1093, 4874, 4867, 938, 3083, 3831, 3202, 1559, 5624, 338, 4326, 1178, 1020, 1441, 5187, 3497, 200, 4460, 2684, 3146, 2683, 5108, 4930, 4660, 3600, 4373, 2937, 794, 4453, 2265, 43, 3978, 5856, 2747, 4194, 5440, 3559, 3206, 4976, 1715, 666, 2744, 1040, 4689, 655, 3001, 5701, 5119, 3558, 5419, 1617, 1489, 5320, 1073, 3653, 5556, 5417, 4618, 622, 4095, 4413, 2784, 4437, 5565, 4081, 476, 1472, 4379, 1778, 2360, 5232, 2121, 2783, 3564, 2857, 118, 3535, 3194, 2347, 461, 2426, 2546, 3788, 5250, 3392, 727, 3523, 2787, 5927, 3013, 3425, 1654, 3339, 980, 4444, 2443, 4661, 5860, 5946, 3993, 2485, 5333, 5733, 2178, 1184, 3642, 335, 3332, 30, 5669, 456, 4941, 4005, 106, 5469, 1927, 269, 670, 3504, 2746, 1704, 2499, 1322, 5962, 3611, 2902, 2170, 3621, 397, 2848, 1262, 3449, 5019, 3218, 5825, 2315, 1205, 2588, 3570, 2971, 4113, 1027, 5975, 3035, 3199, 4959, 2054, 2186, 2450, 1790, 2984, 3887, 1498, 2126, 3304, 4962, 2176, 3995, 1546, 435, 1133, 5179, 4103, 3183, 1780, 1804, 635, 5166, 4436, 3515, 298, 2237, 4308, 1190, 5592, 5842, 3537, 5619, 5024, 5690, 6005, 2644, 3736, 712, 41, 4857, 4746, 2461, 5951, 3951, 2090, 3280, 3229, 742, 2954, 1531, 4521, 102, 4811, 5192, 5430, 4717, 125, 5602, 3227, 4869, 4174, 3836, 1977, 3044, 3288, 2254, 3909, 4933, 1131, 2028, 33, 1889, 4273, 1792, 2406, 1542, 5493, 3024, 2260, 1513, 3950, 2893, 2088, 1357, 5080, 136, 5713, 3433, 189, 1537, 4298, 562, 3369, 4346, 2807, 4151, 2858, 5884, 2306, 1852, 723, 1204, 1831, 4450, 5403, 1369, 5685, 4221, 2604, 982, 1749, 3328, 6010, 3441, 4222, 1194, 601, 5321, 3491, 3954, 295, 2271, 5096, 1366, 5907, 2354, 4234, 4333, 4739, 4974, 2594, 5768, 5677, 2679, 2247, 5910, 2214, 3606, 1859, 2968, 3174, 4614, 2733, 842, 690, 1337, 3527, 1722, 5079, 2373, 10, 2813, 547, 101, 3698, 2319, 2205, 1975, 959, 4926, 662, 5536, 3144, 3496, 425, 4796, 1391, 4039, 384, 5892, 3821, 1414, 2622, 68, 710, 3911, 1062, 2119, 5704, 2351, 4464, 4101, 4865, 2034, 2918, 2095, 1370, 2007, 815, 1981, 5208, 5615, 536, 3276, 3048, 5923, 1689, 808, 2935, 3937, 2561, 1950, 4092, 5028, 4017, 4484, 3751, 2598, 4687, 2129, 6017, 5750, 4901, 594, 658, 3624, 3563, 1064, 4161, 4972, 4915, 1526, 5781, 3443, 4779, 1314, 4035, 1113, 4900, 3581, 1512, 2139, 1594, 1823, 5413, 4756, 3213, 5287, 2735, 5326, 4415, 1182, 259, 4043, 1031, 2113, 3201, 2408, 5354, 4792, 4470, 1918, 2875, 290, 4997, 2942, 5269, 1647, 603, 4835, 182, 4465, 753, 3262, 804, 5719, 566, 3762, 3037, 717, 1806, 1110, 5775, 509, 2558, 5896, 3456, 874, 1570, 495, 3348, 1785, 1995, 64, 2777, 5062, 604, 1257, 4097, 1019, 4180, 348, 115, 2003, 4716, 2821, 2698, 4217, 2301, 4029, 3360, 2075, 1576, 805, 5407, 3604, 2774, 5101, 5415, 236, 5334, 5546, 3720, 1197, 5452, 704, 1025, 1164, 610, 1422, 2574, 4328, 4070, 3386]\n",
      "CORE USERS:           uid   mid  ratings\n",
      "254         4  2775        4\n",
      "255         4  2140        4\n",
      "256         4  1087        5\n",
      "257         4    38        3\n",
      "258         4   279        2\n",
      "...       ...   ...      ...\n",
      "1000204  6039  1019        1\n",
      "1000205  6039  1022        5\n",
      "1000206  6039   548        5\n",
      "1000207  6039  1024        4\n",
      "1000208  6039  1025        4\n",
      "\n",
      "[769795 rows x 3 columns]\n",
      "NUMBER OF CORE USERS: 2416\n"
     ]
    }
   ],
   "source": [
    "# core_users = CUR_ExtractCoreUsers(core_user_ko_input_train_df, len(np.unique(uid_of_train_df)), unique_mids, percent_core_user=0.40)\n",
    "# sdf.to_csv('file_name.csv', index=False)\n",
    "# core_users = ExtractCoreUsers(core_user_ko_input_train_df, len(np.unique(uid_of_train_df)), unique_mids)\n",
    "# core_users = RandomSampling(core_user_ko_input_train_df, len(np.unique(uid_of_train_df)), unique_mids, percent_core_user=0.40)\n",
    "core_users = Extract_LLS(df, len(np.unique(df['uid'])), unique_mids, percent_core_user=0.40)\n",
    "support_user_list = np.unique(core_users['uid'])\n",
    "print(\"CORE USERS:\" ,core_users)\n",
    "print(\"NUMBER OF CORE USERS:\", len(support_user_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE SNIPPET FOR GETTING NESTED CORE USERS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER LEN: 2416\n",
      "MOVIE LEN: 3706\n",
      "USER ITEM MATRIX: \n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " [5. 5. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 0.]]\n",
      "MAT: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " [5. 5. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 0.]]\n",
      "(2416, 3706)\n",
      "[0.00020753 0.00020781 0.00066301 ... 0.00099564 0.00027636 0.0004537 ]\n",
      "1208\n",
      "NESTED CORE USERS:\n",
      "          uid   mid  ratings\n",
      "254        4  2775        4\n",
      "255        4  2140        4\n",
      "256        4  1087        5\n",
      "257        4    38        3\n",
      "258        4   279        2\n",
      "...      ...   ...      ...\n",
      "999720  6036  1008        4\n",
      "999721  6036  1014        4\n",
      "999722  6036  1017        3\n",
      "999723  6036   548        4\n",
      "999724  6036  1025        5\n",
      "\n",
      "[474791 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "core_users_nested = CUR_ExtractCoreUsers(core_users, len(np.unique(core_users['uid'])), unique_mids, percent_core_user=0.50)\n",
    "print(len(np.unique(core_users_nested['uid'])))\n",
    "print(\"NESTED CORE USERS:\\n\" ,core_users_nested)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CODE SNIPPET FOR GETTING NESTED CORE USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON CORE USERS:          uid   mid  ratings\n",
      "0          0  1104        5\n",
      "1          0   639        3\n",
      "2          0   853        3\n",
      "3          0  3177        4\n",
      "4          0  2162        5\n",
      "...      ...   ...      ...\n",
      "999863  6038  1009        4\n",
      "999864  6038  1011        3\n",
      "999865  6038  1014        4\n",
      "999866  6038  1016        4\n",
      "999867  6038  1025        4\n",
      "\n",
      "[230414 rows x 3 columns]\n",
      "CORE USERS:          uid   mid  ratings\n",
      "254        4  2775        4\n",
      "255        4  2140        4\n",
      "256        4  1087        5\n",
      "257        4    38        3\n",
      "258        4   279        2\n",
      "...      ...   ...      ...\n",
      "999720  6036  1008        4\n",
      "999721  6036  1014        4\n",
      "999722  6036  1017        3\n",
      "999723  6036   548        4\n",
      "999724  6036  1025        5\n",
      "\n",
      "[474791 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "core_users_index_list_nested = core_users_nested.index.to_list()\n",
    "non_core_user_index = (df.index.difference(core_users.index))\n",
    "non_core_user_index = non_core_user_index.tolist()\n",
    "\n",
    "core_users_df_nested = df.loc[core_users_index_list_nested]\n",
    "non_core_user_df = df.loc[non_core_user_index]\n",
    "print(\"NON CORE USERS:\" ,non_core_user_df)\n",
    "print(\"CORE USERS:\", core_users_nested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_test_df = core_users_df_nested.groupby(\"uid\").tail(1)\n",
    "# print(len(df_gt_30))\n",
    "support_train_df = core_users_df_nested.drop(core_users_df_nested.groupby('uid').tail(1).index, inplace=False)\n",
    "# print(\"#TEST INSTANCES: \" ,len(support_test_df))\n",
    "# print(\"#TRAIN INSTANCES: \" ,len(support_train_df))\n",
    "assert(len(core_users_df_nested) == len(support_test_df) + len(support_train_df))\n",
    "# print(len(test_df))\n",
    "# print(len(train_df))\n",
    "query_test_df = non_core_user_df.groupby(\"uid\").tail(1)\n",
    "query_train_df = non_core_user_df.drop(non_core_user_df.groupby('uid').tail(1).index, inplace=False)\n",
    "assert(len(non_core_user_df)== len(query_test_df) + len(query_train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ui_dic = {}    \n",
    "for user in range(unique_uids):\n",
    "    train_ui_dic[user] = []\n",
    "for index,row in support_train_df.iterrows():\n",
    "        train_ui_dic[row['uid']].append(row['mid'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CODE SNIPPET FOR GETTING NESTED CORE USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208\n",
      "SUPPORT TEST DF:          uid   mid  ratings\n",
      "451        4   683        4\n",
      "1199       9  1868        5\n",
      "1336      10  1152        4\n",
      "1939      16  2773        5\n",
      "2244      17  1154        5\n",
      "...      ...   ...      ...\n",
      "995572  6010  1865        5\n",
      "995719  6012   548        5\n",
      "996791  6015  3540        4\n",
      "997442  6022  1017        1\n",
      "999724  6036  1025        5\n",
      "\n",
      "[1208 rows x 3 columns]\n",
      "QUERY TEST DF:\n",
      "          uid   mid  ratings\n",
      "52         0  1154        4\n",
      "181        1  1155        5\n",
      "232        2  1900        4\n",
      "253        3  1148        5\n",
      "522        5    33        4\n",
      "...      ...   ...      ...\n",
      "998273  6031  1012        2\n",
      "998333  6032  1848        5\n",
      "998354  6033   527        5\n",
      "999744  6037  1007        5\n",
      "999867  6038  1025        4\n",
      "\n",
      "[3624 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "unique_uids_in_support_trian = np.unique(np.array(core_users_df_nested['uid']))\n",
    "unique_uids_in_query_trian = np.unique(query_train_df['uid'])\n",
    "print(len(unique_uids_in_support_trian))\n",
    "support_test_df = support_test_df.loc[support_test_df['uid'].isin(unique_uids_in_support_trian)]\n",
    "print(\"SUPPORT TEST DF:\" ,support_test_df)\n",
    "query_test_df = query_test_df\n",
    "print(\"QUERY TEST DF:\\n\", query_test_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CODE SNIPPET FOR GETTING NESTED CORE USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_train = []\n",
    "for index,row in core_users_df_nested.iterrows():\n",
    "    support_train.append([row['uid'], row['mid'], row['ratings']])\n",
    "query_train = []\n",
    "for index, row in query_train_df.iterrows():\n",
    "    query_train.append([row['uid'], row['mid'], row['ratings']])\n",
    "support_test = []\n",
    "for index, row in support_test_df.iterrows():\n",
    "    support_test.append([row['uid'], row['mid'], row['ratings']])\n",
    "query_test = []\n",
    "for index, row in query_test_df.iterrows():\n",
    "    query_test.append([row['uid'], row['mid'], row['ratings']])\n",
    "user_his_dic = {}\n",
    "for u in train_ui_dic.keys():\n",
    "    user_his_dic[u] = train_ui_dic[u]\n",
    "user_supp_list = np.unique(core_users_df_nested['uid']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"input_for_getting_query_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(support_train, f)\n",
    "    pickle.dump(query_train, f)\n",
    "    pickle.dump(support_test, f)\n",
    "    pickle.dump(query_test, f)\n",
    "    pickle.dump(user_supp_list, f)\n",
    "    pickle.dump(user_his_dic, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting embeddings for query users and which we will use to mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 474791/226790\n",
      "test set size: support/query 1208/3624\n",
      "Epoch 0 Step 441: Train 1.8473 Reg: 0.5707\n",
      "Test: 0.7986 MAE: 0.7136 RMSE: 0.8936\n",
      "Val: 0.8094 MAE: 0.7109 RMSE: 0.8997\n",
      "Epoch 1 Step 882: Train 0.8168 Reg: 0.4363\n",
      "Test: 0.7943 MAE: 0.7073 RMSE: 0.8912\n",
      "Val: 0.8037 MAE: 0.7092 RMSE: 0.8965\n",
      "Epoch 2 Step 1323: Train 0.8131 Reg: 0.3538\n",
      "Test: 0.7955 MAE: 0.7112 RMSE: 0.8919\n",
      "Val: 0.8012 MAE: 0.7076 RMSE: 0.8951\n",
      "Epoch 3 Step 1764: Train 0.8079 Reg: 0.3152\n",
      "Test: 0.8019 MAE: 0.7061 RMSE: 0.8955\n",
      "Val: 0.7943 MAE: 0.7023 RMSE: 0.8912\n",
      "Epoch 4 Step 2205: Train 0.7967 Reg: 0.3053\n",
      "Test: 0.7890 MAE: 0.7046 RMSE: 0.8882\n",
      "Val: 0.7837 MAE: 0.6995 RMSE: 0.8852\n",
      "Epoch 5 Step 2646: Train 0.7779 Reg: 0.3112\n",
      "Test: 0.7681 MAE: 0.6885 RMSE: 0.8764\n",
      "Val: 0.7643 MAE: 0.6885 RMSE: 0.8743\n",
      "Epoch 6 Step 3087: Train 0.7627 Reg: 0.3066\n",
      "Test: 0.7618 MAE: 0.6843 RMSE: 0.8728\n",
      "Val: 0.7535 MAE: 0.6824 RMSE: 0.8681\n",
      "Epoch 7 Step 3528: Train 0.7488 Reg: 0.3024\n",
      "Test: 0.7392 MAE: 0.6787 RMSE: 0.8597\n",
      "Val: 0.7422 MAE: 0.6784 RMSE: 0.8615\n",
      "Epoch 8 Step 3969: Train 0.7357 Reg: 0.3048\n",
      "Test: 0.7394 MAE: 0.6758 RMSE: 0.8599\n",
      "Val: 0.7305 MAE: 0.6697 RMSE: 0.8547\n",
      "Epoch 9 Step 4410: Train 0.7202 Reg: 0.3125\n",
      "Test: 0.7270 MAE: 0.6753 RMSE: 0.8526\n",
      "Val: 0.7208 MAE: 0.6655 RMSE: 0.8490\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"pretrain-1m.py\", line 124, in <module>\n",
      "    loss_r, loss_reg = train(model, optimizer, train_set_supp_i_x, train_set_supp_i_y)\n",
      "  File \"pretrain-1m.py\", line 85, in train\n",
      "    loss_reg = model.regularization_loss()\n",
      "  File \"/raid/home/jayantkalani/IDCF/code/ml-1m/IDCF-NN/model.py\", line 45, in regularization_loss\n",
      "    return self.embedding_model.regularization_loss()\n",
      "  File \"/raid/home/jayantkalani/IDCF/code/ml-1m/IDCF-NN/model.py\", line 19, in regularization_loss\n",
      "    loss_reg += torch.sum( torch.sqrt( torch.sum(self.user_embedding ** 2, 1) ) )\n",
      "KeyboardInterrupt\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 474791/226790\n",
      "test set size: support/query 1208/3624\n",
      "Epoch 0: TrainLoss 0.9259 RecLoss: 0.0000 (left: 1:12:22)\n",
      "TestLoss: 0.9639 MAE: 0.7720 RMSE: 0.9818\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "# !python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLS sampling 40% and then CUR coreuser 50% effective 20%users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 439388/19100\n",
      "test set size: support/query 1046/809\n",
      "Epoch 0 Step 408: Train 1.9740 Reg: 0.5686\n",
      "Test: 0.8228 MAE: 0.7280 RMSE: 0.9071\n",
      "Val: 0.7987 MAE: 0.7085 RMSE: 0.8937\n",
      "Epoch 1 Step 816: Train 0.8042 Reg: 0.4413\n",
      "Test: 0.8204 MAE: 0.7263 RMSE: 0.9057\n",
      "Val: 0.7971 MAE: 0.7066 RMSE: 0.8928\n",
      "Epoch 2 Step 1224: Train 0.8009 Reg: 0.3585\n",
      "Test: 0.8122 MAE: 0.7216 RMSE: 0.9012\n",
      "Val: 0.7946 MAE: 0.7084 RMSE: 0.8914\n",
      "Epoch 3 Step 1632: Train 0.7980 Reg: 0.3133\n",
      "Test: 0.8011 MAE: 0.7163 RMSE: 0.8951\n",
      "Val: 0.7911 MAE: 0.7055 RMSE: 0.8894\n",
      "Epoch 4 Step 2040: Train 0.7947 Reg: 0.2881\n",
      "Test: 0.8032 MAE: 0.7144 RMSE: 0.8962\n",
      "Val: 0.7846 MAE: 0.7027 RMSE: 0.8858\n",
      "Epoch 5 Step 2448: Train 0.7902 Reg: 0.2725\n",
      "Test: 0.8044 MAE: 0.7187 RMSE: 0.8969\n",
      "Val: 0.7843 MAE: 0.7024 RMSE: 0.8856\n",
      "Epoch 6 Step 2856: Train 0.7832 Reg: 0.2641\n",
      "Test: 0.8140 MAE: 0.7209 RMSE: 0.9022\n",
      "Val: 0.7724 MAE: 0.6936 RMSE: 0.8789\n",
      "Epoch 7 Step 3264: Train 0.7731 Reg: 0.2616\n",
      "Test: 0.8107 MAE: 0.7199 RMSE: 0.9004\n",
      "Val: 0.7636 MAE: 0.6908 RMSE: 0.8739\n",
      "Epoch 8 Step 3672: Train 0.7619 Reg: 0.2597\n",
      "Test: 0.7856 MAE: 0.7015 RMSE: 0.8864\n",
      "Val: 0.7504 MAE: 0.6827 RMSE: 0.8663\n",
      "Epoch 9 Step 4080: Train 0.7448 Reg: 0.2679\n",
      "Test: 0.7716 MAE: 0.6985 RMSE: 0.8784\n",
      "Val: 0.7345 MAE: 0.6754 RMSE: 0.8570\n",
      "Epoch 10 Step 4488: Train 0.7280 Reg: 0.2770\n",
      "Test: 0.7603 MAE: 0.6974 RMSE: 0.8720\n",
      "Val: 0.7245 MAE: 0.6704 RMSE: 0.8512\n",
      "Epoch 11 Step 4896: Train 0.7160 Reg: 0.2831\n",
      "Test: 0.7564 MAE: 0.6913 RMSE: 0.8697\n",
      "Val: 0.7157 MAE: 0.6663 RMSE: 0.8460\n",
      "Epoch 12 Step 5304: Train 0.7007 Reg: 0.2981\n",
      "Test: 0.7506 MAE: 0.6893 RMSE: 0.8664\n",
      "Val: 0.7060 MAE: 0.6631 RMSE: 0.8403\n",
      "Epoch 13 Step 5712: Train 0.6834 Reg: 0.3125\n",
      "Test: 0.7363 MAE: 0.6798 RMSE: 0.8581\n",
      "Val: 0.6934 MAE: 0.6548 RMSE: 0.8327\n",
      "Epoch 14 Step 6120: Train 0.6647 Reg: 0.3277\n",
      "Test: 0.7271 MAE: 0.6783 RMSE: 0.8527\n",
      "Val: 0.6854 MAE: 0.6510 RMSE: 0.8279\n",
      "Epoch 15 Step 6528: Train 0.6465 Reg: 0.3482\n",
      "Test: 0.7198 MAE: 0.6720 RMSE: 0.8484\n",
      "Val: 0.6807 MAE: 0.6485 RMSE: 0.8250\n",
      "Epoch 16 Step 6936: Train 0.6262 Reg: 0.3696\n",
      "Test: 0.7150 MAE: 0.6674 RMSE: 0.8456\n",
      "Val: 0.6785 MAE: 0.6468 RMSE: 0.8237\n",
      "Epoch 17 Step 7344: Train 0.6060 Reg: 0.3917\n",
      "Test: 0.7107 MAE: 0.6642 RMSE: 0.8430\n",
      "Val: 0.6784 MAE: 0.6459 RMSE: 0.8237\n",
      "Epoch 18 Step 7752: Train 0.5849 Reg: 0.4138\n",
      "Test: 0.7187 MAE: 0.6679 RMSE: 0.8477\n",
      "Val: 0.6812 MAE: 0.6467 RMSE: 0.8253\n",
      "Epoch 19 Step 8160: Train 0.5623 Reg: 0.4380\n",
      "Test: 0.7263 MAE: 0.6734 RMSE: 0.8522\n",
      "Val: 0.6907 MAE: 0.6498 RMSE: 0.8311\n",
      "Epoch 20 Step 8568: Train 0.5395 Reg: 0.4612\n",
      "Test: 0.7388 MAE: 0.6756 RMSE: 0.8595\n",
      "Val: 0.6995 MAE: 0.6517 RMSE: 0.8364\n",
      "Epoch 21 Step 8976: Train 0.5172 Reg: 0.4800\n",
      "Test: 0.7579 MAE: 0.6803 RMSE: 0.8706\n",
      "Val: 0.7107 MAE: 0.6554 RMSE: 0.8430\n",
      "Epoch 22 Step 9384: Train 0.4981 Reg: 0.4927\n",
      "Test: 0.7689 MAE: 0.6889 RMSE: 0.8769\n",
      "Val: 0.7217 MAE: 0.6608 RMSE: 0.8495\n",
      "Epoch 23 Step 9792: Train 0.4815 Reg: 0.5021\n",
      "Test: 0.7869 MAE: 0.6956 RMSE: 0.8871\n",
      "Val: 0.7323 MAE: 0.6645 RMSE: 0.8558\n",
      "Epoch 24 Step 10200: Train 0.4686 Reg: 0.5066\n",
      "Test: 0.7969 MAE: 0.6988 RMSE: 0.8927\n",
      "Val: 0.7439 MAE: 0.6681 RMSE: 0.8625\n",
      "Epoch 25 Step 10608: Train 0.4583 Reg: 0.5093\n",
      "Test: 0.8117 MAE: 0.7036 RMSE: 0.9009\n",
      "Val: 0.7521 MAE: 0.6710 RMSE: 0.8672\n",
      "Epoch 26 Step 11016: Train 0.4494 Reg: 0.5098\n",
      "Test: 0.8178 MAE: 0.7071 RMSE: 0.9043\n",
      "Val: 0.7623 MAE: 0.6758 RMSE: 0.8731\n",
      "Epoch 27 Step 11424: Train 0.4425 Reg: 0.5086\n",
      "Test: 0.8266 MAE: 0.7090 RMSE: 0.9091\n",
      "Val: 0.7686 MAE: 0.6778 RMSE: 0.8767\n",
      "Epoch 28 Step 11832: Train 0.4369 Reg: 0.5065\n",
      "Test: 0.8245 MAE: 0.7074 RMSE: 0.9080\n",
      "Val: 0.7758 MAE: 0.6807 RMSE: 0.8808\n",
      "Epoch 29 Step 12240: Train 0.4322 Reg: 0.5033\n",
      "Test: 0.8354 MAE: 0.7115 RMSE: 0.9140\n",
      "Val: 0.7825 MAE: 0.6829 RMSE: 0.8846\n",
      "Epoch 30 Step 12648: Train 0.4280 Reg: 0.5000\n",
      "Test: 0.8435 MAE: 0.7133 RMSE: 0.9184\n",
      "Val: 0.7902 MAE: 0.6856 RMSE: 0.8890\n",
      "Epoch 31 Step 13056: Train 0.4242 Reg: 0.4967\n",
      "Test: 0.8512 MAE: 0.7144 RMSE: 0.9226\n",
      "Val: 0.7937 MAE: 0.6860 RMSE: 0.8909\n",
      "Epoch 32 Step 13464: Train 0.4207 Reg: 0.4931\n",
      "Test: 0.8550 MAE: 0.7186 RMSE: 0.9246\n",
      "Val: 0.8019 MAE: 0.6901 RMSE: 0.8955\n",
      "Epoch 33 Step 13872: Train 0.4177 Reg: 0.4897\n",
      "Test: 0.8605 MAE: 0.7165 RMSE: 0.9276\n",
      "Val: 0.8032 MAE: 0.6895 RMSE: 0.8962\n",
      "Epoch 34 Step 14280: Train 0.4149 Reg: 0.4861\n",
      "Test: 0.8717 MAE: 0.7207 RMSE: 0.9336\n",
      "Val: 0.8078 MAE: 0.6908 RMSE: 0.8988\n",
      "Epoch 35 Step 14688: Train 0.4122 Reg: 0.4825\n",
      "Test: 0.8751 MAE: 0.7225 RMSE: 0.9355\n",
      "Val: 0.8122 MAE: 0.6929 RMSE: 0.9012\n",
      "Epoch 36 Step 15096: Train 0.4097 Reg: 0.4792\n",
      "Test: 0.8762 MAE: 0.7225 RMSE: 0.9360\n",
      "Val: 0.8185 MAE: 0.6955 RMSE: 0.9047\n",
      "Epoch 37 Step 15504: Train 0.4071 Reg: 0.4758\n",
      "Test: 0.8837 MAE: 0.7260 RMSE: 0.9401\n",
      "Val: 0.8209 MAE: 0.6965 RMSE: 0.9061\n",
      "Epoch 38 Step 15912: Train 0.4047 Reg: 0.4729\n",
      "Test: 0.8918 MAE: 0.7268 RMSE: 0.9443\n",
      "Val: 0.8235 MAE: 0.6968 RMSE: 0.9075\n",
      "Epoch 39 Step 16320: Train 0.4019 Reg: 0.4704\n",
      "Test: 0.8952 MAE: 0.7282 RMSE: 0.9462\n",
      "Val: 0.8293 MAE: 0.6989 RMSE: 0.9106\n",
      "Epoch 40 Step 16728: Train 0.3989 Reg: 0.4682\n",
      "Test: 0.8989 MAE: 0.7311 RMSE: 0.9481\n",
      "Val: 0.8336 MAE: 0.7008 RMSE: 0.9130\n",
      "Epoch 41 Step 17136: Train 0.3963 Reg: 0.4658\n",
      "Test: 0.9042 MAE: 0.7305 RMSE: 0.9509\n",
      "Val: 0.8368 MAE: 0.7019 RMSE: 0.9147\n",
      "Epoch 42 Step 17544: Train 0.3940 Reg: 0.4633\n",
      "Test: 0.9111 MAE: 0.7336 RMSE: 0.9545\n",
      "Val: 0.8414 MAE: 0.7033 RMSE: 0.9173\n",
      "Epoch 43 Step 17952: Train 0.3919 Reg: 0.4608\n",
      "Test: 0.9168 MAE: 0.7351 RMSE: 0.9575\n",
      "Val: 0.8430 MAE: 0.7036 RMSE: 0.9182\n",
      "Epoch 44 Step 18360: Train 0.3899 Reg: 0.4582\n",
      "Test: 0.9250 MAE: 0.7394 RMSE: 0.9618\n",
      "Val: 0.8485 MAE: 0.7062 RMSE: 0.9212\n",
      "Epoch 45 Step 18768: Train 0.3879 Reg: 0.4560\n",
      "Test: 0.9272 MAE: 0.7374 RMSE: 0.9629\n",
      "Val: 0.8511 MAE: 0.7060 RMSE: 0.9225\n",
      "Epoch 46 Step 19176: Train 0.3859 Reg: 0.4539\n",
      "Test: 0.9345 MAE: 0.7403 RMSE: 0.9667\n",
      "Val: 0.8538 MAE: 0.7072 RMSE: 0.9240\n",
      "Epoch 47 Step 19584: Train 0.3839 Reg: 0.4520\n",
      "Test: 0.9355 MAE: 0.7402 RMSE: 0.9672\n",
      "Val: 0.8564 MAE: 0.7079 RMSE: 0.9254\n",
      "Epoch 48 Step 19992: Train 0.3817 Reg: 0.4502\n",
      "Test: 0.9419 MAE: 0.7424 RMSE: 0.9705\n",
      "Val: 0.8611 MAE: 0.7098 RMSE: 0.9280\n",
      "Epoch 49 Step 20400: Train 0.3797 Reg: 0.4485\n",
      "Test: 0.9463 MAE: 0.7440 RMSE: 0.9728\n",
      "Val: 0.8631 MAE: 0.7102 RMSE: 0.9290\n",
      "Epoch 50 Step 20808: Train 0.3778 Reg: 0.4466\n",
      "Test: 0.9513 MAE: 0.7454 RMSE: 0.9753\n",
      "Val: 0.8671 MAE: 0.7119 RMSE: 0.9312\n",
      "Epoch 51 Step 21216: Train 0.3762 Reg: 0.4448\n",
      "Test: 0.9536 MAE: 0.7466 RMSE: 0.9765\n",
      "Val: 0.8697 MAE: 0.7132 RMSE: 0.9326\n",
      "Epoch 52 Step 21624: Train 0.3747 Reg: 0.4430\n",
      "Test: 0.9586 MAE: 0.7467 RMSE: 0.9791\n",
      "Val: 0.8719 MAE: 0.7133 RMSE: 0.9337\n",
      "Epoch 53 Step 22032: Train 0.3733 Reg: 0.4412\n",
      "Test: 0.9580 MAE: 0.7470 RMSE: 0.9788\n",
      "Val: 0.8750 MAE: 0.7148 RMSE: 0.9354\n",
      "Epoch 54 Step 22440: Train 0.3720 Reg: 0.4394\n",
      "Test: 0.9645 MAE: 0.7497 RMSE: 0.9821\n",
      "Val: 0.8776 MAE: 0.7159 RMSE: 0.9368\n",
      "Epoch 55 Step 22848: Train 0.3709 Reg: 0.4377\n",
      "Test: 0.9661 MAE: 0.7498 RMSE: 0.9829\n",
      "Val: 0.8789 MAE: 0.7159 RMSE: 0.9375\n",
      "Epoch 56 Step 23256: Train 0.3698 Reg: 0.4360\n",
      "Test: 0.9696 MAE: 0.7510 RMSE: 0.9847\n",
      "Val: 0.8810 MAE: 0.7168 RMSE: 0.9386\n",
      "Epoch 57 Step 23664: Train 0.3687 Reg: 0.4343\n",
      "Test: 0.9709 MAE: 0.7518 RMSE: 0.9854\n",
      "Val: 0.8833 MAE: 0.7177 RMSE: 0.9398\n",
      "Epoch 58 Step 24072: Train 0.3677 Reg: 0.4328\n",
      "Test: 0.9748 MAE: 0.7522 RMSE: 0.9873\n",
      "Val: 0.8846 MAE: 0.7178 RMSE: 0.9405\n",
      "Epoch 59 Step 24480: Train 0.3668 Reg: 0.4312\n",
      "Test: 0.9771 MAE: 0.7526 RMSE: 0.9885\n",
      "Val: 0.8863 MAE: 0.7180 RMSE: 0.9414\n",
      "Epoch 60 Step 24888: Train 0.3660 Reg: 0.4298\n",
      "Test: 0.9791 MAE: 0.7534 RMSE: 0.9895\n",
      "Val: 0.8883 MAE: 0.7190 RMSE: 0.9425\n",
      "Epoch 61 Step 25296: Train 0.3651 Reg: 0.4284\n",
      "Test: 0.9834 MAE: 0.7548 RMSE: 0.9917\n",
      "Val: 0.8899 MAE: 0.7194 RMSE: 0.9434\n",
      "Epoch 62 Step 25704: Train 0.3643 Reg: 0.4271\n",
      "Test: 0.9835 MAE: 0.7563 RMSE: 0.9917\n",
      "Val: 0.8929 MAE: 0.7214 RMSE: 0.9449\n",
      "Epoch 63 Step 26112: Train 0.3636 Reg: 0.4258\n",
      "Test: 0.9858 MAE: 0.7566 RMSE: 0.9929\n",
      "Val: 0.8942 MAE: 0.7219 RMSE: 0.9456\n",
      "Epoch 64 Step 26520: Train 0.3628 Reg: 0.4245\n",
      "Test: 0.9860 MAE: 0.7560 RMSE: 0.9930\n",
      "Val: 0.8942 MAE: 0.7212 RMSE: 0.9456\n",
      "Epoch 65 Step 26928: Train 0.3622 Reg: 0.4233\n",
      "Test: 0.9886 MAE: 0.7568 RMSE: 0.9943\n",
      "Val: 0.8955 MAE: 0.7217 RMSE: 0.9463\n",
      "Epoch 66 Step 27336: Train 0.3615 Reg: 0.4222\n",
      "Test: 0.9905 MAE: 0.7571 RMSE: 0.9952\n",
      "Val: 0.8970 MAE: 0.7221 RMSE: 0.9471\n",
      "Epoch 67 Step 27744: Train 0.3609 Reg: 0.4211\n",
      "Test: 0.9929 MAE: 0.7591 RMSE: 0.9965\n",
      "Val: 0.8988 MAE: 0.7232 RMSE: 0.9481\n",
      "Epoch 68 Step 28152: Train 0.3603 Reg: 0.4201\n",
      "Test: 0.9945 MAE: 0.7585 RMSE: 0.9973\n",
      "Val: 0.8995 MAE: 0.7230 RMSE: 0.9484\n",
      "Epoch 69 Step 28560: Train 0.3597 Reg: 0.4191\n",
      "Test: 0.9953 MAE: 0.7592 RMSE: 0.9977\n",
      "Val: 0.9009 MAE: 0.7236 RMSE: 0.9492\n",
      "Epoch 70 Step 28968: Train 0.3592 Reg: 0.4181\n",
      "Test: 0.9979 MAE: 0.7594 RMSE: 0.9989\n",
      "Val: 0.9010 MAE: 0.7234 RMSE: 0.9492\n",
      "Epoch 71 Step 29376: Train 0.3587 Reg: 0.4172\n",
      "Test: 0.9981 MAE: 0.7596 RMSE: 0.9990\n",
      "Val: 0.9026 MAE: 0.7241 RMSE: 0.9500\n",
      "Epoch 72 Step 29784: Train 0.3583 Reg: 0.4164\n",
      "Test: 0.9995 MAE: 0.7602 RMSE: 0.9998\n",
      "Val: 0.9033 MAE: 0.7243 RMSE: 0.9504\n",
      "Epoch 73 Step 30192: Train 0.3578 Reg: 0.4155\n",
      "Test: 1.0009 MAE: 0.7606 RMSE: 1.0004\n",
      "Val: 0.9044 MAE: 0.7247 RMSE: 0.9510\n",
      "Epoch 74 Step 30600: Train 0.3574 Reg: 0.4147\n",
      "Test: 1.0021 MAE: 0.7606 RMSE: 1.0011\n",
      "Val: 0.9045 MAE: 0.7244 RMSE: 0.9511\n",
      "Epoch 75 Step 31008: Train 0.3569 Reg: 0.4140\n",
      "Test: 1.0029 MAE: 0.7610 RMSE: 1.0014\n",
      "Val: 0.9055 MAE: 0.7249 RMSE: 0.9516\n",
      "Epoch 76 Step 31416: Train 0.3565 Reg: 0.4133\n",
      "Test: 1.0042 MAE: 0.7614 RMSE: 1.0021\n",
      "Val: 0.9066 MAE: 0.7253 RMSE: 0.9521\n",
      "Epoch 77 Step 31824: Train 0.3562 Reg: 0.4126\n",
      "Test: 1.0057 MAE: 0.7617 RMSE: 1.0028\n",
      "Val: 0.9069 MAE: 0.7252 RMSE: 0.9523\n",
      "Epoch 78 Step 32232: Train 0.3558 Reg: 0.4119\n",
      "Test: 1.0069 MAE: 0.7619 RMSE: 1.0035\n",
      "Val: 0.9076 MAE: 0.7254 RMSE: 0.9527\n",
      "Epoch 79 Step 32640: Train 0.3555 Reg: 0.4113\n",
      "Test: 1.0079 MAE: 0.7621 RMSE: 1.0040\n",
      "Val: 0.9082 MAE: 0.7256 RMSE: 0.9530\n",
      "Epoch 80 Step 33048: Train 0.3551 Reg: 0.4107\n",
      "Test: 1.0081 MAE: 0.7625 RMSE: 1.0040\n",
      "Val: 0.9092 MAE: 0.7262 RMSE: 0.9535\n",
      "Epoch 81 Step 33456: Train 0.3548 Reg: 0.4101\n",
      "Test: 1.0092 MAE: 0.7629 RMSE: 1.0046\n",
      "Val: 0.9096 MAE: 0.7261 RMSE: 0.9537\n",
      "Epoch 82 Step 33864: Train 0.3545 Reg: 0.4096\n",
      "Test: 1.0100 MAE: 0.7631 RMSE: 1.0050\n",
      "Val: 0.9102 MAE: 0.7264 RMSE: 0.9541\n",
      "Epoch 83 Step 34272: Train 0.3542 Reg: 0.4091\n",
      "Test: 1.0108 MAE: 0.7639 RMSE: 1.0054\n",
      "Val: 0.9116 MAE: 0.7272 RMSE: 0.9548\n",
      "Epoch 84 Step 34680: Train 0.3540 Reg: 0.4086\n",
      "Test: 1.0115 MAE: 0.7635 RMSE: 1.0057\n",
      "Val: 0.9112 MAE: 0.7267 RMSE: 0.9546\n",
      "Epoch 85 Step 35088: Train 0.3537 Reg: 0.4081\n",
      "Test: 1.0124 MAE: 0.7639 RMSE: 1.0062\n",
      "Val: 0.9119 MAE: 0.7270 RMSE: 0.9549\n",
      "Epoch 86 Step 35496: Train 0.3535 Reg: 0.4077\n",
      "Test: 1.0126 MAE: 0.7642 RMSE: 1.0063\n",
      "Val: 0.9128 MAE: 0.7274 RMSE: 0.9554\n",
      "Epoch 87 Step 35904: Train 0.3533 Reg: 0.4073\n",
      "Test: 1.0135 MAE: 0.7642 RMSE: 1.0067\n",
      "Val: 0.9128 MAE: 0.7273 RMSE: 0.9554\n",
      "Epoch 88 Step 36312: Train 0.3530 Reg: 0.4069\n",
      "Test: 1.0141 MAE: 0.7643 RMSE: 1.0070\n",
      "Val: 0.9129 MAE: 0.7272 RMSE: 0.9555\n",
      "Epoch 89 Step 36720: Train 0.3528 Reg: 0.4065\n",
      "Test: 1.0148 MAE: 0.7645 RMSE: 1.0074\n",
      "Val: 0.9135 MAE: 0.7274 RMSE: 0.9558\n",
      "Epoch 90 Step 37128: Train 0.3526 Reg: 0.4061\n",
      "Test: 1.0155 MAE: 0.7645 RMSE: 1.0077\n",
      "Val: 0.9136 MAE: 0.7273 RMSE: 0.9558\n",
      "Epoch 91 Step 37536: Train 0.3524 Reg: 0.4058\n",
      "Test: 1.0161 MAE: 0.7646 RMSE: 1.0080\n",
      "Val: 0.9142 MAE: 0.7275 RMSE: 0.9561\n",
      "Epoch 92 Step 37944: Train 0.3523 Reg: 0.4055\n",
      "Test: 1.0165 MAE: 0.7649 RMSE: 1.0082\n",
      "Val: 0.9145 MAE: 0.7277 RMSE: 0.9563\n",
      "Epoch 93 Step 38352: Train 0.3521 Reg: 0.4051\n",
      "Test: 1.0172 MAE: 0.7651 RMSE: 1.0086\n",
      "Val: 0.9149 MAE: 0.7278 RMSE: 0.9565\n",
      "Epoch 94 Step 38760: Train 0.3519 Reg: 0.4048\n",
      "Test: 1.0175 MAE: 0.7656 RMSE: 1.0087\n",
      "Val: 0.9160 MAE: 0.7285 RMSE: 0.9571\n",
      "Epoch 95 Step 39168: Train 0.3518 Reg: 0.4046\n",
      "Test: 1.0183 MAE: 0.7654 RMSE: 1.0091\n",
      "Val: 0.9154 MAE: 0.7280 RMSE: 0.9568\n",
      "Epoch 96 Step 39576: Train 0.3516 Reg: 0.4043\n",
      "Test: 1.0184 MAE: 0.7654 RMSE: 1.0092\n",
      "Val: 0.9156 MAE: 0.7280 RMSE: 0.9569\n",
      "Epoch 97 Step 39984: Train 0.3515 Reg: 0.4040\n",
      "Test: 1.0187 MAE: 0.7654 RMSE: 1.0093\n",
      "Val: 0.9158 MAE: 0.7280 RMSE: 0.9570\n",
      "Epoch 98 Step 40392: Train 0.3514 Reg: 0.4038\n",
      "Test: 1.0189 MAE: 0.7659 RMSE: 1.0094\n",
      "Val: 0.9167 MAE: 0.7286 RMSE: 0.9574\n",
      "Epoch 99 Step 40800: Train 0.3512 Reg: 0.4036\n",
      "Test: 1.0192 MAE: 0.7658 RMSE: 1.0096\n",
      "Val: 0.9166 MAE: 0.7284 RMSE: 0.9574\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 439388/19100\n",
      "test set size: support/query 1046/809\n",
      "Epoch 0: TrainLoss 1.1510 RecLoss: 0.0000 (left: 0:16:11)\n",
      "TestLoss: 1.0720 MAE: 0.8048 RMSE: 1.0354\n",
      "ValLoss: 1.1438 MAE: 0.8407 RMSE: 1.0695\n",
      "Epoch 1: TrainLoss 1.0057 RecLoss: 0.0000 (left: 0:14:37)\n",
      "TestLoss: 1.0324 MAE: 0.8143 RMSE: 1.0161\n",
      "ValLoss: 1.0743 MAE: 0.8375 RMSE: 1.0365\n",
      "Epoch 2: TrainLoss 0.9678 RecLoss: 0.0000 (left: 0:14:18)\n",
      "TestLoss: 1.0200 MAE: 0.8077 RMSE: 1.0099\n",
      "ValLoss: 1.0545 MAE: 0.8287 RMSE: 1.0269\n",
      "Epoch 3: TrainLoss 0.9522 RecLoss: 0.0000 (left: 0:13:00)\n",
      "TestLoss: 1.0196 MAE: 0.8140 RMSE: 1.0098\n",
      "ValLoss: 1.0525 MAE: 0.8326 RMSE: 1.0259\n",
      "Epoch 4: TrainLoss 0.9318 RecLoss: 0.0000 (left: 0:13:33)\n",
      "TestLoss: 0.9960 MAE: 0.7943 RMSE: 0.9980\n",
      "ValLoss: 1.0361 MAE: 0.8173 RMSE: 1.0179\n",
      "Epoch 5: TrainLoss 0.9200 RecLoss: 0.0000 (left: 0:13:12)\n",
      "TestLoss: 0.9959 MAE: 0.7908 RMSE: 0.9980\n",
      "ValLoss: 1.0343 MAE: 0.8139 RMSE: 1.0170\n",
      "Epoch 6: TrainLoss 0.9127 RecLoss: 0.0000 (left: 0:13:08)\n",
      "TestLoss: 0.9940 MAE: 0.7911 RMSE: 0.9970\n",
      "ValLoss: 1.0350 MAE: 0.8142 RMSE: 1.0174\n",
      "Epoch 7: TrainLoss 0.9069 RecLoss: 0.0000 (left: 0:12:50)\n",
      "TestLoss: 0.9917 MAE: 0.7889 RMSE: 0.9958\n",
      "ValLoss: 1.0272 MAE: 0.8108 RMSE: 1.0135\n",
      "Epoch 8: TrainLoss 0.9050 RecLoss: 0.0000 (left: 0:12:29)\n",
      "TestLoss: 0.9973 MAE: 0.7987 RMSE: 0.9987\n",
      "ValLoss: 1.0299 MAE: 0.8181 RMSE: 1.0148\n",
      "Epoch 9: TrainLoss 0.9027 RecLoss: 0.0000 (left: 0:12:06)\n",
      "TestLoss: 0.9930 MAE: 0.7932 RMSE: 0.9965\n",
      "ValLoss: 1.0305 MAE: 0.8144 RMSE: 1.0151\n",
      "Epoch 10: TrainLoss 0.8962 RecLoss: 0.0000 (left: 0:11:35)\n",
      "TestLoss: 0.9939 MAE: 0.7932 RMSE: 0.9970\n",
      "ValLoss: 1.0335 MAE: 0.8156 RMSE: 1.0166\n",
      "Epoch 11: TrainLoss 0.8936 RecLoss: 0.0000 (left: 0:11:12)\n",
      "TestLoss: 0.9914 MAE: 0.7857 RMSE: 0.9957\n",
      "ValLoss: 1.0337 MAE: 0.8095 RMSE: 1.0167\n",
      "Epoch 12: TrainLoss 0.8935 RecLoss: 0.0000 (left: 0:10:44)\n",
      "TestLoss: 0.9967 MAE: 0.7854 RMSE: 0.9984\n",
      "ValLoss: 1.0418 MAE: 0.8101 RMSE: 1.0207\n",
      "Epoch 13: TrainLoss 0.8922 RecLoss: 0.0000 (left: 0:10:33)\n",
      "TestLoss: 0.9934 MAE: 0.7900 RMSE: 0.9967\n",
      "ValLoss: 1.0342 MAE: 0.8125 RMSE: 1.0170\n",
      "Epoch 14: TrainLoss 0.8935 RecLoss: 0.0000 (left: 0:10:17)\n",
      "TestLoss: 1.0202 MAE: 0.8149 RMSE: 1.0100\n",
      "ValLoss: 1.0478 MAE: 0.8302 RMSE: 1.0236\n",
      "Epoch 15: TrainLoss 0.8951 RecLoss: 0.0000 (left: 0:09:58)\n",
      "TestLoss: 0.9968 MAE: 0.7914 RMSE: 0.9984\n",
      "ValLoss: 1.0396 MAE: 0.8148 RMSE: 1.0196\n",
      "Epoch 16: TrainLoss 0.8891 RecLoss: 0.0000 (left: 0:09:46)\n",
      "TestLoss: 0.9980 MAE: 0.7940 RMSE: 0.9990\n",
      "ValLoss: 1.0380 MAE: 0.8162 RMSE: 1.0188\n",
      "Epoch 17: TrainLoss 0.8904 RecLoss: 0.0000 (left: 0:09:36)\n",
      "TestLoss: 0.9981 MAE: 0.7846 RMSE: 0.9990\n",
      "ValLoss: 1.0462 MAE: 0.8106 RMSE: 1.0228\n",
      "Epoch 18: TrainLoss 0.8908 RecLoss: 0.0000 (left: 0:09:18)\n",
      "TestLoss: 1.0050 MAE: 0.8025 RMSE: 1.0025\n",
      "ValLoss: 1.0428 MAE: 0.8221 RMSE: 1.0212\n",
      "Epoch 19: TrainLoss 0.8933 RecLoss: 0.0000 (left: 0:09:01)\n",
      "TestLoss: 0.9979 MAE: 0.7917 RMSE: 0.9990\n",
      "ValLoss: 1.0412 MAE: 0.8150 RMSE: 1.0204\n",
      "Epoch 20: TrainLoss 0.8902 RecLoss: 0.0000 (left: 0:08:56)\n",
      "TestLoss: 1.0004 MAE: 0.7967 RMSE: 1.0002\n",
      "ValLoss: 1.0404 MAE: 0.8181 RMSE: 1.0200\n",
      "Epoch 21: TrainLoss 0.8898 RecLoss: 0.0000 (left: 0:08:45)\n",
      "TestLoss: 0.9987 MAE: 0.7845 RMSE: 0.9993\n",
      "ValLoss: 1.0490 MAE: 0.8109 RMSE: 1.0242\n",
      "Epoch 22: TrainLoss 0.8899 RecLoss: 0.0000 (left: 0:08:34)\n",
      "TestLoss: 1.0008 MAE: 0.7927 RMSE: 1.0004\n",
      "ValLoss: 1.0408 MAE: 0.8143 RMSE: 1.0202\n",
      "Epoch 23: TrainLoss 0.8896 RecLoss: 0.0000 (left: 0:08:21)\n",
      "TestLoss: 1.0202 MAE: 0.8136 RMSE: 1.0101\n",
      "ValLoss: 1.0565 MAE: 0.8314 RMSE: 1.0279\n",
      "Epoch 24: TrainLoss 0.8950 RecLoss: 0.0000 (left: 0:08:13)\n",
      "TestLoss: 1.0033 MAE: 0.7994 RMSE: 1.0016\n",
      "ValLoss: 1.0431 MAE: 0.8197 RMSE: 1.0213\n",
      "Epoch 25: TrainLoss 0.8876 RecLoss: 0.0000 (left: 0:08:03)\n",
      "TestLoss: 0.9976 MAE: 0.7890 RMSE: 0.9988\n",
      "ValLoss: 1.0448 MAE: 0.8139 RMSE: 1.0222\n",
      "Epoch 26: TrainLoss 0.8880 RecLoss: 0.0000 (left: 0:07:52)\n",
      "TestLoss: 1.0048 MAE: 0.7831 RMSE: 1.0024\n",
      "ValLoss: 1.0590 MAE: 0.8122 RMSE: 1.0291\n",
      "Epoch 27: TrainLoss 0.8903 RecLoss: 0.0000 (left: 0:07:45)\n",
      "TestLoss: 0.9976 MAE: 0.7863 RMSE: 0.9988\n",
      "ValLoss: 1.0486 MAE: 0.8131 RMSE: 1.0240\n",
      "Epoch 28: TrainLoss 0.8887 RecLoss: 0.0000 (left: 0:07:38)\n",
      "TestLoss: 1.0039 MAE: 0.7974 RMSE: 1.0020\n",
      "ValLoss: 1.0477 MAE: 0.8196 RMSE: 1.0236\n",
      "Epoch 29: TrainLoss 0.8897 RecLoss: 0.0000 (left: 0:07:26)\n",
      "TestLoss: 0.9990 MAE: 0.7911 RMSE: 0.9995\n",
      "ValLoss: 1.0473 MAE: 0.8161 RMSE: 1.0234\n",
      "Epoch 30: TrainLoss 0.8887 RecLoss: 0.0000 (left: 0:07:17)\n",
      "TestLoss: 1.0092 MAE: 0.7813 RMSE: 1.0046\n",
      "ValLoss: 1.0686 MAE: 0.8122 RMSE: 1.0337\n",
      "Epoch 31: TrainLoss 0.8919 RecLoss: 0.0000 (left: 0:07:08)\n",
      "TestLoss: 1.0000 MAE: 0.7853 RMSE: 1.0000\n",
      "ValLoss: 1.0521 MAE: 0.8121 RMSE: 1.0257\n",
      "Epoch 32: TrainLoss 0.8861 RecLoss: 0.0000 (left: 0:07:05)\n",
      "TestLoss: 0.9993 MAE: 0.7903 RMSE: 0.9996\n",
      "ValLoss: 1.0496 MAE: 0.8154 RMSE: 1.0245\n",
      "Epoch 33: TrainLoss 0.8876 RecLoss: 0.0000 (left: 0:06:57)\n",
      "TestLoss: 1.0000 MAE: 0.7892 RMSE: 1.0000\n",
      "ValLoss: 1.0500 MAE: 0.8151 RMSE: 1.0247\n",
      "Epoch 34: TrainLoss 0.8864 RecLoss: 0.0000 (left: 0:06:49)\n",
      "TestLoss: 1.0038 MAE: 0.7818 RMSE: 1.0019\n",
      "ValLoss: 1.0610 MAE: 0.8119 RMSE: 1.0301\n",
      "Epoch 35: TrainLoss 0.8889 RecLoss: 0.0000 (left: 0:06:43)\n",
      "TestLoss: 1.0101 MAE: 0.8040 RMSE: 1.0050\n",
      "ValLoss: 1.0508 MAE: 0.8236 RMSE: 1.0251\n",
      "Epoch 36: TrainLoss 0.8878 RecLoss: 0.0000 (left: 0:06:35)\n",
      "TestLoss: 1.0005 MAE: 0.7906 RMSE: 1.0002\n",
      "ValLoss: 1.0480 MAE: 0.8149 RMSE: 1.0237\n",
      "Epoch 37: TrainLoss 0.8869 RecLoss: 0.0000 (left: 0:06:30)\n",
      "TestLoss: 1.0029 MAE: 0.7958 RMSE: 1.0014\n",
      "ValLoss: 1.0507 MAE: 0.8194 RMSE: 1.0250\n",
      "Epoch 38: TrainLoss 0.8885 RecLoss: 0.0000 (left: 0:06:25)\n",
      "TestLoss: 1.0026 MAE: 0.7966 RMSE: 1.0013\n",
      "ValLoss: 1.0496 MAE: 0.8199 RMSE: 1.0245\n",
      "Epoch 39: TrainLoss 0.8888 RecLoss: 0.0000 (left: 0:06:17)\n",
      "TestLoss: 1.0032 MAE: 0.7835 RMSE: 1.0016\n",
      "ValLoss: 1.0590 MAE: 0.8122 RMSE: 1.0291\n",
      "Epoch 40: TrainLoss 0.8889 RecLoss: 0.0000 (left: 0:06:08)\n",
      "TestLoss: 1.0056 MAE: 0.7836 RMSE: 1.0028\n",
      "ValLoss: 1.0653 MAE: 0.8136 RMSE: 1.0321\n",
      "Epoch 41: TrainLoss 0.8873 RecLoss: 0.0000 (left: 0:06:03)\n",
      "TestLoss: 1.0004 MAE: 0.7920 RMSE: 1.0002\n",
      "ValLoss: 1.0501 MAE: 0.8164 RMSE: 1.0248\n",
      "Epoch 42: TrainLoss 0.8877 RecLoss: 0.0000 (left: 0:05:56)\n",
      "TestLoss: 1.0046 MAE: 0.7971 RMSE: 1.0023\n",
      "ValLoss: 1.0498 MAE: 0.8200 RMSE: 1.0246\n",
      "Epoch 43: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:05:51)\n",
      "TestLoss: 1.0002 MAE: 0.7867 RMSE: 1.0001\n",
      "ValLoss: 1.0523 MAE: 0.8129 RMSE: 1.0258\n",
      "Epoch 44: TrainLoss 0.8862 RecLoss: 0.0000 (left: 0:05:42)\n",
      "TestLoss: 1.0004 MAE: 0.7898 RMSE: 1.0002\n",
      "ValLoss: 1.0539 MAE: 0.8162 RMSE: 1.0266\n",
      "Epoch 45: TrainLoss 0.8858 RecLoss: 0.0000 (left: 0:05:34)\n",
      "TestLoss: 1.0010 MAE: 0.7916 RMSE: 1.0005\n",
      "ValLoss: 1.0503 MAE: 0.8161 RMSE: 1.0249\n",
      "Epoch 46: TrainLoss 0.8852 RecLoss: 0.0000 (left: 0:05:27)\n",
      "TestLoss: 1.0012 MAE: 0.7885 RMSE: 1.0006\n",
      "ValLoss: 1.0528 MAE: 0.8147 RMSE: 1.0261\n",
      "Epoch 47: TrainLoss 0.8866 RecLoss: 0.0000 (left: 0:05:22)\n",
      "TestLoss: 0.9999 MAE: 0.7860 RMSE: 0.9999\n",
      "ValLoss: 1.0551 MAE: 0.8138 RMSE: 1.0272\n",
      "Epoch 48: TrainLoss 0.8878 RecLoss: 0.0000 (left: 0:05:15)\n",
      "TestLoss: 1.0027 MAE: 0.7852 RMSE: 1.0013\n",
      "ValLoss: 1.0580 MAE: 0.8132 RMSE: 1.0286\n",
      "Epoch 49: TrainLoss 0.8874 RecLoss: 0.0000 (left: 0:05:08)\n",
      "TestLoss: 1.0030 MAE: 0.7852 RMSE: 1.0015\n",
      "ValLoss: 1.0575 MAE: 0.8134 RMSE: 1.0283\n",
      "Epoch 50: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:05:02)\n",
      "TestLoss: 1.0024 MAE: 0.7854 RMSE: 1.0012\n",
      "ValLoss: 1.0573 MAE: 0.8131 RMSE: 1.0283\n",
      "Epoch 51: TrainLoss 0.8866 RecLoss: 0.0000 (left: 0:04:56)\n",
      "TestLoss: 1.0015 MAE: 0.7929 RMSE: 1.0007\n",
      "ValLoss: 1.0530 MAE: 0.8181 RMSE: 1.0261\n",
      "Epoch 52: TrainLoss 0.8860 RecLoss: 0.0000 (left: 0:04:50)\n",
      "TestLoss: 1.0024 MAE: 0.7949 RMSE: 1.0012\n",
      "ValLoss: 1.0525 MAE: 0.8194 RMSE: 1.0259\n",
      "Epoch 53: TrainLoss 0.8883 RecLoss: 0.0000 (left: 0:04:45)\n",
      "TestLoss: 1.0027 MAE: 0.7944 RMSE: 1.0014\n",
      "ValLoss: 1.0505 MAE: 0.8187 RMSE: 1.0250\n",
      "Epoch 54: TrainLoss 0.8867 RecLoss: 0.0000 (left: 0:04:39)\n",
      "TestLoss: 1.0002 MAE: 0.7886 RMSE: 1.0001\n",
      "ValLoss: 1.0531 MAE: 0.8149 RMSE: 1.0262\n",
      "Epoch 55: TrainLoss 0.8867 RecLoss: 0.0000 (left: 0:04:33)\n",
      "TestLoss: 1.0030 MAE: 0.7934 RMSE: 1.0015\n",
      "ValLoss: 1.0512 MAE: 0.8181 RMSE: 1.0253\n",
      "Epoch 56: TrainLoss 0.8862 RecLoss: 0.0000 (left: 0:04:26)\n",
      "TestLoss: 1.0011 MAE: 0.7924 RMSE: 1.0006\n",
      "ValLoss: 1.0522 MAE: 0.8179 RMSE: 1.0258\n",
      "Epoch 57: TrainLoss 0.8870 RecLoss: 0.0000 (left: 0:04:20)\n",
      "TestLoss: 1.0028 MAE: 0.7842 RMSE: 1.0014\n",
      "ValLoss: 1.0599 MAE: 0.8132 RMSE: 1.0295\n",
      "Epoch 58: TrainLoss 0.8854 RecLoss: 0.0000 (left: 0:04:13)\n",
      "TestLoss: 1.0015 MAE: 0.7912 RMSE: 1.0007\n",
      "ValLoss: 1.0516 MAE: 0.8160 RMSE: 1.0255\n",
      "Epoch 59: TrainLoss 0.8853 RecLoss: 0.0000 (left: 0:04:06)\n",
      "TestLoss: 1.0017 MAE: 0.7913 RMSE: 1.0009\n",
      "ValLoss: 1.0518 MAE: 0.8166 RMSE: 1.0256\n",
      "Epoch 60: TrainLoss 0.8853 RecLoss: 0.0000 (left: 0:04:00)\n",
      "TestLoss: 1.0006 MAE: 0.7875 RMSE: 1.0003\n",
      "ValLoss: 1.0530 MAE: 0.8137 RMSE: 1.0262\n",
      "Epoch 61: TrainLoss 0.8861 RecLoss: 0.0000 (left: 0:03:55)\n",
      "TestLoss: 1.0014 MAE: 0.7930 RMSE: 1.0007\n",
      "ValLoss: 1.0521 MAE: 0.8180 RMSE: 1.0257\n",
      "Epoch 62: TrainLoss 0.8859 RecLoss: 0.0000 (left: 0:03:48)\n",
      "TestLoss: 1.0053 MAE: 0.7992 RMSE: 1.0026\n",
      "ValLoss: 1.0521 MAE: 0.8217 RMSE: 1.0257\n",
      "Epoch 63: TrainLoss 0.8887 RecLoss: 0.0000 (left: 0:03:42)\n",
      "TestLoss: 1.0089 MAE: 0.8011 RMSE: 1.0044\n",
      "ValLoss: 1.0527 MAE: 0.8232 RMSE: 1.0260\n",
      "Epoch 64: TrainLoss 0.8871 RecLoss: 0.0000 (left: 0:03:35)\n",
      "TestLoss: 1.0021 MAE: 0.7897 RMSE: 1.0011\n",
      "ValLoss: 1.0549 MAE: 0.8158 RMSE: 1.0271\n",
      "Epoch 65: TrainLoss 0.8850 RecLoss: 0.0000 (left: 0:03:29)\n",
      "TestLoss: 1.0015 MAE: 0.7856 RMSE: 1.0007\n",
      "ValLoss: 1.0563 MAE: 0.8134 RMSE: 1.0278\n",
      "Epoch 66: TrainLoss 0.8852 RecLoss: 0.0000 (left: 0:03:24)\n",
      "TestLoss: 0.9996 MAE: 0.7885 RMSE: 0.9998\n",
      "ValLoss: 1.0527 MAE: 0.8151 RMSE: 1.0260\n",
      "Epoch 67: TrainLoss 0.8851 RecLoss: 0.0000 (left: 0:03:17)\n",
      "TestLoss: 1.0012 MAE: 0.7874 RMSE: 1.0006\n",
      "ValLoss: 1.0551 MAE: 0.8142 RMSE: 1.0272\n",
      "Epoch 68: TrainLoss 0.8870 RecLoss: 0.0000 (left: 0:03:11)\n",
      "TestLoss: 0.9997 MAE: 0.7864 RMSE: 0.9999\n",
      "ValLoss: 1.0522 MAE: 0.8130 RMSE: 1.0258\n",
      "Epoch 69: TrainLoss 0.8891 RecLoss: 0.0000 (left: 0:03:05)\n",
      "TestLoss: 1.0037 MAE: 0.7837 RMSE: 1.0019\n",
      "ValLoss: 1.0627 MAE: 0.8134 RMSE: 1.0309\n",
      "Epoch 70: TrainLoss 0.8909 RecLoss: 0.0000 (left: 0:02:59)\n",
      "TestLoss: 1.0164 MAE: 0.7820 RMSE: 1.0082\n",
      "ValLoss: 1.0802 MAE: 0.8142 RMSE: 1.0393\n",
      "Epoch 71: TrainLoss 0.8882 RecLoss: 0.0000 (left: 0:02:53)\n",
      "TestLoss: 1.0003 MAE: 0.7883 RMSE: 1.0002\n",
      "ValLoss: 1.0541 MAE: 0.8150 RMSE: 1.0267\n",
      "Epoch 72: TrainLoss 0.8859 RecLoss: 0.0000 (left: 0:02:47)\n",
      "TestLoss: 1.0023 MAE: 0.7851 RMSE: 1.0011\n",
      "ValLoss: 1.0594 MAE: 0.8139 RMSE: 1.0293\n",
      "Epoch 73: TrainLoss 0.8856 RecLoss: 0.0000 (left: 0:02:41)\n",
      "TestLoss: 1.0013 MAE: 0.7903 RMSE: 1.0007\n",
      "ValLoss: 1.0529 MAE: 0.8160 RMSE: 1.0261\n",
      "Epoch 74: TrainLoss 0.8863 RecLoss: 0.0000 (left: 0:02:35)\n",
      "TestLoss: 1.0007 MAE: 0.7892 RMSE: 1.0003\n",
      "ValLoss: 1.0529 MAE: 0.8154 RMSE: 1.0261\n",
      "Epoch 75: TrainLoss 0.8853 RecLoss: 0.0000 (left: 0:02:29)\n",
      "TestLoss: 1.0059 MAE: 0.7837 RMSE: 1.0029\n",
      "ValLoss: 1.0644 MAE: 0.8132 RMSE: 1.0317\n",
      "Epoch 76: TrainLoss 0.8872 RecLoss: 0.0000 (left: 0:02:23)\n",
      "TestLoss: 1.0015 MAE: 0.7863 RMSE: 1.0007\n",
      "ValLoss: 1.0566 MAE: 0.8138 RMSE: 1.0279\n",
      "Epoch 77: TrainLoss 0.8859 RecLoss: 0.0000 (left: 0:02:17)\n",
      "TestLoss: 1.0012 MAE: 0.7862 RMSE: 1.0006\n",
      "ValLoss: 1.0548 MAE: 0.8132 RMSE: 1.0271\n",
      "Epoch 78: TrainLoss 0.8867 RecLoss: 0.0000 (left: 0:02:10)\n",
      "TestLoss: 1.0062 MAE: 0.7833 RMSE: 1.0031\n",
      "ValLoss: 1.0671 MAE: 0.8142 RMSE: 1.0330\n",
      "Epoch 79: TrainLoss 0.8855 RecLoss: 0.0000 (left: 0:02:04)\n",
      "TestLoss: 1.0021 MAE: 0.7931 RMSE: 1.0011\n",
      "ValLoss: 1.0523 MAE: 0.8177 RMSE: 1.0258\n",
      "Epoch 80: TrainLoss 0.8860 RecLoss: 0.0000 (left: 0:01:58)\n",
      "TestLoss: 1.0023 MAE: 0.7944 RMSE: 1.0012\n",
      "ValLoss: 1.0518 MAE: 0.8188 RMSE: 1.0256\n",
      "Epoch 81: TrainLoss 0.8850 RecLoss: 0.0000 (left: 0:01:53)\n",
      "TestLoss: 0.9990 MAE: 0.7903 RMSE: 0.9995\n",
      "ValLoss: 1.0508 MAE: 0.8159 RMSE: 1.0251\n",
      "Epoch 82: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:01:47)\n",
      "TestLoss: 1.0055 MAE: 0.7831 RMSE: 1.0028\n",
      "ValLoss: 1.0654 MAE: 0.8135 RMSE: 1.0322\n",
      "Epoch 83: TrainLoss 0.8924 RecLoss: 0.0000 (left: 0:01:41)\n",
      "TestLoss: 1.0018 MAE: 0.7857 RMSE: 1.0009\n",
      "ValLoss: 1.0583 MAE: 0.8138 RMSE: 1.0287\n",
      "Epoch 84: TrainLoss 0.8846 RecLoss: 0.0000 (left: 0:01:35)\n",
      "TestLoss: 1.0029 MAE: 0.7941 RMSE: 1.0015\n",
      "ValLoss: 1.0524 MAE: 0.8183 RMSE: 1.0258\n",
      "Epoch 85: TrainLoss 0.8868 RecLoss: 0.0000 (left: 0:01:29)\n",
      "TestLoss: 1.0008 MAE: 0.7888 RMSE: 1.0004\n",
      "ValLoss: 1.0552 MAE: 0.8159 RMSE: 1.0272\n",
      "Epoch 86: TrainLoss 0.8870 RecLoss: 0.0000 (left: 0:01:23)\n",
      "TestLoss: 1.0033 MAE: 0.7841 RMSE: 1.0017\n",
      "ValLoss: 1.0611 MAE: 0.8134 RMSE: 1.0301\n",
      "Epoch 87: TrainLoss 0.8867 RecLoss: 0.0000 (left: 0:01:17)\n",
      "TestLoss: 1.0008 MAE: 0.7882 RMSE: 1.0004\n",
      "ValLoss: 1.0542 MAE: 0.8148 RMSE: 1.0267\n",
      "Epoch 88: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:01:11)\n",
      "TestLoss: 1.0037 MAE: 0.7861 RMSE: 1.0019\n",
      "ValLoss: 1.0584 MAE: 0.8138 RMSE: 1.0288\n",
      "Epoch 89: TrainLoss 0.8864 RecLoss: 0.0000 (left: 0:01:05)\n",
      "TestLoss: 1.0010 MAE: 0.7871 RMSE: 1.0005\n",
      "ValLoss: 1.0564 MAE: 0.8149 RMSE: 1.0278\n",
      "Epoch 90: TrainLoss 0.8853 RecLoss: 0.0000 (left: 0:00:59)\n",
      "TestLoss: 1.0020 MAE: 0.7934 RMSE: 1.0010\n",
      "ValLoss: 1.0532 MAE: 0.8186 RMSE: 1.0263\n",
      "Epoch 91: TrainLoss 0.8872 RecLoss: 0.0000 (left: 0:00:53)\n",
      "TestLoss: 0.9997 MAE: 0.7892 RMSE: 0.9998\n",
      "ValLoss: 1.0532 MAE: 0.8156 RMSE: 1.0262\n",
      "Epoch 92: TrainLoss 0.8848 RecLoss: 0.0000 (left: 0:00:47)\n",
      "TestLoss: 1.0007 MAE: 0.7897 RMSE: 1.0003\n",
      "ValLoss: 1.0533 MAE: 0.8158 RMSE: 1.0263\n",
      "Epoch 93: TrainLoss 0.8850 RecLoss: 0.0000 (left: 0:00:41)\n",
      "TestLoss: 1.0053 MAE: 0.7980 RMSE: 1.0026\n",
      "ValLoss: 1.0534 MAE: 0.8213 RMSE: 1.0264\n",
      "Epoch 94: TrainLoss 0.8891 RecLoss: 0.0000 (left: 0:00:35)\n",
      "TestLoss: 1.0002 MAE: 0.7876 RMSE: 1.0001\n",
      "ValLoss: 1.0542 MAE: 0.8144 RMSE: 1.0268\n",
      "Epoch 95: TrainLoss 0.8878 RecLoss: 0.0000 (left: 0:00:29)\n",
      "TestLoss: 1.0013 MAE: 0.7869 RMSE: 1.0007\n",
      "ValLoss: 1.0569 MAE: 0.8150 RMSE: 1.0281\n",
      "Epoch 96: TrainLoss 0.8857 RecLoss: 0.0000 (left: 0:00:23)\n",
      "TestLoss: 1.0055 MAE: 0.7836 RMSE: 1.0027\n",
      "ValLoss: 1.0639 MAE: 0.8130 RMSE: 1.0315\n",
      "Epoch 97: TrainLoss 0.8862 RecLoss: 0.0000 (left: 0:00:17)\n",
      "TestLoss: 1.0004 MAE: 0.7887 RMSE: 1.0002\n",
      "ValLoss: 1.0541 MAE: 0.8154 RMSE: 1.0267\n",
      "Epoch 98: TrainLoss 0.8846 RecLoss: 0.0000 (left: 0:00:11)\n",
      "TestLoss: 1.0009 MAE: 0.7915 RMSE: 1.0005\n",
      "ValLoss: 1.0521 MAE: 0.8164 RMSE: 1.0257\n",
      "Epoch 99: TrainLoss 0.8847 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 1.0023 MAE: 0.7955 RMSE: 1.0012\n",
      "ValLoss: 1.0518 MAE: 0.8195 RMSE: 1.0256\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 439388/19100\n",
      "test set size: support/query 1046/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.6642 RMSE: 0.8430 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7889 RMSE: 0.9958 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7186 RMSE: 0.9128 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested ml1m 40-50 cur input to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 407656/19100\n",
      "test set size: support/query 1046/809\n",
      "Epoch 0 Step 379: Train 1.2150 Reg: 0.6210\n",
      "Test: 0.8129 MAE: 0.7267 RMSE: 0.9016\n",
      "Val: 0.7963 MAE: 0.7067 RMSE: 0.8924\n",
      "Epoch 1 Step 758: Train 0.7784 Reg: 0.5679\n",
      "Test: 0.7425 MAE: 0.6862 RMSE: 0.8617\n",
      "Val: 0.7649 MAE: 0.6911 RMSE: 0.8746\n",
      "Epoch 2 Step 1137: Train 0.7473 Reg: 0.5873\n",
      "Test: 0.7377 MAE: 0.6777 RMSE: 0.8589\n",
      "Val: 0.7434 MAE: 0.6752 RMSE: 0.8622\n",
      "Epoch 3 Step 1516: Train 0.7269 Reg: 0.5840\n",
      "Test: 0.7570 MAE: 0.6889 RMSE: 0.8701\n",
      "Val: 0.7333 MAE: 0.6712 RMSE: 0.8563\n",
      "Epoch 4 Step 1895: Train 0.7119 Reg: 0.5836\n",
      "Test: 0.7321 MAE: 0.6762 RMSE: 0.8556\n",
      "Val: 0.7217 MAE: 0.6665 RMSE: 0.8495\n",
      "Epoch 5 Step 2274: Train 0.7025 Reg: 0.5792\n",
      "Test: 0.7446 MAE: 0.6762 RMSE: 0.8629\n",
      "Val: 0.7254 MAE: 0.6646 RMSE: 0.8517\n",
      "Epoch 6 Step 2653: Train 0.6955 Reg: 0.5824\n",
      "Test: 0.7145 MAE: 0.6631 RMSE: 0.8453\n",
      "Val: 0.7187 MAE: 0.6617 RMSE: 0.8478\n",
      "Epoch 7 Step 3032: Train 0.6877 Reg: 0.5996\n",
      "Test: 0.7227 MAE: 0.6791 RMSE: 0.8501\n",
      "Val: 0.7135 MAE: 0.6672 RMSE: 0.8447\n",
      "Epoch 8 Step 3411: Train 0.6796 Reg: 0.6222\n",
      "Test: 0.7388 MAE: 0.6821 RMSE: 0.8596\n",
      "Val: 0.7038 MAE: 0.6591 RMSE: 0.8389\n",
      "Epoch 9 Step 3790: Train 0.6707 Reg: 0.6491\n",
      "Test: 0.7193 MAE: 0.6717 RMSE: 0.8481\n",
      "Val: 0.7006 MAE: 0.6584 RMSE: 0.8370\n",
      "Epoch 10 Step 4169: Train 0.6625 Reg: 0.6554\n",
      "Test: 0.7276 MAE: 0.6702 RMSE: 0.8530\n",
      "Val: 0.7065 MAE: 0.6568 RMSE: 0.8405\n",
      "Epoch 11 Step 4548: Train 0.6556 Reg: 0.6553\n",
      "Test: 0.7187 MAE: 0.6703 RMSE: 0.8477\n",
      "Val: 0.6951 MAE: 0.6540 RMSE: 0.8337\n",
      "Epoch 12 Step 4927: Train 0.6504 Reg: 0.6384\n",
      "Test: 0.7191 MAE: 0.6628 RMSE: 0.8480\n",
      "Val: 0.6974 MAE: 0.6538 RMSE: 0.8351\n",
      "Epoch 13 Step 5306: Train 0.6452 Reg: 0.6305\n",
      "Test: 0.7453 MAE: 0.6843 RMSE: 0.8633\n",
      "Val: 0.7002 MAE: 0.6601 RMSE: 0.8368\n",
      "Epoch 14 Step 5685: Train 0.6410 Reg: 0.6298\n",
      "Test: 0.7199 MAE: 0.6683 RMSE: 0.8485\n",
      "Val: 0.6950 MAE: 0.6532 RMSE: 0.8337\n",
      "Epoch 15 Step 6064: Train 0.6368 Reg: 0.6190\n",
      "Test: 0.7218 MAE: 0.6643 RMSE: 0.8496\n",
      "Val: 0.6996 MAE: 0.6531 RMSE: 0.8364\n",
      "Epoch 16 Step 6443: Train 0.6321 Reg: 0.6200\n",
      "Test: 0.7235 MAE: 0.6669 RMSE: 0.8506\n",
      "Val: 0.6945 MAE: 0.6514 RMSE: 0.8334\n",
      "Epoch 17 Step 6822: Train 0.6275 Reg: 0.6209\n",
      "Test: 0.7405 MAE: 0.6733 RMSE: 0.8605\n",
      "Val: 0.6983 MAE: 0.6523 RMSE: 0.8356\n",
      "Epoch 18 Step 7201: Train 0.6220 Reg: 0.6228\n",
      "Test: 0.7284 MAE: 0.6677 RMSE: 0.8535\n",
      "Val: 0.6956 MAE: 0.6520 RMSE: 0.8340\n",
      "Epoch 19 Step 7580: Train 0.6165 Reg: 0.6168\n",
      "Test: 0.7374 MAE: 0.6743 RMSE: 0.8587\n",
      "Val: 0.6957 MAE: 0.6511 RMSE: 0.8341\n",
      "Epoch 20 Step 7959: Train 0.6117 Reg: 0.6080\n",
      "Test: 0.7232 MAE: 0.6668 RMSE: 0.8504\n",
      "Val: 0.6969 MAE: 0.6507 RMSE: 0.8348\n",
      "Epoch 21 Step 8338: Train 0.6075 Reg: 0.6069\n",
      "Test: 0.7234 MAE: 0.6632 RMSE: 0.8505\n",
      "Val: 0.6964 MAE: 0.6530 RMSE: 0.8345\n",
      "Epoch 22 Step 8717: Train 0.6016 Reg: 0.6153\n",
      "Test: 0.7339 MAE: 0.6640 RMSE: 0.8567\n",
      "Val: 0.7006 MAE: 0.6514 RMSE: 0.8370\n",
      "Epoch 23 Step 9096: Train 0.5942 Reg: 0.6298\n",
      "Test: 0.7350 MAE: 0.6695 RMSE: 0.8573\n",
      "Val: 0.6985 MAE: 0.6519 RMSE: 0.8358\n",
      "Epoch 24 Step 9475: Train 0.5850 Reg: 0.6458\n",
      "Test: 0.7361 MAE: 0.6721 RMSE: 0.8580\n",
      "Val: 0.7036 MAE: 0.6545 RMSE: 0.8388\n",
      "Epoch 25 Step 9854: Train 0.5743 Reg: 0.6550\n",
      "Test: 0.7334 MAE: 0.6670 RMSE: 0.8564\n",
      "Val: 0.7058 MAE: 0.6535 RMSE: 0.8401\n",
      "Epoch 26 Step 10233: Train 0.5646 Reg: 0.6601\n",
      "Test: 0.7325 MAE: 0.6643 RMSE: 0.8559\n",
      "Val: 0.7094 MAE: 0.6541 RMSE: 0.8423\n",
      "Epoch 27 Step 10612: Train 0.5543 Reg: 0.6764\n",
      "Test: 0.7325 MAE: 0.6641 RMSE: 0.8558\n",
      "Val: 0.7152 MAE: 0.6578 RMSE: 0.8457\n",
      "Epoch 28 Step 10991: Train 0.5422 Reg: 0.6907\n",
      "Test: 0.7360 MAE: 0.6614 RMSE: 0.8579\n",
      "Val: 0.7264 MAE: 0.6606 RMSE: 0.8523\n",
      "Epoch 29 Step 11370: Train 0.5287 Reg: 0.7056\n",
      "Test: 0.7564 MAE: 0.6751 RMSE: 0.8697\n",
      "Val: 0.7287 MAE: 0.6639 RMSE: 0.8536\n",
      "Epoch 30 Step 11749: Train 0.5153 Reg: 0.7142\n",
      "Test: 0.7529 MAE: 0.6701 RMSE: 0.8677\n",
      "Val: 0.7417 MAE: 0.6676 RMSE: 0.8612\n",
      "Epoch 31 Step 12128: Train 0.5020 Reg: 0.7255\n",
      "Test: 0.7608 MAE: 0.6816 RMSE: 0.8722\n",
      "Val: 0.7509 MAE: 0.6730 RMSE: 0.8666\n",
      "Epoch 32 Step 12507: Train 0.4884 Reg: 0.7354\n",
      "Test: 0.7788 MAE: 0.6866 RMSE: 0.8825\n",
      "Val: 0.7623 MAE: 0.6762 RMSE: 0.8731\n",
      "Epoch 33 Step 12886: Train 0.4744 Reg: 0.7414\n",
      "Test: 0.7780 MAE: 0.6824 RMSE: 0.8820\n",
      "Val: 0.7761 MAE: 0.6789 RMSE: 0.8810\n",
      "Epoch 34 Step 13265: Train 0.4617 Reg: 0.7429\n",
      "Test: 0.7864 MAE: 0.6955 RMSE: 0.8868\n",
      "Val: 0.7825 MAE: 0.6841 RMSE: 0.8846\n",
      "Epoch 35 Step 13644: Train 0.4497 Reg: 0.7418\n",
      "Test: 0.8032 MAE: 0.6960 RMSE: 0.8962\n",
      "Val: 0.7903 MAE: 0.6856 RMSE: 0.8890\n",
      "Epoch 36 Step 14023: Train 0.4391 Reg: 0.7393\n",
      "Test: 0.8116 MAE: 0.6973 RMSE: 0.9009\n",
      "Val: 0.8074 MAE: 0.6932 RMSE: 0.8986\n",
      "Epoch 37 Step 14402: Train 0.4302 Reg: 0.7331\n",
      "Test: 0.8232 MAE: 0.7019 RMSE: 0.9073\n",
      "Val: 0.8185 MAE: 0.6973 RMSE: 0.9047\n",
      "Epoch 38 Step 14781: Train 0.4217 Reg: 0.7252\n",
      "Test: 0.8367 MAE: 0.7065 RMSE: 0.9147\n",
      "Val: 0.8261 MAE: 0.6990 RMSE: 0.9089\n",
      "Epoch 39 Step 15160: Train 0.4156 Reg: 0.7171\n",
      "Test: 0.8323 MAE: 0.7057 RMSE: 0.9123\n",
      "Val: 0.8363 MAE: 0.7028 RMSE: 0.9145\n",
      "Epoch 40 Step 15539: Train 0.4085 Reg: 0.7090\n",
      "Test: 0.8563 MAE: 0.7135 RMSE: 0.9254\n",
      "Val: 0.8450 MAE: 0.7060 RMSE: 0.9192\n",
      "Epoch 41 Step 15918: Train 0.4028 Reg: 0.7002\n",
      "Test: 0.8697 MAE: 0.7195 RMSE: 0.9326\n",
      "Val: 0.8535 MAE: 0.7093 RMSE: 0.9239\n",
      "Epoch 42 Step 16297: Train 0.3973 Reg: 0.6912\n",
      "Test: 0.8779 MAE: 0.7222 RMSE: 0.9370\n",
      "Val: 0.8627 MAE: 0.7135 RMSE: 0.9288\n",
      "Epoch 43 Step 16676: Train 0.3925 Reg: 0.6830\n",
      "Test: 0.8900 MAE: 0.7263 RMSE: 0.9434\n",
      "Val: 0.8739 MAE: 0.7166 RMSE: 0.9349\n",
      "Epoch 44 Step 17055: Train 0.3875 Reg: 0.6745\n",
      "Test: 0.9002 MAE: 0.7306 RMSE: 0.9488\n",
      "Val: 0.8840 MAE: 0.7193 RMSE: 0.9402\n",
      "Epoch 45 Step 17434: Train 0.3832 Reg: 0.6662\n",
      "Test: 0.9049 MAE: 0.7287 RMSE: 0.9513\n",
      "Val: 0.8887 MAE: 0.7208 RMSE: 0.9427\n",
      "Epoch 46 Step 17813: Train 0.3783 Reg: 0.6584\n",
      "Test: 0.9190 MAE: 0.7389 RMSE: 0.9587\n",
      "Val: 0.8974 MAE: 0.7237 RMSE: 0.9473\n",
      "Epoch 47 Step 18192: Train 0.3743 Reg: 0.6503\n",
      "Test: 0.9132 MAE: 0.7383 RMSE: 0.9556\n",
      "Val: 0.8955 MAE: 0.7234 RMSE: 0.9463\n",
      "Epoch 48 Step 18571: Train 0.3705 Reg: 0.6427\n",
      "Test: 0.9279 MAE: 0.7405 RMSE: 0.9633\n",
      "Val: 0.9076 MAE: 0.7273 RMSE: 0.9527\n",
      "Epoch 49 Step 18950: Train 0.3664 Reg: 0.6355\n",
      "Test: 0.9265 MAE: 0.7421 RMSE: 0.9625\n",
      "Val: 0.9131 MAE: 0.7302 RMSE: 0.9556\n",
      "Epoch 50 Step 19329: Train 0.3626 Reg: 0.6286\n",
      "Test: 0.9328 MAE: 0.7456 RMSE: 0.9658\n",
      "Val: 0.9233 MAE: 0.7336 RMSE: 0.9609\n",
      "Epoch 51 Step 19708: Train 0.3592 Reg: 0.6213\n",
      "Test: 0.9297 MAE: 0.7404 RMSE: 0.9642\n",
      "Val: 0.9268 MAE: 0.7331 RMSE: 0.9627\n",
      "Epoch 52 Step 20087: Train 0.3556 Reg: 0.6150\n",
      "Test: 0.9356 MAE: 0.7452 RMSE: 0.9673\n",
      "Val: 0.9281 MAE: 0.7351 RMSE: 0.9634\n",
      "Epoch 53 Step 20466: Train 0.3524 Reg: 0.6084\n",
      "Test: 0.9574 MAE: 0.7524 RMSE: 0.9785\n",
      "Val: 0.9438 MAE: 0.7401 RMSE: 0.9715\n",
      "Epoch 54 Step 20845: Train 0.3496 Reg: 0.6024\n",
      "Test: 0.9564 MAE: 0.7497 RMSE: 0.9779\n",
      "Val: 0.9454 MAE: 0.7398 RMSE: 0.9723\n",
      "Epoch 55 Step 21224: Train 0.3463 Reg: 0.5965\n",
      "Test: 0.9610 MAE: 0.7514 RMSE: 0.9803\n",
      "Val: 0.9502 MAE: 0.7425 RMSE: 0.9748\n",
      "Epoch 56 Step 21603: Train 0.3434 Reg: 0.5907\n",
      "Test: 0.9577 MAE: 0.7512 RMSE: 0.9786\n",
      "Val: 0.9541 MAE: 0.7438 RMSE: 0.9768\n",
      "Epoch 57 Step 21982: Train 0.3407 Reg: 0.5852\n",
      "Test: 0.9588 MAE: 0.7500 RMSE: 0.9792\n",
      "Val: 0.9548 MAE: 0.7438 RMSE: 0.9772\n",
      "Epoch 58 Step 22361: Train 0.3379 Reg: 0.5801\n",
      "Test: 0.9837 MAE: 0.7595 RMSE: 0.9918\n",
      "Val: 0.9664 MAE: 0.7479 RMSE: 0.9831\n",
      "Epoch 59 Step 22740: Train 0.3353 Reg: 0.5751\n",
      "Test: 0.9921 MAE: 0.7619 RMSE: 0.9960\n",
      "Val: 0.9770 MAE: 0.7509 RMSE: 0.9884\n",
      "Epoch 60 Step 23119: Train 0.3329 Reg: 0.5703\n",
      "Test: 0.9837 MAE: 0.7585 RMSE: 0.9918\n",
      "Val: 0.9801 MAE: 0.7522 RMSE: 0.9900\n",
      "Epoch 61 Step 23498: Train 0.3306 Reg: 0.5656\n",
      "Test: 0.9971 MAE: 0.7636 RMSE: 0.9986\n",
      "Val: 0.9835 MAE: 0.7533 RMSE: 0.9917\n",
      "Epoch 62 Step 23877: Train 0.3283 Reg: 0.5613\n",
      "Test: 0.9890 MAE: 0.7580 RMSE: 0.9945\n",
      "Val: 0.9829 MAE: 0.7529 RMSE: 0.9914\n",
      "Epoch 63 Step 24256: Train 0.3261 Reg: 0.5568\n",
      "Test: 0.9947 MAE: 0.7608 RMSE: 0.9974\n",
      "Val: 0.9863 MAE: 0.7540 RMSE: 0.9931\n",
      "Epoch 64 Step 24635: Train 0.3241 Reg: 0.5528\n",
      "Test: 1.0080 MAE: 0.7654 RMSE: 1.0040\n",
      "Val: 0.9994 MAE: 0.7586 RMSE: 0.9997\n",
      "Epoch 65 Step 25014: Train 0.3220 Reg: 0.5489\n",
      "Test: 1.0023 MAE: 0.7644 RMSE: 1.0011\n",
      "Val: 0.9964 MAE: 0.7574 RMSE: 0.9982\n",
      "Epoch 66 Step 25393: Train 0.3201 Reg: 0.5454\n",
      "Test: 1.0149 MAE: 0.7680 RMSE: 1.0074\n",
      "Val: 1.0020 MAE: 0.7597 RMSE: 1.0010\n",
      "Epoch 67 Step 25772: Train 0.3183 Reg: 0.5417\n",
      "Test: 1.0122 MAE: 0.7667 RMSE: 1.0061\n",
      "Val: 1.0048 MAE: 0.7602 RMSE: 1.0024\n",
      "Epoch 68 Step 26151: Train 0.3164 Reg: 0.5385\n",
      "Test: 1.0233 MAE: 0.7698 RMSE: 1.0116\n",
      "Val: 1.0151 MAE: 0.7637 RMSE: 1.0075\n",
      "Epoch 69 Step 26530: Train 0.3148 Reg: 0.5352\n",
      "Test: 1.0204 MAE: 0.7696 RMSE: 1.0102\n",
      "Val: 1.0168 MAE: 0.7641 RMSE: 1.0084\n",
      "Epoch 70 Step 26909: Train 0.3131 Reg: 0.5321\n",
      "Test: 1.0217 MAE: 0.7682 RMSE: 1.0108\n",
      "Val: 1.0177 MAE: 0.7644 RMSE: 1.0088\n",
      "Epoch 71 Step 27288: Train 0.3116 Reg: 0.5290\n",
      "Test: 1.0261 MAE: 0.7708 RMSE: 1.0130\n",
      "Val: 1.0219 MAE: 0.7657 RMSE: 1.0109\n",
      "Epoch 72 Step 27667: Train 0.3101 Reg: 0.5262\n",
      "Test: 1.0410 MAE: 0.7774 RMSE: 1.0203\n",
      "Val: 1.0334 MAE: 0.7699 RMSE: 1.0166\n",
      "Epoch 73 Step 28046: Train 0.3088 Reg: 0.5236\n",
      "Test: 1.0466 MAE: 0.7788 RMSE: 1.0230\n",
      "Val: 1.0346 MAE: 0.7700 RMSE: 1.0172\n",
      "Epoch 74 Step 28425: Train 0.3073 Reg: 0.5209\n",
      "Test: 1.0390 MAE: 0.7747 RMSE: 1.0193\n",
      "Val: 1.0310 MAE: 0.7684 RMSE: 1.0154\n",
      "Epoch 75 Step 28804: Train 0.3060 Reg: 0.5185\n",
      "Test: 1.0459 MAE: 0.7784 RMSE: 1.0227\n",
      "Val: 1.0348 MAE: 0.7701 RMSE: 1.0172\n",
      "Epoch 76 Step 29183: Train 0.3048 Reg: 0.5161\n",
      "Test: 1.0440 MAE: 0.7755 RMSE: 1.0217\n",
      "Val: 1.0341 MAE: 0.7693 RMSE: 1.0169\n",
      "Epoch 77 Step 29562: Train 0.3036 Reg: 0.5139\n",
      "Test: 1.0515 MAE: 0.7796 RMSE: 1.0254\n",
      "Val: 1.0417 MAE: 0.7721 RMSE: 1.0206\n",
      "Epoch 78 Step 29941: Train 0.3024 Reg: 0.5118\n",
      "Test: 1.0546 MAE: 0.7803 RMSE: 1.0269\n",
      "Val: 1.0433 MAE: 0.7726 RMSE: 1.0214\n",
      "Epoch 79 Step 30320: Train 0.3014 Reg: 0.5097\n",
      "Test: 1.0565 MAE: 0.7809 RMSE: 1.0279\n",
      "Val: 1.0471 MAE: 0.7739 RMSE: 1.0233\n",
      "Epoch 80 Step 30699: Train 0.3003 Reg: 0.5078\n",
      "Test: 1.0601 MAE: 0.7820 RMSE: 1.0296\n",
      "Val: 1.0518 MAE: 0.7754 RMSE: 1.0256\n",
      "Epoch 81 Step 31078: Train 0.2994 Reg: 0.5059\n",
      "Test: 1.0656 MAE: 0.7848 RMSE: 1.0323\n",
      "Val: 1.0558 MAE: 0.7770 RMSE: 1.0275\n",
      "Epoch 82 Step 31457: Train 0.2984 Reg: 0.5041\n",
      "Test: 1.0616 MAE: 0.7825 RMSE: 1.0303\n",
      "Val: 1.0518 MAE: 0.7753 RMSE: 1.0256\n",
      "Epoch 83 Step 31836: Train 0.2975 Reg: 0.5024\n",
      "Test: 1.0648 MAE: 0.7831 RMSE: 1.0319\n",
      "Val: 1.0545 MAE: 0.7761 RMSE: 1.0269\n",
      "Epoch 84 Step 32215: Train 0.2967 Reg: 0.5009\n",
      "Test: 1.0706 MAE: 0.7869 RMSE: 1.0347\n",
      "Val: 1.0595 MAE: 0.7779 RMSE: 1.0293\n",
      "Epoch 85 Step 32594: Train 0.2958 Reg: 0.4993\n",
      "Test: 1.0683 MAE: 0.7849 RMSE: 1.0336\n",
      "Val: 1.0587 MAE: 0.7774 RMSE: 1.0289\n",
      "Epoch 86 Step 32973: Train 0.2950 Reg: 0.4979\n",
      "Test: 1.0711 MAE: 0.7862 RMSE: 1.0349\n",
      "Val: 1.0598 MAE: 0.7777 RMSE: 1.0295\n",
      "Epoch 87 Step 33352: Train 0.2943 Reg: 0.4965\n",
      "Test: 1.0798 MAE: 0.7899 RMSE: 1.0391\n",
      "Val: 1.0659 MAE: 0.7799 RMSE: 1.0324\n",
      "Epoch 88 Step 33731: Train 0.2936 Reg: 0.4952\n",
      "Test: 1.0778 MAE: 0.7886 RMSE: 1.0382\n",
      "Val: 1.0656 MAE: 0.7798 RMSE: 1.0323\n",
      "Epoch 89 Step 34110: Train 0.2929 Reg: 0.4939\n",
      "Test: 1.0757 MAE: 0.7877 RMSE: 1.0372\n",
      "Val: 1.0648 MAE: 0.7794 RMSE: 1.0319\n",
      "Epoch 90 Step 34489: Train 0.2923 Reg: 0.4927\n",
      "Test: 1.0823 MAE: 0.7898 RMSE: 1.0403\n",
      "Val: 1.0695 MAE: 0.7810 RMSE: 1.0342\n",
      "Epoch 91 Step 34868: Train 0.2916 Reg: 0.4916\n",
      "Test: 1.0775 MAE: 0.7876 RMSE: 1.0380\n",
      "Val: 1.0659 MAE: 0.7796 RMSE: 1.0324\n",
      "Epoch 92 Step 35247: Train 0.2910 Reg: 0.4905\n",
      "Test: 1.0805 MAE: 0.7885 RMSE: 1.0395\n",
      "Val: 1.0679 MAE: 0.7802 RMSE: 1.0334\n",
      "Epoch 93 Step 35626: Train 0.2905 Reg: 0.4895\n",
      "Test: 1.0777 MAE: 0.7869 RMSE: 1.0381\n",
      "Val: 1.0677 MAE: 0.7801 RMSE: 1.0333\n",
      "Epoch 94 Step 36005: Train 0.2899 Reg: 0.4885\n",
      "Test: 1.0826 MAE: 0.7893 RMSE: 1.0405\n",
      "Val: 1.0710 MAE: 0.7812 RMSE: 1.0349\n",
      "Epoch 95 Step 36384: Train 0.2894 Reg: 0.4875\n",
      "Test: 1.0832 MAE: 0.7892 RMSE: 1.0408\n",
      "Val: 1.0717 MAE: 0.7815 RMSE: 1.0352\n",
      "Epoch 96 Step 36763: Train 0.2889 Reg: 0.4866\n",
      "Test: 1.0858 MAE: 0.7905 RMSE: 1.0420\n",
      "Val: 1.0743 MAE: 0.7824 RMSE: 1.0365\n",
      "Epoch 97 Step 37142: Train 0.2884 Reg: 0.4858\n",
      "Test: 1.0867 MAE: 0.7909 RMSE: 1.0424\n",
      "Val: 1.0749 MAE: 0.7826 RMSE: 1.0368\n",
      "Epoch 98 Step 37521: Train 0.2880 Reg: 0.4850\n",
      "Test: 1.0902 MAE: 0.7920 RMSE: 1.0441\n",
      "Val: 1.0773 MAE: 0.7834 RMSE: 1.0379\n",
      "Epoch 99 Step 37900: Train 0.2876 Reg: 0.4842\n",
      "Test: 1.0892 MAE: 0.7914 RMSE: 1.0437\n",
      "Val: 1.0757 MAE: 0.7828 RMSE: 1.0372\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 407656/19100\n",
      "test set size: support/query 1046/809\n",
      "Epoch 0: TrainLoss 1.0459 RecLoss: 0.0000 (left: 0:12:19)\n",
      "TestLoss: 1.0620 MAE: 0.8118 RMSE: 1.0305\n",
      "ValLoss: 1.1143 MAE: 0.8412 RMSE: 1.0556\n",
      "Epoch 1: TrainLoss 1.0160 RecLoss: 0.0000 (left: 0:10:44)\n",
      "TestLoss: 1.0493 MAE: 0.8066 RMSE: 1.0244\n",
      "ValLoss: 1.1016 MAE: 0.8363 RMSE: 1.0496\n",
      "Epoch 2: TrainLoss 0.9964 RecLoss: 0.0000 (left: 0:09:55)\n",
      "TestLoss: 1.0352 MAE: 0.8042 RMSE: 1.0174\n",
      "ValLoss: 1.0848 MAE: 0.8332 RMSE: 1.0415\n",
      "Epoch 3: TrainLoss 0.9863 RecLoss: 0.0000 (left: 0:09:44)\n",
      "TestLoss: 1.0386 MAE: 0.8167 RMSE: 1.0191\n",
      "ValLoss: 1.0810 MAE: 0.8404 RMSE: 1.0397\n",
      "Epoch 4: TrainLoss 0.9686 RecLoss: 0.0000 (left: 0:09:30)\n",
      "TestLoss: 1.0192 MAE: 0.7996 RMSE: 1.0095\n",
      "ValLoss: 1.0671 MAE: 0.8274 RMSE: 1.0330\n",
      "Epoch 5: TrainLoss 0.9568 RecLoss: 0.0000 (left: 0:09:30)\n",
      "TestLoss: 1.0125 MAE: 0.7954 RMSE: 1.0062\n",
      "ValLoss: 1.0593 MAE: 0.8225 RMSE: 1.0292\n",
      "Epoch 6: TrainLoss 0.9462 RecLoss: 0.0000 (left: 0:09:32)\n",
      "TestLoss: 1.0085 MAE: 0.7914 RMSE: 1.0042\n",
      "ValLoss: 1.0560 MAE: 0.8202 RMSE: 1.0276\n",
      "Epoch 7: TrainLoss 0.9387 RecLoss: 0.0000 (left: 0:09:16)\n",
      "TestLoss: 1.0034 MAE: 0.7906 RMSE: 1.0017\n",
      "ValLoss: 1.0507 MAE: 0.8186 RMSE: 1.0250\n",
      "Epoch 8: TrainLoss 0.9322 RecLoss: 0.0000 (left: 0:09:07)\n",
      "TestLoss: 1.0010 MAE: 0.7876 RMSE: 1.0005\n",
      "ValLoss: 1.0483 MAE: 0.8157 RMSE: 1.0239\n",
      "Epoch 9: TrainLoss 0.9262 RecLoss: 0.0000 (left: 0:09:03)\n",
      "TestLoss: 1.0027 MAE: 0.7853 RMSE: 1.0013\n",
      "ValLoss: 1.0471 MAE: 0.8125 RMSE: 1.0233\n",
      "Epoch 10: TrainLoss 0.9211 RecLoss: 0.0000 (left: 0:09:06)\n",
      "TestLoss: 1.0000 MAE: 0.7821 RMSE: 1.0000\n",
      "ValLoss: 1.0482 MAE: 0.8108 RMSE: 1.0238\n",
      "Epoch 11: TrainLoss 0.9168 RecLoss: 0.0000 (left: 0:08:54)\n",
      "TestLoss: 1.0012 MAE: 0.7806 RMSE: 1.0006\n",
      "ValLoss: 1.0513 MAE: 0.8107 RMSE: 1.0253\n",
      "Epoch 12: TrainLoss 0.9137 RecLoss: 0.0000 (left: 0:08:47)\n",
      "TestLoss: 0.9935 MAE: 0.7888 RMSE: 0.9967\n",
      "ValLoss: 1.0380 MAE: 0.8148 RMSE: 1.0188\n",
      "Epoch 13: TrainLoss 0.9106 RecLoss: 0.0000 (left: 0:08:35)\n",
      "TestLoss: 0.9997 MAE: 0.8012 RMSE: 0.9999\n",
      "ValLoss: 1.0410 MAE: 0.8230 RMSE: 1.0203\n",
      "Epoch 14: TrainLoss 0.9096 RecLoss: 0.0000 (left: 0:08:30)\n",
      "TestLoss: 0.9938 MAE: 0.7927 RMSE: 0.9969\n",
      "ValLoss: 1.0373 MAE: 0.8167 RMSE: 1.0185\n",
      "Epoch 15: TrainLoss 0.9043 RecLoss: 0.0000 (left: 0:08:20)\n",
      "TestLoss: 0.9940 MAE: 0.7826 RMSE: 0.9970\n",
      "ValLoss: 1.0423 MAE: 0.8104 RMSE: 1.0209\n",
      "Epoch 16: TrainLoss 0.8999 RecLoss: 0.0000 (left: 0:08:16)\n",
      "TestLoss: 0.9915 MAE: 0.7845 RMSE: 0.9957\n",
      "ValLoss: 1.0368 MAE: 0.8111 RMSE: 1.0182\n",
      "Epoch 17: TrainLoss 0.8974 RecLoss: 0.0000 (left: 0:08:07)\n",
      "TestLoss: 0.9923 MAE: 0.7849 RMSE: 0.9961\n",
      "ValLoss: 1.0400 MAE: 0.8124 RMSE: 1.0198\n",
      "Epoch 18: TrainLoss 0.8965 RecLoss: 0.0000 (left: 0:08:07)\n",
      "TestLoss: 0.9923 MAE: 0.7893 RMSE: 0.9962\n",
      "ValLoss: 1.0377 MAE: 0.8147 RMSE: 1.0187\n",
      "Epoch 19: TrainLoss 0.8958 RecLoss: 0.0000 (left: 0:08:01)\n",
      "TestLoss: 0.9936 MAE: 0.7824 RMSE: 0.9968\n",
      "ValLoss: 1.0411 MAE: 0.8098 RMSE: 1.0203\n",
      "Epoch 20: TrainLoss 0.8937 RecLoss: 0.0000 (left: 0:07:52)\n",
      "TestLoss: 0.9929 MAE: 0.7940 RMSE: 0.9965\n",
      "ValLoss: 1.0377 MAE: 0.8179 RMSE: 1.0187\n",
      "Epoch 21: TrainLoss 0.8923 RecLoss: 0.0000 (left: 0:07:43)\n",
      "TestLoss: 0.9910 MAE: 0.7886 RMSE: 0.9955\n",
      "ValLoss: 1.0368 MAE: 0.8141 RMSE: 1.0182\n",
      "Epoch 22: TrainLoss 0.8931 RecLoss: 0.0000 (left: 0:07:36)\n",
      "TestLoss: 0.9932 MAE: 0.7927 RMSE: 0.9966\n",
      "ValLoss: 1.0349 MAE: 0.8150 RMSE: 1.0173\n",
      "Epoch 23: TrainLoss 0.8941 RecLoss: 0.0000 (left: 0:07:33)\n",
      "TestLoss: 0.9910 MAE: 0.7865 RMSE: 0.9955\n",
      "ValLoss: 1.0395 MAE: 0.8129 RMSE: 1.0196\n",
      "Epoch 24: TrainLoss 0.8906 RecLoss: 0.0000 (left: 0:07:27)\n",
      "TestLoss: 0.9917 MAE: 0.7863 RMSE: 0.9958\n",
      "ValLoss: 1.0382 MAE: 0.8119 RMSE: 1.0189\n",
      "Epoch 25: TrainLoss 0.8889 RecLoss: 0.0000 (left: 0:07:16)\n",
      "TestLoss: 0.9924 MAE: 0.7878 RMSE: 0.9962\n",
      "ValLoss: 1.0390 MAE: 0.8135 RMSE: 1.0193\n",
      "Epoch 26: TrainLoss 0.8896 RecLoss: 0.0000 (left: 0:07:09)\n",
      "TestLoss: 0.9919 MAE: 0.7889 RMSE: 0.9959\n",
      "ValLoss: 1.0375 MAE: 0.8134 RMSE: 1.0186\n",
      "Epoch 27: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:07:01)\n",
      "TestLoss: 0.9917 MAE: 0.7862 RMSE: 0.9958\n",
      "ValLoss: 1.0444 MAE: 0.8145 RMSE: 1.0219\n",
      "Epoch 28: TrainLoss 0.8878 RecLoss: 0.0000 (left: 0:06:53)\n",
      "TestLoss: 0.9925 MAE: 0.7869 RMSE: 0.9962\n",
      "ValLoss: 1.0387 MAE: 0.8122 RMSE: 1.0191\n",
      "Epoch 29: TrainLoss 0.8870 RecLoss: 0.0000 (left: 0:06:46)\n",
      "TestLoss: 0.9928 MAE: 0.7866 RMSE: 0.9964\n",
      "ValLoss: 1.0406 MAE: 0.8128 RMSE: 1.0201\n",
      "Epoch 30: TrainLoss 0.8862 RecLoss: 0.0000 (left: 0:06:41)\n",
      "TestLoss: 0.9977 MAE: 0.7807 RMSE: 0.9988\n",
      "ValLoss: 1.0497 MAE: 0.8097 RMSE: 1.0245\n",
      "Epoch 31: TrainLoss 0.8874 RecLoss: 0.0000 (left: 0:06:35)\n",
      "TestLoss: 0.9940 MAE: 0.7892 RMSE: 0.9970\n",
      "ValLoss: 1.0435 MAE: 0.8159 RMSE: 1.0215\n",
      "Epoch 32: TrainLoss 0.8856 RecLoss: 0.0000 (left: 0:06:29)\n",
      "TestLoss: 0.9928 MAE: 0.7909 RMSE: 0.9964\n",
      "ValLoss: 1.0410 MAE: 0.8159 RMSE: 1.0203\n",
      "Epoch 33: TrainLoss 0.8859 RecLoss: 0.0000 (left: 0:06:25)\n",
      "TestLoss: 0.9954 MAE: 0.7831 RMSE: 0.9977\n",
      "ValLoss: 1.0466 MAE: 0.8113 RMSE: 1.0230\n",
      "Epoch 34: TrainLoss 0.8852 RecLoss: 0.0000 (left: 0:06:17)\n",
      "TestLoss: 1.0030 MAE: 0.7796 RMSE: 1.0015\n",
      "ValLoss: 1.0551 MAE: 0.8097 RMSE: 1.0272\n",
      "Epoch 35: TrainLoss 0.8848 RecLoss: 0.0000 (left: 0:06:09)\n",
      "TestLoss: 0.9936 MAE: 0.7908 RMSE: 0.9968\n",
      "ValLoss: 1.0429 MAE: 0.8164 RMSE: 1.0212\n",
      "Epoch 36: TrainLoss 0.8850 RecLoss: 0.0000 (left: 0:06:03)\n",
      "TestLoss: 0.9964 MAE: 0.7822 RMSE: 0.9982\n",
      "ValLoss: 1.0465 MAE: 0.8098 RMSE: 1.0230\n",
      "Epoch 37: TrainLoss 0.8845 RecLoss: 0.0000 (left: 0:05:55)\n",
      "TestLoss: 0.9933 MAE: 0.7872 RMSE: 0.9966\n",
      "ValLoss: 1.0464 MAE: 0.8155 RMSE: 1.0230\n",
      "Epoch 38: TrainLoss 0.8845 RecLoss: 0.0000 (left: 0:05:48)\n",
      "TestLoss: 0.9956 MAE: 0.7940 RMSE: 0.9978\n",
      "ValLoss: 1.0464 MAE: 0.8198 RMSE: 1.0229\n",
      "Epoch 39: TrainLoss 0.8845 RecLoss: 0.0000 (left: 0:05:43)\n",
      "TestLoss: 0.9986 MAE: 0.7813 RMSE: 0.9993\n",
      "ValLoss: 1.0513 MAE: 0.8105 RMSE: 1.0253\n",
      "Epoch 40: TrainLoss 0.8848 RecLoss: 0.0000 (left: 0:05:38)\n",
      "TestLoss: 0.9958 MAE: 0.7835 RMSE: 0.9979\n",
      "ValLoss: 1.0503 MAE: 0.8129 RMSE: 1.0248\n",
      "Epoch 41: TrainLoss 0.8832 RecLoss: 0.0000 (left: 0:05:33)\n",
      "TestLoss: 0.9939 MAE: 0.7904 RMSE: 0.9969\n",
      "ValLoss: 1.0440 MAE: 0.8161 RMSE: 1.0217\n",
      "Epoch 42: TrainLoss 0.8839 RecLoss: 0.0000 (left: 0:05:28)\n",
      "TestLoss: 0.9943 MAE: 0.7849 RMSE: 0.9972\n",
      "ValLoss: 1.0463 MAE: 0.8131 RMSE: 1.0229\n",
      "Epoch 43: TrainLoss 0.8840 RecLoss: 0.0000 (left: 0:05:23)\n",
      "TestLoss: 0.9947 MAE: 0.7868 RMSE: 0.9973\n",
      "ValLoss: 1.0464 MAE: 0.8147 RMSE: 1.0229\n",
      "Epoch 44: TrainLoss 0.8830 RecLoss: 0.0000 (left: 0:05:17)\n",
      "TestLoss: 0.9955 MAE: 0.7839 RMSE: 0.9977\n",
      "ValLoss: 1.0478 MAE: 0.8123 RMSE: 1.0236\n",
      "Epoch 45: TrainLoss 0.8828 RecLoss: 0.0000 (left: 0:05:11)\n",
      "TestLoss: 0.9955 MAE: 0.7840 RMSE: 0.9977\n",
      "ValLoss: 1.0494 MAE: 0.8127 RMSE: 1.0244\n",
      "Epoch 46: TrainLoss 0.8825 RecLoss: 0.0000 (left: 0:05:05)\n",
      "TestLoss: 0.9948 MAE: 0.7862 RMSE: 0.9974\n",
      "ValLoss: 1.0470 MAE: 0.8140 RMSE: 1.0232\n",
      "Epoch 47: TrainLoss 0.8826 RecLoss: 0.0000 (left: 0:04:58)\n",
      "TestLoss: 0.9938 MAE: 0.7856 RMSE: 0.9969\n",
      "ValLoss: 1.0487 MAE: 0.8146 RMSE: 1.0241\n",
      "Epoch 48: TrainLoss 0.8836 RecLoss: 0.0000 (left: 0:04:52)\n",
      "TestLoss: 1.0091 MAE: 0.7791 RMSE: 1.0045\n",
      "ValLoss: 1.0632 MAE: 0.8109 RMSE: 1.0311\n",
      "Epoch 49: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:04:47)\n",
      "TestLoss: 0.9991 MAE: 0.7964 RMSE: 0.9995\n",
      "ValLoss: 1.0497 MAE: 0.8215 RMSE: 1.0245\n",
      "Epoch 50: TrainLoss 0.8834 RecLoss: 0.0000 (left: 0:04:42)\n",
      "TestLoss: 0.9954 MAE: 0.7887 RMSE: 0.9977\n",
      "ValLoss: 1.0490 MAE: 0.8164 RMSE: 1.0242\n",
      "Epoch 51: TrainLoss 0.8824 RecLoss: 0.0000 (left: 0:04:37)\n",
      "TestLoss: 0.9956 MAE: 0.7842 RMSE: 0.9978\n",
      "ValLoss: 1.0520 MAE: 0.8145 RMSE: 1.0257\n",
      "Epoch 52: TrainLoss 0.8819 RecLoss: 0.0000 (left: 0:04:32)\n",
      "TestLoss: 0.9963 MAE: 0.7836 RMSE: 0.9981\n",
      "ValLoss: 1.0521 MAE: 0.8133 RMSE: 1.0257\n",
      "Epoch 53: TrainLoss 0.8819 RecLoss: 0.0000 (left: 0:04:26)\n",
      "TestLoss: 0.9963 MAE: 0.7834 RMSE: 0.9981\n",
      "ValLoss: 1.0509 MAE: 0.8129 RMSE: 1.0252\n",
      "Epoch 54: TrainLoss 0.8835 RecLoss: 0.0000 (left: 0:04:21)\n",
      "TestLoss: 0.9958 MAE: 0.7919 RMSE: 0.9979\n",
      "ValLoss: 1.0492 MAE: 0.8188 RMSE: 1.0243\n",
      "Epoch 55: TrainLoss 0.8834 RecLoss: 0.0000 (left: 0:04:16)\n",
      "TestLoss: 0.9960 MAE: 0.7853 RMSE: 0.9980\n",
      "ValLoss: 1.0481 MAE: 0.8134 RMSE: 1.0238\n",
      "Epoch 56: TrainLoss 0.8819 RecLoss: 0.0000 (left: 0:04:11)\n",
      "TestLoss: 0.9951 MAE: 0.7876 RMSE: 0.9975\n",
      "ValLoss: 1.0502 MAE: 0.8165 RMSE: 1.0248\n",
      "Epoch 57: TrainLoss 0.8819 RecLoss: 0.0000 (left: 0:04:06)\n",
      "TestLoss: 0.9971 MAE: 0.7830 RMSE: 0.9986\n",
      "ValLoss: 1.0519 MAE: 0.8125 RMSE: 1.0256\n",
      "Epoch 58: TrainLoss 0.8827 RecLoss: 0.0000 (left: 0:04:00)\n",
      "TestLoss: 0.9961 MAE: 0.7842 RMSE: 0.9980\n",
      "ValLoss: 1.0526 MAE: 0.8144 RMSE: 1.0260\n",
      "Epoch 59: TrainLoss 0.8823 RecLoss: 0.0000 (left: 0:03:54)\n",
      "TestLoss: 0.9973 MAE: 0.7828 RMSE: 0.9987\n",
      "ValLoss: 1.0539 MAE: 0.8132 RMSE: 1.0266\n",
      "Epoch 60: TrainLoss 0.8827 RecLoss: 0.0000 (left: 0:03:48)\n",
      "TestLoss: 0.9963 MAE: 0.7899 RMSE: 0.9981\n",
      "ValLoss: 1.0481 MAE: 0.8167 RMSE: 1.0238\n",
      "Epoch 61: TrainLoss 0.8835 RecLoss: 0.0000 (left: 0:03:42)\n",
      "TestLoss: 0.9975 MAE: 0.7823 RMSE: 0.9988\n",
      "ValLoss: 1.0538 MAE: 0.8128 RMSE: 1.0266\n",
      "Epoch 62: TrainLoss 0.8816 RecLoss: 0.0000 (left: 0:03:36)\n",
      "TestLoss: 0.9953 MAE: 0.7874 RMSE: 0.9976\n",
      "ValLoss: 1.0502 MAE: 0.8164 RMSE: 1.0248\n",
      "Epoch 63: TrainLoss 0.8818 RecLoss: 0.0000 (left: 0:03:30)\n",
      "TestLoss: 0.9952 MAE: 0.7863 RMSE: 0.9976\n",
      "ValLoss: 1.0508 MAE: 0.8157 RMSE: 1.0251\n",
      "Epoch 64: TrainLoss 0.8817 RecLoss: 0.0000 (left: 0:03:24)\n",
      "TestLoss: 1.0003 MAE: 0.7812 RMSE: 1.0002\n",
      "ValLoss: 1.0579 MAE: 0.8125 RMSE: 1.0286\n",
      "Epoch 65: TrainLoss 0.8826 RecLoss: 0.0000 (left: 0:03:18)\n",
      "TestLoss: 0.9997 MAE: 0.7824 RMSE: 0.9999\n",
      "ValLoss: 1.0555 MAE: 0.8128 RMSE: 1.0274\n",
      "Epoch 66: TrainLoss 0.8819 RecLoss: 0.0000 (left: 0:03:13)\n",
      "TestLoss: 0.9953 MAE: 0.7859 RMSE: 0.9977\n",
      "ValLoss: 1.0499 MAE: 0.8148 RMSE: 1.0246\n",
      "Epoch 67: TrainLoss 0.8814 RecLoss: 0.0000 (left: 0:03:08)\n",
      "TestLoss: 0.9956 MAE: 0.7866 RMSE: 0.9978\n",
      "ValLoss: 1.0502 MAE: 0.8153 RMSE: 1.0248\n",
      "Epoch 68: TrainLoss 0.8814 RecLoss: 0.0000 (left: 0:03:02)\n",
      "TestLoss: 0.9965 MAE: 0.7849 RMSE: 0.9982\n",
      "ValLoss: 1.0507 MAE: 0.8142 RMSE: 1.0250\n",
      "Epoch 69: TrainLoss 0.8816 RecLoss: 0.0000 (left: 0:02:57)\n",
      "TestLoss: 0.9955 MAE: 0.7851 RMSE: 0.9977\n",
      "ValLoss: 1.0530 MAE: 0.8159 RMSE: 1.0262\n",
      "Epoch 70: TrainLoss 0.8825 RecLoss: 0.0000 (left: 0:02:51)\n",
      "TestLoss: 0.9964 MAE: 0.7836 RMSE: 0.9982\n",
      "ValLoss: 1.0517 MAE: 0.8129 RMSE: 1.0255\n",
      "Epoch 71: TrainLoss 0.8811 RecLoss: 0.0000 (left: 0:02:45)\n",
      "TestLoss: 0.9968 MAE: 0.7902 RMSE: 0.9984\n",
      "ValLoss: 1.0511 MAE: 0.8179 RMSE: 1.0252\n",
      "Epoch 72: TrainLoss 0.8807 RecLoss: 0.0000 (left: 0:02:39)\n",
      "TestLoss: 0.9995 MAE: 0.7822 RMSE: 0.9997\n",
      "ValLoss: 1.0558 MAE: 0.8128 RMSE: 1.0275\n",
      "Epoch 73: TrainLoss 0.8818 RecLoss: 0.0000 (left: 0:02:33)\n",
      "TestLoss: 0.9972 MAE: 0.7917 RMSE: 0.9986\n",
      "ValLoss: 1.0507 MAE: 0.8188 RMSE: 1.0250\n",
      "Epoch 74: TrainLoss 0.8814 RecLoss: 0.0000 (left: 0:02:27)\n",
      "TestLoss: 0.9960 MAE: 0.7865 RMSE: 0.9980\n",
      "ValLoss: 1.0526 MAE: 0.8166 RMSE: 1.0260\n",
      "Epoch 75: TrainLoss 0.8809 RecLoss: 0.0000 (left: 0:02:21)\n",
      "TestLoss: 1.0015 MAE: 0.7809 RMSE: 1.0008\n",
      "ValLoss: 1.0575 MAE: 0.8116 RMSE: 1.0284\n",
      "Epoch 76: TrainLoss 0.8810 RecLoss: 0.0000 (left: 0:02:16)\n",
      "TestLoss: 0.9964 MAE: 0.7848 RMSE: 0.9982\n",
      "ValLoss: 1.0528 MAE: 0.8149 RMSE: 1.0261\n",
      "Epoch 77: TrainLoss 0.8814 RecLoss: 0.0000 (left: 0:02:10)\n",
      "TestLoss: 0.9988 MAE: 0.7833 RMSE: 0.9994\n",
      "ValLoss: 1.0534 MAE: 0.8130 RMSE: 1.0263\n",
      "Epoch 78: TrainLoss 0.8814 RecLoss: 0.0000 (left: 0:02:05)\n",
      "TestLoss: 0.9972 MAE: 0.7830 RMSE: 0.9986\n",
      "ValLoss: 1.0543 MAE: 0.8136 RMSE: 1.0268\n",
      "Epoch 79: TrainLoss 0.8815 RecLoss: 0.0000 (left: 0:01:59)\n",
      "TestLoss: 0.9964 MAE: 0.7852 RMSE: 0.9982\n",
      "ValLoss: 1.0537 MAE: 0.8159 RMSE: 1.0265\n",
      "Epoch 80: TrainLoss 0.8808 RecLoss: 0.0000 (left: 0:01:53)\n",
      "TestLoss: 1.0004 MAE: 0.7815 RMSE: 1.0002\n",
      "ValLoss: 1.0575 MAE: 0.8129 RMSE: 1.0284\n",
      "Epoch 81: TrainLoss 0.8808 RecLoss: 0.0000 (left: 0:01:48)\n",
      "TestLoss: 0.9971 MAE: 0.7835 RMSE: 0.9985\n",
      "ValLoss: 1.0533 MAE: 0.8141 RMSE: 1.0263\n",
      "Epoch 82: TrainLoss 0.8831 RecLoss: 0.0000 (left: 0:01:42)\n",
      "TestLoss: 1.0079 MAE: 0.7791 RMSE: 1.0040\n",
      "ValLoss: 1.0665 MAE: 0.8120 RMSE: 1.0327\n",
      "Epoch 83: TrainLoss 0.8830 RecLoss: 0.0000 (left: 0:01:36)\n",
      "TestLoss: 0.9959 MAE: 0.7877 RMSE: 0.9979\n",
      "ValLoss: 1.0537 MAE: 0.8178 RMSE: 1.0265\n",
      "Epoch 84: TrainLoss 0.8814 RecLoss: 0.0000 (left: 0:01:30)\n",
      "TestLoss: 0.9973 MAE: 0.7837 RMSE: 0.9987\n",
      "ValLoss: 1.0535 MAE: 0.8139 RMSE: 1.0264\n",
      "Epoch 85: TrainLoss 0.8815 RecLoss: 0.0000 (left: 0:01:24)\n",
      "TestLoss: 0.9999 MAE: 0.7819 RMSE: 0.9999\n",
      "ValLoss: 1.0568 MAE: 0.8133 RMSE: 1.0280\n",
      "Epoch 86: TrainLoss 0.8811 RecLoss: 0.0000 (left: 0:01:19)\n",
      "TestLoss: 1.0037 MAE: 0.7800 RMSE: 1.0018\n",
      "ValLoss: 1.0612 MAE: 0.8119 RMSE: 1.0302\n",
      "Epoch 87: TrainLoss 0.8815 RecLoss: 0.0000 (left: 0:01:13)\n",
      "TestLoss: 0.9975 MAE: 0.7909 RMSE: 0.9988\n",
      "ValLoss: 1.0538 MAE: 0.8200 RMSE: 1.0265\n",
      "Epoch 88: TrainLoss 0.8812 RecLoss: 0.0000 (left: 0:01:08)\n",
      "TestLoss: 0.9971 MAE: 0.7844 RMSE: 0.9986\n",
      "ValLoss: 1.0540 MAE: 0.8150 RMSE: 1.0267\n",
      "Epoch 89: TrainLoss 0.8805 RecLoss: 0.0000 (left: 0:01:02)\n",
      "TestLoss: 0.9972 MAE: 0.7835 RMSE: 0.9986\n",
      "ValLoss: 1.0539 MAE: 0.8142 RMSE: 1.0266\n",
      "Epoch 90: TrainLoss 0.8805 RecLoss: 0.0000 (left: 0:00:56)\n",
      "TestLoss: 0.9960 MAE: 0.7880 RMSE: 0.9980\n",
      "ValLoss: 1.0544 MAE: 0.8184 RMSE: 1.0268\n",
      "Epoch 91: TrainLoss 0.8805 RecLoss: 0.0000 (left: 0:00:51)\n",
      "TestLoss: 1.0029 MAE: 0.7799 RMSE: 1.0014\n",
      "ValLoss: 1.0608 MAE: 0.8121 RMSE: 1.0300\n",
      "Epoch 92: TrainLoss 0.8824 RecLoss: 0.0000 (left: 0:00:45)\n",
      "TestLoss: 0.9973 MAE: 0.7842 RMSE: 0.9986\n",
      "ValLoss: 1.0543 MAE: 0.8153 RMSE: 1.0268\n",
      "Epoch 93: TrainLoss 0.8806 RecLoss: 0.0000 (left: 0:00:39)\n",
      "TestLoss: 0.9963 MAE: 0.7857 RMSE: 0.9981\n",
      "ValLoss: 1.0533 MAE: 0.8161 RMSE: 1.0263\n",
      "Epoch 94: TrainLoss 0.8820 RecLoss: 0.0000 (left: 0:00:34)\n",
      "TestLoss: 1.0007 MAE: 0.7810 RMSE: 1.0004\n",
      "ValLoss: 1.0585 MAE: 0.8129 RMSE: 1.0289\n",
      "Epoch 95: TrainLoss 0.8809 RecLoss: 0.0000 (left: 0:00:28)\n",
      "TestLoss: 0.9989 MAE: 0.7820 RMSE: 0.9994\n",
      "ValLoss: 1.0561 MAE: 0.8133 RMSE: 1.0277\n",
      "Epoch 96: TrainLoss 0.8809 RecLoss: 0.0000 (left: 0:00:22)\n",
      "TestLoss: 0.9984 MAE: 0.7827 RMSE: 0.9992\n",
      "ValLoss: 1.0556 MAE: 0.8140 RMSE: 1.0274\n",
      "Epoch 97: TrainLoss 0.8804 RecLoss: 0.0000 (left: 0:00:17)\n",
      "TestLoss: 0.9975 MAE: 0.7840 RMSE: 0.9988\n",
      "ValLoss: 1.0551 MAE: 0.8150 RMSE: 1.0272\n",
      "Epoch 98: TrainLoss 0.8803 RecLoss: 0.0000 (left: 0:00:11)\n",
      "TestLoss: 1.0000 MAE: 0.7817 RMSE: 1.0000\n",
      "ValLoss: 1.0564 MAE: 0.8126 RMSE: 1.0278\n",
      "Epoch 99: TrainLoss 0.8816 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 0.9973 MAE: 0.7842 RMSE: 0.9987\n",
      "ValLoss: 1.0543 MAE: 0.8152 RMSE: 1.0268\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 407656/19100\n",
      "test set size: support/query 1046/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.6669 RMSE: 0.8506 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7927 RMSE: 0.9966 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7217 RMSE: 0.9171 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random sampling nested ml1m 40-50 cur input to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 288576/19100\n",
      "test set size: support/query 322/809\n",
      "Epoch 0 Step 268: Train 1.3841 Reg: 0.6287\n",
      "Test: 0.8858 MAE: 0.7462 RMSE: 0.9412\n",
      "Val: 0.8231 MAE: 0.7200 RMSE: 0.9073\n",
      "Epoch 1 Step 536: Train 0.8057 Reg: 0.6206\n",
      "Test: 0.8582 MAE: 0.7234 RMSE: 0.9264\n",
      "Val: 0.7894 MAE: 0.6994 RMSE: 0.8885\n",
      "Epoch 2 Step 804: Train 0.7752 Reg: 0.6143\n",
      "Test: 0.8555 MAE: 0.7159 RMSE: 0.9249\n",
      "Val: 0.7672 MAE: 0.6916 RMSE: 0.8759\n",
      "Epoch 3 Step 1072: Train 0.7558 Reg: 0.6206\n",
      "Test: 0.8628 MAE: 0.7231 RMSE: 0.9289\n",
      "Val: 0.7547 MAE: 0.6864 RMSE: 0.8687\n",
      "Epoch 4 Step 1340: Train 0.7356 Reg: 0.6668\n",
      "Test: 0.8579 MAE: 0.7265 RMSE: 0.9262\n",
      "Val: 0.7455 MAE: 0.6783 RMSE: 0.8634\n",
      "Epoch 5 Step 1608: Train 0.7140 Reg: 0.7285\n",
      "Test: 0.8587 MAE: 0.7290 RMSE: 0.9267\n",
      "Val: 0.7315 MAE: 0.6741 RMSE: 0.8553\n",
      "Epoch 6 Step 1876: Train 0.6950 Reg: 0.7601\n",
      "Test: 0.8426 MAE: 0.7244 RMSE: 0.9179\n",
      "Val: 0.7278 MAE: 0.6732 RMSE: 0.8531\n",
      "Epoch 7 Step 2144: Train 0.6788 Reg: 0.7771\n",
      "Test: 0.8712 MAE: 0.7324 RMSE: 0.9334\n",
      "Val: 0.7272 MAE: 0.6734 RMSE: 0.8528\n",
      "Epoch 8 Step 2412: Train 0.6650 Reg: 0.7963\n",
      "Test: 0.8525 MAE: 0.7084 RMSE: 0.9233\n",
      "Val: 0.7251 MAE: 0.6670 RMSE: 0.8516\n",
      "Epoch 9 Step 2680: Train 0.6524 Reg: 0.8222\n",
      "Test: 0.8333 MAE: 0.7078 RMSE: 0.9129\n",
      "Val: 0.7279 MAE: 0.6681 RMSE: 0.8531\n",
      "Epoch 10 Step 2948: Train 0.6380 Reg: 0.8504\n",
      "Test: 0.8609 MAE: 0.7230 RMSE: 0.9278\n",
      "Val: 0.7330 MAE: 0.6659 RMSE: 0.8562\n",
      "Epoch 11 Step 3216: Train 0.6232 Reg: 0.8751\n",
      "Test: 0.8629 MAE: 0.7333 RMSE: 0.9289\n",
      "Val: 0.7292 MAE: 0.6685 RMSE: 0.8539\n",
      "Epoch 12 Step 3484: Train 0.6073 Reg: 0.9032\n",
      "Test: 0.8801 MAE: 0.7216 RMSE: 0.9381\n",
      "Val: 0.7349 MAE: 0.6675 RMSE: 0.8573\n",
      "Epoch 13 Step 3752: Train 0.5917 Reg: 0.9306\n",
      "Test: 0.8769 MAE: 0.7212 RMSE: 0.9364\n",
      "Val: 0.7360 MAE: 0.6666 RMSE: 0.8579\n",
      "Epoch 14 Step 4020: Train 0.5734 Reg: 0.9544\n",
      "Test: 0.8853 MAE: 0.7215 RMSE: 0.9409\n",
      "Val: 0.7442 MAE: 0.6695 RMSE: 0.8627\n",
      "Epoch 15 Step 4288: Train 0.5559 Reg: 0.9731\n",
      "Test: 0.8829 MAE: 0.7228 RMSE: 0.9396\n",
      "Val: 0.7506 MAE: 0.6725 RMSE: 0.8664\n",
      "Epoch 16 Step 4556: Train 0.5397 Reg: 0.9908\n",
      "Test: 0.8924 MAE: 0.7305 RMSE: 0.9447\n",
      "Val: 0.7646 MAE: 0.6801 RMSE: 0.8744\n",
      "Epoch 17 Step 4824: Train 0.5206 Reg: 1.0025\n",
      "Test: 0.9229 MAE: 0.7331 RMSE: 0.9607\n",
      "Val: 0.7765 MAE: 0.6818 RMSE: 0.8812\n",
      "Epoch 18 Step 5092: Train 0.5039 Reg: 1.0145\n",
      "Test: 0.9236 MAE: 0.7473 RMSE: 0.9610\n",
      "Val: 0.7878 MAE: 0.6853 RMSE: 0.8876\n",
      "Epoch 19 Step 5360: Train 0.4854 Reg: 1.0258\n",
      "Test: 0.9286 MAE: 0.7420 RMSE: 0.9636\n",
      "Val: 0.8050 MAE: 0.6909 RMSE: 0.8972\n",
      "Epoch 20 Step 5628: Train 0.4687 Reg: 1.0234\n",
      "Test: 0.9467 MAE: 0.7493 RMSE: 0.9730\n",
      "Val: 0.8234 MAE: 0.6982 RMSE: 0.9074\n",
      "Epoch 21 Step 5896: Train 0.4535 Reg: 1.0198\n",
      "Test: 0.9127 MAE: 0.7305 RMSE: 0.9553\n",
      "Val: 0.8308 MAE: 0.7011 RMSE: 0.9115\n",
      "Epoch 22 Step 6164: Train 0.4382 Reg: 1.0132\n",
      "Test: 0.9861 MAE: 0.7569 RMSE: 0.9930\n",
      "Val: 0.8432 MAE: 0.7031 RMSE: 0.9182\n",
      "Epoch 23 Step 6432: Train 0.4270 Reg: 1.0009\n",
      "Test: 0.9567 MAE: 0.7490 RMSE: 0.9781\n",
      "Val: 0.8515 MAE: 0.7072 RMSE: 0.9228\n",
      "Epoch 24 Step 6700: Train 0.4147 Reg: 0.9906\n",
      "Test: 0.9883 MAE: 0.7594 RMSE: 0.9941\n",
      "Val: 0.8671 MAE: 0.7103 RMSE: 0.9312\n",
      "Epoch 25 Step 6968: Train 0.4047 Reg: 0.9769\n",
      "Test: 1.0123 MAE: 0.7653 RMSE: 1.0061\n",
      "Val: 0.8928 MAE: 0.7201 RMSE: 0.9449\n",
      "Epoch 26 Step 7236: Train 0.3942 Reg: 0.9636\n",
      "Test: 1.0623 MAE: 0.7867 RMSE: 1.0307\n",
      "Val: 0.8988 MAE: 0.7210 RMSE: 0.9480\n",
      "Epoch 27 Step 7504: Train 0.3858 Reg: 0.9478\n",
      "Test: 1.0745 MAE: 0.7831 RMSE: 1.0366\n",
      "Val: 0.9080 MAE: 0.7256 RMSE: 0.9529\n",
      "Epoch 28 Step 7772: Train 0.3779 Reg: 0.9313\n",
      "Test: 1.0486 MAE: 0.7701 RMSE: 1.0240\n",
      "Val: 0.9173 MAE: 0.7285 RMSE: 0.9577\n",
      "Epoch 29 Step 8040: Train 0.3711 Reg: 0.9167\n",
      "Test: 1.0882 MAE: 0.7906 RMSE: 1.0432\n",
      "Val: 0.9256 MAE: 0.7326 RMSE: 0.9621\n",
      "Epoch 30 Step 8308: Train 0.3636 Reg: 0.9018\n",
      "Test: 1.1127 MAE: 0.7961 RMSE: 1.0548\n",
      "Val: 0.9373 MAE: 0.7357 RMSE: 0.9681\n",
      "Epoch 31 Step 8576: Train 0.3572 Reg: 0.8861\n",
      "Test: 1.1020 MAE: 0.7932 RMSE: 1.0497\n",
      "Val: 0.9432 MAE: 0.7385 RMSE: 0.9712\n",
      "Epoch 32 Step 8844: Train 0.3507 Reg: 0.8708\n",
      "Test: 1.1016 MAE: 0.7884 RMSE: 1.0496\n",
      "Val: 0.9615 MAE: 0.7440 RMSE: 0.9806\n",
      "Epoch 33 Step 9112: Train 0.3458 Reg: 0.8570\n",
      "Test: 1.1628 MAE: 0.8106 RMSE: 1.0783\n",
      "Val: 0.9690 MAE: 0.7476 RMSE: 0.9844\n",
      "Epoch 34 Step 9380: Train 0.3404 Reg: 0.8435\n",
      "Test: 1.1591 MAE: 0.8129 RMSE: 1.0766\n",
      "Val: 0.9799 MAE: 0.7522 RMSE: 0.9899\n",
      "Epoch 35 Step 9648: Train 0.3344 Reg: 0.8295\n",
      "Test: 1.1892 MAE: 0.8170 RMSE: 1.0905\n",
      "Val: 0.9980 MAE: 0.7581 RMSE: 0.9990\n",
      "Epoch 36 Step 9916: Train 0.3296 Reg: 0.8175\n",
      "Test: 1.1758 MAE: 0.8181 RMSE: 1.0843\n",
      "Val: 0.9841 MAE: 0.7544 RMSE: 0.9920\n",
      "Epoch 37 Step 10184: Train 0.3247 Reg: 0.8046\n",
      "Test: 1.2180 MAE: 0.8307 RMSE: 1.1036\n",
      "Val: 0.9958 MAE: 0.7561 RMSE: 0.9979\n",
      "Epoch 38 Step 10452: Train 0.3200 Reg: 0.7923\n",
      "Test: 1.2072 MAE: 0.8277 RMSE: 1.0987\n",
      "Val: 1.0092 MAE: 0.7616 RMSE: 1.0046\n",
      "Epoch 39 Step 10720: Train 0.3153 Reg: 0.7809\n",
      "Test: 1.2443 MAE: 0.8375 RMSE: 1.1155\n",
      "Val: 1.0150 MAE: 0.7622 RMSE: 1.0075\n",
      "Epoch 40 Step 10988: Train 0.3109 Reg: 0.7694\n",
      "Test: 1.2351 MAE: 0.8334 RMSE: 1.1114\n",
      "Val: 1.0229 MAE: 0.7651 RMSE: 1.0114\n",
      "Epoch 41 Step 11256: Train 0.3066 Reg: 0.7590\n",
      "Test: 1.2369 MAE: 0.8360 RMSE: 1.1122\n",
      "Val: 1.0303 MAE: 0.7676 RMSE: 1.0150\n",
      "Epoch 42 Step 11524: Train 0.3028 Reg: 0.7482\n",
      "Test: 1.2284 MAE: 0.8288 RMSE: 1.1083\n",
      "Val: 1.0349 MAE: 0.7695 RMSE: 1.0173\n",
      "Epoch 43 Step 11792: Train 0.2987 Reg: 0.7382\n",
      "Test: 1.2394 MAE: 0.8343 RMSE: 1.1133\n",
      "Val: 1.0553 MAE: 0.7777 RMSE: 1.0273\n",
      "Epoch 44 Step 12060: Train 0.2953 Reg: 0.7287\n",
      "Test: 1.2610 MAE: 0.8392 RMSE: 1.1229\n",
      "Val: 1.0492 MAE: 0.7733 RMSE: 1.0243\n",
      "Epoch 45 Step 12328: Train 0.2912 Reg: 0.7194\n",
      "Test: 1.2432 MAE: 0.8389 RMSE: 1.1150\n",
      "Val: 1.0629 MAE: 0.7797 RMSE: 1.0310\n",
      "Epoch 46 Step 12596: Train 0.2876 Reg: 0.7109\n",
      "Test: 1.2702 MAE: 0.8441 RMSE: 1.1270\n",
      "Val: 1.0679 MAE: 0.7814 RMSE: 1.0334\n",
      "Epoch 47 Step 12864: Train 0.2845 Reg: 0.7018\n",
      "Test: 1.2819 MAE: 0.8466 RMSE: 1.1322\n",
      "Val: 1.0773 MAE: 0.7838 RMSE: 1.0379\n",
      "Epoch 48 Step 13132: Train 0.2812 Reg: 0.6938\n",
      "Test: 1.2883 MAE: 0.8497 RMSE: 1.1350\n",
      "Val: 1.0764 MAE: 0.7841 RMSE: 1.0375\n",
      "Epoch 49 Step 13400: Train 0.2781 Reg: 0.6863\n",
      "Test: 1.2905 MAE: 0.8537 RMSE: 1.1360\n",
      "Val: 1.0805 MAE: 0.7845 RMSE: 1.0395\n",
      "Epoch 50 Step 13668: Train 0.2754 Reg: 0.6784\n",
      "Test: 1.2896 MAE: 0.8504 RMSE: 1.1356\n",
      "Val: 1.0929 MAE: 0.7902 RMSE: 1.0454\n",
      "Epoch 51 Step 13936: Train 0.2725 Reg: 0.6712\n",
      "Test: 1.2939 MAE: 0.8518 RMSE: 1.1375\n",
      "Val: 1.1016 MAE: 0.7918 RMSE: 1.0496\n",
      "Epoch 52 Step 14204: Train 0.2698 Reg: 0.6645\n",
      "Test: 1.3025 MAE: 0.8484 RMSE: 1.1413\n",
      "Val: 1.0990 MAE: 0.7904 RMSE: 1.0483\n",
      "Epoch 53 Step 14472: Train 0.2671 Reg: 0.6582\n",
      "Test: 1.3170 MAE: 0.8610 RMSE: 1.1476\n",
      "Val: 1.1188 MAE: 0.7984 RMSE: 1.0577\n",
      "Epoch 54 Step 14740: Train 0.2646 Reg: 0.6519\n",
      "Test: 1.3378 MAE: 0.8630 RMSE: 1.1566\n",
      "Val: 1.1249 MAE: 0.8001 RMSE: 1.0606\n",
      "Epoch 55 Step 15008: Train 0.2622 Reg: 0.6458\n",
      "Test: 1.3212 MAE: 0.8569 RMSE: 1.1494\n",
      "Val: 1.1224 MAE: 0.7991 RMSE: 1.0594\n",
      "Epoch 56 Step 15276: Train 0.2598 Reg: 0.6402\n",
      "Test: 1.3328 MAE: 0.8649 RMSE: 1.1545\n",
      "Val: 1.1326 MAE: 0.8030 RMSE: 1.0642\n",
      "Epoch 57 Step 15544: Train 0.2577 Reg: 0.6347\n",
      "Test: 1.3270 MAE: 0.8625 RMSE: 1.1520\n",
      "Val: 1.1385 MAE: 0.8044 RMSE: 1.0670\n",
      "Epoch 58 Step 15812: Train 0.2556 Reg: 0.6294\n",
      "Test: 1.3390 MAE: 0.8649 RMSE: 1.1572\n",
      "Val: 1.1422 MAE: 0.8059 RMSE: 1.0688\n",
      "Epoch 59 Step 16080: Train 0.2536 Reg: 0.6245\n",
      "Test: 1.3409 MAE: 0.8666 RMSE: 1.1580\n",
      "Val: 1.1428 MAE: 0.8060 RMSE: 1.0690\n",
      "Epoch 60 Step 16348: Train 0.2517 Reg: 0.6198\n",
      "Test: 1.3597 MAE: 0.8676 RMSE: 1.1661\n",
      "Val: 1.1526 MAE: 0.8093 RMSE: 1.0736\n",
      "Epoch 61 Step 16616: Train 0.2498 Reg: 0.6152\n",
      "Test: 1.3641 MAE: 0.8668 RMSE: 1.1679\n",
      "Val: 1.1520 MAE: 0.8083 RMSE: 1.0733\n",
      "Epoch 62 Step 16884: Train 0.2479 Reg: 0.6111\n",
      "Test: 1.3619 MAE: 0.8664 RMSE: 1.1670\n",
      "Val: 1.1553 MAE: 0.8097 RMSE: 1.0749\n",
      "Epoch 63 Step 17152: Train 0.2462 Reg: 0.6069\n",
      "Test: 1.3670 MAE: 0.8708 RMSE: 1.1692\n",
      "Val: 1.1624 MAE: 0.8120 RMSE: 1.0781\n",
      "Epoch 64 Step 17420: Train 0.2445 Reg: 0.6031\n",
      "Test: 1.3712 MAE: 0.8685 RMSE: 1.1710\n",
      "Val: 1.1704 MAE: 0.8145 RMSE: 1.0818\n",
      "Epoch 65 Step 17688: Train 0.2431 Reg: 0.5994\n",
      "Test: 1.3809 MAE: 0.8733 RMSE: 1.1751\n",
      "Val: 1.1777 MAE: 0.8172 RMSE: 1.0852\n",
      "Epoch 66 Step 17956: Train 0.2416 Reg: 0.5957\n",
      "Test: 1.3832 MAE: 0.8745 RMSE: 1.1761\n",
      "Val: 1.1805 MAE: 0.8178 RMSE: 1.0865\n",
      "Epoch 67 Step 18224: Train 0.2401 Reg: 0.5925\n",
      "Test: 1.3934 MAE: 0.8759 RMSE: 1.1804\n",
      "Val: 1.1847 MAE: 0.8190 RMSE: 1.0885\n",
      "Epoch 68 Step 18492: Train 0.2387 Reg: 0.5891\n",
      "Test: 1.3917 MAE: 0.8791 RMSE: 1.1797\n",
      "Val: 1.1868 MAE: 0.8200 RMSE: 1.0894\n",
      "Epoch 69 Step 18760: Train 0.2374 Reg: 0.5861\n",
      "Test: 1.3914 MAE: 0.8760 RMSE: 1.1796\n",
      "Val: 1.1912 MAE: 0.8215 RMSE: 1.0914\n",
      "Epoch 70 Step 19028: Train 0.2362 Reg: 0.5832\n",
      "Test: 1.3954 MAE: 0.8772 RMSE: 1.1813\n",
      "Val: 1.1957 MAE: 0.8227 RMSE: 1.0935\n",
      "Epoch 71 Step 19296: Train 0.2349 Reg: 0.5804\n",
      "Test: 1.4091 MAE: 0.8805 RMSE: 1.1871\n",
      "Val: 1.1925 MAE: 0.8211 RMSE: 1.0920\n",
      "Epoch 72 Step 19564: Train 0.2338 Reg: 0.5777\n",
      "Test: 1.4078 MAE: 0.8809 RMSE: 1.1865\n",
      "Val: 1.2001 MAE: 0.8239 RMSE: 1.0955\n",
      "Epoch 73 Step 19832: Train 0.2328 Reg: 0.5751\n",
      "Test: 1.4151 MAE: 0.8842 RMSE: 1.1896\n",
      "Val: 1.2016 MAE: 0.8244 RMSE: 1.0962\n",
      "Epoch 74 Step 20100: Train 0.2317 Reg: 0.5728\n",
      "Test: 1.4128 MAE: 0.8815 RMSE: 1.1886\n",
      "Val: 1.2052 MAE: 0.8254 RMSE: 1.0978\n",
      "Epoch 75 Step 20368: Train 0.2308 Reg: 0.5705\n",
      "Test: 1.4190 MAE: 0.8852 RMSE: 1.1912\n",
      "Val: 1.2103 MAE: 0.8272 RMSE: 1.1001\n",
      "Epoch 76 Step 20636: Train 0.2298 Reg: 0.5683\n",
      "Test: 1.4239 MAE: 0.8864 RMSE: 1.1933\n",
      "Val: 1.2117 MAE: 0.8274 RMSE: 1.1008\n",
      "Epoch 77 Step 20904: Train 0.2289 Reg: 0.5662\n",
      "Test: 1.4295 MAE: 0.8893 RMSE: 1.1956\n",
      "Val: 1.2120 MAE: 0.8275 RMSE: 1.1009\n",
      "Epoch 78 Step 21172: Train 0.2280 Reg: 0.5642\n",
      "Test: 1.4314 MAE: 0.8898 RMSE: 1.1964\n",
      "Val: 1.2177 MAE: 0.8294 RMSE: 1.1035\n",
      "Epoch 79 Step 21440: Train 0.2273 Reg: 0.5623\n",
      "Test: 1.4350 MAE: 0.8905 RMSE: 1.1979\n",
      "Val: 1.2172 MAE: 0.8290 RMSE: 1.1033\n",
      "Epoch 80 Step 21708: Train 0.2264 Reg: 0.5605\n",
      "Test: 1.4396 MAE: 0.8926 RMSE: 1.1998\n",
      "Val: 1.2240 MAE: 0.8315 RMSE: 1.1064\n",
      "Epoch 81 Step 21976: Train 0.2257 Reg: 0.5588\n",
      "Test: 1.4425 MAE: 0.8926 RMSE: 1.2011\n",
      "Val: 1.2237 MAE: 0.8312 RMSE: 1.1062\n",
      "Epoch 82 Step 22244: Train 0.2250 Reg: 0.5572\n",
      "Test: 1.4438 MAE: 0.8936 RMSE: 1.2016\n",
      "Val: 1.2300 MAE: 0.8334 RMSE: 1.1091\n",
      "Epoch 83 Step 22512: Train 0.2243 Reg: 0.5555\n",
      "Test: 1.4412 MAE: 0.8931 RMSE: 1.2005\n",
      "Val: 1.2233 MAE: 0.8310 RMSE: 1.1060\n",
      "Epoch 84 Step 22780: Train 0.2237 Reg: 0.5541\n",
      "Test: 1.4511 MAE: 0.8946 RMSE: 1.2046\n",
      "Val: 1.2312 MAE: 0.8336 RMSE: 1.1096\n",
      "Epoch 85 Step 23048: Train 0.2230 Reg: 0.5526\n",
      "Test: 1.4488 MAE: 0.8946 RMSE: 1.2037\n",
      "Val: 1.2306 MAE: 0.8332 RMSE: 1.1093\n",
      "Epoch 86 Step 23316: Train 0.2225 Reg: 0.5513\n",
      "Test: 1.4515 MAE: 0.8955 RMSE: 1.2048\n",
      "Val: 1.2355 MAE: 0.8351 RMSE: 1.1115\n",
      "Epoch 87 Step 23584: Train 0.2219 Reg: 0.5500\n",
      "Test: 1.4589 MAE: 0.8976 RMSE: 1.2078\n",
      "Val: 1.2398 MAE: 0.8365 RMSE: 1.1135\n",
      "Epoch 88 Step 23852: Train 0.2214 Reg: 0.5488\n",
      "Test: 1.4559 MAE: 0.8967 RMSE: 1.2066\n",
      "Val: 1.2396 MAE: 0.8364 RMSE: 1.1134\n",
      "Epoch 89 Step 24120: Train 0.2209 Reg: 0.5476\n",
      "Test: 1.4537 MAE: 0.8964 RMSE: 1.2057\n",
      "Val: 1.2363 MAE: 0.8350 RMSE: 1.1119\n",
      "Epoch 90 Step 24388: Train 0.2204 Reg: 0.5465\n",
      "Test: 1.4528 MAE: 0.8960 RMSE: 1.2053\n",
      "Val: 1.2378 MAE: 0.8356 RMSE: 1.1126\n",
      "Epoch 91 Step 24656: Train 0.2200 Reg: 0.5454\n",
      "Test: 1.4603 MAE: 0.8981 RMSE: 1.2084\n",
      "Val: 1.2426 MAE: 0.8371 RMSE: 1.1147\n",
      "Epoch 92 Step 24924: Train 0.2195 Reg: 0.5445\n",
      "Test: 1.4605 MAE: 0.8982 RMSE: 1.2085\n",
      "Val: 1.2428 MAE: 0.8371 RMSE: 1.1148\n",
      "Epoch 93 Step 25192: Train 0.2191 Reg: 0.5435\n",
      "Test: 1.4560 MAE: 0.8974 RMSE: 1.2066\n",
      "Val: 1.2400 MAE: 0.8361 RMSE: 1.1135\n",
      "Epoch 94 Step 25460: Train 0.2188 Reg: 0.5426\n",
      "Test: 1.4631 MAE: 0.8996 RMSE: 1.2096\n",
      "Val: 1.2468 MAE: 0.8385 RMSE: 1.1166\n",
      "Epoch 95 Step 25728: Train 0.2183 Reg: 0.5417\n",
      "Test: 1.4665 MAE: 0.9005 RMSE: 1.2110\n",
      "Val: 1.2503 MAE: 0.8397 RMSE: 1.1182\n",
      "Epoch 96 Step 25996: Train 0.2180 Reg: 0.5409\n",
      "Test: 1.4672 MAE: 0.9010 RMSE: 1.2113\n",
      "Val: 1.2504 MAE: 0.8397 RMSE: 1.1182\n",
      "Epoch 97 Step 26264: Train 0.2177 Reg: 0.5401\n",
      "Test: 1.4665 MAE: 0.9011 RMSE: 1.2110\n",
      "Val: 1.2490 MAE: 0.8392 RMSE: 1.1176\n",
      "Epoch 98 Step 26532: Train 0.2174 Reg: 0.5393\n",
      "Test: 1.4692 MAE: 0.9014 RMSE: 1.2121\n",
      "Val: 1.2486 MAE: 0.8390 RMSE: 1.1174\n",
      "Epoch 99 Step 26800: Train 0.2170 Reg: 0.5386\n",
      "Test: 1.4690 MAE: 0.9011 RMSE: 1.2120\n",
      "Val: 1.2499 MAE: 0.8394 RMSE: 1.1180\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 288576/19100\n",
      "test set size: support/query 322/809\n",
      "Epoch 0: TrainLoss 1.0484 RecLoss: 0.0000 (left: 0:12:25)\n",
      "TestLoss: 1.0655 MAE: 0.8165 RMSE: 1.0322\n",
      "ValLoss: 1.1115 MAE: 0.8411 RMSE: 1.0543\n",
      "Epoch 1: TrainLoss 1.0179 RecLoss: 0.0000 (left: 0:10:47)\n",
      "TestLoss: 1.0532 MAE: 0.8137 RMSE: 1.0263\n",
      "ValLoss: 1.0932 MAE: 0.8373 RMSE: 1.0456\n",
      "Epoch 2: TrainLoss 0.9981 RecLoss: 0.0000 (left: 0:10:17)\n",
      "TestLoss: 1.0390 MAE: 0.8119 RMSE: 1.0193\n",
      "ValLoss: 1.0757 MAE: 0.8327 RMSE: 1.0372\n",
      "Epoch 3: TrainLoss 0.9873 RecLoss: 0.0000 (left: 0:09:54)\n",
      "TestLoss: 1.0405 MAE: 0.8214 RMSE: 1.0200\n",
      "ValLoss: 1.0737 MAE: 0.8385 RMSE: 1.0362\n",
      "Epoch 4: TrainLoss 0.9710 RecLoss: 0.0000 (left: 0:09:34)\n",
      "TestLoss: 1.0223 MAE: 0.8059 RMSE: 1.0111\n",
      "ValLoss: 1.0594 MAE: 0.8268 RMSE: 1.0293\n",
      "Epoch 5: TrainLoss 0.9593 RecLoss: 0.0000 (left: 0:09:24)\n",
      "TestLoss: 1.0155 MAE: 0.8025 RMSE: 1.0077\n",
      "ValLoss: 1.0519 MAE: 0.8225 RMSE: 1.0256\n",
      "Epoch 6: TrainLoss 0.9492 RecLoss: 0.0000 (left: 0:09:18)\n",
      "TestLoss: 1.0098 MAE: 0.7996 RMSE: 1.0049\n",
      "ValLoss: 1.0469 MAE: 0.8213 RMSE: 1.0232\n",
      "Epoch 7: TrainLoss 0.9415 RecLoss: 0.0000 (left: 0:09:05)\n",
      "TestLoss: 1.0051 MAE: 0.7980 RMSE: 1.0025\n",
      "ValLoss: 1.0406 MAE: 0.8187 RMSE: 1.0201\n",
      "Epoch 8: TrainLoss 0.9356 RecLoss: 0.0000 (left: 0:09:08)\n",
      "TestLoss: 1.0032 MAE: 0.7938 RMSE: 1.0016\n",
      "ValLoss: 1.0408 MAE: 0.8160 RMSE: 1.0202\n",
      "Epoch 9: TrainLoss 0.9292 RecLoss: 0.0000 (left: 0:09:11)\n",
      "TestLoss: 1.0057 MAE: 0.7896 RMSE: 1.0028\n",
      "ValLoss: 1.0445 MAE: 0.8123 RMSE: 1.0220\n",
      "Epoch 10: TrainLoss 0.9245 RecLoss: 0.0000 (left: 0:09:06)\n",
      "TestLoss: 1.0001 MAE: 0.7866 RMSE: 1.0001\n",
      "ValLoss: 1.0419 MAE: 0.8103 RMSE: 1.0207\n",
      "Epoch 11: TrainLoss 0.9209 RecLoss: 0.0000 (left: 0:08:58)\n",
      "TestLoss: 0.9988 MAE: 0.7889 RMSE: 0.9994\n",
      "ValLoss: 1.0394 MAE: 0.8120 RMSE: 1.0195\n",
      "Epoch 12: TrainLoss 0.9176 RecLoss: 0.0000 (left: 0:08:53)\n",
      "TestLoss: 0.9987 MAE: 0.8010 RMSE: 0.9993\n",
      "ValLoss: 1.0308 MAE: 0.8188 RMSE: 1.0153\n",
      "Epoch 13: TrainLoss 0.9129 RecLoss: 0.0000 (left: 0:08:47)\n",
      "TestLoss: 1.0024 MAE: 0.8049 RMSE: 1.0012\n",
      "ValLoss: 1.0322 MAE: 0.8209 RMSE: 1.0160\n",
      "Epoch 14: TrainLoss 0.9136 RecLoss: 0.0000 (left: 0:08:43)\n",
      "TestLoss: 0.9940 MAE: 0.7910 RMSE: 0.9970\n",
      "ValLoss: 1.0302 MAE: 0.8120 RMSE: 1.0150\n",
      "Epoch 15: TrainLoss 0.9059 RecLoss: 0.0000 (left: 0:08:36)\n",
      "TestLoss: 0.9929 MAE: 0.7884 RMSE: 0.9964\n",
      "ValLoss: 1.0331 MAE: 0.8110 RMSE: 1.0164\n",
      "Epoch 16: TrainLoss 0.9027 RecLoss: 0.0000 (left: 0:08:30)\n",
      "TestLoss: 0.9943 MAE: 0.7915 RMSE: 0.9971\n",
      "ValLoss: 1.0309 MAE: 0.8129 RMSE: 1.0153\n",
      "Epoch 17: TrainLoss 0.9009 RecLoss: 0.0000 (left: 0:08:26)\n",
      "TestLoss: 0.9943 MAE: 0.7914 RMSE: 0.9972\n",
      "ValLoss: 1.0316 MAE: 0.8130 RMSE: 1.0157\n",
      "Epoch 18: TrainLoss 0.8995 RecLoss: 0.0000 (left: 0:08:20)\n",
      "TestLoss: 0.9947 MAE: 0.7944 RMSE: 0.9973\n",
      "ValLoss: 1.0309 MAE: 0.8147 RMSE: 1.0153\n",
      "Epoch 19: TrainLoss 0.8994 RecLoss: 0.0000 (left: 0:08:14)\n",
      "TestLoss: 0.9948 MAE: 0.7872 RMSE: 0.9974\n",
      "ValLoss: 1.0363 MAE: 0.8105 RMSE: 1.0180\n",
      "Epoch 20: TrainLoss 0.8979 RecLoss: 0.0000 (left: 0:08:10)\n",
      "TestLoss: 0.9972 MAE: 0.7995 RMSE: 0.9986\n",
      "ValLoss: 1.0319 MAE: 0.8184 RMSE: 1.0158\n",
      "Epoch 21: TrainLoss 0.8957 RecLoss: 0.0000 (left: 0:08:04)\n",
      "TestLoss: 0.9929 MAE: 0.7939 RMSE: 0.9965\n",
      "ValLoss: 1.0304 MAE: 0.8147 RMSE: 1.0151\n",
      "Epoch 22: TrainLoss 0.8963 RecLoss: 0.0000 (left: 0:07:55)\n",
      "TestLoss: 0.9948 MAE: 0.7932 RMSE: 0.9974\n",
      "ValLoss: 1.0322 MAE: 0.8134 RMSE: 1.0160\n",
      "Epoch 23: TrainLoss 0.8965 RecLoss: 0.0000 (left: 0:07:46)\n",
      "TestLoss: 0.9940 MAE: 0.7918 RMSE: 0.9970\n",
      "ValLoss: 1.0347 MAE: 0.8141 RMSE: 1.0172\n",
      "Epoch 24: TrainLoss 0.8935 RecLoss: 0.0000 (left: 0:07:38)\n",
      "TestLoss: 0.9942 MAE: 0.7925 RMSE: 0.9971\n",
      "ValLoss: 1.0334 MAE: 0.8136 RMSE: 1.0165\n",
      "Epoch 25: TrainLoss 0.8926 RecLoss: 0.0000 (left: 0:07:30)\n",
      "TestLoss: 0.9941 MAE: 0.7927 RMSE: 0.9971\n",
      "ValLoss: 1.0324 MAE: 0.8130 RMSE: 1.0161\n",
      "Epoch 26: TrainLoss 0.8934 RecLoss: 0.0000 (left: 0:07:22)\n",
      "TestLoss: 0.9979 MAE: 0.7973 RMSE: 0.9990\n",
      "ValLoss: 1.0346 MAE: 0.8169 RMSE: 1.0172\n",
      "Epoch 27: TrainLoss 0.8912 RecLoss: 0.0000 (left: 0:07:16)\n",
      "TestLoss: 0.9948 MAE: 0.7903 RMSE: 0.9974\n",
      "ValLoss: 1.0383 MAE: 0.8139 RMSE: 1.0190\n",
      "Epoch 28: TrainLoss 0.8909 RecLoss: 0.0000 (left: 0:07:10)\n",
      "TestLoss: 0.9953 MAE: 0.7914 RMSE: 0.9977\n",
      "ValLoss: 1.0367 MAE: 0.8135 RMSE: 1.0182\n",
      "Epoch 29: TrainLoss 0.8904 RecLoss: 0.0000 (left: 0:07:04)\n",
      "TestLoss: 0.9962 MAE: 0.7930 RMSE: 0.9981\n",
      "ValLoss: 1.0369 MAE: 0.8147 RMSE: 1.0183\n",
      "Epoch 30: TrainLoss 0.8894 RecLoss: 0.0000 (left: 0:06:59)\n",
      "TestLoss: 0.9980 MAE: 0.7863 RMSE: 0.9990\n",
      "ValLoss: 1.0462 MAE: 0.8117 RMSE: 1.0229\n",
      "Epoch 31: TrainLoss 0.8903 RecLoss: 0.0000 (left: 0:06:53)\n",
      "TestLoss: 0.9970 MAE: 0.7942 RMSE: 0.9985\n",
      "ValLoss: 1.0367 MAE: 0.8149 RMSE: 1.0182\n",
      "Epoch 32: TrainLoss 0.8893 RecLoss: 0.0000 (left: 0:06:47)\n",
      "TestLoss: 0.9992 MAE: 0.7969 RMSE: 0.9996\n",
      "ValLoss: 1.0385 MAE: 0.8177 RMSE: 1.0191\n",
      "Epoch 33: TrainLoss 0.8894 RecLoss: 0.0000 (left: 0:06:42)\n",
      "TestLoss: 0.9965 MAE: 0.7885 RMSE: 0.9982\n",
      "ValLoss: 1.0425 MAE: 0.8124 RMSE: 1.0210\n",
      "Epoch 34: TrainLoss 0.8886 RecLoss: 0.0000 (left: 0:06:36)\n",
      "TestLoss: 1.0031 MAE: 0.7848 RMSE: 1.0016\n",
      "ValLoss: 1.0510 MAE: 0.8099 RMSE: 1.0252\n",
      "Epoch 35: TrainLoss 0.8885 RecLoss: 0.0000 (left: 0:06:30)\n",
      "TestLoss: 0.9989 MAE: 0.7967 RMSE: 0.9994\n",
      "ValLoss: 1.0389 MAE: 0.8169 RMSE: 1.0193\n",
      "Epoch 36: TrainLoss 0.8882 RecLoss: 0.0000 (left: 0:06:23)\n",
      "TestLoss: 0.9998 MAE: 0.7880 RMSE: 0.9999\n",
      "ValLoss: 1.0445 MAE: 0.8112 RMSE: 1.0220\n",
      "Epoch 37: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:06:17)\n",
      "TestLoss: 0.9980 MAE: 0.7939 RMSE: 0.9990\n",
      "ValLoss: 1.0398 MAE: 0.8152 RMSE: 1.0197\n",
      "Epoch 38: TrainLoss 0.8882 RecLoss: 0.0000 (left: 0:06:11)\n",
      "TestLoss: 1.0018 MAE: 0.7998 RMSE: 1.0009\n",
      "ValLoss: 1.0422 MAE: 0.8201 RMSE: 1.0209\n",
      "Epoch 39: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:06:04)\n",
      "TestLoss: 1.0016 MAE: 0.7861 RMSE: 1.0008\n",
      "ValLoss: 1.0486 MAE: 0.8106 RMSE: 1.0240\n",
      "Epoch 40: TrainLoss 0.8890 RecLoss: 0.0000 (left: 0:05:58)\n",
      "TestLoss: 0.9987 MAE: 0.7898 RMSE: 0.9993\n",
      "ValLoss: 1.0435 MAE: 0.8127 RMSE: 1.0215\n",
      "Epoch 41: TrainLoss 0.8864 RecLoss: 0.0000 (left: 0:05:52)\n",
      "TestLoss: 1.0001 MAE: 0.7970 RMSE: 1.0001\n",
      "ValLoss: 1.0410 MAE: 0.8177 RMSE: 1.0203\n",
      "Epoch 42: TrainLoss 0.8870 RecLoss: 0.0000 (left: 0:05:46)\n",
      "TestLoss: 0.9989 MAE: 0.7903 RMSE: 0.9995\n",
      "ValLoss: 1.0431 MAE: 0.8132 RMSE: 1.0213\n",
      "Epoch 43: TrainLoss 0.8875 RecLoss: 0.0000 (left: 0:05:40)\n",
      "TestLoss: 0.9992 MAE: 0.7942 RMSE: 0.9996\n",
      "ValLoss: 1.0411 MAE: 0.8152 RMSE: 1.0204\n",
      "Epoch 44: TrainLoss 0.8874 RecLoss: 0.0000 (left: 0:05:33)\n",
      "TestLoss: 0.9987 MAE: 0.7893 RMSE: 0.9993\n",
      "ValLoss: 1.0449 MAE: 0.8129 RMSE: 1.0222\n",
      "Epoch 45: TrainLoss 0.8863 RecLoss: 0.0000 (left: 0:05:26)\n",
      "TestLoss: 0.9986 MAE: 0.7906 RMSE: 0.9993\n",
      "ValLoss: 1.0441 MAE: 0.8134 RMSE: 1.0218\n",
      "Epoch 46: TrainLoss 0.8860 RecLoss: 0.0000 (left: 0:05:21)\n",
      "TestLoss: 0.9997 MAE: 0.7924 RMSE: 0.9998\n",
      "ValLoss: 1.0427 MAE: 0.8140 RMSE: 1.0211\n",
      "Epoch 47: TrainLoss 0.8860 RecLoss: 0.0000 (left: 0:05:13)\n",
      "TestLoss: 0.9984 MAE: 0.7910 RMSE: 0.9992\n",
      "ValLoss: 1.0421 MAE: 0.8128 RMSE: 1.0208\n",
      "Epoch 48: TrainLoss 0.8867 RecLoss: 0.0000 (left: 0:05:07)\n",
      "TestLoss: 1.0093 MAE: 0.7849 RMSE: 1.0046\n",
      "ValLoss: 1.0597 MAE: 0.8114 RMSE: 1.0294\n",
      "Epoch 49: TrainLoss 0.8919 RecLoss: 0.0000 (left: 0:05:00)\n",
      "TestLoss: 1.0077 MAE: 0.8034 RMSE: 1.0038\n",
      "ValLoss: 1.0464 MAE: 0.8230 RMSE: 1.0229\n",
      "Epoch 50: TrainLoss 0.8866 RecLoss: 0.0000 (left: 0:04:55)\n",
      "TestLoss: 1.0006 MAE: 0.7928 RMSE: 1.0003\n",
      "ValLoss: 1.0441 MAE: 0.8144 RMSE: 1.0218\n",
      "Epoch 51: TrainLoss 0.8854 RecLoss: 0.0000 (left: 0:04:48)\n",
      "TestLoss: 0.9998 MAE: 0.7910 RMSE: 0.9999\n",
      "ValLoss: 1.0452 MAE: 0.8137 RMSE: 1.0224\n",
      "Epoch 52: TrainLoss 0.8854 RecLoss: 0.0000 (left: 0:04:41)\n",
      "TestLoss: 1.0012 MAE: 0.7901 RMSE: 1.0006\n",
      "ValLoss: 1.0471 MAE: 0.8132 RMSE: 1.0233\n",
      "Epoch 53: TrainLoss 0.8853 RecLoss: 0.0000 (left: 0:04:35)\n",
      "TestLoss: 1.0000 MAE: 0.7902 RMSE: 1.0000\n",
      "ValLoss: 1.0453 MAE: 0.8131 RMSE: 1.0224\n",
      "Epoch 54: TrainLoss 0.8866 RecLoss: 0.0000 (left: 0:04:29)\n",
      "TestLoss: 1.0024 MAE: 0.7975 RMSE: 1.0012\n",
      "ValLoss: 1.0435 MAE: 0.8178 RMSE: 1.0215\n",
      "Epoch 55: TrainLoss 0.8862 RecLoss: 0.0000 (left: 0:04:23)\n",
      "TestLoss: 1.0015 MAE: 0.7917 RMSE: 1.0008\n",
      "ValLoss: 1.0453 MAE: 0.8139 RMSE: 1.0224\n",
      "Epoch 56: TrainLoss 0.8849 RecLoss: 0.0000 (left: 0:04:17)\n",
      "TestLoss: 1.0014 MAE: 0.7951 RMSE: 1.0007\n",
      "ValLoss: 1.0457 MAE: 0.8169 RMSE: 1.0226\n",
      "Epoch 57: TrainLoss 0.8852 RecLoss: 0.0000 (left: 0:04:11)\n",
      "TestLoss: 1.0014 MAE: 0.7884 RMSE: 1.0007\n",
      "ValLoss: 1.0484 MAE: 0.8121 RMSE: 1.0239\n",
      "Epoch 58: TrainLoss 0.8862 RecLoss: 0.0000 (left: 0:04:06)\n",
      "TestLoss: 1.0016 MAE: 0.7900 RMSE: 1.0008\n",
      "ValLoss: 1.0470 MAE: 0.8124 RMSE: 1.0232\n",
      "Epoch 59: TrainLoss 0.8854 RecLoss: 0.0000 (left: 0:04:00)\n",
      "TestLoss: 1.0011 MAE: 0.7901 RMSE: 1.0005\n",
      "ValLoss: 1.0473 MAE: 0.8130 RMSE: 1.0234\n",
      "Epoch 60: TrainLoss 0.8854 RecLoss: 0.0000 (left: 0:03:53)\n",
      "TestLoss: 1.0024 MAE: 0.7954 RMSE: 1.0012\n",
      "ValLoss: 1.0453 MAE: 0.8166 RMSE: 1.0224\n",
      "Epoch 61: TrainLoss 0.8869 RecLoss: 0.0000 (left: 0:03:47)\n",
      "TestLoss: 1.0023 MAE: 0.7881 RMSE: 1.0012\n",
      "ValLoss: 1.0497 MAE: 0.8122 RMSE: 1.0245\n",
      "Epoch 62: TrainLoss 0.8846 RecLoss: 0.0000 (left: 0:03:41)\n",
      "TestLoss: 1.0020 MAE: 0.7944 RMSE: 1.0010\n",
      "ValLoss: 1.0453 MAE: 0.8156 RMSE: 1.0224\n",
      "Epoch 63: TrainLoss 0.8851 RecLoss: 0.0000 (left: 0:03:36)\n",
      "TestLoss: 1.0018 MAE: 0.7932 RMSE: 1.0009\n",
      "ValLoss: 1.0455 MAE: 0.8148 RMSE: 1.0225\n",
      "Epoch 64: TrainLoss 0.8855 RecLoss: 0.0000 (left: 0:03:30)\n",
      "TestLoss: 1.0040 MAE: 0.7883 RMSE: 1.0020\n",
      "ValLoss: 1.0527 MAE: 0.8129 RMSE: 1.0260\n",
      "Epoch 65: TrainLoss 0.8856 RecLoss: 0.0000 (left: 0:03:24)\n",
      "TestLoss: 1.0023 MAE: 0.7877 RMSE: 1.0011\n",
      "ValLoss: 1.0502 MAE: 0.8118 RMSE: 1.0248\n",
      "Epoch 66: TrainLoss 0.8848 RecLoss: 0.0000 (left: 0:03:19)\n",
      "TestLoss: 1.0020 MAE: 0.7912 RMSE: 1.0010\n",
      "ValLoss: 1.0466 MAE: 0.8134 RMSE: 1.0230\n",
      "Epoch 67: TrainLoss 0.8845 RecLoss: 0.0000 (left: 0:03:13)\n",
      "TestLoss: 1.0011 MAE: 0.7936 RMSE: 1.0006\n",
      "ValLoss: 1.0457 MAE: 0.8153 RMSE: 1.0226\n",
      "Epoch 68: TrainLoss 0.8846 RecLoss: 0.0000 (left: 0:03:07)\n",
      "TestLoss: 1.0016 MAE: 0.7914 RMSE: 1.0008\n",
      "ValLoss: 1.0462 MAE: 0.8135 RMSE: 1.0228\n",
      "Epoch 69: TrainLoss 0.8851 RecLoss: 0.0000 (left: 0:03:01)\n",
      "TestLoss: 1.0011 MAE: 0.7921 RMSE: 1.0005\n",
      "ValLoss: 1.0462 MAE: 0.8142 RMSE: 1.0228\n",
      "Epoch 70: TrainLoss 0.8856 RecLoss: 0.0000 (left: 0:02:55)\n",
      "TestLoss: 1.0026 MAE: 0.7902 RMSE: 1.0013\n",
      "ValLoss: 1.0485 MAE: 0.8129 RMSE: 1.0240\n",
      "Epoch 71: TrainLoss 0.8836 RecLoss: 0.0000 (left: 0:02:49)\n",
      "TestLoss: 1.0032 MAE: 0.7962 RMSE: 1.0016\n",
      "ValLoss: 1.0464 MAE: 0.8173 RMSE: 1.0229\n",
      "Epoch 72: TrainLoss 0.8841 RecLoss: 0.0000 (left: 0:02:43)\n",
      "TestLoss: 1.0041 MAE: 0.7885 RMSE: 1.0020\n",
      "ValLoss: 1.0517 MAE: 0.8122 RMSE: 1.0255\n",
      "Epoch 73: TrainLoss 0.8854 RecLoss: 0.0000 (left: 0:02:37)\n",
      "TestLoss: 1.0044 MAE: 0.7975 RMSE: 1.0022\n",
      "ValLoss: 1.0464 MAE: 0.8181 RMSE: 1.0230\n",
      "Epoch 74: TrainLoss 0.8847 RecLoss: 0.0000 (left: 0:02:31)\n",
      "TestLoss: 1.0023 MAE: 0.7930 RMSE: 1.0012\n",
      "ValLoss: 1.0464 MAE: 0.8148 RMSE: 1.0230\n",
      "Epoch 75: TrainLoss 0.8844 RecLoss: 0.0000 (left: 0:02:26)\n",
      "TestLoss: 1.0052 MAE: 0.7873 RMSE: 1.0026\n",
      "ValLoss: 1.0541 MAE: 0.8119 RMSE: 1.0267\n",
      "Epoch 76: TrainLoss 0.8844 RecLoss: 0.0000 (left: 0:02:20)\n",
      "TestLoss: 1.0028 MAE: 0.7911 RMSE: 1.0014\n",
      "ValLoss: 1.0482 MAE: 0.8135 RMSE: 1.0238\n",
      "Epoch 77: TrainLoss 0.8846 RecLoss: 0.0000 (left: 0:02:14)\n",
      "TestLoss: 1.0029 MAE: 0.7898 RMSE: 1.0014\n",
      "ValLoss: 1.0491 MAE: 0.8125 RMSE: 1.0242\n",
      "Epoch 78: TrainLoss 0.8847 RecLoss: 0.0000 (left: 0:02:08)\n",
      "TestLoss: 1.0022 MAE: 0.7885 RMSE: 1.0011\n",
      "ValLoss: 1.0503 MAE: 0.8124 RMSE: 1.0248\n",
      "Epoch 79: TrainLoss 0.8849 RecLoss: 0.0000 (left: 0:02:02)\n",
      "TestLoss: 1.0016 MAE: 0.7918 RMSE: 1.0008\n",
      "ValLoss: 1.0477 MAE: 0.8143 RMSE: 1.0236\n",
      "Epoch 80: TrainLoss 0.8840 RecLoss: 0.0000 (left: 0:01:56)\n",
      "TestLoss: 1.0036 MAE: 0.7880 RMSE: 1.0018\n",
      "ValLoss: 1.0521 MAE: 0.8123 RMSE: 1.0257\n",
      "Epoch 81: TrainLoss 0.8841 RecLoss: 0.0000 (left: 0:01:51)\n",
      "TestLoss: 1.0022 MAE: 0.7909 RMSE: 1.0011\n",
      "ValLoss: 1.0482 MAE: 0.8137 RMSE: 1.0238\n",
      "Epoch 82: TrainLoss 0.8866 RecLoss: 0.0000 (left: 0:01:45)\n",
      "TestLoss: 1.0106 MAE: 0.7854 RMSE: 1.0053\n",
      "ValLoss: 1.0621 MAE: 0.8118 RMSE: 1.0306\n",
      "Epoch 83: TrainLoss 0.8864 RecLoss: 0.0000 (left: 0:01:39)\n",
      "TestLoss: 1.0038 MAE: 0.7952 RMSE: 1.0019\n",
      "ValLoss: 1.0469 MAE: 0.8164 RMSE: 1.0232\n",
      "Epoch 84: TrainLoss 0.8851 RecLoss: 0.0000 (left: 0:01:33)\n",
      "TestLoss: 1.0019 MAE: 0.7907 RMSE: 1.0009\n",
      "ValLoss: 1.0494 MAE: 0.8138 RMSE: 1.0244\n",
      "Epoch 85: TrainLoss 0.8847 RecLoss: 0.0000 (left: 0:01:27)\n",
      "TestLoss: 1.0024 MAE: 0.7890 RMSE: 1.0012\n",
      "ValLoss: 1.0507 MAE: 0.8127 RMSE: 1.0250\n",
      "Epoch 86: TrainLoss 0.8847 RecLoss: 0.0000 (left: 0:01:22)\n",
      "TestLoss: 1.0071 MAE: 0.7865 RMSE: 1.0035\n",
      "ValLoss: 1.0571 MAE: 0.8117 RMSE: 1.0282\n",
      "Epoch 87: TrainLoss 0.8850 RecLoss: 0.0000 (left: 0:01:16)\n",
      "TestLoss: 1.0040 MAE: 0.7977 RMSE: 1.0020\n",
      "ValLoss: 1.0478 MAE: 0.8190 RMSE: 1.0236\n",
      "Epoch 88: TrainLoss 0.8846 RecLoss: 0.0000 (left: 0:01:10)\n",
      "TestLoss: 1.0034 MAE: 0.7909 RMSE: 1.0017\n",
      "ValLoss: 1.0487 MAE: 0.8130 RMSE: 1.0241\n",
      "Epoch 89: TrainLoss 0.8839 RecLoss: 0.0000 (left: 0:01:04)\n",
      "TestLoss: 1.0021 MAE: 0.7904 RMSE: 1.0011\n",
      "ValLoss: 1.0487 MAE: 0.8132 RMSE: 1.0241\n",
      "Epoch 90: TrainLoss 0.8838 RecLoss: 0.0000 (left: 0:00:58)\n",
      "TestLoss: 1.0028 MAE: 0.7942 RMSE: 1.0014\n",
      "ValLoss: 1.0487 MAE: 0.8166 RMSE: 1.0241\n",
      "Epoch 91: TrainLoss 0.8841 RecLoss: 0.0000 (left: 0:00:52)\n",
      "TestLoss: 1.0063 MAE: 0.7866 RMSE: 1.0031\n",
      "ValLoss: 1.0560 MAE: 0.8117 RMSE: 1.0276\n",
      "Epoch 92: TrainLoss 0.8855 RecLoss: 0.0000 (left: 0:00:46)\n",
      "TestLoss: 1.0027 MAE: 0.7919 RMSE: 1.0014\n",
      "ValLoss: 1.0492 MAE: 0.8149 RMSE: 1.0243\n",
      "Epoch 93: TrainLoss 0.8845 RecLoss: 0.0000 (left: 0:00:41)\n",
      "TestLoss: 1.0027 MAE: 0.7921 RMSE: 1.0014\n",
      "ValLoss: 1.0481 MAE: 0.8143 RMSE: 1.0238\n",
      "Epoch 94: TrainLoss 0.8851 RecLoss: 0.0000 (left: 0:00:35)\n",
      "TestLoss: 1.0042 MAE: 0.7878 RMSE: 1.0021\n",
      "ValLoss: 1.0533 MAE: 0.8122 RMSE: 1.0263\n",
      "Epoch 95: TrainLoss 0.8841 RecLoss: 0.0000 (left: 0:00:29)\n",
      "TestLoss: 1.0029 MAE: 0.7895 RMSE: 1.0014\n",
      "ValLoss: 1.0513 MAE: 0.8135 RMSE: 1.0253\n",
      "Epoch 96: TrainLoss 0.8841 RecLoss: 0.0000 (left: 0:00:23)\n",
      "TestLoss: 1.0023 MAE: 0.7890 RMSE: 1.0012\n",
      "ValLoss: 1.0503 MAE: 0.8125 RMSE: 1.0248\n",
      "Epoch 97: TrainLoss 0.8838 RecLoss: 0.0000 (left: 0:00:17)\n",
      "TestLoss: 1.0034 MAE: 0.7914 RMSE: 1.0017\n",
      "ValLoss: 1.0494 MAE: 0.8139 RMSE: 1.0244\n",
      "Epoch 98: TrainLoss 0.8838 RecLoss: 0.0000 (left: 0:00:11)\n",
      "TestLoss: 1.0036 MAE: 0.7883 RMSE: 1.0018\n",
      "ValLoss: 1.0517 MAE: 0.8123 RMSE: 1.0255\n",
      "Epoch 99: TrainLoss 0.8850 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 1.0021 MAE: 0.7908 RMSE: 1.0010\n",
      "ValLoss: 1.0488 MAE: 0.8137 RMSE: 1.0241\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 288576/19100\n",
      "test set size: support/query 322/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.7084 RMSE: 0.9233 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7910 RMSE: 0.9970 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7675 RMSE: 0.9766 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20% cur coreusers into IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 350454/19100\n",
      "test set size: support/query 1046/809\n",
      "Epoch 0 Step 326: Train 2.3744 Reg: 0.5801\n",
      "Test: 0.8841 MAE: 0.7485 RMSE: 0.9403\n",
      "Val: 0.8295 MAE: 0.7204 RMSE: 0.9108\n",
      "Epoch 1 Step 652: Train 0.8227 Reg: 0.4742\n",
      "Test: 0.8720 MAE: 0.7455 RMSE: 0.9338\n",
      "Val: 0.8162 MAE: 0.7159 RMSE: 0.9034\n",
      "Epoch 2 Step 978: Train 0.8162 Reg: 0.3923\n",
      "Test: 0.8831 MAE: 0.7473 RMSE: 0.9397\n",
      "Val: 0.8117 MAE: 0.7120 RMSE: 0.9010\n",
      "Epoch 3 Step 1304: Train 0.8133 Reg: 0.3389\n",
      "Test: 0.8575 MAE: 0.7363 RMSE: 0.9260\n",
      "Val: 0.8067 MAE: 0.7109 RMSE: 0.8982\n",
      "Epoch 4 Step 1630: Train 0.8103 Reg: 0.3066\n",
      "Test: 0.8620 MAE: 0.7369 RMSE: 0.9284\n",
      "Val: 0.8071 MAE: 0.7100 RMSE: 0.8984\n",
      "Epoch 5 Step 1956: Train 0.8064 Reg: 0.2876\n",
      "Test: 0.8742 MAE: 0.7433 RMSE: 0.9350\n",
      "Val: 0.8034 MAE: 0.7067 RMSE: 0.8963\n",
      "Epoch 6 Step 2282: Train 0.8025 Reg: 0.2758\n",
      "Test: 0.8604 MAE: 0.7388 RMSE: 0.9276\n",
      "Val: 0.7992 MAE: 0.7075 RMSE: 0.8940\n",
      "Epoch 7 Step 2608: Train 0.7960 Reg: 0.2701\n",
      "Test: 0.8504 MAE: 0.7321 RMSE: 0.9222\n",
      "Val: 0.7935 MAE: 0.7035 RMSE: 0.8908\n",
      "Epoch 8 Step 2934: Train 0.7887 Reg: 0.2694\n",
      "Test: 0.8536 MAE: 0.7333 RMSE: 0.9239\n",
      "Val: 0.7844 MAE: 0.6988 RMSE: 0.8857\n",
      "Epoch 9 Step 3260: Train 0.7804 Reg: 0.2688\n",
      "Test: 0.8416 MAE: 0.7262 RMSE: 0.9174\n",
      "Val: 0.7808 MAE: 0.6977 RMSE: 0.8836\n",
      "Epoch 10 Step 3586: Train 0.7705 Reg: 0.2698\n",
      "Test: 0.8435 MAE: 0.7275 RMSE: 0.9184\n",
      "Val: 0.7731 MAE: 0.6923 RMSE: 0.8793\n",
      "Epoch 11 Step 3912: Train 0.7574 Reg: 0.2722\n",
      "Test: 0.8416 MAE: 0.7282 RMSE: 0.9174\n",
      "Val: 0.7623 MAE: 0.6857 RMSE: 0.8731\n",
      "Epoch 12 Step 4238: Train 0.7446 Reg: 0.2769\n",
      "Test: 0.8260 MAE: 0.7220 RMSE: 0.9088\n",
      "Val: 0.7515 MAE: 0.6807 RMSE: 0.8669\n",
      "Epoch 13 Step 4564: Train 0.7314 Reg: 0.2833\n",
      "Test: 0.8114 MAE: 0.7144 RMSE: 0.9008\n",
      "Val: 0.7433 MAE: 0.6780 RMSE: 0.8622\n",
      "Epoch 14 Step 4890: Train 0.7170 Reg: 0.2922\n",
      "Test: 0.7973 MAE: 0.7149 RMSE: 0.8929\n",
      "Val: 0.7357 MAE: 0.6753 RMSE: 0.8578\n",
      "Epoch 15 Step 5216: Train 0.7029 Reg: 0.3004\n",
      "Test: 0.7947 MAE: 0.7039 RMSE: 0.8914\n",
      "Val: 0.7335 MAE: 0.6688 RMSE: 0.8564\n",
      "Epoch 16 Step 5542: Train 0.6891 Reg: 0.3113\n",
      "Test: 0.7869 MAE: 0.7028 RMSE: 0.8871\n",
      "Val: 0.7278 MAE: 0.6672 RMSE: 0.8531\n",
      "Epoch 17 Step 5868: Train 0.6758 Reg: 0.3213\n",
      "Test: 0.7811 MAE: 0.7044 RMSE: 0.8838\n",
      "Val: 0.7227 MAE: 0.6667 RMSE: 0.8501\n",
      "Epoch 18 Step 6194: Train 0.6618 Reg: 0.3310\n",
      "Test: 0.7718 MAE: 0.6975 RMSE: 0.8785\n",
      "Val: 0.7196 MAE: 0.6643 RMSE: 0.8483\n",
      "Epoch 19 Step 6520: Train 0.6465 Reg: 0.3420\n",
      "Test: 0.7642 MAE: 0.6919 RMSE: 0.8742\n",
      "Val: 0.7179 MAE: 0.6625 RMSE: 0.8473\n",
      "Epoch 20 Step 6846: Train 0.6270 Reg: 0.3596\n",
      "Test: 0.7540 MAE: 0.6888 RMSE: 0.8683\n",
      "Val: 0.7174 MAE: 0.6617 RMSE: 0.8470\n",
      "Epoch 21 Step 7172: Train 0.6049 Reg: 0.3805\n",
      "Test: 0.7477 MAE: 0.6871 RMSE: 0.8647\n",
      "Val: 0.7237 MAE: 0.6659 RMSE: 0.8507\n",
      "Epoch 22 Step 7498: Train 0.5803 Reg: 0.4034\n",
      "Test: 0.7497 MAE: 0.6807 RMSE: 0.8658\n",
      "Val: 0.7308 MAE: 0.6642 RMSE: 0.8549\n",
      "Epoch 23 Step 7824: Train 0.5511 Reg: 0.4307\n",
      "Test: 0.7560 MAE: 0.6876 RMSE: 0.8695\n",
      "Val: 0.7420 MAE: 0.6695 RMSE: 0.8614\n",
      "Epoch 24 Step 8150: Train 0.5205 Reg: 0.4550\n",
      "Test: 0.7651 MAE: 0.6881 RMSE: 0.8747\n",
      "Val: 0.7574 MAE: 0.6753 RMSE: 0.8703\n",
      "Epoch 25 Step 8476: Train 0.4935 Reg: 0.4738\n",
      "Test: 0.7752 MAE: 0.6942 RMSE: 0.8805\n",
      "Val: 0.7749 MAE: 0.6825 RMSE: 0.8803\n",
      "Epoch 26 Step 8802: Train 0.4714 Reg: 0.4871\n",
      "Test: 0.7911 MAE: 0.6970 RMSE: 0.8894\n",
      "Val: 0.7898 MAE: 0.6867 RMSE: 0.8887\n",
      "Epoch 27 Step 9128: Train 0.4539 Reg: 0.4954\n",
      "Test: 0.8018 MAE: 0.7003 RMSE: 0.8954\n",
      "Val: 0.8066 MAE: 0.6940 RMSE: 0.8981\n",
      "Epoch 28 Step 9454: Train 0.4402 Reg: 0.5004\n",
      "Test: 0.8183 MAE: 0.7058 RMSE: 0.9046\n",
      "Val: 0.8182 MAE: 0.6981 RMSE: 0.9045\n",
      "Epoch 29 Step 9780: Train 0.4297 Reg: 0.5029\n",
      "Test: 0.8298 MAE: 0.7103 RMSE: 0.9110\n",
      "Val: 0.8320 MAE: 0.7036 RMSE: 0.9121\n",
      "Epoch 30 Step 10106: Train 0.4209 Reg: 0.5042\n",
      "Test: 0.8400 MAE: 0.7114 RMSE: 0.9165\n",
      "Val: 0.8428 MAE: 0.7067 RMSE: 0.9180\n",
      "Epoch 31 Step 10432: Train 0.4132 Reg: 0.5048\n",
      "Test: 0.8538 MAE: 0.7171 RMSE: 0.9240\n",
      "Val: 0.8518 MAE: 0.7100 RMSE: 0.9229\n",
      "Epoch 32 Step 10758: Train 0.4065 Reg: 0.5044\n",
      "Test: 0.8666 MAE: 0.7201 RMSE: 0.9309\n",
      "Val: 0.8623 MAE: 0.7140 RMSE: 0.9286\n",
      "Epoch 33 Step 11084: Train 0.4006 Reg: 0.5038\n",
      "Test: 0.8802 MAE: 0.7256 RMSE: 0.9382\n",
      "Val: 0.8706 MAE: 0.7169 RMSE: 0.9331\n",
      "Epoch 34 Step 11410: Train 0.3954 Reg: 0.5026\n",
      "Test: 0.8889 MAE: 0.7286 RMSE: 0.9428\n",
      "Val: 0.8777 MAE: 0.7196 RMSE: 0.9369\n",
      "Epoch 35 Step 11736: Train 0.3902 Reg: 0.5014\n",
      "Test: 0.9010 MAE: 0.7345 RMSE: 0.9492\n",
      "Val: 0.8868 MAE: 0.7238 RMSE: 0.9417\n",
      "Epoch 36 Step 12062: Train 0.3857 Reg: 0.4999\n",
      "Test: 0.9089 MAE: 0.7353 RMSE: 0.9534\n",
      "Val: 0.8924 MAE: 0.7246 RMSE: 0.9447\n",
      "Epoch 37 Step 12388: Train 0.3816 Reg: 0.4981\n",
      "Test: 0.9223 MAE: 0.7411 RMSE: 0.9604\n",
      "Val: 0.9001 MAE: 0.7276 RMSE: 0.9488\n",
      "Epoch 38 Step 12714: Train 0.3779 Reg: 0.4963\n",
      "Test: 0.9327 MAE: 0.7441 RMSE: 0.9658\n",
      "Val: 0.9053 MAE: 0.7289 RMSE: 0.9515\n",
      "Epoch 39 Step 13040: Train 0.3744 Reg: 0.4943\n",
      "Test: 0.9411 MAE: 0.7488 RMSE: 0.9701\n",
      "Val: 0.9142 MAE: 0.7334 RMSE: 0.9561\n",
      "Epoch 40 Step 13366: Train 0.3714 Reg: 0.4921\n",
      "Test: 0.9489 MAE: 0.7497 RMSE: 0.9741\n",
      "Val: 0.9192 MAE: 0.7342 RMSE: 0.9587\n",
      "Epoch 41 Step 13692: Train 0.3685 Reg: 0.4901\n",
      "Test: 0.9566 MAE: 0.7527 RMSE: 0.9781\n",
      "Val: 0.9229 MAE: 0.7357 RMSE: 0.9607\n",
      "Epoch 42 Step 14018: Train 0.3659 Reg: 0.4878\n",
      "Test: 0.9640 MAE: 0.7540 RMSE: 0.9818\n",
      "Val: 0.9287 MAE: 0.7369 RMSE: 0.9637\n",
      "Epoch 43 Step 14344: Train 0.3634 Reg: 0.4858\n",
      "Test: 0.9727 MAE: 0.7579 RMSE: 0.9863\n",
      "Val: 0.9329 MAE: 0.7393 RMSE: 0.9658\n",
      "Epoch 44 Step 14670: Train 0.3612 Reg: 0.4837\n",
      "Test: 0.9773 MAE: 0.7589 RMSE: 0.9886\n",
      "Val: 0.9382 MAE: 0.7406 RMSE: 0.9686\n",
      "Epoch 45 Step 14996: Train 0.3591 Reg: 0.4816\n",
      "Test: 0.9873 MAE: 0.7622 RMSE: 0.9936\n",
      "Val: 0.9431 MAE: 0.7424 RMSE: 0.9711\n",
      "Epoch 46 Step 15322: Train 0.3570 Reg: 0.4795\n",
      "Test: 0.9928 MAE: 0.7640 RMSE: 0.9964\n",
      "Val: 0.9452 MAE: 0.7429 RMSE: 0.9722\n",
      "Epoch 47 Step 15648: Train 0.3552 Reg: 0.4774\n",
      "Test: 0.9969 MAE: 0.7647 RMSE: 0.9985\n",
      "Val: 0.9493 MAE: 0.7439 RMSE: 0.9743\n",
      "Epoch 48 Step 15974: Train 0.3534 Reg: 0.4756\n",
      "Test: 1.0039 MAE: 0.7678 RMSE: 1.0019\n",
      "Val: 0.9540 MAE: 0.7459 RMSE: 0.9768\n",
      "Epoch 49 Step 16300: Train 0.3517 Reg: 0.4736\n",
      "Test: 1.0082 MAE: 0.7684 RMSE: 1.0041\n",
      "Val: 0.9577 MAE: 0.7470 RMSE: 0.9786\n",
      "Epoch 50 Step 16626: Train 0.3501 Reg: 0.4718\n",
      "Test: 1.0122 MAE: 0.7693 RMSE: 1.0061\n",
      "Val: 0.9596 MAE: 0.7474 RMSE: 0.9796\n",
      "Epoch 51 Step 16952: Train 0.3486 Reg: 0.4699\n",
      "Test: 1.0168 MAE: 0.7703 RMSE: 1.0084\n",
      "Val: 0.9633 MAE: 0.7486 RMSE: 0.9815\n",
      "Epoch 52 Step 17278: Train 0.3472 Reg: 0.4682\n",
      "Test: 1.0217 MAE: 0.7719 RMSE: 1.0108\n",
      "Val: 0.9667 MAE: 0.7498 RMSE: 0.9832\n",
      "Epoch 53 Step 17604: Train 0.3459 Reg: 0.4666\n",
      "Test: 1.0263 MAE: 0.7731 RMSE: 1.0130\n",
      "Val: 0.9696 MAE: 0.7505 RMSE: 0.9847\n",
      "Epoch 54 Step 17930: Train 0.3446 Reg: 0.4650\n",
      "Test: 1.0303 MAE: 0.7735 RMSE: 1.0150\n",
      "Val: 0.9719 MAE: 0.7510 RMSE: 0.9859\n",
      "Epoch 55 Step 18256: Train 0.3434 Reg: 0.4635\n",
      "Test: 1.0333 MAE: 0.7748 RMSE: 1.0165\n",
      "Val: 0.9749 MAE: 0.7523 RMSE: 0.9873\n",
      "Epoch 56 Step 18582: Train 0.3423 Reg: 0.4619\n",
      "Test: 1.0359 MAE: 0.7758 RMSE: 1.0178\n",
      "Val: 0.9764 MAE: 0.7528 RMSE: 0.9881\n",
      "Epoch 57 Step 18908: Train 0.3412 Reg: 0.4605\n",
      "Test: 1.0407 MAE: 0.7761 RMSE: 1.0202\n",
      "Val: 0.9801 MAE: 0.7536 RMSE: 0.9900\n",
      "Epoch 58 Step 19234: Train 0.3401 Reg: 0.4591\n",
      "Test: 1.0448 MAE: 0.7779 RMSE: 1.0221\n",
      "Val: 0.9823 MAE: 0.7545 RMSE: 0.9911\n",
      "Epoch 59 Step 19560: Train 0.3392 Reg: 0.4578\n",
      "Test: 1.0458 MAE: 0.7784 RMSE: 1.0226\n",
      "Val: 0.9842 MAE: 0.7554 RMSE: 0.9921\n",
      "Epoch 60 Step 19886: Train 0.3383 Reg: 0.4565\n",
      "Test: 1.0482 MAE: 0.7787 RMSE: 1.0238\n",
      "Val: 0.9856 MAE: 0.7554 RMSE: 0.9928\n",
      "Epoch 61 Step 20212: Train 0.3374 Reg: 0.4553\n",
      "Test: 1.0515 MAE: 0.7801 RMSE: 1.0254\n",
      "Val: 0.9879 MAE: 0.7563 RMSE: 0.9939\n",
      "Epoch 62 Step 20538: Train 0.3365 Reg: 0.4540\n",
      "Test: 1.0552 MAE: 0.7809 RMSE: 1.0272\n",
      "Val: 0.9895 MAE: 0.7568 RMSE: 0.9948\n",
      "Epoch 63 Step 20864: Train 0.3358 Reg: 0.4529\n",
      "Test: 1.0570 MAE: 0.7816 RMSE: 1.0281\n",
      "Val: 0.9915 MAE: 0.7575 RMSE: 0.9957\n",
      "Epoch 64 Step 21190: Train 0.3350 Reg: 0.4519\n",
      "Test: 1.0592 MAE: 0.7823 RMSE: 1.0292\n",
      "Val: 0.9931 MAE: 0.7581 RMSE: 0.9966\n",
      "Epoch 65 Step 21516: Train 0.3343 Reg: 0.4508\n",
      "Test: 1.0618 MAE: 0.7832 RMSE: 1.0304\n",
      "Val: 0.9943 MAE: 0.7585 RMSE: 0.9971\n",
      "Epoch 66 Step 21842: Train 0.3336 Reg: 0.4498\n",
      "Test: 1.0636 MAE: 0.7845 RMSE: 1.0313\n",
      "Val: 0.9966 MAE: 0.7596 RMSE: 0.9983\n",
      "Epoch 67 Step 22168: Train 0.3330 Reg: 0.4489\n",
      "Test: 1.0658 MAE: 0.7839 RMSE: 1.0324\n",
      "Val: 0.9973 MAE: 0.7592 RMSE: 0.9986\n",
      "Epoch 68 Step 22494: Train 0.3324 Reg: 0.4480\n",
      "Test: 1.0666 MAE: 0.7843 RMSE: 1.0327\n",
      "Val: 0.9989 MAE: 0.7600 RMSE: 0.9994\n",
      "Epoch 69 Step 22820: Train 0.3318 Reg: 0.4471\n",
      "Test: 1.0697 MAE: 0.7861 RMSE: 1.0343\n",
      "Val: 1.0005 MAE: 0.7609 RMSE: 1.0003\n",
      "Epoch 70 Step 23146: Train 0.3312 Reg: 0.4463\n",
      "Test: 1.0699 MAE: 0.7852 RMSE: 1.0344\n",
      "Val: 1.0009 MAE: 0.7604 RMSE: 1.0004\n",
      "Epoch 71 Step 23472: Train 0.3307 Reg: 0.4455\n",
      "Test: 1.0724 MAE: 0.7859 RMSE: 1.0356\n",
      "Val: 1.0025 MAE: 0.7610 RMSE: 1.0012\n",
      "Epoch 72 Step 23798: Train 0.3302 Reg: 0.4447\n",
      "Test: 1.0742 MAE: 0.7865 RMSE: 1.0364\n",
      "Val: 1.0036 MAE: 0.7614 RMSE: 1.0018\n",
      "Epoch 73 Step 24124: Train 0.3298 Reg: 0.4440\n",
      "Test: 1.0752 MAE: 0.7868 RMSE: 1.0369\n",
      "Val: 1.0047 MAE: 0.7616 RMSE: 1.0024\n",
      "Epoch 74 Step 24450: Train 0.3293 Reg: 0.4433\n",
      "Test: 1.0761 MAE: 0.7867 RMSE: 1.0373\n",
      "Val: 1.0057 MAE: 0.7619 RMSE: 1.0028\n",
      "Epoch 75 Step 24776: Train 0.3289 Reg: 0.4427\n",
      "Test: 1.0780 MAE: 0.7880 RMSE: 1.0383\n",
      "Val: 1.0067 MAE: 0.7625 RMSE: 1.0034\n",
      "Epoch 76 Step 25102: Train 0.3285 Reg: 0.4421\n",
      "Test: 1.0793 MAE: 0.7876 RMSE: 1.0389\n",
      "Val: 1.0072 MAE: 0.7622 RMSE: 1.0036\n",
      "Epoch 77 Step 25428: Train 0.3281 Reg: 0.4414\n",
      "Test: 1.0806 MAE: 0.7890 RMSE: 1.0395\n",
      "Val: 1.0087 MAE: 0.7633 RMSE: 1.0044\n",
      "Epoch 78 Step 25754: Train 0.3277 Reg: 0.4409\n",
      "Test: 1.0818 MAE: 0.7886 RMSE: 1.0401\n",
      "Val: 1.0093 MAE: 0.7630 RMSE: 1.0047\n",
      "Epoch 79 Step 26080: Train 0.3274 Reg: 0.4403\n",
      "Test: 1.0825 MAE: 0.7888 RMSE: 1.0404\n",
      "Val: 1.0101 MAE: 0.7633 RMSE: 1.0050\n",
      "Epoch 80 Step 26406: Train 0.3270 Reg: 0.4398\n",
      "Test: 1.0835 MAE: 0.7892 RMSE: 1.0409\n",
      "Val: 1.0106 MAE: 0.7635 RMSE: 1.0053\n",
      "Epoch 81 Step 26732: Train 0.3267 Reg: 0.4393\n",
      "Test: 1.0849 MAE: 0.7897 RMSE: 1.0416\n",
      "Val: 1.0114 MAE: 0.7638 RMSE: 1.0057\n",
      "Epoch 82 Step 27058: Train 0.3264 Reg: 0.4389\n",
      "Test: 1.0858 MAE: 0.7903 RMSE: 1.0420\n",
      "Val: 1.0120 MAE: 0.7642 RMSE: 1.0060\n",
      "Epoch 83 Step 27384: Train 0.3261 Reg: 0.4384\n",
      "Test: 1.0865 MAE: 0.7906 RMSE: 1.0424\n",
      "Val: 1.0129 MAE: 0.7645 RMSE: 1.0064\n",
      "Epoch 84 Step 27710: Train 0.3259 Reg: 0.4380\n",
      "Test: 1.0874 MAE: 0.7907 RMSE: 1.0428\n",
      "Val: 1.0134 MAE: 0.7647 RMSE: 1.0067\n",
      "Epoch 85 Step 28036: Train 0.3256 Reg: 0.4376\n",
      "Test: 1.0878 MAE: 0.7905 RMSE: 1.0430\n",
      "Val: 1.0137 MAE: 0.7646 RMSE: 1.0068\n",
      "Epoch 86 Step 28362: Train 0.3253 Reg: 0.4372\n",
      "Test: 1.0886 MAE: 0.7909 RMSE: 1.0434\n",
      "Val: 1.0145 MAE: 0.7649 RMSE: 1.0072\n",
      "Epoch 87 Step 28688: Train 0.3251 Reg: 0.4368\n",
      "Test: 1.0891 MAE: 0.7911 RMSE: 1.0436\n",
      "Val: 1.0149 MAE: 0.7650 RMSE: 1.0074\n",
      "Epoch 88 Step 29014: Train 0.3249 Reg: 0.4365\n",
      "Test: 1.0899 MAE: 0.7914 RMSE: 1.0440\n",
      "Val: 1.0154 MAE: 0.7652 RMSE: 1.0076\n",
      "Epoch 89 Step 29340: Train 0.3247 Reg: 0.4361\n",
      "Test: 1.0908 MAE: 0.7918 RMSE: 1.0444\n",
      "Val: 1.0161 MAE: 0.7656 RMSE: 1.0080\n",
      "Epoch 90 Step 29666: Train 0.3245 Reg: 0.4358\n",
      "Test: 1.0914 MAE: 0.7918 RMSE: 1.0447\n",
      "Val: 1.0164 MAE: 0.7656 RMSE: 1.0081\n",
      "Epoch 91 Step 29992: Train 0.3243 Reg: 0.4355\n",
      "Test: 1.0917 MAE: 0.7917 RMSE: 1.0448\n",
      "Val: 1.0167 MAE: 0.7656 RMSE: 1.0083\n",
      "Epoch 92 Step 30318: Train 0.3241 Reg: 0.4352\n",
      "Test: 1.0922 MAE: 0.7917 RMSE: 1.0451\n",
      "Val: 1.0171 MAE: 0.7656 RMSE: 1.0085\n",
      "Epoch 93 Step 30644: Train 0.3239 Reg: 0.4349\n",
      "Test: 1.0928 MAE: 0.7920 RMSE: 1.0454\n",
      "Val: 1.0174 MAE: 0.7658 RMSE: 1.0087\n",
      "Epoch 94 Step 30970: Train 0.3238 Reg: 0.4347\n",
      "Test: 1.0935 MAE: 0.7923 RMSE: 1.0457\n",
      "Val: 1.0179 MAE: 0.7660 RMSE: 1.0089\n",
      "Epoch 95 Step 31296: Train 0.3236 Reg: 0.4344\n",
      "Test: 1.0938 MAE: 0.7921 RMSE: 1.0459\n",
      "Val: 1.0181 MAE: 0.7659 RMSE: 1.0090\n",
      "Epoch 96 Step 31622: Train 0.3235 Reg: 0.4342\n",
      "Test: 1.0941 MAE: 0.7921 RMSE: 1.0460\n",
      "Val: 1.0184 MAE: 0.7659 RMSE: 1.0091\n",
      "Epoch 97 Step 31948: Train 0.3234 Reg: 0.4340\n",
      "Test: 1.0946 MAE: 0.7925 RMSE: 1.0462\n",
      "Val: 1.0188 MAE: 0.7662 RMSE: 1.0093\n",
      "Epoch 98 Step 32274: Train 0.3232 Reg: 0.4338\n",
      "Test: 1.0949 MAE: 0.7926 RMSE: 1.0464\n",
      "Val: 1.0191 MAE: 0.7664 RMSE: 1.0095\n",
      "Epoch 99 Step 32600: Train 0.3231 Reg: 0.4336\n",
      "Test: 1.0954 MAE: 0.7929 RMSE: 1.0466\n",
      "Val: 1.0195 MAE: 0.7666 RMSE: 1.0097\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 350454/19100\n",
      "test set size: support/query 1046/809\n",
      "Epoch 0: TrainLoss 1.1397 RecLoss: 0.0000 (left: 0:08:35)\n",
      "TestLoss: 1.0780 MAE: 0.8056 RMSE: 1.0383\n",
      "ValLoss: 1.1385 MAE: 0.8391 RMSE: 1.0670\n",
      "Epoch 1: TrainLoss 1.0048 RecLoss: 0.0000 (left: 0:08:15)\n",
      "TestLoss: 1.0285 MAE: 0.8056 RMSE: 1.0141\n",
      "ValLoss: 1.0701 MAE: 0.8327 RMSE: 1.0344\n",
      "Epoch 2: TrainLoss 0.9693 RecLoss: 0.0000 (left: 0:08:23)\n",
      "TestLoss: 1.0158 MAE: 0.8051 RMSE: 1.0079\n",
      "ValLoss: 1.0528 MAE: 0.8283 RMSE: 1.0261\n",
      "Epoch 3: TrainLoss 0.9541 RecLoss: 0.0000 (left: 0:08:48)\n",
      "TestLoss: 1.0216 MAE: 0.8156 RMSE: 1.0108\n",
      "ValLoss: 1.0534 MAE: 0.8346 RMSE: 1.0264\n",
      "Epoch 4: TrainLoss 0.9341 RecLoss: 0.0000 (left: 0:08:55)\n",
      "TestLoss: 0.9953 MAE: 0.7925 RMSE: 0.9976\n",
      "ValLoss: 1.0336 MAE: 0.8167 RMSE: 1.0167\n",
      "Epoch 5: TrainLoss 0.9220 RecLoss: 0.0000 (left: 0:08:44)\n",
      "TestLoss: 0.9949 MAE: 0.7872 RMSE: 0.9975\n",
      "ValLoss: 1.0341 MAE: 0.8113 RMSE: 1.0169\n",
      "Epoch 6: TrainLoss 0.9141 RecLoss: 0.0000 (left: 0:08:41)\n",
      "TestLoss: 0.9935 MAE: 0.7860 RMSE: 0.9967\n",
      "ValLoss: 1.0338 MAE: 0.8124 RMSE: 1.0167\n",
      "Epoch 7: TrainLoss 0.9099 RecLoss: 0.0000 (left: 0:08:33)\n",
      "TestLoss: 0.9869 MAE: 0.7875 RMSE: 0.9935\n",
      "ValLoss: 1.0262 MAE: 0.8115 RMSE: 1.0130\n",
      "Epoch 8: TrainLoss 0.9068 RecLoss: 0.0000 (left: 0:08:35)\n",
      "TestLoss: 0.9974 MAE: 0.7992 RMSE: 0.9987\n",
      "ValLoss: 1.0289 MAE: 0.8182 RMSE: 1.0144\n",
      "Epoch 9: TrainLoss 0.9046 RecLoss: 0.0000 (left: 0:08:33)\n",
      "TestLoss: 0.9878 MAE: 0.7862 RMSE: 0.9939\n",
      "ValLoss: 1.0269 MAE: 0.8091 RMSE: 1.0134\n",
      "Epoch 10: TrainLoss 0.8978 RecLoss: 0.0000 (left: 0:08:30)\n",
      "TestLoss: 0.9909 MAE: 0.7890 RMSE: 0.9955\n",
      "ValLoss: 1.0326 MAE: 0.8153 RMSE: 1.0162\n",
      "Epoch 11: TrainLoss 0.8952 RecLoss: 0.0000 (left: 0:08:30)\n",
      "TestLoss: 0.9875 MAE: 0.7827 RMSE: 0.9937\n",
      "ValLoss: 1.0293 MAE: 0.8082 RMSE: 1.0145\n",
      "Epoch 12: TrainLoss 0.8952 RecLoss: 0.0000 (left: 0:08:23)\n",
      "TestLoss: 0.9941 MAE: 0.7828 RMSE: 0.9971\n",
      "ValLoss: 1.0394 MAE: 0.8098 RMSE: 1.0195\n",
      "Epoch 13: TrainLoss 0.8936 RecLoss: 0.0000 (left: 0:08:14)\n",
      "TestLoss: 0.9908 MAE: 0.7893 RMSE: 0.9954\n",
      "ValLoss: 1.0315 MAE: 0.8132 RMSE: 1.0156\n",
      "Epoch 14: TrainLoss 0.8954 RecLoss: 0.0000 (left: 0:08:05)\n",
      "TestLoss: 1.0091 MAE: 0.8083 RMSE: 1.0046\n",
      "ValLoss: 1.0418 MAE: 0.8264 RMSE: 1.0207\n",
      "Epoch 15: TrainLoss 0.8957 RecLoss: 0.0000 (left: 0:08:01)\n",
      "TestLoss: 0.9923 MAE: 0.7836 RMSE: 0.9962\n",
      "ValLoss: 1.0398 MAE: 0.8106 RMSE: 1.0197\n",
      "Epoch 16: TrainLoss 0.8915 RecLoss: 0.0000 (left: 0:07:57)\n",
      "TestLoss: 0.9933 MAE: 0.7909 RMSE: 0.9967\n",
      "ValLoss: 1.0355 MAE: 0.8156 RMSE: 1.0176\n",
      "Epoch 17: TrainLoss 0.8916 RecLoss: 0.0000 (left: 0:07:55)\n",
      "TestLoss: 0.9944 MAE: 0.7819 RMSE: 0.9972\n",
      "ValLoss: 1.0452 MAE: 0.8102 RMSE: 1.0223\n",
      "Epoch 18: TrainLoss 0.8923 RecLoss: 0.0000 (left: 0:07:50)\n",
      "TestLoss: 1.0032 MAE: 0.8021 RMSE: 1.0016\n",
      "ValLoss: 1.0449 MAE: 0.8245 RMSE: 1.0222\n",
      "Epoch 19: TrainLoss 0.8958 RecLoss: 0.0000 (left: 0:07:42)\n",
      "TestLoss: 0.9928 MAE: 0.7846 RMSE: 0.9964\n",
      "ValLoss: 1.0386 MAE: 0.8109 RMSE: 1.0191\n",
      "Epoch 20: TrainLoss 0.8909 RecLoss: 0.0000 (left: 0:07:37)\n",
      "TestLoss: 0.9919 MAE: 0.7875 RMSE: 0.9959\n",
      "ValLoss: 1.0403 MAE: 0.8144 RMSE: 1.0200\n",
      "Epoch 21: TrainLoss 0.8910 RecLoss: 0.0000 (left: 0:07:30)\n",
      "TestLoss: 0.9979 MAE: 0.7801 RMSE: 0.9989\n",
      "ValLoss: 1.0497 MAE: 0.8086 RMSE: 1.0246\n",
      "Epoch 22: TrainLoss 0.8921 RecLoss: 0.0000 (left: 0:07:22)\n",
      "TestLoss: 0.9954 MAE: 0.7914 RMSE: 0.9977\n",
      "ValLoss: 1.0393 MAE: 0.8151 RMSE: 1.0195\n",
      "Epoch 23: TrainLoss 0.8914 RecLoss: 0.0000 (left: 0:07:16)\n",
      "TestLoss: 1.0156 MAE: 0.8099 RMSE: 1.0078\n",
      "ValLoss: 1.0564 MAE: 0.8309 RMSE: 1.0278\n",
      "Epoch 24: TrainLoss 0.8983 RecLoss: 0.0000 (left: 0:07:10)\n",
      "TestLoss: 0.9934 MAE: 0.7893 RMSE: 0.9967\n",
      "ValLoss: 1.0420 MAE: 0.8153 RMSE: 1.0208\n",
      "Epoch 25: TrainLoss 0.8892 RecLoss: 0.0000 (left: 0:07:02)\n",
      "TestLoss: 0.9927 MAE: 0.7838 RMSE: 0.9964\n",
      "ValLoss: 1.0436 MAE: 0.8112 RMSE: 1.0216\n",
      "Epoch 26: TrainLoss 0.8893 RecLoss: 0.0000 (left: 0:06:53)\n",
      "TestLoss: 1.0025 MAE: 0.7794 RMSE: 1.0012\n",
      "ValLoss: 1.0550 MAE: 0.8090 RMSE: 1.0271\n",
      "Epoch 27: TrainLoss 0.8921 RecLoss: 0.0000 (left: 0:06:46)\n",
      "TestLoss: 0.9935 MAE: 0.7849 RMSE: 0.9967\n",
      "ValLoss: 1.0476 MAE: 0.8134 RMSE: 1.0235\n",
      "Epoch 28: TrainLoss 0.8904 RecLoss: 0.0000 (left: 0:06:39)\n",
      "TestLoss: 0.9985 MAE: 0.7936 RMSE: 0.9993\n",
      "ValLoss: 1.0465 MAE: 0.8189 RMSE: 1.0230\n",
      "Epoch 29: TrainLoss 0.8914 RecLoss: 0.0000 (left: 0:06:31)\n",
      "TestLoss: 0.9939 MAE: 0.7860 RMSE: 0.9969\n",
      "ValLoss: 1.0464 MAE: 0.8137 RMSE: 1.0229\n",
      "Epoch 30: TrainLoss 0.8903 RecLoss: 0.0000 (left: 0:06:21)\n",
      "TestLoss: 1.0085 MAE: 0.7780 RMSE: 1.0043\n",
      "ValLoss: 1.0698 MAE: 0.8101 RMSE: 1.0343\n",
      "Epoch 31: TrainLoss 0.8938 RecLoss: 0.0000 (left: 0:06:15)\n",
      "TestLoss: 0.9952 MAE: 0.7844 RMSE: 0.9976\n",
      "ValLoss: 1.0492 MAE: 0.8126 RMSE: 1.0243\n",
      "Epoch 32: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:06:11)\n",
      "TestLoss: 0.9942 MAE: 0.7843 RMSE: 0.9971\n",
      "ValLoss: 1.0476 MAE: 0.8121 RMSE: 1.0235\n",
      "Epoch 33: TrainLoss 0.8899 RecLoss: 0.0000 (left: 0:06:05)\n",
      "TestLoss: 0.9949 MAE: 0.7861 RMSE: 0.9975\n",
      "ValLoss: 1.0482 MAE: 0.8140 RMSE: 1.0238\n",
      "Epoch 34: TrainLoss 0.8882 RecLoss: 0.0000 (left: 0:06:02)\n",
      "TestLoss: 1.0019 MAE: 0.7787 RMSE: 1.0009\n",
      "ValLoss: 1.0601 MAE: 0.8099 RMSE: 1.0296\n",
      "Epoch 35: TrainLoss 0.8911 RecLoss: 0.0000 (left: 0:05:57)\n",
      "TestLoss: 1.0006 MAE: 0.7967 RMSE: 1.0003\n",
      "ValLoss: 1.0490 MAE: 0.8212 RMSE: 1.0242\n",
      "Epoch 36: TrainLoss 0.8893 RecLoss: 0.0000 (left: 0:05:53)\n",
      "TestLoss: 0.9955 MAE: 0.7869 RMSE: 0.9977\n",
      "ValLoss: 1.0465 MAE: 0.8132 RMSE: 1.0230\n",
      "Epoch 37: TrainLoss 0.8886 RecLoss: 0.0000 (left: 0:05:49)\n",
      "TestLoss: 0.9963 MAE: 0.7908 RMSE: 0.9981\n",
      "ValLoss: 1.0487 MAE: 0.8179 RMSE: 1.0241\n",
      "Epoch 38: TrainLoss 0.8895 RecLoss: 0.0000 (left: 0:05:43)\n",
      "TestLoss: 0.9975 MAE: 0.7914 RMSE: 0.9988\n",
      "ValLoss: 1.0483 MAE: 0.8179 RMSE: 1.0238\n",
      "Epoch 39: TrainLoss 0.8897 RecLoss: 0.0000 (left: 0:05:37)\n",
      "TestLoss: 0.9996 MAE: 0.7801 RMSE: 0.9998\n",
      "ValLoss: 1.0604 MAE: 0.8112 RMSE: 1.0298\n",
      "Epoch 40: TrainLoss 0.8913 RecLoss: 0.0000 (left: 0:05:30)\n",
      "TestLoss: 1.0039 MAE: 0.7803 RMSE: 1.0019\n",
      "ValLoss: 1.0643 MAE: 0.8115 RMSE: 1.0316\n",
      "Epoch 41: TrainLoss 0.8900 RecLoss: 0.0000 (left: 0:05:25)\n",
      "TestLoss: 0.9946 MAE: 0.7870 RMSE: 0.9973\n",
      "ValLoss: 1.0485 MAE: 0.8139 RMSE: 1.0240\n",
      "Epoch 42: TrainLoss 0.8900 RecLoss: 0.0000 (left: 0:05:20)\n",
      "TestLoss: 0.9994 MAE: 0.7931 RMSE: 0.9997\n",
      "ValLoss: 1.0490 MAE: 0.8186 RMSE: 1.0242\n",
      "Epoch 43: TrainLoss 0.8900 RecLoss: 0.0000 (left: 0:05:15)\n",
      "TestLoss: 0.9954 MAE: 0.7834 RMSE: 0.9977\n",
      "ValLoss: 1.0511 MAE: 0.8119 RMSE: 1.0252\n",
      "Epoch 44: TrainLoss 0.8876 RecLoss: 0.0000 (left: 0:05:10)\n",
      "TestLoss: 0.9948 MAE: 0.7860 RMSE: 0.9974\n",
      "ValLoss: 1.0517 MAE: 0.8150 RMSE: 1.0255\n",
      "Epoch 45: TrainLoss 0.8872 RecLoss: 0.0000 (left: 0:05:05)\n",
      "TestLoss: 0.9948 MAE: 0.7864 RMSE: 0.9974\n",
      "ValLoss: 1.0496 MAE: 0.8140 RMSE: 1.0245\n",
      "Epoch 46: TrainLoss 0.8867 RecLoss: 0.0000 (left: 0:04:59)\n",
      "TestLoss: 0.9956 MAE: 0.7849 RMSE: 0.9978\n",
      "ValLoss: 1.0505 MAE: 0.8125 RMSE: 1.0250\n",
      "Epoch 47: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:04:55)\n",
      "TestLoss: 0.9968 MAE: 0.7823 RMSE: 0.9984\n",
      "ValLoss: 1.0534 MAE: 0.8115 RMSE: 1.0264\n",
      "Epoch 48: TrainLoss 0.8892 RecLoss: 0.0000 (left: 0:04:49)\n",
      "TestLoss: 0.9969 MAE: 0.7818 RMSE: 0.9984\n",
      "ValLoss: 1.0565 MAE: 0.8124 RMSE: 1.0279\n",
      "Epoch 49: TrainLoss 0.8887 RecLoss: 0.0000 (left: 0:04:44)\n",
      "TestLoss: 0.9971 MAE: 0.7826 RMSE: 0.9985\n",
      "ValLoss: 1.0534 MAE: 0.8115 RMSE: 1.0264\n",
      "Epoch 50: TrainLoss 0.8885 RecLoss: 0.0000 (left: 0:04:37)\n",
      "TestLoss: 0.9978 MAE: 0.7827 RMSE: 0.9989\n",
      "ValLoss: 1.0558 MAE: 0.8123 RMSE: 1.0275\n",
      "Epoch 51: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:04:31)\n",
      "TestLoss: 0.9957 MAE: 0.7879 RMSE: 0.9979\n",
      "ValLoss: 1.0510 MAE: 0.8161 RMSE: 1.0252\n",
      "Epoch 52: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:04:25)\n",
      "TestLoss: 0.9972 MAE: 0.7910 RMSE: 0.9986\n",
      "ValLoss: 1.0512 MAE: 0.8179 RMSE: 1.0253\n",
      "Epoch 53: TrainLoss 0.8901 RecLoss: 0.0000 (left: 0:04:19)\n",
      "TestLoss: 0.9971 MAE: 0.7894 RMSE: 0.9985\n",
      "ValLoss: 1.0496 MAE: 0.8162 RMSE: 1.0245\n",
      "Epoch 54: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:04:13)\n",
      "TestLoss: 0.9961 MAE: 0.7835 RMSE: 0.9981\n",
      "ValLoss: 1.0535 MAE: 0.8122 RMSE: 1.0264\n",
      "Epoch 55: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:04:07)\n",
      "TestLoss: 0.9962 MAE: 0.7873 RMSE: 0.9981\n",
      "ValLoss: 1.0500 MAE: 0.8153 RMSE: 1.0247\n",
      "Epoch 56: TrainLoss 0.8871 RecLoss: 0.0000 (left: 0:04:02)\n",
      "TestLoss: 0.9949 MAE: 0.7870 RMSE: 0.9975\n",
      "ValLoss: 1.0518 MAE: 0.8152 RMSE: 1.0256\n",
      "Epoch 57: TrainLoss 0.8885 RecLoss: 0.0000 (left: 0:03:57)\n",
      "TestLoss: 0.9995 MAE: 0.7807 RMSE: 0.9998\n",
      "ValLoss: 1.0573 MAE: 0.8108 RMSE: 1.0283\n",
      "Epoch 58: TrainLoss 0.8872 RecLoss: 0.0000 (left: 0:03:52)\n",
      "TestLoss: 0.9956 MAE: 0.7868 RMSE: 0.9978\n",
      "ValLoss: 1.0503 MAE: 0.8139 RMSE: 1.0248\n",
      "Epoch 59: TrainLoss 0.8865 RecLoss: 0.0000 (left: 0:03:47)\n",
      "TestLoss: 0.9949 MAE: 0.7861 RMSE: 0.9975\n",
      "ValLoss: 1.0507 MAE: 0.8140 RMSE: 1.0251\n",
      "Epoch 60: TrainLoss 0.8870 RecLoss: 0.0000 (left: 0:03:41)\n",
      "TestLoss: 0.9961 MAE: 0.7823 RMSE: 0.9980\n",
      "ValLoss: 1.0535 MAE: 0.8110 RMSE: 1.0264\n",
      "Epoch 61: TrainLoss 0.8883 RecLoss: 0.0000 (left: 0:03:36)\n",
      "TestLoss: 0.9947 MAE: 0.7871 RMSE: 0.9973\n",
      "ValLoss: 1.0506 MAE: 0.8153 RMSE: 1.0250\n",
      "Epoch 62: TrainLoss 0.8867 RecLoss: 0.0000 (left: 0:03:30)\n",
      "TestLoss: 0.9993 MAE: 0.7935 RMSE: 0.9997\n",
      "ValLoss: 1.0506 MAE: 0.8196 RMSE: 1.0250\n",
      "Epoch 63: TrainLoss 0.8901 RecLoss: 0.0000 (left: 0:03:25)\n",
      "TestLoss: 1.0010 MAE: 0.7952 RMSE: 1.0005\n",
      "ValLoss: 1.0525 MAE: 0.8213 RMSE: 1.0259\n",
      "Epoch 64: TrainLoss 0.8887 RecLoss: 0.0000 (left: 0:03:19)\n",
      "TestLoss: 0.9959 MAE: 0.7851 RMSE: 0.9979\n",
      "ValLoss: 1.0532 MAE: 0.8136 RMSE: 1.0262\n",
      "Epoch 65: TrainLoss 0.8869 RecLoss: 0.0000 (left: 0:03:13)\n",
      "TestLoss: 0.9978 MAE: 0.7820 RMSE: 0.9989\n",
      "ValLoss: 1.0572 MAE: 0.8119 RMSE: 1.0282\n",
      "Epoch 66: TrainLoss 0.8871 RecLoss: 0.0000 (left: 0:03:08)\n",
      "TestLoss: 0.9940 MAE: 0.7842 RMSE: 0.9970\n",
      "ValLoss: 1.0509 MAE: 0.8128 RMSE: 1.0251\n",
      "Epoch 67: TrainLoss 0.8868 RecLoss: 0.0000 (left: 0:03:02)\n",
      "TestLoss: 0.9961 MAE: 0.7827 RMSE: 0.9980\n",
      "ValLoss: 1.0542 MAE: 0.8119 RMSE: 1.0267\n",
      "Epoch 68: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:02:57)\n",
      "TestLoss: 0.9949 MAE: 0.7831 RMSE: 0.9974\n",
      "ValLoss: 1.0514 MAE: 0.8115 RMSE: 1.0254\n",
      "Epoch 69: TrainLoss 0.8905 RecLoss: 0.0000 (left: 0:02:51)\n",
      "TestLoss: 1.0012 MAE: 0.7800 RMSE: 1.0006\n",
      "ValLoss: 1.0630 MAE: 0.8119 RMSE: 1.0310\n",
      "Epoch 70: TrainLoss 0.8933 RecLoss: 0.0000 (left: 0:02:46)\n",
      "TestLoss: 1.0152 MAE: 0.7787 RMSE: 1.0076\n",
      "ValLoss: 1.0804 MAE: 0.8123 RMSE: 1.0394\n",
      "Epoch 71: TrainLoss 0.8898 RecLoss: 0.0000 (left: 0:02:40)\n",
      "TestLoss: 0.9951 MAE: 0.7844 RMSE: 0.9975\n",
      "ValLoss: 1.0529 MAE: 0.8129 RMSE: 1.0261\n",
      "Epoch 72: TrainLoss 0.8871 RecLoss: 0.0000 (left: 0:02:34)\n",
      "TestLoss: 0.9983 MAE: 0.7814 RMSE: 0.9991\n",
      "ValLoss: 1.0586 MAE: 0.8119 RMSE: 1.0289\n",
      "Epoch 73: TrainLoss 0.8871 RecLoss: 0.0000 (left: 0:02:29)\n",
      "TestLoss: 0.9956 MAE: 0.7858 RMSE: 0.9978\n",
      "ValLoss: 1.0509 MAE: 0.8138 RMSE: 1.0252\n",
      "Epoch 74: TrainLoss 0.8876 RecLoss: 0.0000 (left: 0:02:23)\n",
      "TestLoss: 0.9947 MAE: 0.7846 RMSE: 0.9973\n",
      "ValLoss: 1.0526 MAE: 0.8132 RMSE: 1.0260\n",
      "Epoch 75: TrainLoss 0.8869 RecLoss: 0.0000 (left: 0:02:18)\n",
      "TestLoss: 1.0029 MAE: 0.7797 RMSE: 1.0015\n",
      "ValLoss: 1.0632 MAE: 0.8108 RMSE: 1.0311\n",
      "Epoch 76: TrainLoss 0.8891 RecLoss: 0.0000 (left: 0:02:12)\n",
      "TestLoss: 0.9971 MAE: 0.7820 RMSE: 0.9985\n",
      "ValLoss: 1.0569 MAE: 0.8123 RMSE: 1.0280\n",
      "Epoch 77: TrainLoss 0.8873 RecLoss: 0.0000 (left: 0:02:07)\n",
      "TestLoss: 0.9979 MAE: 0.7822 RMSE: 0.9990\n",
      "ValLoss: 1.0562 MAE: 0.8110 RMSE: 1.0277\n",
      "Epoch 78: TrainLoss 0.8887 RecLoss: 0.0000 (left: 0:02:01)\n",
      "TestLoss: 1.0034 MAE: 0.7792 RMSE: 1.0017\n",
      "ValLoss: 1.0677 MAE: 0.8122 RMSE: 1.0333\n",
      "Epoch 79: TrainLoss 0.8874 RecLoss: 0.0000 (left: 0:01:56)\n",
      "TestLoss: 0.9963 MAE: 0.7885 RMSE: 0.9981\n",
      "ValLoss: 1.0506 MAE: 0.8157 RMSE: 1.0250\n",
      "Epoch 80: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:01:50)\n",
      "TestLoss: 0.9966 MAE: 0.7903 RMSE: 0.9983\n",
      "ValLoss: 1.0509 MAE: 0.8173 RMSE: 1.0251\n",
      "Epoch 81: TrainLoss 0.8865 RecLoss: 0.0000 (left: 0:01:45)\n",
      "TestLoss: 0.9933 MAE: 0.7859 RMSE: 0.9967\n",
      "ValLoss: 1.0513 MAE: 0.8146 RMSE: 1.0253\n",
      "Epoch 82: TrainLoss 0.8898 RecLoss: 0.0000 (left: 0:01:39)\n",
      "TestLoss: 1.0021 MAE: 0.7798 RMSE: 1.0010\n",
      "ValLoss: 1.0646 MAE: 0.8116 RMSE: 1.0318\n",
      "Epoch 83: TrainLoss 0.8932 RecLoss: 0.0000 (left: 0:01:34)\n",
      "TestLoss: 0.9979 MAE: 0.7823 RMSE: 0.9990\n",
      "ValLoss: 1.0581 MAE: 0.8119 RMSE: 1.0287\n",
      "Epoch 84: TrainLoss 0.8860 RecLoss: 0.0000 (left: 0:01:28)\n",
      "TestLoss: 0.9967 MAE: 0.7892 RMSE: 0.9983\n",
      "ValLoss: 1.0516 MAE: 0.8167 RMSE: 1.0255\n",
      "Epoch 85: TrainLoss 0.8882 RecLoss: 0.0000 (left: 0:01:22)\n",
      "TestLoss: 0.9949 MAE: 0.7836 RMSE: 0.9974\n",
      "ValLoss: 1.0541 MAE: 0.8132 RMSE: 1.0267\n",
      "Epoch 86: TrainLoss 0.8882 RecLoss: 0.0000 (left: 0:01:17)\n",
      "TestLoss: 0.9991 MAE: 0.7815 RMSE: 0.9996\n",
      "ValLoss: 1.0594 MAE: 0.8117 RMSE: 1.0293\n",
      "Epoch 87: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:01:11)\n",
      "TestLoss: 0.9952 MAE: 0.7845 RMSE: 0.9976\n",
      "ValLoss: 1.0534 MAE: 0.8134 RMSE: 1.0263\n",
      "Epoch 88: TrainLoss 0.8893 RecLoss: 0.0000 (left: 0:01:06)\n",
      "TestLoss: 0.9983 MAE: 0.7822 RMSE: 0.9991\n",
      "ValLoss: 1.0571 MAE: 0.8117 RMSE: 1.0282\n",
      "Epoch 89: TrainLoss 0.8874 RecLoss: 0.0000 (left: 0:01:00)\n",
      "TestLoss: 0.9960 MAE: 0.7836 RMSE: 0.9980\n",
      "ValLoss: 1.0546 MAE: 0.8128 RMSE: 1.0270\n",
      "Epoch 90: TrainLoss 0.8863 RecLoss: 0.0000 (left: 0:00:55)\n",
      "TestLoss: 0.9959 MAE: 0.7886 RMSE: 0.9980\n",
      "ValLoss: 1.0522 MAE: 0.8165 RMSE: 1.0258\n",
      "Epoch 91: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:00:49)\n",
      "TestLoss: 0.9950 MAE: 0.7843 RMSE: 0.9975\n",
      "ValLoss: 1.0531 MAE: 0.8131 RMSE: 1.0262\n",
      "Epoch 92: TrainLoss 0.8865 RecLoss: 0.0000 (left: 0:00:44)\n",
      "TestLoss: 0.9954 MAE: 0.7854 RMSE: 0.9977\n",
      "ValLoss: 1.0518 MAE: 0.8137 RMSE: 1.0256\n",
      "Epoch 93: TrainLoss 0.8867 RecLoss: 0.0000 (left: 0:00:38)\n",
      "TestLoss: 0.9993 MAE: 0.7933 RMSE: 0.9997\n",
      "ValLoss: 1.0520 MAE: 0.8197 RMSE: 1.0257\n",
      "Epoch 94: TrainLoss 0.8908 RecLoss: 0.0000 (left: 0:00:33)\n",
      "TestLoss: 0.9950 MAE: 0.7835 RMSE: 0.9975\n",
      "ValLoss: 1.0537 MAE: 0.8124 RMSE: 1.0265\n",
      "Epoch 95: TrainLoss 0.8892 RecLoss: 0.0000 (left: 0:00:27)\n",
      "TestLoss: 0.9963 MAE: 0.7834 RMSE: 0.9982\n",
      "ValLoss: 1.0556 MAE: 0.8131 RMSE: 1.0274\n",
      "Epoch 96: TrainLoss 0.8871 RecLoss: 0.0000 (left: 0:00:21)\n",
      "TestLoss: 1.0014 MAE: 0.7800 RMSE: 1.0007\n",
      "ValLoss: 1.0627 MAE: 0.8110 RMSE: 1.0309\n",
      "Epoch 97: TrainLoss 0.8877 RecLoss: 0.0000 (left: 0:00:16)\n",
      "TestLoss: 0.9954 MAE: 0.7848 RMSE: 0.9977\n",
      "ValLoss: 1.0533 MAE: 0.8138 RMSE: 1.0263\n",
      "Epoch 98: TrainLoss 0.8860 RecLoss: 0.0000 (left: 0:00:10)\n",
      "TestLoss: 0.9950 MAE: 0.7863 RMSE: 0.9975\n",
      "ValLoss: 1.0514 MAE: 0.8145 RMSE: 1.0254\n",
      "Epoch 99: TrainLoss 0.8861 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 0.9966 MAE: 0.7906 RMSE: 0.9983\n",
      "ValLoss: 1.0511 MAE: 0.8179 RMSE: 1.0253\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 350454/19100\n",
      "test set size: support/query 1046/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.6888 RMSE: 0.8683 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7875 RMSE: 0.9935 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7318 RMSE: 0.9250 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10% CUR coueusers to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 181085/19100\n",
      "test set size: support/query 523/809\n",
      "Epoch 0 Step 168: Train 3.6543 Reg: 0.5106\n",
      "Test: 0.9035 MAE: 0.7842 RMSE: 0.9506\n",
      "Val: 0.8944 MAE: 0.7500 RMSE: 0.9457\n",
      "Epoch 1 Step 336: Train 0.8412 Reg: 0.4776\n",
      "Test: 0.8339 MAE: 0.7370 RMSE: 0.9132\n",
      "Val: 0.8397 MAE: 0.7243 RMSE: 0.9164\n",
      "Epoch 2 Step 504: Train 0.8179 Reg: 0.4384\n",
      "Test: 0.8199 MAE: 0.7289 RMSE: 0.9055\n",
      "Val: 0.8333 MAE: 0.7230 RMSE: 0.9129\n",
      "Epoch 3 Step 672: Train 0.8120 Reg: 0.4062\n",
      "Test: 0.8104 MAE: 0.7268 RMSE: 0.9002\n",
      "Val: 0.8261 MAE: 0.7184 RMSE: 0.9089\n",
      "Epoch 4 Step 840: Train 0.8091 Reg: 0.3781\n",
      "Test: 0.8072 MAE: 0.7271 RMSE: 0.8984\n",
      "Val: 0.8276 MAE: 0.7198 RMSE: 0.9097\n",
      "Epoch 5 Step 1008: Train 0.8074 Reg: 0.3540\n",
      "Test: 0.8100 MAE: 0.7274 RMSE: 0.9000\n",
      "Val: 0.8269 MAE: 0.7192 RMSE: 0.9093\n",
      "Epoch 6 Step 1176: Train 0.8061 Reg: 0.3343\n",
      "Test: 0.8202 MAE: 0.7295 RMSE: 0.9056\n",
      "Val: 0.8256 MAE: 0.7187 RMSE: 0.9086\n",
      "Epoch 7 Step 1344: Train 0.8031 Reg: 0.3189\n",
      "Test: 0.8000 MAE: 0.7192 RMSE: 0.8944\n",
      "Val: 0.8210 MAE: 0.7166 RMSE: 0.9061\n",
      "Epoch 8 Step 1512: Train 0.8013 Reg: 0.3045\n",
      "Test: 0.7944 MAE: 0.7219 RMSE: 0.8913\n",
      "Val: 0.8188 MAE: 0.7171 RMSE: 0.9049\n",
      "Epoch 9 Step 1680: Train 0.7987 Reg: 0.2928\n",
      "Test: 0.7965 MAE: 0.7161 RMSE: 0.8925\n",
      "Val: 0.8161 MAE: 0.7141 RMSE: 0.9034\n",
      "Epoch 10 Step 1848: Train 0.7956 Reg: 0.2837\n",
      "Test: 0.7936 MAE: 0.7153 RMSE: 0.8909\n",
      "Val: 0.8121 MAE: 0.7118 RMSE: 0.9012\n",
      "Epoch 11 Step 2016: Train 0.7923 Reg: 0.2751\n",
      "Test: 0.7988 MAE: 0.7208 RMSE: 0.8938\n",
      "Val: 0.8092 MAE: 0.7124 RMSE: 0.8996\n",
      "Epoch 12 Step 2184: Train 0.7878 Reg: 0.2696\n",
      "Test: 0.7967 MAE: 0.7133 RMSE: 0.8926\n",
      "Val: 0.8086 MAE: 0.7098 RMSE: 0.8992\n",
      "Epoch 13 Step 2352: Train 0.7824 Reg: 0.2650\n",
      "Test: 0.7837 MAE: 0.7096 RMSE: 0.8853\n",
      "Val: 0.8020 MAE: 0.7076 RMSE: 0.8955\n",
      "Epoch 14 Step 2520: Train 0.7762 Reg: 0.2621\n",
      "Test: 0.7859 MAE: 0.7085 RMSE: 0.8865\n",
      "Val: 0.7978 MAE: 0.7060 RMSE: 0.8932\n",
      "Epoch 15 Step 2688: Train 0.7700 Reg: 0.2591\n",
      "Test: 0.7764 MAE: 0.7054 RMSE: 0.8811\n",
      "Val: 0.7943 MAE: 0.7035 RMSE: 0.8912\n",
      "Epoch 16 Step 2856: Train 0.7642 Reg: 0.2569\n",
      "Test: 0.7814 MAE: 0.7070 RMSE: 0.8840\n",
      "Val: 0.7933 MAE: 0.7031 RMSE: 0.8907\n",
      "Epoch 17 Step 3024: Train 0.7589 Reg: 0.2543\n",
      "Test: 0.7700 MAE: 0.7043 RMSE: 0.8775\n",
      "Val: 0.7904 MAE: 0.7028 RMSE: 0.8891\n",
      "Epoch 18 Step 3192: Train 0.7551 Reg: 0.2510\n",
      "Test: 0.7682 MAE: 0.7009 RMSE: 0.8765\n",
      "Val: 0.7889 MAE: 0.7018 RMSE: 0.8882\n",
      "Epoch 19 Step 3360: Train 0.7514 Reg: 0.2478\n",
      "Test: 0.7714 MAE: 0.6991 RMSE: 0.8783\n",
      "Val: 0.7880 MAE: 0.7008 RMSE: 0.8877\n",
      "Epoch 20 Step 3528: Train 0.7478 Reg: 0.2446\n",
      "Test: 0.7700 MAE: 0.7008 RMSE: 0.8775\n",
      "Val: 0.7889 MAE: 0.7018 RMSE: 0.8882\n",
      "Epoch 21 Step 3696: Train 0.7447 Reg: 0.2417\n",
      "Test: 0.7550 MAE: 0.6931 RMSE: 0.8689\n",
      "Val: 0.7857 MAE: 0.6990 RMSE: 0.8864\n",
      "Epoch 22 Step 3864: Train 0.7416 Reg: 0.2388\n",
      "Test: 0.7602 MAE: 0.6940 RMSE: 0.8719\n",
      "Val: 0.7860 MAE: 0.6999 RMSE: 0.8865\n",
      "Epoch 23 Step 4032: Train 0.7393 Reg: 0.2363\n",
      "Test: 0.7651 MAE: 0.6969 RMSE: 0.8747\n",
      "Val: 0.7860 MAE: 0.7001 RMSE: 0.8866\n",
      "Epoch 24 Step 4200: Train 0.7362 Reg: 0.2339\n",
      "Test: 0.7611 MAE: 0.6965 RMSE: 0.8724\n",
      "Val: 0.7857 MAE: 0.6987 RMSE: 0.8864\n",
      "Epoch 25 Step 4368: Train 0.7330 Reg: 0.2322\n",
      "Test: 0.7573 MAE: 0.6929 RMSE: 0.8702\n",
      "Val: 0.7834 MAE: 0.6974 RMSE: 0.8851\n",
      "Epoch 26 Step 4536: Train 0.7302 Reg: 0.2303\n",
      "Test: 0.7564 MAE: 0.6932 RMSE: 0.8697\n",
      "Val: 0.7826 MAE: 0.6975 RMSE: 0.8847\n",
      "Epoch 27 Step 4704: Train 0.7271 Reg: 0.2290\n",
      "Test: 0.7609 MAE: 0.6936 RMSE: 0.8723\n",
      "Val: 0.7806 MAE: 0.6971 RMSE: 0.8835\n",
      "Epoch 28 Step 4872: Train 0.7240 Reg: 0.2281\n",
      "Test: 0.7591 MAE: 0.6932 RMSE: 0.8713\n",
      "Val: 0.7803 MAE: 0.6972 RMSE: 0.8833\n",
      "Epoch 29 Step 5040: Train 0.7207 Reg: 0.2277\n",
      "Test: 0.7583 MAE: 0.6918 RMSE: 0.8708\n",
      "Val: 0.7800 MAE: 0.6949 RMSE: 0.8832\n",
      "Epoch 30 Step 5208: Train 0.7173 Reg: 0.2275\n",
      "Test: 0.7582 MAE: 0.6917 RMSE: 0.8707\n",
      "Val: 0.7781 MAE: 0.6952 RMSE: 0.8821\n",
      "Epoch 31 Step 5376: Train 0.7135 Reg: 0.2279\n",
      "Test: 0.7560 MAE: 0.6891 RMSE: 0.8695\n",
      "Val: 0.7774 MAE: 0.6936 RMSE: 0.8817\n",
      "Epoch 32 Step 5544: Train 0.7094 Reg: 0.2287\n",
      "Test: 0.7504 MAE: 0.6873 RMSE: 0.8662\n",
      "Val: 0.7756 MAE: 0.6930 RMSE: 0.8807\n",
      "Epoch 33 Step 5712: Train 0.7046 Reg: 0.2305\n",
      "Test: 0.7484 MAE: 0.6861 RMSE: 0.8651\n",
      "Val: 0.7755 MAE: 0.6927 RMSE: 0.8806\n",
      "Epoch 34 Step 5880: Train 0.6992 Reg: 0.2327\n",
      "Test: 0.7460 MAE: 0.6849 RMSE: 0.8637\n",
      "Val: 0.7725 MAE: 0.6910 RMSE: 0.8789\n",
      "Epoch 35 Step 6048: Train 0.6933 Reg: 0.2357\n",
      "Test: 0.7481 MAE: 0.6873 RMSE: 0.8649\n",
      "Val: 0.7711 MAE: 0.6908 RMSE: 0.8781\n",
      "Epoch 36 Step 6216: Train 0.6863 Reg: 0.2392\n",
      "Test: 0.7442 MAE: 0.6841 RMSE: 0.8627\n",
      "Val: 0.7692 MAE: 0.6895 RMSE: 0.8771\n",
      "Epoch 37 Step 6384: Train 0.6789 Reg: 0.2432\n",
      "Test: 0.7405 MAE: 0.6827 RMSE: 0.8605\n",
      "Val: 0.7667 MAE: 0.6885 RMSE: 0.8756\n",
      "Epoch 38 Step 6552: Train 0.6713 Reg: 0.2473\n",
      "Test: 0.7399 MAE: 0.6835 RMSE: 0.8602\n",
      "Val: 0.7644 MAE: 0.6886 RMSE: 0.8743\n",
      "Epoch 39 Step 6720: Train 0.6634 Reg: 0.2515\n",
      "Test: 0.7389 MAE: 0.6820 RMSE: 0.8596\n",
      "Val: 0.7633 MAE: 0.6876 RMSE: 0.8736\n",
      "Epoch 40 Step 6888: Train 0.6558 Reg: 0.2554\n",
      "Test: 0.7352 MAE: 0.6787 RMSE: 0.8574\n",
      "Val: 0.7628 MAE: 0.6867 RMSE: 0.8734\n",
      "Epoch 41 Step 7056: Train 0.6482 Reg: 0.2593\n",
      "Test: 0.7331 MAE: 0.6763 RMSE: 0.8562\n",
      "Val: 0.7617 MAE: 0.6867 RMSE: 0.8727\n",
      "Epoch 42 Step 7224: Train 0.6405 Reg: 0.2630\n",
      "Test: 0.7327 MAE: 0.6769 RMSE: 0.8560\n",
      "Val: 0.7623 MAE: 0.6868 RMSE: 0.8731\n",
      "Epoch 43 Step 7392: Train 0.6330 Reg: 0.2667\n",
      "Test: 0.7336 MAE: 0.6791 RMSE: 0.8565\n",
      "Val: 0.7620 MAE: 0.6870 RMSE: 0.8729\n",
      "Epoch 44 Step 7560: Train 0.6255 Reg: 0.2703\n",
      "Test: 0.7318 MAE: 0.6775 RMSE: 0.8555\n",
      "Val: 0.7630 MAE: 0.6873 RMSE: 0.8735\n",
      "Epoch 45 Step 7728: Train 0.6178 Reg: 0.2740\n",
      "Test: 0.7334 MAE: 0.6789 RMSE: 0.8564\n",
      "Val: 0.7637 MAE: 0.6880 RMSE: 0.8739\n",
      "Epoch 46 Step 7896: Train 0.6100 Reg: 0.2776\n",
      "Test: 0.7362 MAE: 0.6802 RMSE: 0.8580\n",
      "Val: 0.7643 MAE: 0.6888 RMSE: 0.8743\n",
      "Epoch 47 Step 8064: Train 0.6021 Reg: 0.2811\n",
      "Test: 0.7335 MAE: 0.6767 RMSE: 0.8564\n",
      "Val: 0.7659 MAE: 0.6885 RMSE: 0.8751\n",
      "Epoch 48 Step 8232: Train 0.5941 Reg: 0.2849\n",
      "Test: 0.7354 MAE: 0.6780 RMSE: 0.8575\n",
      "Val: 0.7677 MAE: 0.6893 RMSE: 0.8762\n",
      "Epoch 49 Step 8400: Train 0.5859 Reg: 0.2885\n",
      "Test: 0.7365 MAE: 0.6782 RMSE: 0.8582\n",
      "Val: 0.7696 MAE: 0.6901 RMSE: 0.8773\n",
      "Epoch 50 Step 8568: Train 0.5778 Reg: 0.2921\n",
      "Test: 0.7372 MAE: 0.6797 RMSE: 0.8586\n",
      "Val: 0.7717 MAE: 0.6914 RMSE: 0.8784\n",
      "Epoch 51 Step 8736: Train 0.5696 Reg: 0.2957\n",
      "Test: 0.7382 MAE: 0.6786 RMSE: 0.8592\n",
      "Val: 0.7744 MAE: 0.6921 RMSE: 0.8800\n",
      "Epoch 52 Step 8904: Train 0.5617 Reg: 0.2991\n",
      "Test: 0.7383 MAE: 0.6772 RMSE: 0.8592\n",
      "Val: 0.7768 MAE: 0.6926 RMSE: 0.8814\n",
      "Epoch 53 Step 9072: Train 0.5537 Reg: 0.3025\n",
      "Test: 0.7398 MAE: 0.6782 RMSE: 0.8601\n",
      "Val: 0.7799 MAE: 0.6936 RMSE: 0.8831\n",
      "Epoch 54 Step 9240: Train 0.5461 Reg: 0.3056\n",
      "Test: 0.7413 MAE: 0.6795 RMSE: 0.8610\n",
      "Val: 0.7827 MAE: 0.6950 RMSE: 0.8847\n",
      "Epoch 55 Step 9408: Train 0.5387 Reg: 0.3087\n",
      "Test: 0.7423 MAE: 0.6794 RMSE: 0.8616\n",
      "Val: 0.7856 MAE: 0.6961 RMSE: 0.8864\n",
      "Epoch 56 Step 9576: Train 0.5315 Reg: 0.3115\n",
      "Test: 0.7457 MAE: 0.6819 RMSE: 0.8636\n",
      "Val: 0.7887 MAE: 0.6976 RMSE: 0.8881\n",
      "Epoch 57 Step 9744: Train 0.5246 Reg: 0.3142\n",
      "Test: 0.7456 MAE: 0.6807 RMSE: 0.8635\n",
      "Val: 0.7916 MAE: 0.6985 RMSE: 0.8897\n",
      "Epoch 58 Step 9912: Train 0.5179 Reg: 0.3167\n",
      "Test: 0.7478 MAE: 0.6829 RMSE: 0.8648\n",
      "Val: 0.7944 MAE: 0.7002 RMSE: 0.8913\n",
      "Epoch 59 Step 10080: Train 0.5116 Reg: 0.3190\n",
      "Test: 0.7497 MAE: 0.6826 RMSE: 0.8658\n",
      "Val: 0.7981 MAE: 0.7011 RMSE: 0.8934\n",
      "Epoch 60 Step 10248: Train 0.5056 Reg: 0.3212\n",
      "Test: 0.7502 MAE: 0.6831 RMSE: 0.8661\n",
      "Val: 0.8009 MAE: 0.7023 RMSE: 0.8949\n",
      "Epoch 61 Step 10416: Train 0.4999 Reg: 0.3232\n",
      "Test: 0.7524 MAE: 0.6842 RMSE: 0.8674\n",
      "Val: 0.8036 MAE: 0.7034 RMSE: 0.8964\n",
      "Epoch 62 Step 10584: Train 0.4945 Reg: 0.3251\n",
      "Test: 0.7544 MAE: 0.6851 RMSE: 0.8685\n",
      "Val: 0.8068 MAE: 0.7046 RMSE: 0.8982\n",
      "Epoch 63 Step 10752: Train 0.4894 Reg: 0.3268\n",
      "Test: 0.7556 MAE: 0.6850 RMSE: 0.8692\n",
      "Val: 0.8092 MAE: 0.7053 RMSE: 0.8996\n",
      "Epoch 64 Step 10920: Train 0.4845 Reg: 0.3284\n",
      "Test: 0.7577 MAE: 0.6861 RMSE: 0.8705\n",
      "Val: 0.8121 MAE: 0.7066 RMSE: 0.9012\n",
      "Epoch 65 Step 11088: Train 0.4799 Reg: 0.3299\n",
      "Test: 0.7595 MAE: 0.6859 RMSE: 0.8715\n",
      "Val: 0.8144 MAE: 0.7073 RMSE: 0.9024\n",
      "Epoch 66 Step 11256: Train 0.4756 Reg: 0.3313\n",
      "Test: 0.7613 MAE: 0.6866 RMSE: 0.8725\n",
      "Val: 0.8170 MAE: 0.7082 RMSE: 0.9039\n",
      "Epoch 67 Step 11424: Train 0.4715 Reg: 0.3325\n",
      "Test: 0.7625 MAE: 0.6873 RMSE: 0.8732\n",
      "Val: 0.8195 MAE: 0.7093 RMSE: 0.9053\n",
      "Epoch 68 Step 11592: Train 0.4676 Reg: 0.3337\n",
      "Test: 0.7648 MAE: 0.6892 RMSE: 0.8745\n",
      "Val: 0.8215 MAE: 0.7105 RMSE: 0.9064\n",
      "Epoch 69 Step 11760: Train 0.4640 Reg: 0.3348\n",
      "Test: 0.7660 MAE: 0.6883 RMSE: 0.8752\n",
      "Val: 0.8237 MAE: 0.7108 RMSE: 0.9076\n",
      "Epoch 70 Step 11928: Train 0.4605 Reg: 0.3358\n",
      "Test: 0.7678 MAE: 0.6886 RMSE: 0.8762\n",
      "Val: 0.8257 MAE: 0.7115 RMSE: 0.9087\n",
      "Epoch 71 Step 12096: Train 0.4572 Reg: 0.3368\n",
      "Test: 0.7694 MAE: 0.6886 RMSE: 0.8772\n",
      "Val: 0.8279 MAE: 0.7121 RMSE: 0.9099\n",
      "Epoch 72 Step 12264: Train 0.4542 Reg: 0.3377\n",
      "Test: 0.7705 MAE: 0.6891 RMSE: 0.8778\n",
      "Val: 0.8297 MAE: 0.7130 RMSE: 0.9109\n",
      "Epoch 73 Step 12432: Train 0.4513 Reg: 0.3385\n",
      "Test: 0.7719 MAE: 0.6897 RMSE: 0.8786\n",
      "Val: 0.8315 MAE: 0.7138 RMSE: 0.9119\n",
      "Epoch 74 Step 12600: Train 0.4485 Reg: 0.3392\n",
      "Test: 0.7733 MAE: 0.6901 RMSE: 0.8794\n",
      "Val: 0.8332 MAE: 0.7145 RMSE: 0.9128\n",
      "Epoch 75 Step 12768: Train 0.4459 Reg: 0.3399\n",
      "Test: 0.7749 MAE: 0.6905 RMSE: 0.8803\n",
      "Val: 0.8351 MAE: 0.7151 RMSE: 0.9138\n",
      "Epoch 76 Step 12936: Train 0.4435 Reg: 0.3406\n",
      "Test: 0.7758 MAE: 0.6903 RMSE: 0.8808\n",
      "Val: 0.8366 MAE: 0.7156 RMSE: 0.9147\n",
      "Epoch 77 Step 13104: Train 0.4411 Reg: 0.3412\n",
      "Test: 0.7770 MAE: 0.6910 RMSE: 0.8815\n",
      "Val: 0.8381 MAE: 0.7163 RMSE: 0.9155\n",
      "Epoch 78 Step 13272: Train 0.4389 Reg: 0.3418\n",
      "Test: 0.7783 MAE: 0.6920 RMSE: 0.8822\n",
      "Val: 0.8395 MAE: 0.7170 RMSE: 0.9162\n",
      "Epoch 79 Step 13440: Train 0.4369 Reg: 0.3423\n",
      "Test: 0.7791 MAE: 0.6922 RMSE: 0.8827\n",
      "Val: 0.8408 MAE: 0.7176 RMSE: 0.9169\n",
      "Epoch 80 Step 13608: Train 0.4349 Reg: 0.3428\n",
      "Test: 0.7803 MAE: 0.6926 RMSE: 0.8834\n",
      "Val: 0.8420 MAE: 0.7181 RMSE: 0.9176\n",
      "Epoch 81 Step 13776: Train 0.4330 Reg: 0.3432\n",
      "Test: 0.7817 MAE: 0.6925 RMSE: 0.8841\n",
      "Val: 0.8433 MAE: 0.7184 RMSE: 0.9183\n",
      "Epoch 82 Step 13944: Train 0.4313 Reg: 0.3437\n",
      "Test: 0.7823 MAE: 0.6928 RMSE: 0.8845\n",
      "Val: 0.8444 MAE: 0.7189 RMSE: 0.9189\n",
      "Epoch 83 Step 14112: Train 0.4296 Reg: 0.3441\n",
      "Test: 0.7831 MAE: 0.6935 RMSE: 0.8849\n",
      "Val: 0.8455 MAE: 0.7195 RMSE: 0.9195\n",
      "Epoch 84 Step 14280: Train 0.4281 Reg: 0.3445\n",
      "Test: 0.7843 MAE: 0.6935 RMSE: 0.8856\n",
      "Val: 0.8467 MAE: 0.7198 RMSE: 0.9201\n",
      "Epoch 85 Step 14448: Train 0.4266 Reg: 0.3448\n",
      "Test: 0.7851 MAE: 0.6938 RMSE: 0.8860\n",
      "Val: 0.8477 MAE: 0.7203 RMSE: 0.9207\n",
      "Epoch 86 Step 14616: Train 0.4252 Reg: 0.3451\n",
      "Test: 0.7860 MAE: 0.6936 RMSE: 0.8866\n",
      "Val: 0.8487 MAE: 0.7206 RMSE: 0.9213\n",
      "Epoch 87 Step 14784: Train 0.4239 Reg: 0.3454\n",
      "Test: 0.7867 MAE: 0.6943 RMSE: 0.8870\n",
      "Val: 0.8496 MAE: 0.7210 RMSE: 0.9217\n",
      "Epoch 88 Step 14952: Train 0.4226 Reg: 0.3457\n",
      "Test: 0.7872 MAE: 0.6941 RMSE: 0.8872\n",
      "Val: 0.8505 MAE: 0.7213 RMSE: 0.9222\n",
      "Epoch 89 Step 15120: Train 0.4214 Reg: 0.3460\n",
      "Test: 0.7881 MAE: 0.6947 RMSE: 0.8877\n",
      "Val: 0.8513 MAE: 0.7217 RMSE: 0.9227\n",
      "Epoch 90 Step 15288: Train 0.4203 Reg: 0.3463\n",
      "Test: 0.7888 MAE: 0.6951 RMSE: 0.8881\n",
      "Val: 0.8520 MAE: 0.7221 RMSE: 0.9231\n",
      "Epoch 91 Step 15456: Train 0.4192 Reg: 0.3465\n",
      "Test: 0.7896 MAE: 0.6951 RMSE: 0.8886\n",
      "Val: 0.8528 MAE: 0.7223 RMSE: 0.9235\n",
      "Epoch 92 Step 15624: Train 0.4182 Reg: 0.3467\n",
      "Test: 0.7901 MAE: 0.6951 RMSE: 0.8889\n",
      "Val: 0.8536 MAE: 0.7225 RMSE: 0.9239\n",
      "Epoch 93 Step 15792: Train 0.4173 Reg: 0.3469\n",
      "Test: 0.7908 MAE: 0.6950 RMSE: 0.8893\n",
      "Val: 0.8543 MAE: 0.7227 RMSE: 0.9243\n",
      "Epoch 94 Step 15960: Train 0.4163 Reg: 0.3471\n",
      "Test: 0.7915 MAE: 0.6950 RMSE: 0.8897\n",
      "Val: 0.8550 MAE: 0.7229 RMSE: 0.9247\n",
      "Epoch 95 Step 16128: Train 0.4155 Reg: 0.3473\n",
      "Test: 0.7920 MAE: 0.6955 RMSE: 0.8899\n",
      "Val: 0.8556 MAE: 0.7233 RMSE: 0.9250\n",
      "Epoch 96 Step 16296: Train 0.4147 Reg: 0.3475\n",
      "Test: 0.7924 MAE: 0.6961 RMSE: 0.8902\n",
      "Val: 0.8562 MAE: 0.7237 RMSE: 0.9253\n",
      "Epoch 97 Step 16464: Train 0.4139 Reg: 0.3477\n",
      "Test: 0.7929 MAE: 0.6959 RMSE: 0.8905\n",
      "Val: 0.8568 MAE: 0.7238 RMSE: 0.9256\n",
      "Epoch 98 Step 16632: Train 0.4132 Reg: 0.3478\n",
      "Test: 0.7934 MAE: 0.6960 RMSE: 0.8907\n",
      "Val: 0.8573 MAE: 0.7240 RMSE: 0.9259\n",
      "Epoch 99 Step 16800: Train 0.4125 Reg: 0.3480\n",
      "Test: 0.7940 MAE: 0.6962 RMSE: 0.8911\n",
      "Val: 0.8578 MAE: 0.7242 RMSE: 0.9262\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 181085/19100\n",
      "test set size: support/query 523/809\n",
      "Epoch 0: TrainLoss 1.1273 RecLoss: 0.0000 (left: 0:09:13)\n",
      "TestLoss: 1.0638 MAE: 0.8091 RMSE: 1.0314\n",
      "ValLoss: 1.1340 MAE: 0.8431 RMSE: 1.0649\n",
      "Epoch 1: TrainLoss 1.0037 RecLoss: 0.0000 (left: 0:08:51)\n",
      "TestLoss: 1.0320 MAE: 0.8053 RMSE: 1.0159\n",
      "ValLoss: 1.0861 MAE: 0.8292 RMSE: 1.0422\n",
      "Epoch 2: TrainLoss 0.9710 RecLoss: 0.0000 (left: 0:08:46)\n",
      "TestLoss: 1.0200 MAE: 0.8107 RMSE: 1.0099\n",
      "ValLoss: 1.0623 MAE: 0.8277 RMSE: 1.0307\n",
      "Epoch 3: TrainLoss 0.9551 RecLoss: 0.0000 (left: 0:08:43)\n",
      "TestLoss: 1.0275 MAE: 0.8230 RMSE: 1.0137\n",
      "ValLoss: 1.0612 MAE: 0.8348 RMSE: 1.0301\n",
      "Epoch 4: TrainLoss 0.9358 RecLoss: 0.0000 (left: 0:08:22)\n",
      "TestLoss: 1.0030 MAE: 0.7998 RMSE: 1.0015\n",
      "ValLoss: 1.0447 MAE: 0.8185 RMSE: 1.0221\n",
      "Epoch 5: TrainLoss 0.9240 RecLoss: 0.0000 (left: 0:08:07)\n",
      "TestLoss: 0.9994 MAE: 0.7950 RMSE: 0.9997\n",
      "ValLoss: 1.0496 MAE: 0.8155 RMSE: 1.0245\n",
      "Epoch 6: TrainLoss 0.9161 RecLoss: 0.0000 (left: 0:07:48)\n",
      "TestLoss: 0.9978 MAE: 0.7923 RMSE: 0.9989\n",
      "ValLoss: 1.0435 MAE: 0.8128 RMSE: 1.0215\n",
      "Epoch 7: TrainLoss 0.9108 RecLoss: 0.0000 (left: 0:07:45)\n",
      "TestLoss: 0.9947 MAE: 0.7928 RMSE: 0.9973\n",
      "ValLoss: 1.0405 MAE: 0.8138 RMSE: 1.0200\n",
      "Epoch 8: TrainLoss 0.9090 RecLoss: 0.0000 (left: 0:07:35)\n",
      "TestLoss: 1.0003 MAE: 0.8018 RMSE: 1.0002\n",
      "ValLoss: 1.0397 MAE: 0.8179 RMSE: 1.0197\n",
      "Epoch 9: TrainLoss 0.9055 RecLoss: 0.0000 (left: 0:07:31)\n",
      "TestLoss: 0.9993 MAE: 0.7977 RMSE: 0.9996\n",
      "ValLoss: 1.0399 MAE: 0.8155 RMSE: 1.0198\n",
      "Epoch 10: TrainLoss 0.8998 RecLoss: 0.0000 (left: 0:07:16)\n",
      "TestLoss: 0.9979 MAE: 0.7979 RMSE: 0.9990\n",
      "ValLoss: 1.0390 MAE: 0.8162 RMSE: 1.0193\n",
      "Epoch 11: TrainLoss 0.8972 RecLoss: 0.0000 (left: 0:07:14)\n",
      "TestLoss: 0.9966 MAE: 0.7895 RMSE: 0.9983\n",
      "ValLoss: 1.0440 MAE: 0.8101 RMSE: 1.0218\n",
      "Epoch 12: TrainLoss 0.8969 RecLoss: 0.0000 (left: 0:07:08)\n",
      "TestLoss: 0.9988 MAE: 0.7896 RMSE: 0.9994\n",
      "ValLoss: 1.0501 MAE: 0.8119 RMSE: 1.0248\n",
      "Epoch 13: TrainLoss 0.8958 RecLoss: 0.0000 (left: 0:06:56)\n",
      "TestLoss: 0.9994 MAE: 0.7929 RMSE: 0.9997\n",
      "ValLoss: 1.0436 MAE: 0.8120 RMSE: 1.0216\n",
      "Epoch 14: TrainLoss 0.8977 RecLoss: 0.0000 (left: 0:06:43)\n",
      "TestLoss: 1.0266 MAE: 0.8220 RMSE: 1.0132\n",
      "ValLoss: 1.0578 MAE: 0.8343 RMSE: 1.0285\n",
      "Epoch 15: TrainLoss 0.8994 RecLoss: 0.0000 (left: 0:06:31)\n",
      "TestLoss: 1.0005 MAE: 0.7959 RMSE: 1.0003\n",
      "ValLoss: 1.0480 MAE: 0.8158 RMSE: 1.0237\n",
      "Epoch 16: TrainLoss 0.8929 RecLoss: 0.0000 (left: 0:06:23)\n",
      "TestLoss: 1.0015 MAE: 0.7965 RMSE: 1.0007\n",
      "ValLoss: 1.0474 MAE: 0.8165 RMSE: 1.0234\n",
      "Epoch 17: TrainLoss 0.8936 RecLoss: 0.0000 (left: 0:06:15)\n",
      "TestLoss: 1.0018 MAE: 0.7899 RMSE: 1.0009\n",
      "ValLoss: 1.0575 MAE: 0.8135 RMSE: 1.0283\n",
      "Epoch 18: TrainLoss 0.8948 RecLoss: 0.0000 (left: 0:06:07)\n",
      "TestLoss: 1.0072 MAE: 0.8039 RMSE: 1.0036\n",
      "ValLoss: 1.0531 MAE: 0.8235 RMSE: 1.0262\n",
      "Epoch 19: TrainLoss 0.8963 RecLoss: 0.0000 (left: 0:05:59)\n",
      "TestLoss: 1.0030 MAE: 0.7948 RMSE: 1.0015\n",
      "ValLoss: 1.0493 MAE: 0.8145 RMSE: 1.0244\n",
      "Epoch 20: TrainLoss 0.8936 RecLoss: 0.0000 (left: 0:05:57)\n",
      "TestLoss: 1.0042 MAE: 0.7993 RMSE: 1.0021\n",
      "ValLoss: 1.0503 MAE: 0.8193 RMSE: 1.0248\n",
      "Epoch 21: TrainLoss 0.8935 RecLoss: 0.0000 (left: 0:05:53)\n",
      "TestLoss: 1.0053 MAE: 0.7867 RMSE: 1.0026\n",
      "ValLoss: 1.0636 MAE: 0.8104 RMSE: 1.0313\n",
      "Epoch 22: TrainLoss 0.8939 RecLoss: 0.0000 (left: 0:05:50)\n",
      "TestLoss: 1.0048 MAE: 0.7977 RMSE: 1.0024\n",
      "ValLoss: 1.0518 MAE: 0.8164 RMSE: 1.0256\n",
      "Epoch 23: TrainLoss 0.8934 RecLoss: 0.0000 (left: 0:05:47)\n",
      "TestLoss: 1.0258 MAE: 0.8181 RMSE: 1.0128\n",
      "ValLoss: 1.0643 MAE: 0.8338 RMSE: 1.0316\n",
      "Epoch 24: TrainLoss 0.8991 RecLoss: 0.0000 (left: 0:05:46)\n",
      "TestLoss: 1.0086 MAE: 0.8030 RMSE: 1.0043\n",
      "ValLoss: 1.0540 MAE: 0.8216 RMSE: 1.0267\n",
      "Epoch 25: TrainLoss 0.8910 RecLoss: 0.0000 (left: 0:05:45)\n",
      "TestLoss: 1.0020 MAE: 0.7932 RMSE: 1.0010\n",
      "ValLoss: 1.0542 MAE: 0.8150 RMSE: 1.0267\n",
      "Epoch 26: TrainLoss 0.8913 RecLoss: 0.0000 (left: 0:05:39)\n",
      "TestLoss: 1.0081 MAE: 0.7858 RMSE: 1.0041\n",
      "ValLoss: 1.0692 MAE: 0.8100 RMSE: 1.0340\n",
      "Epoch 27: TrainLoss 0.8941 RecLoss: 0.0000 (left: 0:05:34)\n",
      "TestLoss: 1.0040 MAE: 0.7918 RMSE: 1.0020\n",
      "ValLoss: 1.0610 MAE: 0.8153 RMSE: 1.0300\n",
      "Epoch 28: TrainLoss 0.8922 RecLoss: 0.0000 (left: 0:05:29)\n",
      "TestLoss: 1.0082 MAE: 0.8006 RMSE: 1.0041\n",
      "ValLoss: 1.0562 MAE: 0.8201 RMSE: 1.0277\n",
      "Epoch 29: TrainLoss 0.8931 RecLoss: 0.0000 (left: 0:05:25)\n",
      "TestLoss: 1.0031 MAE: 0.7934 RMSE: 1.0016\n",
      "ValLoss: 1.0589 MAE: 0.8159 RMSE: 1.0290\n",
      "Epoch 30: TrainLoss 0.8920 RecLoss: 0.0000 (left: 0:05:21)\n",
      "TestLoss: 1.0135 MAE: 0.7837 RMSE: 1.0067\n",
      "ValLoss: 1.0804 MAE: 0.8113 RMSE: 1.0394\n",
      "Epoch 31: TrainLoss 0.8955 RecLoss: 0.0000 (left: 0:05:17)\n",
      "TestLoss: 1.0032 MAE: 0.7903 RMSE: 1.0016\n",
      "ValLoss: 1.0614 MAE: 0.8141 RMSE: 1.0303\n",
      "Epoch 32: TrainLoss 0.8897 RecLoss: 0.0000 (left: 0:05:12)\n",
      "TestLoss: 1.0036 MAE: 0.7922 RMSE: 1.0018\n",
      "ValLoss: 1.0588 MAE: 0.8141 RMSE: 1.0290\n",
      "Epoch 33: TrainLoss 0.8915 RecLoss: 0.0000 (left: 0:05:08)\n",
      "TestLoss: 1.0042 MAE: 0.7949 RMSE: 1.0021\n",
      "ValLoss: 1.0581 MAE: 0.8164 RMSE: 1.0287\n",
      "Epoch 34: TrainLoss 0.8903 RecLoss: 0.0000 (left: 0:05:02)\n",
      "TestLoss: 1.0071 MAE: 0.7864 RMSE: 1.0035\n",
      "ValLoss: 1.0693 MAE: 0.8113 RMSE: 1.0341\n",
      "Epoch 35: TrainLoss 0.8926 RecLoss: 0.0000 (left: 0:04:57)\n",
      "TestLoss: 1.0146 MAE: 0.8074 RMSE: 1.0073\n",
      "ValLoss: 1.0613 MAE: 0.8257 RMSE: 1.0302\n",
      "Epoch 36: TrainLoss 0.8919 RecLoss: 0.0000 (left: 0:04:52)\n",
      "TestLoss: 1.0044 MAE: 0.7933 RMSE: 1.0022\n",
      "ValLoss: 1.0569 MAE: 0.8141 RMSE: 1.0280\n",
      "Epoch 37: TrainLoss 0.8901 RecLoss: 0.0000 (left: 0:04:47)\n",
      "TestLoss: 1.0057 MAE: 0.7979 RMSE: 1.0028\n",
      "ValLoss: 1.0599 MAE: 0.8187 RMSE: 1.0295\n",
      "Epoch 38: TrainLoss 0.8913 RecLoss: 0.0000 (left: 0:04:45)\n",
      "TestLoss: 1.0070 MAE: 0.7986 RMSE: 1.0035\n",
      "ValLoss: 1.0587 MAE: 0.8188 RMSE: 1.0289\n",
      "Epoch 39: TrainLoss 0.8914 RecLoss: 0.0000 (left: 0:04:41)\n",
      "TestLoss: 1.0099 MAE: 0.7851 RMSE: 1.0049\n",
      "ValLoss: 1.0764 MAE: 0.8128 RMSE: 1.0375\n",
      "Epoch 40: TrainLoss 0.8948 RecLoss: 0.0000 (left: 0:04:35)\n",
      "TestLoss: 1.0095 MAE: 0.7870 RMSE: 1.0047\n",
      "ValLoss: 1.0743 MAE: 0.8129 RMSE: 1.0365\n",
      "Epoch 41: TrainLoss 0.8919 RecLoss: 0.0000 (left: 0:04:30)\n",
      "TestLoss: 1.0067 MAE: 0.7978 RMSE: 1.0033\n",
      "ValLoss: 1.0589 MAE: 0.8175 RMSE: 1.0290\n",
      "Epoch 42: TrainLoss 0.8928 RecLoss: 0.0000 (left: 0:04:25)\n",
      "TestLoss: 1.0093 MAE: 0.8023 RMSE: 1.0046\n",
      "ValLoss: 1.0596 MAE: 0.8217 RMSE: 1.0294\n",
      "Epoch 43: TrainLoss 0.8919 RecLoss: 0.0000 (left: 0:04:20)\n",
      "TestLoss: 1.0041 MAE: 0.7908 RMSE: 1.0020\n",
      "ValLoss: 1.0632 MAE: 0.8131 RMSE: 1.0311\n",
      "Epoch 44: TrainLoss 0.8893 RecLoss: 0.0000 (left: 0:04:17)\n",
      "TestLoss: 1.0046 MAE: 0.7955 RMSE: 1.0023\n",
      "ValLoss: 1.0603 MAE: 0.8176 RMSE: 1.0297\n",
      "Epoch 45: TrainLoss 0.8897 RecLoss: 0.0000 (left: 0:04:13)\n",
      "TestLoss: 1.0059 MAE: 0.7959 RMSE: 1.0030\n",
      "ValLoss: 1.0606 MAE: 0.8165 RMSE: 1.0298\n",
      "Epoch 46: TrainLoss 0.8892 RecLoss: 0.0000 (left: 0:04:10)\n",
      "TestLoss: 1.0053 MAE: 0.7931 RMSE: 1.0026\n",
      "ValLoss: 1.0617 MAE: 0.8151 RMSE: 1.0304\n",
      "Epoch 47: TrainLoss 0.8902 RecLoss: 0.0000 (left: 0:04:06)\n",
      "TestLoss: 1.0031 MAE: 0.7907 RMSE: 1.0015\n",
      "ValLoss: 1.0616 MAE: 0.8131 RMSE: 1.0303\n",
      "Epoch 48: TrainLoss 0.8911 RecLoss: 0.0000 (left: 0:04:03)\n",
      "TestLoss: 1.0048 MAE: 0.7908 RMSE: 1.0024\n",
      "ValLoss: 1.0629 MAE: 0.8135 RMSE: 1.0310\n",
      "Epoch 49: TrainLoss 0.8903 RecLoss: 0.0000 (left: 0:03:58)\n",
      "TestLoss: 1.0045 MAE: 0.7904 RMSE: 1.0023\n",
      "ValLoss: 1.0648 MAE: 0.8135 RMSE: 1.0319\n",
      "Epoch 50: TrainLoss 0.8906 RecLoss: 0.0000 (left: 0:03:54)\n",
      "TestLoss: 1.0049 MAE: 0.7897 RMSE: 1.0024\n",
      "ValLoss: 1.0663 MAE: 0.8136 RMSE: 1.0326\n",
      "Epoch 51: TrainLoss 0.8903 RecLoss: 0.0000 (left: 0:03:50)\n",
      "TestLoss: 1.0065 MAE: 0.7976 RMSE: 1.0032\n",
      "ValLoss: 1.0603 MAE: 0.8182 RMSE: 1.0297\n",
      "Epoch 52: TrainLoss 0.8902 RecLoss: 0.0000 (left: 0:03:45)\n",
      "TestLoss: 1.0102 MAE: 0.8027 RMSE: 1.0051\n",
      "ValLoss: 1.0617 MAE: 0.8219 RMSE: 1.0304\n",
      "Epoch 53: TrainLoss 0.8928 RecLoss: 0.0000 (left: 0:03:41)\n",
      "TestLoss: 1.0081 MAE: 0.7996 RMSE: 1.0041\n",
      "ValLoss: 1.0574 MAE: 0.8187 RMSE: 1.0283\n",
      "Epoch 54: TrainLoss 0.8902 RecLoss: 0.0000 (left: 0:03:36)\n",
      "TestLoss: 1.0048 MAE: 0.7921 RMSE: 1.0024\n",
      "ValLoss: 1.0628 MAE: 0.8140 RMSE: 1.0309\n",
      "Epoch 55: TrainLoss 0.8903 RecLoss: 0.0000 (left: 0:03:32)\n",
      "TestLoss: 1.0054 MAE: 0.7956 RMSE: 1.0027\n",
      "ValLoss: 1.0601 MAE: 0.8168 RMSE: 1.0296\n",
      "Epoch 56: TrainLoss 0.8898 RecLoss: 0.0000 (left: 0:03:28)\n",
      "TestLoss: 1.0045 MAE: 0.7935 RMSE: 1.0023\n",
      "ValLoss: 1.0622 MAE: 0.8161 RMSE: 1.0306\n",
      "Epoch 57: TrainLoss 0.8915 RecLoss: 0.0000 (left: 0:03:24)\n",
      "TestLoss: 1.0068 MAE: 0.7868 RMSE: 1.0034\n",
      "ValLoss: 1.0695 MAE: 0.8118 RMSE: 1.0341\n",
      "Epoch 58: TrainLoss 0.8891 RecLoss: 0.0000 (left: 0:03:20)\n",
      "TestLoss: 1.0046 MAE: 0.7940 RMSE: 1.0023\n",
      "ValLoss: 1.0613 MAE: 0.8154 RMSE: 1.0302\n",
      "Epoch 59: TrainLoss 0.8890 RecLoss: 0.0000 (left: 0:03:15)\n",
      "TestLoss: 1.0045 MAE: 0.7945 RMSE: 1.0023\n",
      "ValLoss: 1.0601 MAE: 0.8160 RMSE: 1.0296\n",
      "Epoch 60: TrainLoss 0.8889 RecLoss: 0.0000 (left: 0:03:10)\n",
      "TestLoss: 1.0047 MAE: 0.7916 RMSE: 1.0023\n",
      "ValLoss: 1.0617 MAE: 0.8133 RMSE: 1.0304\n",
      "Epoch 61: TrainLoss 0.8895 RecLoss: 0.0000 (left: 0:03:05)\n",
      "TestLoss: 1.0054 MAE: 0.7963 RMSE: 1.0027\n",
      "ValLoss: 1.0596 MAE: 0.8172 RMSE: 1.0294\n",
      "Epoch 62: TrainLoss 0.8892 RecLoss: 0.0000 (left: 0:03:00)\n",
      "TestLoss: 1.0132 MAE: 0.8057 RMSE: 1.0066\n",
      "ValLoss: 1.0601 MAE: 0.8236 RMSE: 1.0296\n",
      "Epoch 63: TrainLoss 0.8931 RecLoss: 0.0000 (left: 0:02:55)\n",
      "TestLoss: 1.0121 MAE: 0.8035 RMSE: 1.0060\n",
      "ValLoss: 1.0611 MAE: 0.8223 RMSE: 1.0301\n",
      "Epoch 64: TrainLoss 0.8908 RecLoss: 0.0000 (left: 0:02:50)\n",
      "TestLoss: 1.0042 MAE: 0.7922 RMSE: 1.0021\n",
      "ValLoss: 1.0631 MAE: 0.8150 RMSE: 1.0311\n",
      "Epoch 65: TrainLoss 0.8891 RecLoss: 0.0000 (left: 0:02:45)\n",
      "TestLoss: 1.0066 MAE: 0.7885 RMSE: 1.0033\n",
      "ValLoss: 1.0697 MAE: 0.8129 RMSE: 1.0343\n",
      "Epoch 66: TrainLoss 0.8891 RecLoss: 0.0000 (left: 0:02:41)\n",
      "TestLoss: 1.0037 MAE: 0.7905 RMSE: 1.0019\n",
      "ValLoss: 1.0615 MAE: 0.8129 RMSE: 1.0303\n",
      "Epoch 67: TrainLoss 0.8891 RecLoss: 0.0000 (left: 0:02:36)\n",
      "TestLoss: 1.0037 MAE: 0.7911 RMSE: 1.0018\n",
      "ValLoss: 1.0642 MAE: 0.8140 RMSE: 1.0316\n",
      "Epoch 68: TrainLoss 0.8902 RecLoss: 0.0000 (left: 0:02:31)\n",
      "TestLoss: 1.0046 MAE: 0.7888 RMSE: 1.0023\n",
      "ValLoss: 1.0632 MAE: 0.8117 RMSE: 1.0311\n",
      "Epoch 69: TrainLoss 0.8934 RecLoss: 0.0000 (left: 0:02:27)\n",
      "TestLoss: 1.0093 MAE: 0.7855 RMSE: 1.0046\n",
      "ValLoss: 1.0757 MAE: 0.8121 RMSE: 1.0371\n",
      "Epoch 70: TrainLoss 0.8966 RecLoss: 0.0000 (left: 0:02:23)\n",
      "TestLoss: 1.0215 MAE: 0.7838 RMSE: 1.0107\n",
      "ValLoss: 1.0957 MAE: 0.8145 RMSE: 1.0468\n",
      "Epoch 71: TrainLoss 0.8927 RecLoss: 0.0000 (left: 0:02:18)\n",
      "TestLoss: 1.0041 MAE: 0.7909 RMSE: 1.0020\n",
      "ValLoss: 1.0632 MAE: 0.8135 RMSE: 1.0311\n",
      "Epoch 72: TrainLoss 0.8897 RecLoss: 0.0000 (left: 0:02:13)\n",
      "TestLoss: 1.0054 MAE: 0.7890 RMSE: 1.0027\n",
      "ValLoss: 1.0676 MAE: 0.8132 RMSE: 1.0333\n",
      "Epoch 73: TrainLoss 0.8887 RecLoss: 0.0000 (left: 0:02:08)\n",
      "TestLoss: 1.0053 MAE: 0.7954 RMSE: 1.0026\n",
      "ValLoss: 1.0602 MAE: 0.8163 RMSE: 1.0297\n",
      "Epoch 74: TrainLoss 0.8890 RecLoss: 0.0000 (left: 0:02:04)\n",
      "TestLoss: 1.0042 MAE: 0.7933 RMSE: 1.0021\n",
      "ValLoss: 1.0618 MAE: 0.8155 RMSE: 1.0304\n",
      "Epoch 75: TrainLoss 0.8889 RecLoss: 0.0000 (left: 0:01:59)\n",
      "TestLoss: 1.0086 MAE: 0.7852 RMSE: 1.0043\n",
      "ValLoss: 1.0740 MAE: 0.8106 RMSE: 1.0363\n",
      "Epoch 76: TrainLoss 0.8913 RecLoss: 0.0000 (left: 0:01:54)\n",
      "TestLoss: 1.0044 MAE: 0.7897 RMSE: 1.0022\n",
      "ValLoss: 1.0662 MAE: 0.8139 RMSE: 1.0326\n",
      "Epoch 77: TrainLoss 0.8894 RecLoss: 0.0000 (left: 0:01:49)\n",
      "TestLoss: 1.0062 MAE: 0.7885 RMSE: 1.0031\n",
      "ValLoss: 1.0680 MAE: 0.8115 RMSE: 1.0334\n",
      "Epoch 78: TrainLoss 0.8905 RecLoss: 0.0000 (left: 0:01:44)\n",
      "TestLoss: 1.0095 MAE: 0.7855 RMSE: 1.0047\n",
      "ValLoss: 1.0773 MAE: 0.8123 RMSE: 1.0379\n",
      "Epoch 79: TrainLoss 0.8894 RecLoss: 0.0000 (left: 0:01:40)\n",
      "TestLoss: 1.0054 MAE: 0.7964 RMSE: 1.0027\n",
      "ValLoss: 1.0593 MAE: 0.8168 RMSE: 1.0292\n",
      "Epoch 80: TrainLoss 0.8897 RecLoss: 0.0000 (left: 0:01:35)\n",
      "TestLoss: 1.0060 MAE: 0.7981 RMSE: 1.0030\n",
      "ValLoss: 1.0606 MAE: 0.8180 RMSE: 1.0299\n",
      "Epoch 81: TrainLoss 0.8884 RecLoss: 0.0000 (left: 0:01:31)\n",
      "TestLoss: 1.0035 MAE: 0.7941 RMSE: 1.0017\n",
      "ValLoss: 1.0605 MAE: 0.8161 RMSE: 1.0298\n",
      "Epoch 82: TrainLoss 0.8918 RecLoss: 0.0000 (left: 0:01:26)\n",
      "TestLoss: 1.0066 MAE: 0.7867 RMSE: 1.0033\n",
      "ValLoss: 1.0711 MAE: 0.8118 RMSE: 1.0349\n",
      "Epoch 83: TrainLoss 0.8954 RecLoss: 0.0000 (left: 0:01:21)\n",
      "TestLoss: 1.0054 MAE: 0.7897 RMSE: 1.0027\n",
      "ValLoss: 1.0676 MAE: 0.8137 RMSE: 1.0333\n",
      "Epoch 84: TrainLoss 0.8884 RecLoss: 0.0000 (left: 0:01:16)\n",
      "TestLoss: 1.0069 MAE: 0.7982 RMSE: 1.0034\n",
      "ValLoss: 1.0599 MAE: 0.8180 RMSE: 1.0295\n",
      "Epoch 85: TrainLoss 0.8910 RecLoss: 0.0000 (left: 0:01:12)\n",
      "TestLoss: 1.0036 MAE: 0.7926 RMSE: 1.0018\n",
      "ValLoss: 1.0625 MAE: 0.8153 RMSE: 1.0308\n",
      "Epoch 86: TrainLoss 0.8907 RecLoss: 0.0000 (left: 0:01:07)\n",
      "TestLoss: 1.0060 MAE: 0.7885 RMSE: 1.0030\n",
      "ValLoss: 1.0698 MAE: 0.8136 RMSE: 1.0343\n",
      "Epoch 87: TrainLoss 0.8903 RecLoss: 0.0000 (left: 0:01:02)\n",
      "TestLoss: 1.0045 MAE: 0.7898 RMSE: 1.0023\n",
      "ValLoss: 1.0649 MAE: 0.8129 RMSE: 1.0320\n",
      "Epoch 88: TrainLoss 0.8915 RecLoss: 0.0000 (left: 0:00:57)\n",
      "TestLoss: 1.0057 MAE: 0.7900 RMSE: 1.0029\n",
      "ValLoss: 1.0671 MAE: 0.8132 RMSE: 1.0330\n",
      "Epoch 89: TrainLoss 0.8897 RecLoss: 0.0000 (left: 0:00:52)\n",
      "TestLoss: 1.0044 MAE: 0.7903 RMSE: 1.0022\n",
      "ValLoss: 1.0642 MAE: 0.8131 RMSE: 1.0316\n",
      "Epoch 90: TrainLoss 0.8894 RecLoss: 0.0000 (left: 0:00:47)\n",
      "TestLoss: 1.0046 MAE: 0.7952 RMSE: 1.0023\n",
      "ValLoss: 1.0622 MAE: 0.8167 RMSE: 1.0306\n",
      "Epoch 91: TrainLoss 0.8914 RecLoss: 0.0000 (left: 0:00:43)\n",
      "TestLoss: 1.0042 MAE: 0.7942 RMSE: 1.0021\n",
      "ValLoss: 1.0607 MAE: 0.8156 RMSE: 1.0299\n",
      "Epoch 92: TrainLoss 0.8884 RecLoss: 0.0000 (left: 0:00:38)\n",
      "TestLoss: 1.0039 MAE: 0.7934 RMSE: 1.0019\n",
      "ValLoss: 1.0607 MAE: 0.8149 RMSE: 1.0299\n",
      "Epoch 93: TrainLoss 0.8886 RecLoss: 0.0000 (left: 0:00:33)\n",
      "TestLoss: 1.0105 MAE: 0.8032 RMSE: 1.0052\n",
      "ValLoss: 1.0612 MAE: 0.8219 RMSE: 1.0302\n",
      "Epoch 94: TrainLoss 0.8929 RecLoss: 0.0000 (left: 0:00:28)\n",
      "TestLoss: 1.0034 MAE: 0.7917 RMSE: 1.0017\n",
      "ValLoss: 1.0626 MAE: 0.8139 RMSE: 1.0308\n",
      "Epoch 95: TrainLoss 0.8916 RecLoss: 0.0000 (left: 0:00:23)\n",
      "TestLoss: 1.0042 MAE: 0.7899 RMSE: 1.0021\n",
      "ValLoss: 1.0660 MAE: 0.8138 RMSE: 1.0325\n",
      "Epoch 96: TrainLoss 0.8892 RecLoss: 0.0000 (left: 0:00:19)\n",
      "TestLoss: 1.0085 MAE: 0.7864 RMSE: 1.0042\n",
      "ValLoss: 1.0727 MAE: 0.8110 RMSE: 1.0357\n",
      "Epoch 97: TrainLoss 0.8899 RecLoss: 0.0000 (left: 0:00:14)\n",
      "TestLoss: 1.0039 MAE: 0.7924 RMSE: 1.0019\n",
      "ValLoss: 1.0635 MAE: 0.8149 RMSE: 1.0313\n",
      "Epoch 98: TrainLoss 0.8878 RecLoss: 0.0000 (left: 0:00:09)\n",
      "TestLoss: 1.0042 MAE: 0.7946 RMSE: 1.0021\n",
      "ValLoss: 1.0594 MAE: 0.8155 RMSE: 1.0293\n",
      "Epoch 99: TrainLoss 0.8882 RecLoss: 0.0000 (left: 0:00:04)\n",
      "TestLoss: 1.0073 MAE: 0.7997 RMSE: 1.0036\n",
      "ValLoss: 1.0602 MAE: 0.8191 RMSE: 1.0297\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 181085/19100\n",
      "test set size: support/query 523/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.6763 RMSE: 0.8562 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7979 RMSE: 0.9990 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7502 RMSE: 0.9455 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 60% CUR core user as input to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 789731/19100\n",
      "test set size: support/query 3138/809\n",
      "Epoch 0 Step 733: Train 1.5780 Reg: 0.6163\n",
      "Test: 0.8974 MAE: 0.7530 RMSE: 0.9473\n",
      "Val: 0.8343 MAE: 0.7252 RMSE: 0.9134\n",
      "Epoch 1 Step 1466: Train 0.8332 Reg: 0.3995\n",
      "Test: 0.8914 MAE: 0.7469 RMSE: 0.9441\n",
      "Val: 0.8254 MAE: 0.7209 RMSE: 0.9085\n",
      "Epoch 2 Step 2199: Train 0.8279 Reg: 0.3445\n",
      "Test: 0.8778 MAE: 0.7447 RMSE: 0.9369\n",
      "Val: 0.8206 MAE: 0.7181 RMSE: 0.9059\n",
      "Epoch 3 Step 2932: Train 0.8215 Reg: 0.3114\n",
      "Test: 0.8715 MAE: 0.7424 RMSE: 0.9335\n",
      "Val: 0.8159 MAE: 0.7185 RMSE: 0.9033\n",
      "Epoch 4 Step 3665: Train 0.8108 Reg: 0.2929\n",
      "Test: 0.8789 MAE: 0.7421 RMSE: 0.9375\n",
      "Val: 0.8003 MAE: 0.7090 RMSE: 0.8946\n",
      "Epoch 5 Step 4398: Train 0.7949 Reg: 0.2933\n",
      "Test: 0.8668 MAE: 0.7350 RMSE: 0.9310\n",
      "Val: 0.7843 MAE: 0.6988 RMSE: 0.8856\n",
      "Epoch 6 Step 5131: Train 0.7749 Reg: 0.3176\n",
      "Test: 0.8413 MAE: 0.7182 RMSE: 0.9172\n",
      "Val: 0.7647 MAE: 0.6878 RMSE: 0.8745\n",
      "Epoch 7 Step 5864: Train 0.7495 Reg: 0.3756\n",
      "Test: 0.8167 MAE: 0.7118 RMSE: 0.9037\n",
      "Val: 0.7417 MAE: 0.6789 RMSE: 0.8612\n",
      "Epoch 8 Step 6597: Train 0.7273 Reg: 0.3985\n",
      "Test: 0.8128 MAE: 0.7154 RMSE: 0.9015\n",
      "Val: 0.7308 MAE: 0.6761 RMSE: 0.8549\n",
      "Epoch 9 Step 7330: Train 0.7095 Reg: 0.4230\n",
      "Test: 0.7916 MAE: 0.7043 RMSE: 0.8897\n",
      "Val: 0.7164 MAE: 0.6684 RMSE: 0.8464\n",
      "Epoch 10 Step 8063: Train 0.6886 Reg: 0.4599\n",
      "Test: 0.7692 MAE: 0.6854 RMSE: 0.8771\n",
      "Val: 0.7037 MAE: 0.6569 RMSE: 0.8388\n",
      "Epoch 11 Step 8796: Train 0.6688 Reg: 0.4880\n",
      "Test: 0.7651 MAE: 0.6906 RMSE: 0.8747\n",
      "Val: 0.6950 MAE: 0.6554 RMSE: 0.8337\n",
      "Epoch 12 Step 9529: Train 0.6524 Reg: 0.5143\n",
      "Test: 0.7631 MAE: 0.6862 RMSE: 0.8735\n",
      "Val: 0.6940 MAE: 0.6536 RMSE: 0.8330\n",
      "Epoch 13 Step 10262: Train 0.6372 Reg: 0.5348\n",
      "Test: 0.7552 MAE: 0.6854 RMSE: 0.8690\n",
      "Val: 0.6916 MAE: 0.6506 RMSE: 0.8316\n",
      "Epoch 14 Step 10995: Train 0.6230 Reg: 0.5510\n",
      "Test: 0.7569 MAE: 0.6843 RMSE: 0.8700\n",
      "Val: 0.6926 MAE: 0.6516 RMSE: 0.8323\n",
      "Epoch 15 Step 11728: Train 0.6099 Reg: 0.5629\n",
      "Test: 0.7563 MAE: 0.6821 RMSE: 0.8697\n",
      "Val: 0.6945 MAE: 0.6517 RMSE: 0.8334\n",
      "Epoch 16 Step 12461: Train 0.5988 Reg: 0.5710\n",
      "Test: 0.7612 MAE: 0.6856 RMSE: 0.8725\n",
      "Val: 0.6965 MAE: 0.6533 RMSE: 0.8346\n",
      "Epoch 17 Step 13194: Train 0.5894 Reg: 0.5761\n",
      "Test: 0.7614 MAE: 0.6876 RMSE: 0.8726\n",
      "Val: 0.7010 MAE: 0.6550 RMSE: 0.8373\n",
      "Epoch 18 Step 13927: Train 0.5800 Reg: 0.5836\n",
      "Test: 0.7656 MAE: 0.6854 RMSE: 0.8750\n",
      "Val: 0.7043 MAE: 0.6552 RMSE: 0.8392\n",
      "Epoch 19 Step 14660: Train 0.5698 Reg: 0.5904\n",
      "Test: 0.7713 MAE: 0.6856 RMSE: 0.8782\n",
      "Val: 0.7055 MAE: 0.6546 RMSE: 0.8400\n",
      "Epoch 20 Step 15393: Train 0.5595 Reg: 0.5978\n",
      "Test: 0.7794 MAE: 0.6909 RMSE: 0.8828\n",
      "Val: 0.7125 MAE: 0.6576 RMSE: 0.8441\n",
      "Epoch 21 Step 16126: Train 0.5488 Reg: 0.6045\n",
      "Test: 0.7864 MAE: 0.6906 RMSE: 0.8868\n",
      "Val: 0.7185 MAE: 0.6590 RMSE: 0.8476\n",
      "Epoch 22 Step 16859: Train 0.5384 Reg: 0.6089\n",
      "Test: 0.7896 MAE: 0.6941 RMSE: 0.8886\n",
      "Val: 0.7255 MAE: 0.6634 RMSE: 0.8517\n",
      "Epoch 23 Step 17592: Train 0.5299 Reg: 0.6095\n",
      "Test: 0.7961 MAE: 0.6974 RMSE: 0.8923\n",
      "Val: 0.7292 MAE: 0.6645 RMSE: 0.8539\n",
      "Epoch 24 Step 18325: Train 0.5231 Reg: 0.6063\n",
      "Test: 0.8089 MAE: 0.7025 RMSE: 0.8994\n",
      "Val: 0.7367 MAE: 0.6681 RMSE: 0.8583\n",
      "Epoch 25 Step 19058: Train 0.5172 Reg: 0.6028\n",
      "Test: 0.8130 MAE: 0.7023 RMSE: 0.9016\n",
      "Val: 0.7398 MAE: 0.6674 RMSE: 0.8601\n",
      "Epoch 26 Step 19791: Train 0.5124 Reg: 0.5986\n",
      "Test: 0.8192 MAE: 0.7076 RMSE: 0.9051\n",
      "Val: 0.7454 MAE: 0.6708 RMSE: 0.8634\n",
      "Epoch 27 Step 20524: Train 0.5067 Reg: 0.5959\n",
      "Test: 0.8243 MAE: 0.7091 RMSE: 0.9079\n",
      "Val: 0.7507 MAE: 0.6732 RMSE: 0.8664\n",
      "Epoch 28 Step 21257: Train 0.5003 Reg: 0.5942\n",
      "Test: 0.8273 MAE: 0.7068 RMSE: 0.9095\n",
      "Val: 0.7538 MAE: 0.6724 RMSE: 0.8682\n",
      "Epoch 29 Step 21990: Train 0.4944 Reg: 0.5912\n",
      "Test: 0.8352 MAE: 0.7088 RMSE: 0.9139\n",
      "Val: 0.7593 MAE: 0.6743 RMSE: 0.8714\n",
      "Epoch 30 Step 22723: Train 0.4895 Reg: 0.5867\n",
      "Test: 0.8388 MAE: 0.7147 RMSE: 0.9159\n",
      "Val: 0.7678 MAE: 0.6798 RMSE: 0.8763\n",
      "Epoch 31 Step 23456: Train 0.4851 Reg: 0.5819\n",
      "Test: 0.8490 MAE: 0.7168 RMSE: 0.9214\n",
      "Val: 0.7703 MAE: 0.6782 RMSE: 0.8777\n",
      "Epoch 32 Step 24189: Train 0.4807 Reg: 0.5788\n",
      "Test: 0.8481 MAE: 0.7128 RMSE: 0.9209\n",
      "Val: 0.7752 MAE: 0.6794 RMSE: 0.8805\n",
      "Epoch 33 Step 24922: Train 0.4751 Reg: 0.5762\n",
      "Test: 0.8593 MAE: 0.7221 RMSE: 0.9270\n",
      "Val: 0.7832 MAE: 0.6847 RMSE: 0.8850\n",
      "Epoch 34 Step 25655: Train 0.4696 Reg: 0.5734\n",
      "Test: 0.8605 MAE: 0.7199 RMSE: 0.9276\n",
      "Val: 0.7872 MAE: 0.6846 RMSE: 0.8872\n",
      "Epoch 35 Step 26388: Train 0.4652 Reg: 0.5692\n",
      "Test: 0.8625 MAE: 0.7217 RMSE: 0.9287\n",
      "Val: 0.7926 MAE: 0.6871 RMSE: 0.8903\n",
      "Epoch 36 Step 27121: Train 0.4612 Reg: 0.5649\n",
      "Test: 0.8714 MAE: 0.7263 RMSE: 0.9335\n",
      "Val: 0.7976 MAE: 0.6898 RMSE: 0.8931\n",
      "Epoch 37 Step 27854: Train 0.4577 Reg: 0.5598\n",
      "Test: 0.8759 MAE: 0.7269 RMSE: 0.9359\n",
      "Val: 0.7999 MAE: 0.6894 RMSE: 0.8944\n",
      "Epoch 38 Step 28587: Train 0.4546 Reg: 0.5546\n",
      "Test: 0.8777 MAE: 0.7273 RMSE: 0.9369\n",
      "Val: 0.8029 MAE: 0.6908 RMSE: 0.8961\n",
      "Epoch 39 Step 29320: Train 0.4517 Reg: 0.5495\n",
      "Test: 0.8823 MAE: 0.7295 RMSE: 0.9393\n",
      "Val: 0.8089 MAE: 0.6926 RMSE: 0.8994\n",
      "Epoch 40 Step 30053: Train 0.4489 Reg: 0.5446\n",
      "Test: 0.8838 MAE: 0.7291 RMSE: 0.9401\n",
      "Val: 0.8107 MAE: 0.6928 RMSE: 0.9004\n",
      "Epoch 41 Step 30786: Train 0.4464 Reg: 0.5395\n",
      "Test: 0.8906 MAE: 0.7302 RMSE: 0.9437\n",
      "Val: 0.8154 MAE: 0.6935 RMSE: 0.9030\n",
      "Epoch 42 Step 31519: Train 0.4439 Reg: 0.5346\n",
      "Test: 0.8937 MAE: 0.7318 RMSE: 0.9453\n",
      "Val: 0.8193 MAE: 0.6964 RMSE: 0.9051\n",
      "Epoch 43 Step 32252: Train 0.4415 Reg: 0.5299\n",
      "Test: 0.8966 MAE: 0.7332 RMSE: 0.9469\n",
      "Val: 0.8239 MAE: 0.6981 RMSE: 0.9077\n",
      "Epoch 44 Step 32985: Train 0.4392 Reg: 0.5254\n",
      "Test: 0.9021 MAE: 0.7352 RMSE: 0.9498\n",
      "Val: 0.8258 MAE: 0.6981 RMSE: 0.9088\n",
      "Epoch 45 Step 33718: Train 0.4371 Reg: 0.5209\n",
      "Test: 0.9059 MAE: 0.7361 RMSE: 0.9518\n",
      "Val: 0.8283 MAE: 0.6984 RMSE: 0.9101\n",
      "Epoch 46 Step 34451: Train 0.4349 Reg: 0.5167\n",
      "Test: 0.9111 MAE: 0.7375 RMSE: 0.9545\n",
      "Val: 0.8325 MAE: 0.6996 RMSE: 0.9124\n",
      "Epoch 47 Step 35184: Train 0.4329 Reg: 0.5125\n",
      "Test: 0.9119 MAE: 0.7386 RMSE: 0.9549\n",
      "Val: 0.8348 MAE: 0.7008 RMSE: 0.9137\n",
      "Epoch 48 Step 35917: Train 0.4310 Reg: 0.5086\n",
      "Test: 0.9166 MAE: 0.7407 RMSE: 0.9574\n",
      "Val: 0.8385 MAE: 0.7021 RMSE: 0.9157\n",
      "Epoch 49 Step 36650: Train 0.4290 Reg: 0.5047\n",
      "Test: 0.9214 MAE: 0.7432 RMSE: 0.9599\n",
      "Val: 0.8413 MAE: 0.7035 RMSE: 0.9172\n",
      "Epoch 50 Step 37383: Train 0.4271 Reg: 0.5011\n",
      "Test: 0.9216 MAE: 0.7436 RMSE: 0.9600\n",
      "Val: 0.8439 MAE: 0.7043 RMSE: 0.9187\n",
      "Epoch 51 Step 38116: Train 0.4254 Reg: 0.4975\n",
      "Test: 0.9259 MAE: 0.7449 RMSE: 0.9622\n",
      "Val: 0.8463 MAE: 0.7052 RMSE: 0.9199\n",
      "Epoch 52 Step 38849: Train 0.4236 Reg: 0.4940\n",
      "Test: 0.9291 MAE: 0.7453 RMSE: 0.9639\n",
      "Val: 0.8485 MAE: 0.7058 RMSE: 0.9212\n",
      "Epoch 53 Step 39582: Train 0.4219 Reg: 0.4908\n",
      "Test: 0.9340 MAE: 0.7475 RMSE: 0.9664\n",
      "Val: 0.8511 MAE: 0.7068 RMSE: 0.9226\n",
      "Epoch 54 Step 40315: Train 0.4203 Reg: 0.4876\n",
      "Test: 0.9368 MAE: 0.7494 RMSE: 0.9679\n",
      "Val: 0.8548 MAE: 0.7085 RMSE: 0.9245\n",
      "Epoch 55 Step 41048: Train 0.4188 Reg: 0.4846\n",
      "Test: 0.9376 MAE: 0.7493 RMSE: 0.9683\n",
      "Val: 0.8558 MAE: 0.7085 RMSE: 0.9251\n",
      "Epoch 56 Step 41781: Train 0.4173 Reg: 0.4817\n",
      "Test: 0.9424 MAE: 0.7511 RMSE: 0.9707\n",
      "Val: 0.8595 MAE: 0.7101 RMSE: 0.9271\n",
      "Epoch 57 Step 42514: Train 0.4159 Reg: 0.4789\n",
      "Test: 0.9444 MAE: 0.7522 RMSE: 0.9718\n",
      "Val: 0.8609 MAE: 0.7105 RMSE: 0.9278\n",
      "Epoch 58 Step 43247: Train 0.4145 Reg: 0.4761\n",
      "Test: 0.9453 MAE: 0.7510 RMSE: 0.9723\n",
      "Val: 0.8628 MAE: 0.7106 RMSE: 0.9288\n",
      "Epoch 59 Step 43980: Train 0.4132 Reg: 0.4737\n",
      "Test: 0.9475 MAE: 0.7513 RMSE: 0.9734\n",
      "Val: 0.8646 MAE: 0.7107 RMSE: 0.9299\n",
      "Epoch 60 Step 44713: Train 0.4119 Reg: 0.4712\n",
      "Test: 0.9512 MAE: 0.7545 RMSE: 0.9753\n",
      "Val: 0.8672 MAE: 0.7127 RMSE: 0.9312\n",
      "Epoch 61 Step 45446: Train 0.4107 Reg: 0.4688\n",
      "Test: 0.9523 MAE: 0.7536 RMSE: 0.9758\n",
      "Val: 0.8678 MAE: 0.7120 RMSE: 0.9316\n",
      "Epoch 62 Step 46179: Train 0.4095 Reg: 0.4665\n",
      "Test: 0.9551 MAE: 0.7557 RMSE: 0.9773\n",
      "Val: 0.8705 MAE: 0.7136 RMSE: 0.9330\n",
      "Epoch 63 Step 46912: Train 0.4084 Reg: 0.4644\n",
      "Test: 0.9579 MAE: 0.7569 RMSE: 0.9787\n",
      "Val: 0.8719 MAE: 0.7143 RMSE: 0.9338\n",
      "Epoch 64 Step 47645: Train 0.4074 Reg: 0.4623\n",
      "Test: 0.9591 MAE: 0.7566 RMSE: 0.9793\n",
      "Val: 0.8731 MAE: 0.7142 RMSE: 0.9344\n",
      "Epoch 65 Step 48378: Train 0.4063 Reg: 0.4604\n",
      "Test: 0.9610 MAE: 0.7578 RMSE: 0.9803\n",
      "Val: 0.8747 MAE: 0.7151 RMSE: 0.9352\n",
      "Epoch 66 Step 49111: Train 0.4054 Reg: 0.4584\n",
      "Test: 0.9614 MAE: 0.7567 RMSE: 0.9805\n",
      "Val: 0.8755 MAE: 0.7147 RMSE: 0.9357\n",
      "Epoch 67 Step 49844: Train 0.4044 Reg: 0.4566\n",
      "Test: 0.9632 MAE: 0.7577 RMSE: 0.9814\n",
      "Val: 0.8770 MAE: 0.7155 RMSE: 0.9365\n",
      "Epoch 68 Step 50577: Train 0.4035 Reg: 0.4549\n",
      "Test: 0.9656 MAE: 0.7595 RMSE: 0.9827\n",
      "Val: 0.8792 MAE: 0.7167 RMSE: 0.9376\n",
      "Epoch 69 Step 51310: Train 0.4026 Reg: 0.4533\n",
      "Test: 0.9675 MAE: 0.7594 RMSE: 0.9836\n",
      "Val: 0.8800 MAE: 0.7164 RMSE: 0.9381\n",
      "Epoch 70 Step 52043: Train 0.4017 Reg: 0.4517\n",
      "Test: 0.9683 MAE: 0.7596 RMSE: 0.9840\n",
      "Val: 0.8812 MAE: 0.7168 RMSE: 0.9387\n",
      "Epoch 71 Step 52776: Train 0.4010 Reg: 0.4501\n",
      "Test: 0.9714 MAE: 0.7616 RMSE: 0.9856\n",
      "Val: 0.8831 MAE: 0.7180 RMSE: 0.9397\n",
      "Epoch 72 Step 53509: Train 0.4002 Reg: 0.4487\n",
      "Test: 0.9730 MAE: 0.7624 RMSE: 0.9864\n",
      "Val: 0.8845 MAE: 0.7185 RMSE: 0.9405\n",
      "Epoch 73 Step 54242: Train 0.3995 Reg: 0.4473\n",
      "Test: 0.9726 MAE: 0.7618 RMSE: 0.9862\n",
      "Val: 0.8848 MAE: 0.7182 RMSE: 0.9407\n",
      "Epoch 74 Step 54975: Train 0.3988 Reg: 0.4460\n",
      "Test: 0.9746 MAE: 0.7625 RMSE: 0.9872\n",
      "Val: 0.8860 MAE: 0.7187 RMSE: 0.9413\n",
      "Epoch 75 Step 55708: Train 0.3981 Reg: 0.4448\n",
      "Test: 0.9764 MAE: 0.7630 RMSE: 0.9881\n",
      "Val: 0.8868 MAE: 0.7189 RMSE: 0.9417\n",
      "Epoch 76 Step 56441: Train 0.3975 Reg: 0.4436\n",
      "Test: 0.9786 MAE: 0.7644 RMSE: 0.9892\n",
      "Val: 0.8884 MAE: 0.7198 RMSE: 0.9425\n",
      "Epoch 77 Step 57174: Train 0.3968 Reg: 0.4424\n",
      "Test: 0.9795 MAE: 0.7648 RMSE: 0.9897\n",
      "Val: 0.8892 MAE: 0.7200 RMSE: 0.9430\n",
      "Epoch 78 Step 57907: Train 0.3963 Reg: 0.4414\n",
      "Test: 0.9808 MAE: 0.7649 RMSE: 0.9903\n",
      "Val: 0.8900 MAE: 0.7201 RMSE: 0.9434\n",
      "Epoch 79 Step 58640: Train 0.3957 Reg: 0.4403\n",
      "Test: 0.9808 MAE: 0.7641 RMSE: 0.9904\n",
      "Val: 0.8900 MAE: 0.7197 RMSE: 0.9434\n",
      "Epoch 80 Step 59373: Train 0.3952 Reg: 0.4393\n",
      "Test: 0.9812 MAE: 0.7643 RMSE: 0.9905\n",
      "Val: 0.8906 MAE: 0.7198 RMSE: 0.9437\n",
      "Epoch 81 Step 60106: Train 0.3947 Reg: 0.4384\n",
      "Test: 0.9839 MAE: 0.7664 RMSE: 0.9919\n",
      "Val: 0.8926 MAE: 0.7212 RMSE: 0.9448\n",
      "Epoch 82 Step 60839: Train 0.3942 Reg: 0.4375\n",
      "Test: 0.9840 MAE: 0.7657 RMSE: 0.9919\n",
      "Val: 0.8923 MAE: 0.7207 RMSE: 0.9446\n",
      "Epoch 83 Step 61572: Train 0.3937 Reg: 0.4366\n",
      "Test: 0.9846 MAE: 0.7658 RMSE: 0.9923\n",
      "Val: 0.8932 MAE: 0.7209 RMSE: 0.9451\n",
      "Epoch 84 Step 62305: Train 0.3933 Reg: 0.4358\n",
      "Test: 0.9857 MAE: 0.7663 RMSE: 0.9928\n",
      "Val: 0.8937 MAE: 0.7211 RMSE: 0.9453\n",
      "Epoch 85 Step 63038: Train 0.3929 Reg: 0.4351\n",
      "Test: 0.9866 MAE: 0.7667 RMSE: 0.9933\n",
      "Val: 0.8945 MAE: 0.7214 RMSE: 0.9458\n",
      "Epoch 86 Step 63771: Train 0.3925 Reg: 0.4343\n",
      "Test: 0.9863 MAE: 0.7661 RMSE: 0.9931\n",
      "Val: 0.8946 MAE: 0.7211 RMSE: 0.9459\n",
      "Epoch 87 Step 64504: Train 0.3921 Reg: 0.4336\n",
      "Test: 0.9876 MAE: 0.7668 RMSE: 0.9938\n",
      "Val: 0.8953 MAE: 0.7215 RMSE: 0.9462\n",
      "Epoch 88 Step 65237: Train 0.3917 Reg: 0.4329\n",
      "Test: 0.9878 MAE: 0.7665 RMSE: 0.9939\n",
      "Val: 0.8956 MAE: 0.7214 RMSE: 0.9464\n",
      "Epoch 89 Step 65970: Train 0.3914 Reg: 0.4323\n",
      "Test: 0.9886 MAE: 0.7670 RMSE: 0.9943\n",
      "Val: 0.8963 MAE: 0.7217 RMSE: 0.9467\n",
      "Epoch 90 Step 66703: Train 0.3910 Reg: 0.4317\n",
      "Test: 0.9894 MAE: 0.7674 RMSE: 0.9947\n",
      "Val: 0.8968 MAE: 0.7220 RMSE: 0.9470\n",
      "Epoch 91 Step 67436: Train 0.3907 Reg: 0.4311\n",
      "Test: 0.9905 MAE: 0.7681 RMSE: 0.9952\n",
      "Val: 0.8974 MAE: 0.7224 RMSE: 0.9473\n",
      "Epoch 92 Step 68169: Train 0.3904 Reg: 0.4306\n",
      "Test: 0.9911 MAE: 0.7684 RMSE: 0.9955\n",
      "Val: 0.8981 MAE: 0.7226 RMSE: 0.9477\n",
      "Epoch 93 Step 68902: Train 0.3901 Reg: 0.4300\n",
      "Test: 0.9911 MAE: 0.7681 RMSE: 0.9956\n",
      "Val: 0.8982 MAE: 0.7224 RMSE: 0.9477\n",
      "Epoch 94 Step 69635: Train 0.3898 Reg: 0.4295\n",
      "Test: 0.9919 MAE: 0.7685 RMSE: 0.9959\n",
      "Val: 0.8987 MAE: 0.7227 RMSE: 0.9480\n",
      "Epoch 95 Step 70368: Train 0.3896 Reg: 0.4291\n",
      "Test: 0.9930 MAE: 0.7694 RMSE: 0.9965\n",
      "Val: 0.8996 MAE: 0.7233 RMSE: 0.9485\n",
      "Epoch 96 Step 71101: Train 0.3893 Reg: 0.4286\n",
      "Test: 0.9922 MAE: 0.7681 RMSE: 0.9961\n",
      "Val: 0.8991 MAE: 0.7225 RMSE: 0.9482\n",
      "Epoch 97 Step 71834: Train 0.3891 Reg: 0.4282\n",
      "Test: 0.9928 MAE: 0.7684 RMSE: 0.9964\n",
      "Val: 0.8995 MAE: 0.7227 RMSE: 0.9484\n",
      "Epoch 98 Step 72567: Train 0.3888 Reg: 0.4278\n",
      "Test: 0.9930 MAE: 0.7685 RMSE: 0.9965\n",
      "Val: 0.8997 MAE: 0.7228 RMSE: 0.9485\n",
      "Epoch 99 Step 73300: Train 0.3886 Reg: 0.4274\n",
      "Test: 0.9934 MAE: 0.7685 RMSE: 0.9967\n",
      "Val: 0.9000 MAE: 0.7228 RMSE: 0.9487\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 789731/19100\n",
      "test set size: support/query 3138/809\n",
      "Epoch 0: TrainLoss 1.1618 RecLoss: 0.0000 (left: 0:09:44)\n",
      "TestLoss: 1.0781 MAE: 0.7962 RMSE: 1.0383\n",
      "ValLoss: 1.1548 MAE: 0.8413 RMSE: 1.0746\n",
      "Epoch 1: TrainLoss 1.0036 RecLoss: 0.0000 (left: 0:10:07)\n",
      "TestLoss: 1.0205 MAE: 0.8093 RMSE: 1.0102\n",
      "ValLoss: 1.0745 MAE: 0.8385 RMSE: 1.0366\n",
      "Epoch 2: TrainLoss 0.9626 RecLoss: 0.0000 (left: 0:09:51)\n",
      "TestLoss: 1.0005 MAE: 0.7981 RMSE: 1.0002\n",
      "ValLoss: 1.0571 MAE: 0.8282 RMSE: 1.0282\n",
      "Epoch 3: TrainLoss 0.9469 RecLoss: 0.0000 (left: 0:09:30)\n",
      "TestLoss: 0.9995 MAE: 0.8039 RMSE: 0.9998\n",
      "ValLoss: 1.0495 MAE: 0.8296 RMSE: 1.0245\n",
      "Epoch 4: TrainLoss 0.9262 RecLoss: 0.0000 (left: 0:09:26)\n",
      "TestLoss: 0.9824 MAE: 0.7849 RMSE: 0.9912\n",
      "ValLoss: 1.0384 MAE: 0.8159 RMSE: 1.0190\n",
      "Epoch 5: TrainLoss 0.9157 RecLoss: 0.0000 (left: 0:09:10)\n",
      "TestLoss: 0.9794 MAE: 0.7829 RMSE: 0.9897\n",
      "ValLoss: 1.0323 MAE: 0.8114 RMSE: 1.0160\n",
      "Epoch 6: TrainLoss 0.9074 RecLoss: 0.0000 (left: 0:09:06)\n",
      "TestLoss: 0.9776 MAE: 0.7808 RMSE: 0.9887\n",
      "ValLoss: 1.0359 MAE: 0.8134 RMSE: 1.0178\n",
      "Epoch 7: TrainLoss 0.9021 RecLoss: 0.0000 (left: 0:09:03)\n",
      "TestLoss: 0.9767 MAE: 0.7808 RMSE: 0.9883\n",
      "ValLoss: 1.0272 MAE: 0.8089 RMSE: 1.0135\n",
      "Epoch 8: TrainLoss 0.9008 RecLoss: 0.0000 (left: 0:08:56)\n",
      "TestLoss: 0.9789 MAE: 0.7891 RMSE: 0.9894\n",
      "ValLoss: 1.0299 MAE: 0.8146 RMSE: 1.0148\n",
      "Epoch 9: TrainLoss 0.8972 RecLoss: 0.0000 (left: 0:08:42)\n",
      "TestLoss: 0.9788 MAE: 0.7849 RMSE: 0.9893\n",
      "ValLoss: 1.0295 MAE: 0.8116 RMSE: 1.0147\n",
      "Epoch 10: TrainLoss 0.8921 RecLoss: 0.0000 (left: 0:08:38)\n",
      "TestLoss: 0.9765 MAE: 0.7858 RMSE: 0.9882\n",
      "ValLoss: 1.0309 MAE: 0.8128 RMSE: 1.0153\n",
      "Epoch 11: TrainLoss 0.8887 RecLoss: 0.0000 (left: 0:08:34)\n",
      "TestLoss: 0.9760 MAE: 0.7795 RMSE: 0.9879\n",
      "ValLoss: 1.0344 MAE: 0.8094 RMSE: 1.0171\n",
      "Epoch 12: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:08:32)\n",
      "TestLoss: 0.9799 MAE: 0.7764 RMSE: 0.9899\n",
      "ValLoss: 1.0382 MAE: 0.8082 RMSE: 1.0189\n",
      "Epoch 13: TrainLoss 0.8867 RecLoss: 0.0000 (left: 0:08:29)\n",
      "TestLoss: 0.9790 MAE: 0.7825 RMSE: 0.9895\n",
      "ValLoss: 1.0347 MAE: 0.8104 RMSE: 1.0172\n",
      "Epoch 14: TrainLoss 0.8876 RecLoss: 0.0000 (left: 0:08:22)\n",
      "TestLoss: 0.9975 MAE: 0.8041 RMSE: 0.9987\n",
      "ValLoss: 1.0445 MAE: 0.8255 RMSE: 1.0220\n",
      "Epoch 15: TrainLoss 0.8890 RecLoss: 0.0000 (left: 0:08:16)\n",
      "TestLoss: 0.9814 MAE: 0.7868 RMSE: 0.9907\n",
      "ValLoss: 1.0385 MAE: 0.8144 RMSE: 1.0191\n",
      "Epoch 16: TrainLoss 0.8841 RecLoss: 0.0000 (left: 0:08:09)\n",
      "TestLoss: 0.9818 MAE: 0.7864 RMSE: 0.9909\n",
      "ValLoss: 1.0372 MAE: 0.8144 RMSE: 1.0184\n",
      "Epoch 17: TrainLoss 0.8848 RecLoss: 0.0000 (left: 0:08:06)\n",
      "TestLoss: 0.9850 MAE: 0.7759 RMSE: 0.9924\n",
      "ValLoss: 1.0469 MAE: 0.8098 RMSE: 1.0232\n",
      "Epoch 18: TrainLoss 0.8844 RecLoss: 0.0000 (left: 0:07:57)\n",
      "TestLoss: 0.9851 MAE: 0.7908 RMSE: 0.9925\n",
      "ValLoss: 1.0408 MAE: 0.8163 RMSE: 1.0202\n",
      "Epoch 19: TrainLoss 0.8867 RecLoss: 0.0000 (left: 0:07:54)\n",
      "TestLoss: 0.9834 MAE: 0.7868 RMSE: 0.9917\n",
      "ValLoss: 1.0418 MAE: 0.8148 RMSE: 1.0207\n",
      "Epoch 20: TrainLoss 0.8857 RecLoss: 0.0000 (left: 0:07:51)\n",
      "TestLoss: 0.9873 MAE: 0.7918 RMSE: 0.9936\n",
      "ValLoss: 1.0414 MAE: 0.8174 RMSE: 1.0205\n",
      "Epoch 21: TrainLoss 0.8851 RecLoss: 0.0000 (left: 0:07:44)\n",
      "TestLoss: 0.9844 MAE: 0.7776 RMSE: 0.9922\n",
      "ValLoss: 1.0459 MAE: 0.8093 RMSE: 1.0227\n",
      "Epoch 22: TrainLoss 0.8845 RecLoss: 0.0000 (left: 0:07:37)\n",
      "TestLoss: 0.9845 MAE: 0.7824 RMSE: 0.9922\n",
      "ValLoss: 1.0430 MAE: 0.8117 RMSE: 1.0213\n",
      "Epoch 23: TrainLoss 0.8830 RecLoss: 0.0000 (left: 0:07:30)\n",
      "TestLoss: 0.9983 MAE: 0.8015 RMSE: 0.9992\n",
      "ValLoss: 1.0530 MAE: 0.8259 RMSE: 1.0261\n",
      "Epoch 24: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:07:22)\n",
      "TestLoss: 0.9937 MAE: 0.7970 RMSE: 0.9969\n",
      "ValLoss: 1.0462 MAE: 0.8204 RMSE: 1.0229\n",
      "Epoch 25: TrainLoss 0.8817 RecLoss: 0.0000 (left: 0:07:17)\n",
      "TestLoss: 0.9838 MAE: 0.7843 RMSE: 0.9919\n",
      "ValLoss: 1.0435 MAE: 0.8128 RMSE: 1.0215\n",
      "Epoch 26: TrainLoss 0.8820 RecLoss: 0.0000 (left: 0:07:10)\n",
      "TestLoss: 0.9884 MAE: 0.7757 RMSE: 0.9942\n",
      "ValLoss: 1.0561 MAE: 0.8110 RMSE: 1.0277\n",
      "Epoch 27: TrainLoss 0.8838 RecLoss: 0.0000 (left: 0:07:05)\n",
      "TestLoss: 0.9859 MAE: 0.7767 RMSE: 0.9929\n",
      "ValLoss: 1.0547 MAE: 0.8116 RMSE: 1.0270\n",
      "Epoch 28: TrainLoss 0.8815 RecLoss: 0.0000 (left: 0:07:00)\n",
      "TestLoss: 0.9869 MAE: 0.7869 RMSE: 0.9934\n",
      "ValLoss: 1.0480 MAE: 0.8153 RMSE: 1.0237\n",
      "Epoch 29: TrainLoss 0.8834 RecLoss: 0.0000 (left: 0:06:54)\n",
      "TestLoss: 0.9846 MAE: 0.7851 RMSE: 0.9923\n",
      "ValLoss: 1.0466 MAE: 0.8140 RMSE: 1.0230\n",
      "Epoch 30: TrainLoss 0.8823 RecLoss: 0.0000 (left: 0:06:49)\n",
      "TestLoss: 0.9920 MAE: 0.7744 RMSE: 0.9960\n",
      "ValLoss: 1.0632 MAE: 0.8120 RMSE: 1.0311\n",
      "Epoch 31: TrainLoss 0.8838 RecLoss: 0.0000 (left: 0:06:43)\n",
      "TestLoss: 0.9873 MAE: 0.7780 RMSE: 0.9936\n",
      "ValLoss: 1.0536 MAE: 0.8110 RMSE: 1.0265\n",
      "Epoch 32: TrainLoss 0.8804 RecLoss: 0.0000 (left: 0:06:37)\n",
      "TestLoss: 0.9848 MAE: 0.7811 RMSE: 0.9924\n",
      "ValLoss: 1.0517 MAE: 0.8130 RMSE: 1.0255\n",
      "Epoch 33: TrainLoss 0.8820 RecLoss: 0.0000 (left: 0:06:32)\n",
      "TestLoss: 0.9860 MAE: 0.7804 RMSE: 0.9930\n",
      "ValLoss: 1.0506 MAE: 0.8121 RMSE: 1.0250\n",
      "Epoch 34: TrainLoss 0.8803 RecLoss: 0.0000 (left: 0:06:25)\n",
      "TestLoss: 0.9946 MAE: 0.7740 RMSE: 0.9973\n",
      "ValLoss: 1.0644 MAE: 0.8111 RMSE: 1.0317\n",
      "Epoch 35: TrainLoss 0.8828 RecLoss: 0.0000 (left: 0:06:18)\n",
      "TestLoss: 0.9904 MAE: 0.7918 RMSE: 0.9952\n",
      "ValLoss: 1.0491 MAE: 0.8174 RMSE: 1.0243\n",
      "Epoch 36: TrainLoss 0.8812 RecLoss: 0.0000 (left: 0:06:12)\n",
      "TestLoss: 0.9867 MAE: 0.7814 RMSE: 0.9933\n",
      "ValLoss: 1.0513 MAE: 0.8123 RMSE: 1.0254\n",
      "Epoch 37: TrainLoss 0.8804 RecLoss: 0.0000 (left: 0:06:06)\n",
      "TestLoss: 0.9859 MAE: 0.7857 RMSE: 0.9929\n",
      "ValLoss: 1.0502 MAE: 0.8151 RMSE: 1.0248\n",
      "Epoch 38: TrainLoss 0.8819 RecLoss: 0.0000 (left: 0:06:01)\n",
      "TestLoss: 0.9903 MAE: 0.7917 RMSE: 0.9951\n",
      "ValLoss: 1.0528 MAE: 0.8198 RMSE: 1.0261\n",
      "Epoch 39: TrainLoss 0.8826 RecLoss: 0.0000 (left: 0:05:56)\n",
      "TestLoss: 0.9880 MAE: 0.7777 RMSE: 0.9940\n",
      "ValLoss: 1.0575 MAE: 0.8117 RMSE: 1.0283\n",
      "Epoch 40: TrainLoss 0.8820 RecLoss: 0.0000 (left: 0:05:49)\n",
      "TestLoss: 0.9935 MAE: 0.7756 RMSE: 0.9967\n",
      "ValLoss: 1.0663 MAE: 0.8129 RMSE: 1.0326\n",
      "Epoch 41: TrainLoss 0.8819 RecLoss: 0.0000 (left: 0:05:42)\n",
      "TestLoss: 0.9869 MAE: 0.7832 RMSE: 0.9934\n",
      "ValLoss: 1.0522 MAE: 0.8133 RMSE: 1.0258\n",
      "Epoch 42: TrainLoss 0.8820 RecLoss: 0.0000 (left: 0:05:36)\n",
      "TestLoss: 0.9893 MAE: 0.7886 RMSE: 0.9946\n",
      "ValLoss: 1.0506 MAE: 0.8162 RMSE: 1.0250\n",
      "Epoch 43: TrainLoss 0.8816 RecLoss: 0.0000 (left: 0:05:30)\n",
      "TestLoss: 0.9876 MAE: 0.7806 RMSE: 0.9938\n",
      "ValLoss: 1.0534 MAE: 0.8122 RMSE: 1.0264\n",
      "Epoch 44: TrainLoss 0.8797 RecLoss: 0.0000 (left: 0:05:23)\n",
      "TestLoss: 0.9862 MAE: 0.7826 RMSE: 0.9931\n",
      "ValLoss: 1.0536 MAE: 0.8144 RMSE: 1.0265\n",
      "Epoch 45: TrainLoss 0.8798 RecLoss: 0.0000 (left: 0:05:17)\n",
      "TestLoss: 0.9881 MAE: 0.7833 RMSE: 0.9940\n",
      "ValLoss: 1.0527 MAE: 0.8139 RMSE: 1.0260\n",
      "Epoch 46: TrainLoss 0.8794 RecLoss: 0.0000 (left: 0:05:10)\n",
      "TestLoss: 0.9881 MAE: 0.7798 RMSE: 0.9940\n",
      "ValLoss: 1.0554 MAE: 0.8123 RMSE: 1.0273\n",
      "Epoch 47: TrainLoss 0.8807 RecLoss: 0.0000 (left: 0:05:05)\n",
      "TestLoss: 0.9870 MAE: 0.7785 RMSE: 0.9935\n",
      "ValLoss: 1.0559 MAE: 0.8121 RMSE: 1.0276\n",
      "Epoch 48: TrainLoss 0.8811 RecLoss: 0.0000 (left: 0:05:00)\n",
      "TestLoss: 0.9924 MAE: 0.7759 RMSE: 0.9962\n",
      "ValLoss: 1.0653 MAE: 0.8124 RMSE: 1.0321\n",
      "Epoch 49: TrainLoss 0.8821 RecLoss: 0.0000 (left: 0:04:53)\n",
      "TestLoss: 0.9911 MAE: 0.7769 RMSE: 0.9955\n",
      "ValLoss: 1.0610 MAE: 0.8122 RMSE: 1.0301\n",
      "Epoch 50: TrainLoss 0.8830 RecLoss: 0.0000 (left: 0:04:48)\n",
      "TestLoss: 0.9908 MAE: 0.7792 RMSE: 0.9954\n",
      "ValLoss: 1.0585 MAE: 0.8127 RMSE: 1.0289\n",
      "Epoch 51: TrainLoss 0.8802 RecLoss: 0.0000 (left: 0:04:42)\n",
      "TestLoss: 0.9881 MAE: 0.7840 RMSE: 0.9940\n",
      "ValLoss: 1.0551 MAE: 0.8150 RMSE: 1.0272\n",
      "Epoch 52: TrainLoss 0.8794 RecLoss: 0.0000 (left: 0:04:37)\n",
      "TestLoss: 0.9878 MAE: 0.7863 RMSE: 0.9939\n",
      "ValLoss: 1.0542 MAE: 0.8162 RMSE: 1.0268\n",
      "Epoch 53: TrainLoss 0.8813 RecLoss: 0.0000 (left: 0:04:31)\n",
      "TestLoss: 0.9884 MAE: 0.7864 RMSE: 0.9942\n",
      "ValLoss: 1.0522 MAE: 0.8150 RMSE: 1.0258\n",
      "Epoch 54: TrainLoss 0.8797 RecLoss: 0.0000 (left: 0:04:26)\n",
      "TestLoss: 0.9863 MAE: 0.7815 RMSE: 0.9931\n",
      "ValLoss: 1.0540 MAE: 0.8133 RMSE: 1.0267\n",
      "Epoch 55: TrainLoss 0.8802 RecLoss: 0.0000 (left: 0:04:20)\n",
      "TestLoss: 0.9899 MAE: 0.7882 RMSE: 0.9949\n",
      "ValLoss: 1.0534 MAE: 0.8172 RMSE: 1.0264\n",
      "Epoch 56: TrainLoss 0.8803 RecLoss: 0.0000 (left: 0:04:14)\n",
      "TestLoss: 0.9882 MAE: 0.7871 RMSE: 0.9941\n",
      "ValLoss: 1.0540 MAE: 0.8168 RMSE: 1.0266\n",
      "Epoch 57: TrainLoss 0.8803 RecLoss: 0.0000 (left: 0:04:08)\n",
      "TestLoss: 0.9903 MAE: 0.7777 RMSE: 0.9951\n",
      "ValLoss: 1.0598 MAE: 0.8121 RMSE: 1.0295\n",
      "Epoch 58: TrainLoss 0.8794 RecLoss: 0.0000 (left: 0:04:02)\n",
      "TestLoss: 0.9878 MAE: 0.7842 RMSE: 0.9939\n",
      "ValLoss: 1.0541 MAE: 0.8147 RMSE: 1.0267\n",
      "Epoch 59: TrainLoss 0.8794 RecLoss: 0.0000 (left: 0:03:57)\n",
      "TestLoss: 0.9874 MAE: 0.7828 RMSE: 0.9937\n",
      "ValLoss: 1.0551 MAE: 0.8144 RMSE: 1.0272\n",
      "Epoch 60: TrainLoss 0.8795 RecLoss: 0.0000 (left: 0:03:51)\n",
      "TestLoss: 0.9884 MAE: 0.7794 RMSE: 0.9942\n",
      "ValLoss: 1.0551 MAE: 0.8116 RMSE: 1.0272\n",
      "Epoch 61: TrainLoss 0.8800 RecLoss: 0.0000 (left: 0:03:44)\n",
      "TestLoss: 0.9868 MAE: 0.7854 RMSE: 0.9934\n",
      "ValLoss: 1.0537 MAE: 0.8159 RMSE: 1.0265\n",
      "Epoch 62: TrainLoss 0.8799 RecLoss: 0.0000 (left: 0:03:39)\n",
      "TestLoss: 0.9921 MAE: 0.7928 RMSE: 0.9961\n",
      "ValLoss: 1.0550 MAE: 0.8200 RMSE: 1.0271\n",
      "Epoch 63: TrainLoss 0.8829 RecLoss: 0.0000 (left: 0:03:33)\n",
      "TestLoss: 0.9944 MAE: 0.7943 RMSE: 0.9972\n",
      "ValLoss: 1.0560 MAE: 0.8206 RMSE: 1.0276\n",
      "Epoch 64: TrainLoss 0.8814 RecLoss: 0.0000 (left: 0:03:26)\n",
      "TestLoss: 0.9873 MAE: 0.7828 RMSE: 0.9936\n",
      "ValLoss: 1.0556 MAE: 0.8148 RMSE: 1.0274\n",
      "Epoch 65: TrainLoss 0.8787 RecLoss: 0.0000 (left: 0:03:20)\n",
      "TestLoss: 0.9903 MAE: 0.7794 RMSE: 0.9952\n",
      "ValLoss: 1.0564 MAE: 0.8124 RMSE: 1.0278\n",
      "Epoch 66: TrainLoss 0.8794 RecLoss: 0.0000 (left: 0:03:14)\n",
      "TestLoss: 0.9857 MAE: 0.7809 RMSE: 0.9928\n",
      "ValLoss: 1.0549 MAE: 0.8133 RMSE: 1.0271\n",
      "Epoch 67: TrainLoss 0.8797 RecLoss: 0.0000 (left: 0:03:09)\n",
      "TestLoss: 0.9874 MAE: 0.7800 RMSE: 0.9937\n",
      "ValLoss: 1.0572 MAE: 0.8131 RMSE: 1.0282\n",
      "Epoch 68: TrainLoss 0.8806 RecLoss: 0.0000 (left: 0:03:03)\n",
      "TestLoss: 0.9880 MAE: 0.7809 RMSE: 0.9940\n",
      "ValLoss: 1.0539 MAE: 0.8125 RMSE: 1.0266\n",
      "Epoch 69: TrainLoss 0.8826 RecLoss: 0.0000 (left: 0:02:57)\n",
      "TestLoss: 0.9897 MAE: 0.7771 RMSE: 0.9948\n",
      "ValLoss: 1.0610 MAE: 0.8131 RMSE: 1.0300\n",
      "Epoch 70: TrainLoss 0.8839 RecLoss: 0.0000 (left: 0:02:51)\n",
      "TestLoss: 1.0033 MAE: 0.7744 RMSE: 1.0016\n",
      "ValLoss: 1.0796 MAE: 0.8142 RMSE: 1.0390\n",
      "Epoch 71: TrainLoss 0.8817 RecLoss: 0.0000 (left: 0:02:45)\n",
      "TestLoss: 0.9871 MAE: 0.7826 RMSE: 0.9935\n",
      "ValLoss: 1.0556 MAE: 0.8145 RMSE: 1.0274\n",
      "Epoch 72: TrainLoss 0.8794 RecLoss: 0.0000 (left: 0:02:39)\n",
      "TestLoss: 0.9894 MAE: 0.7785 RMSE: 0.9947\n",
      "ValLoss: 1.0607 MAE: 0.8131 RMSE: 1.0299\n",
      "Epoch 73: TrainLoss 0.8793 RecLoss: 0.0000 (left: 0:02:34)\n",
      "TestLoss: 0.9875 MAE: 0.7831 RMSE: 0.9937\n",
      "ValLoss: 1.0537 MAE: 0.8142 RMSE: 1.0265\n",
      "Epoch 74: TrainLoss 0.8798 RecLoss: 0.0000 (left: 0:02:28)\n",
      "TestLoss: 0.9878 MAE: 0.7812 RMSE: 0.9939\n",
      "ValLoss: 1.0562 MAE: 0.8136 RMSE: 1.0277\n",
      "Epoch 75: TrainLoss 0.8795 RecLoss: 0.0000 (left: 0:02:22)\n",
      "TestLoss: 0.9942 MAE: 0.7758 RMSE: 0.9971\n",
      "ValLoss: 1.0666 MAE: 0.8126 RMSE: 1.0327\n",
      "Epoch 76: TrainLoss 0.8804 RecLoss: 0.0000 (left: 0:02:17)\n",
      "TestLoss: 0.9888 MAE: 0.7793 RMSE: 0.9944\n",
      "ValLoss: 1.0577 MAE: 0.8129 RMSE: 1.0284\n",
      "Epoch 77: TrainLoss 0.8799 RecLoss: 0.0000 (left: 0:02:11)\n",
      "TestLoss: 0.9887 MAE: 0.7801 RMSE: 0.9943\n",
      "ValLoss: 1.0572 MAE: 0.8126 RMSE: 1.0282\n",
      "Epoch 78: TrainLoss 0.8798 RecLoss: 0.0000 (left: 0:02:05)\n",
      "TestLoss: 0.9931 MAE: 0.7759 RMSE: 0.9965\n",
      "ValLoss: 1.0669 MAE: 0.8132 RMSE: 1.0329\n",
      "Epoch 79: TrainLoss 0.8796 RecLoss: 0.0000 (left: 0:01:59)\n",
      "TestLoss: 0.9891 MAE: 0.7867 RMSE: 0.9946\n",
      "ValLoss: 1.0542 MAE: 0.8158 RMSE: 1.0267\n",
      "Epoch 80: TrainLoss 0.8799 RecLoss: 0.0000 (left: 0:01:53)\n",
      "TestLoss: 0.9885 MAE: 0.7868 RMSE: 0.9942\n",
      "ValLoss: 1.0539 MAE: 0.8164 RMSE: 1.0266\n",
      "Epoch 81: TrainLoss 0.8789 RecLoss: 0.0000 (left: 0:01:47)\n",
      "TestLoss: 0.9868 MAE: 0.7832 RMSE: 0.9934\n",
      "ValLoss: 1.0535 MAE: 0.8139 RMSE: 1.0264\n",
      "Epoch 82: TrainLoss 0.8824 RecLoss: 0.0000 (left: 0:01:42)\n",
      "TestLoss: 0.9958 MAE: 0.7754 RMSE: 0.9979\n",
      "ValLoss: 1.0701 MAE: 0.8136 RMSE: 1.0345\n",
      "Epoch 83: TrainLoss 0.8858 RecLoss: 0.0000 (left: 0:01:36)\n",
      "TestLoss: 0.9904 MAE: 0.7781 RMSE: 0.9952\n",
      "ValLoss: 1.0619 MAE: 0.8132 RMSE: 1.0305\n",
      "Epoch 84: TrainLoss 0.8783 RecLoss: 0.0000 (left: 0:01:30)\n",
      "TestLoss: 0.9892 MAE: 0.7863 RMSE: 0.9946\n",
      "ValLoss: 1.0547 MAE: 0.8160 RMSE: 1.0270\n",
      "Epoch 85: TrainLoss 0.8806 RecLoss: 0.0000 (left: 0:01:24)\n",
      "TestLoss: 0.9884 MAE: 0.7802 RMSE: 0.9942\n",
      "ValLoss: 1.0579 MAE: 0.8136 RMSE: 1.0286\n",
      "Epoch 86: TrainLoss 0.8805 RecLoss: 0.0000 (left: 0:01:19)\n",
      "TestLoss: 0.9918 MAE: 0.7774 RMSE: 0.9959\n",
      "ValLoss: 1.0636 MAE: 0.8131 RMSE: 1.0313\n",
      "Epoch 87: TrainLoss 0.8804 RecLoss: 0.0000 (left: 0:01:13)\n",
      "TestLoss: 0.9885 MAE: 0.7819 RMSE: 0.9942\n",
      "ValLoss: 1.0562 MAE: 0.8140 RMSE: 1.0277\n",
      "Epoch 88: TrainLoss 0.8823 RecLoss: 0.0000 (left: 0:01:07)\n",
      "TestLoss: 0.9896 MAE: 0.7795 RMSE: 0.9948\n",
      "ValLoss: 1.0591 MAE: 0.8131 RMSE: 1.0291\n",
      "Epoch 89: TrainLoss 0.8801 RecLoss: 0.0000 (left: 0:01:02)\n",
      "TestLoss: 0.9881 MAE: 0.7798 RMSE: 0.9940\n",
      "ValLoss: 1.0587 MAE: 0.8135 RMSE: 1.0289\n",
      "Epoch 90: TrainLoss 0.8791 RecLoss: 0.0000 (left: 0:00:56)\n",
      "TestLoss: 0.9879 MAE: 0.7856 RMSE: 0.9939\n",
      "ValLoss: 1.0567 MAE: 0.8166 RMSE: 1.0279\n",
      "Epoch 91: TrainLoss 0.8813 RecLoss: 0.0000 (left: 0:00:50)\n",
      "TestLoss: 0.9873 MAE: 0.7821 RMSE: 0.9937\n",
      "ValLoss: 1.0557 MAE: 0.8140 RMSE: 1.0275\n",
      "Epoch 92: TrainLoss 0.8786 RecLoss: 0.0000 (left: 0:00:45)\n",
      "TestLoss: 0.9884 MAE: 0.7831 RMSE: 0.9942\n",
      "ValLoss: 1.0542 MAE: 0.8139 RMSE: 1.0267\n",
      "Epoch 93: TrainLoss 0.8793 RecLoss: 0.0000 (left: 0:00:39)\n",
      "TestLoss: 0.9910 MAE: 0.7904 RMSE: 0.9955\n",
      "ValLoss: 1.0545 MAE: 0.8183 RMSE: 1.0269\n",
      "Epoch 94: TrainLoss 0.8829 RecLoss: 0.0000 (left: 0:00:33)\n",
      "TestLoss: 0.9890 MAE: 0.7791 RMSE: 0.9945\n",
      "ValLoss: 1.0587 MAE: 0.8129 RMSE: 1.0289\n",
      "Epoch 95: TrainLoss 0.8811 RecLoss: 0.0000 (left: 0:00:28)\n",
      "TestLoss: 0.9888 MAE: 0.7794 RMSE: 0.9944\n",
      "ValLoss: 1.0594 MAE: 0.8139 RMSE: 1.0293\n",
      "Epoch 96: TrainLoss 0.8795 RecLoss: 0.0000 (left: 0:00:22)\n",
      "TestLoss: 0.9944 MAE: 0.7759 RMSE: 0.9972\n",
      "ValLoss: 1.0663 MAE: 0.8123 RMSE: 1.0326\n",
      "Epoch 97: TrainLoss 0.8801 RecLoss: 0.0000 (left: 0:00:16)\n",
      "TestLoss: 0.9878 MAE: 0.7818 RMSE: 0.9939\n",
      "ValLoss: 1.0567 MAE: 0.8144 RMSE: 1.0279\n",
      "Epoch 98: TrainLoss 0.8786 RecLoss: 0.0000 (left: 0:00:11)\n",
      "TestLoss: 0.9879 MAE: 0.7847 RMSE: 0.9939\n",
      "ValLoss: 1.0545 MAE: 0.8147 RMSE: 1.0269\n",
      "Epoch 99: TrainLoss 0.8786 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 0.9886 MAE: 0.7876 RMSE: 0.9943\n",
      "ValLoss: 1.0539 MAE: 0.8163 RMSE: 1.0266\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 789731/19100\n",
      "test set size: support/query 3138/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.6854 RMSE: 0.8690 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7808 RMSE: 0.9883 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7050 RMSE: 0.8947 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 40% CUR coreusers input to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 601508/19100\n",
      "test set size: support/query 2092/809\n",
      "Epoch 0 Step 559: Train 1.7367 Reg: 0.6178\n",
      "Test: 0.8674 MAE: 0.7415 RMSE: 0.9313\n",
      "Val: 0.8281 MAE: 0.7198 RMSE: 0.9100\n",
      "Epoch 1 Step 1118: Train 0.8199 Reg: 0.4178\n",
      "Test: 0.8714 MAE: 0.7433 RMSE: 0.9335\n",
      "Val: 0.8177 MAE: 0.7142 RMSE: 0.9043\n",
      "Epoch 2 Step 1677: Train 0.8154 Reg: 0.3411\n",
      "Test: 0.8585 MAE: 0.7379 RMSE: 0.9265\n",
      "Val: 0.8177 MAE: 0.7152 RMSE: 0.9043\n",
      "Epoch 3 Step 2236: Train 0.8114 Reg: 0.3114\n",
      "Test: 0.8584 MAE: 0.7350 RMSE: 0.9265\n",
      "Val: 0.8129 MAE: 0.7140 RMSE: 0.9016\n",
      "Epoch 4 Step 2795: Train 0.8065 Reg: 0.2894\n",
      "Test: 0.8419 MAE: 0.7302 RMSE: 0.9176\n",
      "Val: 0.8071 MAE: 0.7106 RMSE: 0.8984\n",
      "Epoch 5 Step 3354: Train 0.8000 Reg: 0.2711\n",
      "Test: 0.8575 MAE: 0.7325 RMSE: 0.9260\n",
      "Val: 0.7999 MAE: 0.7054 RMSE: 0.8944\n",
      "Epoch 6 Step 3913: Train 0.7908 Reg: 0.2576\n",
      "Test: 0.8478 MAE: 0.7295 RMSE: 0.9207\n",
      "Val: 0.7921 MAE: 0.7005 RMSE: 0.8900\n",
      "Epoch 7 Step 4472: Train 0.7807 Reg: 0.2529\n",
      "Test: 0.8307 MAE: 0.7228 RMSE: 0.9114\n",
      "Val: 0.7817 MAE: 0.6970 RMSE: 0.8841\n",
      "Epoch 8 Step 5031: Train 0.7620 Reg: 0.2714\n",
      "Test: 0.8099 MAE: 0.7116 RMSE: 0.8999\n",
      "Val: 0.7626 MAE: 0.6867 RMSE: 0.8733\n",
      "Epoch 9 Step 5590: Train 0.7440 Reg: 0.2906\n",
      "Test: 0.8095 MAE: 0.7140 RMSE: 0.8997\n",
      "Val: 0.7558 MAE: 0.6813 RMSE: 0.8693\n",
      "Epoch 10 Step 6149: Train 0.7322 Reg: 0.3028\n",
      "Test: 0.7913 MAE: 0.7013 RMSE: 0.8896\n",
      "Val: 0.7441 MAE: 0.6776 RMSE: 0.8626\n",
      "Epoch 11 Step 6708: Train 0.7137 Reg: 0.3367\n",
      "Test: 0.7829 MAE: 0.7033 RMSE: 0.8848\n",
      "Val: 0.7284 MAE: 0.6672 RMSE: 0.8535\n",
      "Epoch 12 Step 7267: Train 0.6894 Reg: 0.3842\n",
      "Test: 0.7716 MAE: 0.6973 RMSE: 0.8784\n",
      "Val: 0.7159 MAE: 0.6635 RMSE: 0.8461\n",
      "Epoch 13 Step 7826: Train 0.6656 Reg: 0.4197\n",
      "Test: 0.7590 MAE: 0.6885 RMSE: 0.8712\n",
      "Val: 0.7057 MAE: 0.6567 RMSE: 0.8400\n",
      "Epoch 14 Step 8385: Train 0.6423 Reg: 0.4513\n",
      "Test: 0.7551 MAE: 0.6893 RMSE: 0.8690\n",
      "Val: 0.7011 MAE: 0.6557 RMSE: 0.8373\n",
      "Epoch 15 Step 8944: Train 0.6201 Reg: 0.4793\n",
      "Test: 0.7506 MAE: 0.6816 RMSE: 0.8664\n",
      "Val: 0.7037 MAE: 0.6546 RMSE: 0.8389\n",
      "Epoch 16 Step 9503: Train 0.5998 Reg: 0.5023\n",
      "Test: 0.7532 MAE: 0.6824 RMSE: 0.8679\n",
      "Val: 0.7081 MAE: 0.6558 RMSE: 0.8415\n",
      "Epoch 17 Step 10062: Train 0.5796 Reg: 0.5294\n",
      "Test: 0.7589 MAE: 0.6887 RMSE: 0.8711\n",
      "Val: 0.7147 MAE: 0.6604 RMSE: 0.8454\n",
      "Epoch 18 Step 10621: Train 0.5576 Reg: 0.5525\n",
      "Test: 0.7605 MAE: 0.6831 RMSE: 0.8721\n",
      "Val: 0.7197 MAE: 0.6595 RMSE: 0.8484\n",
      "Epoch 19 Step 11180: Train 0.5381 Reg: 0.5687\n",
      "Test: 0.7694 MAE: 0.6887 RMSE: 0.8771\n",
      "Val: 0.7290 MAE: 0.6634 RMSE: 0.8538\n",
      "Epoch 20 Step 11739: Train 0.5218 Reg: 0.5778\n",
      "Test: 0.7774 MAE: 0.6919 RMSE: 0.8817\n",
      "Val: 0.7381 MAE: 0.6688 RMSE: 0.8591\n",
      "Epoch 21 Step 12298: Train 0.5094 Reg: 0.5824\n",
      "Test: 0.7920 MAE: 0.6992 RMSE: 0.8899\n",
      "Val: 0.7465 MAE: 0.6721 RMSE: 0.8640\n",
      "Epoch 22 Step 12857: Train 0.4988 Reg: 0.5855\n",
      "Test: 0.7973 MAE: 0.6982 RMSE: 0.8929\n",
      "Val: 0.7570 MAE: 0.6747 RMSE: 0.8700\n",
      "Epoch 23 Step 13416: Train 0.4889 Reg: 0.5870\n",
      "Test: 0.8080 MAE: 0.7001 RMSE: 0.8989\n",
      "Val: 0.7640 MAE: 0.6757 RMSE: 0.8741\n",
      "Epoch 24 Step 13975: Train 0.4807 Reg: 0.5859\n",
      "Test: 0.8191 MAE: 0.7018 RMSE: 0.9050\n",
      "Val: 0.7717 MAE: 0.6780 RMSE: 0.8784\n",
      "Epoch 25 Step 14534: Train 0.4736 Reg: 0.5841\n",
      "Test: 0.8277 MAE: 0.7073 RMSE: 0.9098\n",
      "Val: 0.7783 MAE: 0.6815 RMSE: 0.8822\n",
      "Epoch 26 Step 15093: Train 0.4672 Reg: 0.5815\n",
      "Test: 0.8367 MAE: 0.7095 RMSE: 0.9147\n",
      "Val: 0.7861 MAE: 0.6839 RMSE: 0.8866\n",
      "Epoch 27 Step 15652: Train 0.4606 Reg: 0.5808\n",
      "Test: 0.8363 MAE: 0.7091 RMSE: 0.9145\n",
      "Val: 0.7922 MAE: 0.6854 RMSE: 0.8901\n",
      "Epoch 28 Step 16211: Train 0.4538 Reg: 0.5785\n",
      "Test: 0.8486 MAE: 0.7164 RMSE: 0.9212\n",
      "Val: 0.8023 MAE: 0.6900 RMSE: 0.8957\n",
      "Epoch 29 Step 16770: Train 0.4479 Reg: 0.5754\n",
      "Test: 0.8527 MAE: 0.7188 RMSE: 0.9234\n",
      "Val: 0.8063 MAE: 0.6911 RMSE: 0.8979\n",
      "Epoch 30 Step 17329: Train 0.4432 Reg: 0.5710\n",
      "Test: 0.8607 MAE: 0.7194 RMSE: 0.9277\n",
      "Val: 0.8149 MAE: 0.6937 RMSE: 0.9027\n",
      "Epoch 31 Step 17888: Train 0.4390 Reg: 0.5666\n",
      "Test: 0.8676 MAE: 0.7231 RMSE: 0.9314\n",
      "Val: 0.8193 MAE: 0.6957 RMSE: 0.9051\n",
      "Epoch 32 Step 18447: Train 0.4350 Reg: 0.5618\n",
      "Test: 0.8713 MAE: 0.7283 RMSE: 0.9334\n",
      "Val: 0.8256 MAE: 0.6987 RMSE: 0.9086\n",
      "Epoch 33 Step 19006: Train 0.4317 Reg: 0.5569\n",
      "Test: 0.8779 MAE: 0.7297 RMSE: 0.9369\n",
      "Val: 0.8310 MAE: 0.7010 RMSE: 0.9116\n",
      "Epoch 34 Step 19565: Train 0.4284 Reg: 0.5519\n",
      "Test: 0.8866 MAE: 0.7336 RMSE: 0.9416\n",
      "Val: 0.8369 MAE: 0.7036 RMSE: 0.9148\n",
      "Epoch 35 Step 20124: Train 0.4254 Reg: 0.5473\n",
      "Test: 0.8879 MAE: 0.7316 RMSE: 0.9423\n",
      "Val: 0.8402 MAE: 0.7028 RMSE: 0.9166\n",
      "Epoch 36 Step 20683: Train 0.4226 Reg: 0.5424\n",
      "Test: 0.8994 MAE: 0.7375 RMSE: 0.9483\n",
      "Val: 0.8456 MAE: 0.7055 RMSE: 0.9196\n",
      "Epoch 37 Step 21242: Train 0.4198 Reg: 0.5378\n",
      "Test: 0.9007 MAE: 0.7370 RMSE: 0.9491\n",
      "Val: 0.8500 MAE: 0.7070 RMSE: 0.9219\n",
      "Epoch 38 Step 21801: Train 0.4171 Reg: 0.5331\n",
      "Test: 0.9055 MAE: 0.7379 RMSE: 0.9516\n",
      "Val: 0.8531 MAE: 0.7067 RMSE: 0.9236\n",
      "Epoch 39 Step 22360: Train 0.4146 Reg: 0.5285\n",
      "Test: 0.9083 MAE: 0.7383 RMSE: 0.9531\n",
      "Val: 0.8570 MAE: 0.7082 RMSE: 0.9257\n",
      "Epoch 40 Step 22919: Train 0.4125 Reg: 0.5241\n",
      "Test: 0.9136 MAE: 0.7418 RMSE: 0.9558\n",
      "Val: 0.8620 MAE: 0.7106 RMSE: 0.9284\n",
      "Epoch 41 Step 23478: Train 0.4102 Reg: 0.5199\n",
      "Test: 0.9161 MAE: 0.7409 RMSE: 0.9571\n",
      "Val: 0.8645 MAE: 0.7110 RMSE: 0.9298\n",
      "Epoch 42 Step 24037: Train 0.4081 Reg: 0.5155\n",
      "Test: 0.9206 MAE: 0.7428 RMSE: 0.9595\n",
      "Val: 0.8687 MAE: 0.7122 RMSE: 0.9320\n",
      "Epoch 43 Step 24596: Train 0.4061 Reg: 0.5115\n",
      "Test: 0.9279 MAE: 0.7443 RMSE: 0.9633\n",
      "Val: 0.8731 MAE: 0.7132 RMSE: 0.9344\n",
      "Epoch 44 Step 25155: Train 0.4041 Reg: 0.5076\n",
      "Test: 0.9277 MAE: 0.7455 RMSE: 0.9632\n",
      "Val: 0.8745 MAE: 0.7149 RMSE: 0.9352\n",
      "Epoch 45 Step 25714: Train 0.4023 Reg: 0.5037\n",
      "Test: 0.9318 MAE: 0.7461 RMSE: 0.9653\n",
      "Val: 0.8779 MAE: 0.7155 RMSE: 0.9369\n",
      "Epoch 46 Step 26273: Train 0.4005 Reg: 0.5000\n",
      "Test: 0.9361 MAE: 0.7481 RMSE: 0.9675\n",
      "Val: 0.8828 MAE: 0.7171 RMSE: 0.9396\n",
      "Epoch 47 Step 26832: Train 0.3988 Reg: 0.4965\n",
      "Test: 0.9420 MAE: 0.7505 RMSE: 0.9706\n",
      "Val: 0.8853 MAE: 0.7182 RMSE: 0.9409\n",
      "Epoch 48 Step 27391: Train 0.3972 Reg: 0.4931\n",
      "Test: 0.9453 MAE: 0.7518 RMSE: 0.9723\n",
      "Val: 0.8873 MAE: 0.7190 RMSE: 0.9419\n",
      "Epoch 49 Step 27950: Train 0.3956 Reg: 0.4898\n",
      "Test: 0.9497 MAE: 0.7537 RMSE: 0.9745\n",
      "Val: 0.8918 MAE: 0.7207 RMSE: 0.9443\n",
      "Epoch 50 Step 28509: Train 0.3941 Reg: 0.4867\n",
      "Test: 0.9522 MAE: 0.7552 RMSE: 0.9758\n",
      "Val: 0.8957 MAE: 0.7227 RMSE: 0.9464\n",
      "Epoch 51 Step 29068: Train 0.3927 Reg: 0.4836\n",
      "Test: 0.9563 MAE: 0.7569 RMSE: 0.9779\n",
      "Val: 0.8970 MAE: 0.7230 RMSE: 0.9471\n",
      "Epoch 52 Step 29627: Train 0.3912 Reg: 0.4807\n",
      "Test: 0.9580 MAE: 0.7567 RMSE: 0.9788\n",
      "Val: 0.9000 MAE: 0.7236 RMSE: 0.9487\n",
      "Epoch 53 Step 30186: Train 0.3900 Reg: 0.4778\n",
      "Test: 0.9627 MAE: 0.7579 RMSE: 0.9812\n",
      "Val: 0.9015 MAE: 0.7238 RMSE: 0.9495\n",
      "Epoch 54 Step 30745: Train 0.3888 Reg: 0.4751\n",
      "Test: 0.9647 MAE: 0.7590 RMSE: 0.9822\n",
      "Val: 0.9044 MAE: 0.7252 RMSE: 0.9510\n",
      "Epoch 55 Step 31304: Train 0.3875 Reg: 0.4725\n",
      "Test: 0.9675 MAE: 0.7592 RMSE: 0.9836\n",
      "Val: 0.9054 MAE: 0.7251 RMSE: 0.9515\n",
      "Epoch 56 Step 31863: Train 0.3863 Reg: 0.4700\n",
      "Test: 0.9693 MAE: 0.7600 RMSE: 0.9845\n",
      "Val: 0.9078 MAE: 0.7258 RMSE: 0.9528\n",
      "Epoch 57 Step 32422: Train 0.3852 Reg: 0.4676\n",
      "Test: 0.9727 MAE: 0.7616 RMSE: 0.9862\n",
      "Val: 0.9109 MAE: 0.7270 RMSE: 0.9544\n",
      "Epoch 58 Step 32981: Train 0.3841 Reg: 0.4654\n",
      "Test: 0.9748 MAE: 0.7636 RMSE: 0.9873\n",
      "Val: 0.9131 MAE: 0.7285 RMSE: 0.9556\n",
      "Epoch 59 Step 33540: Train 0.3831 Reg: 0.4632\n",
      "Test: 0.9768 MAE: 0.7632 RMSE: 0.9883\n",
      "Val: 0.9144 MAE: 0.7285 RMSE: 0.9563\n",
      "Epoch 60 Step 34099: Train 0.3821 Reg: 0.4611\n",
      "Test: 0.9788 MAE: 0.7632 RMSE: 0.9894\n",
      "Val: 0.9165 MAE: 0.7285 RMSE: 0.9573\n",
      "Epoch 61 Step 34658: Train 0.3812 Reg: 0.4591\n",
      "Test: 0.9814 MAE: 0.7646 RMSE: 0.9907\n",
      "Val: 0.9186 MAE: 0.7295 RMSE: 0.9584\n",
      "Epoch 62 Step 35217: Train 0.3803 Reg: 0.4572\n",
      "Test: 0.9830 MAE: 0.7654 RMSE: 0.9915\n",
      "Val: 0.9193 MAE: 0.7298 RMSE: 0.9588\n",
      "Epoch 63 Step 35776: Train 0.3794 Reg: 0.4553\n",
      "Test: 0.9855 MAE: 0.7665 RMSE: 0.9927\n",
      "Val: 0.9211 MAE: 0.7306 RMSE: 0.9597\n",
      "Epoch 64 Step 36335: Train 0.3786 Reg: 0.4535\n",
      "Test: 0.9869 MAE: 0.7670 RMSE: 0.9934\n",
      "Val: 0.9232 MAE: 0.7314 RMSE: 0.9608\n",
      "Epoch 65 Step 36894: Train 0.3778 Reg: 0.4519\n",
      "Test: 0.9875 MAE: 0.7664 RMSE: 0.9937\n",
      "Val: 0.9238 MAE: 0.7310 RMSE: 0.9611\n",
      "Epoch 66 Step 37453: Train 0.3770 Reg: 0.4503\n",
      "Test: 0.9909 MAE: 0.7693 RMSE: 0.9954\n",
      "Val: 0.9268 MAE: 0.7332 RMSE: 0.9627\n",
      "Epoch 67 Step 38012: Train 0.3763 Reg: 0.4488\n",
      "Test: 0.9910 MAE: 0.7676 RMSE: 0.9955\n",
      "Val: 0.9264 MAE: 0.7322 RMSE: 0.9625\n",
      "Epoch 68 Step 38571: Train 0.3756 Reg: 0.4473\n",
      "Test: 0.9934 MAE: 0.7686 RMSE: 0.9967\n",
      "Val: 0.9276 MAE: 0.7325 RMSE: 0.9631\n",
      "Epoch 69 Step 39130: Train 0.3749 Reg: 0.4459\n",
      "Test: 0.9949 MAE: 0.7695 RMSE: 0.9974\n",
      "Val: 0.9290 MAE: 0.7331 RMSE: 0.9638\n",
      "Epoch 70 Step 39689: Train 0.3743 Reg: 0.4445\n",
      "Test: 0.9959 MAE: 0.7690 RMSE: 0.9979\n",
      "Val: 0.9298 MAE: 0.7331 RMSE: 0.9642\n",
      "Epoch 71 Step 40248: Train 0.3737 Reg: 0.4433\n",
      "Test: 0.9989 MAE: 0.7708 RMSE: 0.9995\n",
      "Val: 0.9314 MAE: 0.7340 RMSE: 0.9651\n",
      "Epoch 72 Step 40807: Train 0.3731 Reg: 0.4420\n",
      "Test: 1.0005 MAE: 0.7714 RMSE: 1.0002\n",
      "Val: 0.9331 MAE: 0.7349 RMSE: 0.9660\n",
      "Epoch 73 Step 41366: Train 0.3725 Reg: 0.4409\n",
      "Test: 1.0008 MAE: 0.7709 RMSE: 1.0004\n",
      "Val: 0.9334 MAE: 0.7344 RMSE: 0.9661\n",
      "Epoch 74 Step 41925: Train 0.3720 Reg: 0.4398\n",
      "Test: 1.0020 MAE: 0.7716 RMSE: 1.0010\n",
      "Val: 0.9343 MAE: 0.7349 RMSE: 0.9666\n",
      "Epoch 75 Step 42484: Train 0.3715 Reg: 0.4387\n",
      "Test: 1.0034 MAE: 0.7721 RMSE: 1.0017\n",
      "Val: 0.9350 MAE: 0.7350 RMSE: 0.9669\n",
      "Epoch 76 Step 43043: Train 0.3710 Reg: 0.4377\n",
      "Test: 1.0041 MAE: 0.7723 RMSE: 1.0021\n",
      "Val: 0.9359 MAE: 0.7353 RMSE: 0.9674\n",
      "Epoch 77 Step 43602: Train 0.3705 Reg: 0.4368\n",
      "Test: 1.0055 MAE: 0.7726 RMSE: 1.0027\n",
      "Val: 0.9368 MAE: 0.7355 RMSE: 0.9679\n",
      "Epoch 78 Step 44161: Train 0.3701 Reg: 0.4358\n",
      "Test: 1.0064 MAE: 0.7737 RMSE: 1.0032\n",
      "Val: 0.9379 MAE: 0.7364 RMSE: 0.9685\n",
      "Epoch 79 Step 44720: Train 0.3697 Reg: 0.4350\n",
      "Test: 1.0076 MAE: 0.7737 RMSE: 1.0038\n",
      "Val: 0.9383 MAE: 0.7362 RMSE: 0.9687\n",
      "Epoch 80 Step 45279: Train 0.3693 Reg: 0.4341\n",
      "Test: 1.0079 MAE: 0.7734 RMSE: 1.0040\n",
      "Val: 0.9390 MAE: 0.7363 RMSE: 0.9690\n",
      "Epoch 81 Step 45838: Train 0.3689 Reg: 0.4334\n",
      "Test: 1.0092 MAE: 0.7742 RMSE: 1.0046\n",
      "Val: 0.9396 MAE: 0.7367 RMSE: 0.9693\n",
      "Epoch 82 Step 46397: Train 0.3685 Reg: 0.4326\n",
      "Test: 1.0096 MAE: 0.7737 RMSE: 1.0048\n",
      "Val: 0.9399 MAE: 0.7365 RMSE: 0.9695\n",
      "Epoch 83 Step 46956: Train 0.3682 Reg: 0.4319\n",
      "Test: 1.0107 MAE: 0.7748 RMSE: 1.0053\n",
      "Val: 0.9410 MAE: 0.7373 RMSE: 0.9701\n",
      "Epoch 84 Step 47515: Train 0.3678 Reg: 0.4312\n",
      "Test: 1.0113 MAE: 0.7743 RMSE: 1.0056\n",
      "Val: 0.9412 MAE: 0.7370 RMSE: 0.9702\n",
      "Epoch 85 Step 48074: Train 0.3675 Reg: 0.4306\n",
      "Test: 1.0124 MAE: 0.7746 RMSE: 1.0062\n",
      "Val: 0.9419 MAE: 0.7371 RMSE: 0.9705\n",
      "Epoch 86 Step 48633: Train 0.3672 Reg: 0.4299\n",
      "Test: 1.0131 MAE: 0.7752 RMSE: 1.0065\n",
      "Val: 0.9425 MAE: 0.7376 RMSE: 0.9708\n",
      "Epoch 87 Step 49192: Train 0.3669 Reg: 0.4294\n",
      "Test: 1.0139 MAE: 0.7756 RMSE: 1.0069\n",
      "Val: 0.9433 MAE: 0.7380 RMSE: 0.9713\n",
      "Epoch 88 Step 49751: Train 0.3667 Reg: 0.4288\n",
      "Test: 1.0147 MAE: 0.7763 RMSE: 1.0073\n",
      "Val: 0.9440 MAE: 0.7383 RMSE: 0.9716\n",
      "Epoch 89 Step 50310: Train 0.3664 Reg: 0.4283\n",
      "Test: 1.0151 MAE: 0.7758 RMSE: 1.0075\n",
      "Val: 0.9441 MAE: 0.7381 RMSE: 0.9716\n",
      "Epoch 90 Step 50869: Train 0.3661 Reg: 0.4278\n",
      "Test: 1.0153 MAE: 0.7757 RMSE: 1.0076\n",
      "Val: 0.9445 MAE: 0.7381 RMSE: 0.9718\n",
      "Epoch 91 Step 51428: Train 0.3659 Reg: 0.4273\n",
      "Test: 1.0162 MAE: 0.7764 RMSE: 1.0081\n",
      "Val: 0.9450 MAE: 0.7385 RMSE: 0.9721\n",
      "Epoch 92 Step 51987: Train 0.3657 Reg: 0.4268\n",
      "Test: 1.0165 MAE: 0.7759 RMSE: 1.0082\n",
      "Val: 0.9450 MAE: 0.7382 RMSE: 0.9721\n",
      "Epoch 93 Step 52546: Train 0.3655 Reg: 0.4264\n",
      "Test: 1.0171 MAE: 0.7763 RMSE: 1.0085\n",
      "Val: 0.9455 MAE: 0.7384 RMSE: 0.9723\n",
      "Epoch 94 Step 53105: Train 0.3653 Reg: 0.4260\n",
      "Test: 1.0173 MAE: 0.7763 RMSE: 1.0086\n",
      "Val: 0.9457 MAE: 0.7385 RMSE: 0.9725\n",
      "Epoch 95 Step 53664: Train 0.3651 Reg: 0.4256\n",
      "Test: 1.0180 MAE: 0.7766 RMSE: 1.0089\n",
      "Val: 0.9461 MAE: 0.7386 RMSE: 0.9727\n",
      "Epoch 96 Step 54223: Train 0.3649 Reg: 0.4252\n",
      "Test: 1.0184 MAE: 0.7766 RMSE: 1.0092\n",
      "Val: 0.9463 MAE: 0.7386 RMSE: 0.9728\n",
      "Epoch 97 Step 54782: Train 0.3647 Reg: 0.4248\n",
      "Test: 1.0190 MAE: 0.7774 RMSE: 1.0095\n",
      "Val: 0.9471 MAE: 0.7392 RMSE: 0.9732\n",
      "Epoch 98 Step 55341: Train 0.3645 Reg: 0.4245\n",
      "Test: 1.0194 MAE: 0.7774 RMSE: 1.0096\n",
      "Val: 0.9473 MAE: 0.7392 RMSE: 0.9733\n",
      "Epoch 99 Step 55900: Train 0.3644 Reg: 0.4242\n",
      "Test: 1.0197 MAE: 0.7777 RMSE: 1.0098\n",
      "Val: 0.9476 MAE: 0.7393 RMSE: 0.9734\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 601508/19100\n",
      "test set size: support/query 2092/809\n",
      "Epoch 0: TrainLoss 1.1262 RecLoss: 0.0000 (left: 0:11:04)\n",
      "TestLoss: 1.0681 MAE: 0.7993 RMSE: 1.0335\n",
      "ValLoss: 1.1452 MAE: 0.8433 RMSE: 1.0702\n",
      "Epoch 1: TrainLoss 0.9995 RecLoss: 0.0000 (left: 0:10:05)\n",
      "TestLoss: 1.0147 MAE: 0.8000 RMSE: 1.0073\n",
      "ValLoss: 1.0703 MAE: 0.8359 RMSE: 1.0345\n",
      "Epoch 2: TrainLoss 0.9627 RecLoss: 0.0000 (left: 0:09:35)\n",
      "TestLoss: 1.0014 MAE: 0.7978 RMSE: 1.0007\n",
      "ValLoss: 1.0578 MAE: 0.8327 RMSE: 1.0285\n",
      "Epoch 3: TrainLoss 0.9483 RecLoss: 0.0000 (left: 0:09:15)\n",
      "TestLoss: 1.0093 MAE: 0.8113 RMSE: 1.0046\n",
      "ValLoss: 1.0562 MAE: 0.8384 RMSE: 1.0277\n",
      "Epoch 4: TrainLoss 0.9277 RecLoss: 0.0000 (left: 0:08:50)\n",
      "TestLoss: 0.9840 MAE: 0.7864 RMSE: 0.9920\n",
      "ValLoss: 1.0391 MAE: 0.8212 RMSE: 1.0193\n",
      "Epoch 5: TrainLoss 0.9158 RecLoss: 0.0000 (left: 0:08:50)\n",
      "TestLoss: 0.9809 MAE: 0.7822 RMSE: 0.9904\n",
      "ValLoss: 1.0341 MAE: 0.8160 RMSE: 1.0169\n",
      "Epoch 6: TrainLoss 0.9078 RecLoss: 0.0000 (left: 0:08:41)\n",
      "TestLoss: 0.9819 MAE: 0.7814 RMSE: 0.9909\n",
      "ValLoss: 1.0373 MAE: 0.8160 RMSE: 1.0185\n",
      "Epoch 7: TrainLoss 0.9032 RecLoss: 0.0000 (left: 0:08:18)\n",
      "TestLoss: 0.9775 MAE: 0.7810 RMSE: 0.9887\n",
      "ValLoss: 1.0306 MAE: 0.8139 RMSE: 1.0152\n",
      "Epoch 8: TrainLoss 0.9012 RecLoss: 0.0000 (left: 0:08:22)\n",
      "TestLoss: 0.9859 MAE: 0.7937 RMSE: 0.9929\n",
      "ValLoss: 1.0351 MAE: 0.8231 RMSE: 1.0174\n",
      "Epoch 9: TrainLoss 0.8983 RecLoss: 0.0000 (left: 0:08:12)\n",
      "TestLoss: 0.9814 MAE: 0.7844 RMSE: 0.9906\n",
      "ValLoss: 1.0305 MAE: 0.8153 RMSE: 1.0151\n",
      "Epoch 10: TrainLoss 0.8927 RecLoss: 0.0000 (left: 0:08:06)\n",
      "TestLoss: 0.9798 MAE: 0.7843 RMSE: 0.9899\n",
      "ValLoss: 1.0339 MAE: 0.8175 RMSE: 1.0168\n",
      "Epoch 11: TrainLoss 0.8900 RecLoss: 0.0000 (left: 0:08:03)\n",
      "TestLoss: 0.9804 MAE: 0.7800 RMSE: 0.9902\n",
      "ValLoss: 1.0362 MAE: 0.8139 RMSE: 1.0179\n",
      "Epoch 12: TrainLoss 0.8890 RecLoss: 0.0000 (left: 0:08:00)\n",
      "TestLoss: 0.9838 MAE: 0.7777 RMSE: 0.9919\n",
      "ValLoss: 1.0413 MAE: 0.8135 RMSE: 1.0204\n",
      "Epoch 13: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:07:55)\n",
      "TestLoss: 0.9839 MAE: 0.7846 RMSE: 0.9919\n",
      "ValLoss: 1.0371 MAE: 0.8170 RMSE: 1.0184\n",
      "Epoch 14: TrainLoss 0.8903 RecLoss: 0.0000 (left: 0:07:51)\n",
      "TestLoss: 1.0037 MAE: 0.8064 RMSE: 1.0019\n",
      "ValLoss: 1.0488 MAE: 0.8317 RMSE: 1.0241\n",
      "Epoch 15: TrainLoss 0.8906 RecLoss: 0.0000 (left: 0:07:49)\n",
      "TestLoss: 0.9836 MAE: 0.7836 RMSE: 0.9917\n",
      "ValLoss: 1.0400 MAE: 0.8166 RMSE: 1.0198\n",
      "Epoch 16: TrainLoss 0.8856 RecLoss: 0.0000 (left: 0:07:42)\n",
      "TestLoss: 0.9853 MAE: 0.7857 RMSE: 0.9926\n",
      "ValLoss: 1.0398 MAE: 0.8186 RMSE: 1.0197\n",
      "Epoch 17: TrainLoss 0.8857 RecLoss: 0.0000 (left: 0:07:36)\n",
      "TestLoss: 0.9875 MAE: 0.7780 RMSE: 0.9937\n",
      "ValLoss: 1.0501 MAE: 0.8152 RMSE: 1.0247\n",
      "Epoch 18: TrainLoss 0.8868 RecLoss: 0.0000 (left: 0:07:31)\n",
      "TestLoss: 0.9919 MAE: 0.7932 RMSE: 0.9959\n",
      "ValLoss: 1.0443 MAE: 0.8236 RMSE: 1.0219\n",
      "Epoch 19: TrainLoss 0.8896 RecLoss: 0.0000 (left: 0:07:26)\n",
      "TestLoss: 0.9870 MAE: 0.7866 RMSE: 0.9935\n",
      "ValLoss: 1.0431 MAE: 0.8194 RMSE: 1.0213\n",
      "Epoch 20: TrainLoss 0.8869 RecLoss: 0.0000 (left: 0:07:23)\n",
      "TestLoss: 0.9866 MAE: 0.7874 RMSE: 0.9933\n",
      "ValLoss: 1.0438 MAE: 0.8204 RMSE: 1.0217\n",
      "Epoch 21: TrainLoss 0.8860 RecLoss: 0.0000 (left: 0:07:20)\n",
      "TestLoss: 0.9893 MAE: 0.7779 RMSE: 0.9946\n",
      "ValLoss: 1.0520 MAE: 0.8147 RMSE: 1.0256\n",
      "Epoch 22: TrainLoss 0.8858 RecLoss: 0.0000 (left: 0:07:13)\n",
      "TestLoss: 0.9885 MAE: 0.7857 RMSE: 0.9942\n",
      "ValLoss: 1.0450 MAE: 0.8180 RMSE: 1.0223\n",
      "Epoch 23: TrainLoss 0.8853 RecLoss: 0.0000 (left: 0:07:06)\n",
      "TestLoss: 1.0081 MAE: 0.8068 RMSE: 1.0041\n",
      "ValLoss: 1.0587 MAE: 0.8335 RMSE: 1.0289\n",
      "Epoch 24: TrainLoss 0.8916 RecLoss: 0.0000 (left: 0:07:00)\n",
      "TestLoss: 0.9917 MAE: 0.7920 RMSE: 0.9958\n",
      "ValLoss: 1.0474 MAE: 0.8231 RMSE: 1.0234\n",
      "Epoch 25: TrainLoss 0.8833 RecLoss: 0.0000 (left: 0:06:55)\n",
      "TestLoss: 0.9863 MAE: 0.7817 RMSE: 0.9931\n",
      "ValLoss: 1.0486 MAE: 0.8172 RMSE: 1.0240\n",
      "Epoch 26: TrainLoss 0.8841 RecLoss: 0.0000 (left: 0:06:49)\n",
      "TestLoss: 0.9955 MAE: 0.7772 RMSE: 0.9977\n",
      "ValLoss: 1.0601 MAE: 0.8153 RMSE: 1.0296\n",
      "Epoch 27: TrainLoss 0.8859 RecLoss: 0.0000 (left: 0:06:44)\n",
      "TestLoss: 0.9889 MAE: 0.7794 RMSE: 0.9944\n",
      "ValLoss: 1.0560 MAE: 0.8173 RMSE: 1.0276\n",
      "Epoch 28: TrainLoss 0.8840 RecLoss: 0.0000 (left: 0:06:38)\n",
      "TestLoss: 0.9914 MAE: 0.7888 RMSE: 0.9957\n",
      "ValLoss: 1.0495 MAE: 0.8211 RMSE: 1.0245\n",
      "Epoch 29: TrainLoss 0.8856 RecLoss: 0.0000 (left: 0:06:29)\n",
      "TestLoss: 0.9881 MAE: 0.7835 RMSE: 0.9940\n",
      "ValLoss: 1.0502 MAE: 0.8185 RMSE: 1.0248\n",
      "Epoch 30: TrainLoss 0.8843 RecLoss: 0.0000 (left: 0:06:25)\n",
      "TestLoss: 1.0006 MAE: 0.7753 RMSE: 1.0003\n",
      "ValLoss: 1.0719 MAE: 0.8159 RMSE: 1.0353\n",
      "Epoch 31: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:06:22)\n",
      "TestLoss: 0.9909 MAE: 0.7799 RMSE: 0.9954\n",
      "ValLoss: 1.0555 MAE: 0.8168 RMSE: 1.0274\n",
      "Epoch 32: TrainLoss 0.8823 RecLoss: 0.0000 (left: 0:06:15)\n",
      "TestLoss: 0.9888 MAE: 0.7829 RMSE: 0.9944\n",
      "ValLoss: 1.0523 MAE: 0.8181 RMSE: 1.0258\n",
      "Epoch 33: TrainLoss 0.8834 RecLoss: 0.0000 (left: 0:06:10)\n",
      "TestLoss: 0.9890 MAE: 0.7823 RMSE: 0.9945\n",
      "ValLoss: 1.0540 MAE: 0.8182 RMSE: 1.0266\n",
      "Epoch 34: TrainLoss 0.8828 RecLoss: 0.0000 (left: 0:06:04)\n",
      "TestLoss: 0.9974 MAE: 0.7762 RMSE: 0.9987\n",
      "ValLoss: 1.0656 MAE: 0.8160 RMSE: 1.0323\n",
      "Epoch 35: TrainLoss 0.8856 RecLoss: 0.0000 (left: 0:05:59)\n",
      "TestLoss: 0.9972 MAE: 0.7968 RMSE: 0.9986\n",
      "ValLoss: 1.0543 MAE: 0.8260 RMSE: 1.0268\n",
      "Epoch 36: TrainLoss 0.8842 RecLoss: 0.0000 (left: 0:05:52)\n",
      "TestLoss: 0.9894 MAE: 0.7845 RMSE: 0.9947\n",
      "ValLoss: 1.0522 MAE: 0.8189 RMSE: 1.0258\n",
      "Epoch 37: TrainLoss 0.8828 RecLoss: 0.0000 (left: 0:05:47)\n",
      "TestLoss: 0.9902 MAE: 0.7875 RMSE: 0.9951\n",
      "ValLoss: 1.0520 MAE: 0.8212 RMSE: 1.0257\n",
      "Epoch 38: TrainLoss 0.8840 RecLoss: 0.0000 (left: 0:05:42)\n",
      "TestLoss: 0.9924 MAE: 0.7900 RMSE: 0.9962\n",
      "ValLoss: 1.0539 MAE: 0.8230 RMSE: 1.0266\n",
      "Epoch 39: TrainLoss 0.8845 RecLoss: 0.0000 (left: 0:05:34)\n",
      "TestLoss: 0.9941 MAE: 0.7777 RMSE: 0.9970\n",
      "ValLoss: 1.0632 MAE: 0.8162 RMSE: 1.0311\n",
      "Epoch 40: TrainLoss 0.8854 RecLoss: 0.0000 (left: 0:05:27)\n",
      "TestLoss: 0.9975 MAE: 0.7773 RMSE: 0.9987\n",
      "ValLoss: 1.0693 MAE: 0.8175 RMSE: 1.0341\n",
      "Epoch 41: TrainLoss 0.8844 RecLoss: 0.0000 (left: 0:05:22)\n",
      "TestLoss: 0.9903 MAE: 0.7852 RMSE: 0.9951\n",
      "ValLoss: 1.0535 MAE: 0.8194 RMSE: 1.0264\n",
      "Epoch 42: TrainLoss 0.8848 RecLoss: 0.0000 (left: 0:05:17)\n",
      "TestLoss: 0.9933 MAE: 0.7909 RMSE: 0.9966\n",
      "ValLoss: 1.0542 MAE: 0.8233 RMSE: 1.0268\n",
      "Epoch 43: TrainLoss 0.8842 RecLoss: 0.0000 (left: 0:05:12)\n",
      "TestLoss: 0.9899 MAE: 0.7819 RMSE: 0.9950\n",
      "ValLoss: 1.0555 MAE: 0.8178 RMSE: 1.0274\n",
      "Epoch 44: TrainLoss 0.8818 RecLoss: 0.0000 (left: 0:05:06)\n",
      "TestLoss: 0.9901 MAE: 0.7838 RMSE: 0.9950\n",
      "ValLoss: 1.0561 MAE: 0.8198 RMSE: 1.0277\n",
      "Epoch 45: TrainLoss 0.8818 RecLoss: 0.0000 (left: 0:04:59)\n",
      "TestLoss: 0.9914 MAE: 0.7851 RMSE: 0.9957\n",
      "ValLoss: 1.0544 MAE: 0.8194 RMSE: 1.0269\n",
      "Epoch 46: TrainLoss 0.8813 RecLoss: 0.0000 (left: 0:04:53)\n",
      "TestLoss: 0.9905 MAE: 0.7828 RMSE: 0.9952\n",
      "ValLoss: 1.0551 MAE: 0.8181 RMSE: 1.0272\n",
      "Epoch 47: TrainLoss 0.8826 RecLoss: 0.0000 (left: 0:04:47)\n",
      "TestLoss: 0.9903 MAE: 0.7803 RMSE: 0.9951\n",
      "ValLoss: 1.0578 MAE: 0.8173 RMSE: 1.0285\n",
      "Epoch 48: TrainLoss 0.8836 RecLoss: 0.0000 (left: 0:04:41)\n",
      "TestLoss: 0.9932 MAE: 0.7798 RMSE: 0.9966\n",
      "ValLoss: 1.0613 MAE: 0.8177 RMSE: 1.0302\n",
      "Epoch 49: TrainLoss 0.8833 RecLoss: 0.0000 (left: 0:04:34)\n",
      "TestLoss: 0.9927 MAE: 0.7801 RMSE: 0.9963\n",
      "ValLoss: 1.0601 MAE: 0.8177 RMSE: 1.0296\n",
      "Epoch 50: TrainLoss 0.8839 RecLoss: 0.0000 (left: 0:04:28)\n",
      "TestLoss: 0.9934 MAE: 0.7806 RMSE: 0.9967\n",
      "ValLoss: 1.0602 MAE: 0.8173 RMSE: 1.0296\n",
      "Epoch 51: TrainLoss 0.8829 RecLoss: 0.0000 (left: 0:04:21)\n",
      "TestLoss: 0.9912 MAE: 0.7858 RMSE: 0.9956\n",
      "ValLoss: 1.0560 MAE: 0.8207 RMSE: 1.0276\n",
      "Epoch 52: TrainLoss 0.8819 RecLoss: 0.0000 (left: 0:04:16)\n",
      "TestLoss: 0.9920 MAE: 0.7878 RMSE: 0.9960\n",
      "ValLoss: 1.0556 MAE: 0.8216 RMSE: 1.0274\n",
      "Epoch 53: TrainLoss 0.8841 RecLoss: 0.0000 (left: 0:04:10)\n",
      "TestLoss: 0.9913 MAE: 0.7876 RMSE: 0.9956\n",
      "ValLoss: 1.0541 MAE: 0.8210 RMSE: 1.0267\n",
      "Epoch 54: TrainLoss 0.8829 RecLoss: 0.0000 (left: 0:04:05)\n",
      "TestLoss: 0.9914 MAE: 0.7819 RMSE: 0.9957\n",
      "ValLoss: 1.0571 MAE: 0.8178 RMSE: 1.0282\n",
      "Epoch 55: TrainLoss 0.8828 RecLoss: 0.0000 (left: 0:03:58)\n",
      "TestLoss: 0.9918 MAE: 0.7865 RMSE: 0.9959\n",
      "ValLoss: 1.0549 MAE: 0.8210 RMSE: 1.0271\n",
      "Epoch 56: TrainLoss 0.8821 RecLoss: 0.0000 (left: 0:03:52)\n",
      "TestLoss: 0.9902 MAE: 0.7852 RMSE: 0.9951\n",
      "ValLoss: 1.0555 MAE: 0.8202 RMSE: 1.0274\n",
      "Epoch 57: TrainLoss 0.8832 RecLoss: 0.0000 (left: 0:03:45)\n",
      "TestLoss: 0.9950 MAE: 0.7782 RMSE: 0.9975\n",
      "ValLoss: 1.0635 MAE: 0.8169 RMSE: 1.0313\n",
      "Epoch 58: TrainLoss 0.8817 RecLoss: 0.0000 (left: 0:03:39)\n",
      "TestLoss: 0.9909 MAE: 0.7841 RMSE: 0.9954\n",
      "ValLoss: 1.0560 MAE: 0.8194 RMSE: 1.0276\n",
      "Epoch 59: TrainLoss 0.8812 RecLoss: 0.0000 (left: 0:03:33)\n",
      "TestLoss: 0.9902 MAE: 0.7847 RMSE: 0.9951\n",
      "ValLoss: 1.0548 MAE: 0.8193 RMSE: 1.0270\n",
      "Epoch 60: TrainLoss 0.8812 RecLoss: 0.0000 (left: 0:03:28)\n",
      "TestLoss: 0.9908 MAE: 0.7811 RMSE: 0.9954\n",
      "ValLoss: 1.0574 MAE: 0.8172 RMSE: 1.0283\n",
      "Epoch 61: TrainLoss 0.8822 RecLoss: 0.0000 (left: 0:03:22)\n",
      "TestLoss: 0.9906 MAE: 0.7862 RMSE: 0.9953\n",
      "ValLoss: 1.0547 MAE: 0.8210 RMSE: 1.0270\n",
      "Epoch 62: TrainLoss 0.8820 RecLoss: 0.0000 (left: 0:03:16)\n",
      "TestLoss: 0.9954 MAE: 0.7928 RMSE: 0.9977\n",
      "ValLoss: 1.0554 MAE: 0.8246 RMSE: 1.0273\n",
      "Epoch 63: TrainLoss 0.8848 RecLoss: 0.0000 (left: 0:03:11)\n",
      "TestLoss: 0.9966 MAE: 0.7933 RMSE: 0.9983\n",
      "ValLoss: 1.0563 MAE: 0.8249 RMSE: 1.0277\n",
      "Epoch 64: TrainLoss 0.8832 RecLoss: 0.0000 (left: 0:03:06)\n",
      "TestLoss: 0.9905 MAE: 0.7830 RMSE: 0.9953\n",
      "ValLoss: 1.0593 MAE: 0.8199 RMSE: 1.0292\n",
      "Epoch 65: TrainLoss 0.8816 RecLoss: 0.0000 (left: 0:03:00)\n",
      "TestLoss: 0.9914 MAE: 0.7807 RMSE: 0.9957\n",
      "ValLoss: 1.0595 MAE: 0.8177 RMSE: 1.0293\n",
      "Epoch 66: TrainLoss 0.8812 RecLoss: 0.0000 (left: 0:02:55)\n",
      "TestLoss: 0.9897 MAE: 0.7824 RMSE: 0.9948\n",
      "ValLoss: 1.0549 MAE: 0.8181 RMSE: 1.0271\n",
      "Epoch 67: TrainLoss 0.8812 RecLoss: 0.0000 (left: 0:02:50)\n",
      "TestLoss: 0.9922 MAE: 0.7813 RMSE: 0.9961\n",
      "ValLoss: 1.0594 MAE: 0.8180 RMSE: 1.0293\n",
      "Epoch 68: TrainLoss 0.8826 RecLoss: 0.0000 (left: 0:02:45)\n",
      "TestLoss: 0.9910 MAE: 0.7803 RMSE: 0.9955\n",
      "ValLoss: 1.0576 MAE: 0.8169 RMSE: 1.0284\n",
      "Epoch 69: TrainLoss 0.8860 RecLoss: 0.0000 (left: 0:02:40)\n",
      "TestLoss: 0.9965 MAE: 0.7779 RMSE: 0.9983\n",
      "ValLoss: 1.0669 MAE: 0.8174 RMSE: 1.0329\n",
      "Epoch 70: TrainLoss 0.8877 RecLoss: 0.0000 (left: 0:02:35)\n",
      "TestLoss: 1.0099 MAE: 0.7760 RMSE: 1.0049\n",
      "ValLoss: 1.0843 MAE: 0.8181 RMSE: 1.0413\n",
      "Epoch 71: TrainLoss 0.8850 RecLoss: 0.0000 (left: 0:02:30)\n",
      "TestLoss: 0.9913 MAE: 0.7821 RMSE: 0.9957\n",
      "ValLoss: 1.0586 MAE: 0.8188 RMSE: 1.0289\n",
      "Epoch 72: TrainLoss 0.8821 RecLoss: 0.0000 (left: 0:02:24)\n",
      "TestLoss: 0.9935 MAE: 0.7794 RMSE: 0.9968\n",
      "ValLoss: 1.0635 MAE: 0.8178 RMSE: 1.0313\n",
      "Epoch 73: TrainLoss 0.8818 RecLoss: 0.0000 (left: 0:02:19)\n",
      "TestLoss: 0.9903 MAE: 0.7842 RMSE: 0.9951\n",
      "ValLoss: 1.0560 MAE: 0.8197 RMSE: 1.0276\n",
      "Epoch 74: TrainLoss 0.8823 RecLoss: 0.0000 (left: 0:02:14)\n",
      "TestLoss: 0.9900 MAE: 0.7832 RMSE: 0.9950\n",
      "ValLoss: 1.0572 MAE: 0.8192 RMSE: 1.0282\n",
      "Epoch 75: TrainLoss 0.8813 RecLoss: 0.0000 (left: 0:02:09)\n",
      "TestLoss: 0.9987 MAE: 0.7775 RMSE: 0.9994\n",
      "ValLoss: 1.0696 MAE: 0.8172 RMSE: 1.0342\n",
      "Epoch 76: TrainLoss 0.8837 RecLoss: 0.0000 (left: 0:02:03)\n",
      "TestLoss: 0.9926 MAE: 0.7804 RMSE: 0.9963\n",
      "ValLoss: 1.0610 MAE: 0.8180 RMSE: 1.0300\n",
      "Epoch 77: TrainLoss 0.8824 RecLoss: 0.0000 (left: 0:01:58)\n",
      "TestLoss: 0.9925 MAE: 0.7810 RMSE: 0.9962\n",
      "ValLoss: 1.0602 MAE: 0.8179 RMSE: 1.0297\n",
      "Epoch 78: TrainLoss 0.8825 RecLoss: 0.0000 (left: 0:01:53)\n",
      "TestLoss: 0.9966 MAE: 0.7778 RMSE: 0.9983\n",
      "ValLoss: 1.0684 MAE: 0.8178 RMSE: 1.0336\n",
      "Epoch 79: TrainLoss 0.8820 RecLoss: 0.0000 (left: 0:01:48)\n",
      "TestLoss: 0.9914 MAE: 0.7868 RMSE: 0.9957\n",
      "ValLoss: 1.0554 MAE: 0.8209 RMSE: 1.0273\n",
      "Epoch 80: TrainLoss 0.8821 RecLoss: 0.0000 (left: 0:01:43)\n",
      "TestLoss: 0.9920 MAE: 0.7882 RMSE: 0.9960\n",
      "ValLoss: 1.0551 MAE: 0.8216 RMSE: 1.0272\n",
      "Epoch 81: TrainLoss 0.8808 RecLoss: 0.0000 (left: 0:01:38)\n",
      "TestLoss: 0.9895 MAE: 0.7846 RMSE: 0.9948\n",
      "ValLoss: 1.0557 MAE: 0.8199 RMSE: 1.0275\n",
      "Epoch 82: TrainLoss 0.8844 RecLoss: 0.0000 (left: 0:01:32)\n",
      "TestLoss: 0.9968 MAE: 0.7775 RMSE: 0.9984\n",
      "ValLoss: 1.0681 MAE: 0.8175 RMSE: 1.0335\n",
      "Epoch 83: TrainLoss 0.8878 RecLoss: 0.0000 (left: 0:01:27)\n",
      "TestLoss: 0.9933 MAE: 0.7803 RMSE: 0.9966\n",
      "ValLoss: 1.0618 MAE: 0.8178 RMSE: 1.0304\n",
      "Epoch 84: TrainLoss 0.8805 RecLoss: 0.0000 (left: 0:01:22)\n",
      "TestLoss: 0.9919 MAE: 0.7864 RMSE: 0.9959\n",
      "ValLoss: 1.0570 MAE: 0.8212 RMSE: 1.0281\n",
      "Epoch 85: TrainLoss 0.8824 RecLoss: 0.0000 (left: 0:01:17)\n",
      "TestLoss: 0.9917 MAE: 0.7823 RMSE: 0.9959\n",
      "ValLoss: 1.0587 MAE: 0.8188 RMSE: 1.0289\n",
      "Epoch 86: TrainLoss 0.8826 RecLoss: 0.0000 (left: 0:01:11)\n",
      "TestLoss: 0.9945 MAE: 0.7793 RMSE: 0.9972\n",
      "ValLoss: 1.0640 MAE: 0.8176 RMSE: 1.0315\n",
      "Epoch 87: TrainLoss 0.8824 RecLoss: 0.0000 (left: 0:01:06)\n",
      "TestLoss: 0.9914 MAE: 0.7826 RMSE: 0.9957\n",
      "ValLoss: 1.0584 MAE: 0.8190 RMSE: 1.0288\n",
      "Epoch 88: TrainLoss 0.8842 RecLoss: 0.0000 (left: 0:01:01)\n",
      "TestLoss: 0.9939 MAE: 0.7801 RMSE: 0.9969\n",
      "ValLoss: 1.0630 MAE: 0.8180 RMSE: 1.0310\n",
      "Epoch 89: TrainLoss 0.8828 RecLoss: 0.0000 (left: 0:00:56)\n",
      "TestLoss: 0.9909 MAE: 0.7812 RMSE: 0.9954\n",
      "ValLoss: 1.0592 MAE: 0.8179 RMSE: 1.0292\n",
      "Epoch 90: TrainLoss 0.8814 RecLoss: 0.0000 (left: 0:00:51)\n",
      "TestLoss: 0.9913 MAE: 0.7871 RMSE: 0.9957\n",
      "ValLoss: 1.0563 MAE: 0.8214 RMSE: 1.0278\n",
      "Epoch 91: TrainLoss 0.8831 RecLoss: 0.0000 (left: 0:00:46)\n",
      "TestLoss: 0.9903 MAE: 0.7833 RMSE: 0.9952\n",
      "ValLoss: 1.0571 MAE: 0.8192 RMSE: 1.0282\n",
      "Epoch 92: TrainLoss 0.8810 RecLoss: 0.0000 (left: 0:00:40)\n",
      "TestLoss: 0.9905 MAE: 0.7840 RMSE: 0.9952\n",
      "ValLoss: 1.0564 MAE: 0.8196 RMSE: 1.0278\n",
      "Epoch 93: TrainLoss 0.8810 RecLoss: 0.0000 (left: 0:00:35)\n",
      "TestLoss: 0.9933 MAE: 0.7902 RMSE: 0.9967\n",
      "ValLoss: 1.0560 MAE: 0.8232 RMSE: 1.0276\n",
      "Epoch 94: TrainLoss 0.8848 RecLoss: 0.0000 (left: 0:00:30)\n",
      "TestLoss: 0.9913 MAE: 0.7822 RMSE: 0.9956\n",
      "ValLoss: 1.0581 MAE: 0.8182 RMSE: 1.0286\n",
      "Epoch 95: TrainLoss 0.8837 RecLoss: 0.0000 (left: 0:00:25)\n",
      "TestLoss: 0.9919 MAE: 0.7815 RMSE: 0.9960\n",
      "ValLoss: 1.0597 MAE: 0.8187 RMSE: 1.0294\n",
      "Epoch 96: TrainLoss 0.8819 RecLoss: 0.0000 (left: 0:00:20)\n",
      "TestLoss: 0.9978 MAE: 0.7775 RMSE: 0.9989\n",
      "ValLoss: 1.0676 MAE: 0.8165 RMSE: 1.0333\n",
      "Epoch 97: TrainLoss 0.8824 RecLoss: 0.0000 (left: 0:00:15)\n",
      "TestLoss: 0.9909 MAE: 0.7836 RMSE: 0.9954\n",
      "ValLoss: 1.0572 MAE: 0.8194 RMSE: 1.0282\n",
      "Epoch 98: TrainLoss 0.8805 RecLoss: 0.0000 (left: 0:00:10)\n",
      "TestLoss: 0.9905 MAE: 0.7855 RMSE: 0.9952\n",
      "ValLoss: 1.0555 MAE: 0.8201 RMSE: 1.0274\n",
      "Epoch 99: TrainLoss 0.8805 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 0.9916 MAE: 0.7880 RMSE: 0.9958\n",
      "ValLoss: 1.0558 MAE: 0.8220 RMSE: 1.0275\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 601508/19100\n",
      "test set size: support/query 2092/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.6893 RMSE: 0.8690 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7844 RMSE: 0.9906 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7158 RMSE: 0.9046 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10% optimal cur to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 321973/19100\n",
      "test set size: support/query 523/809\n",
      "Epoch 0 Step 299: Train 2.4073 Reg: 0.5220\n",
      "Test: 0.7121 MAE: 0.6744 RMSE: 0.8439\n",
      "Val: 0.8141 MAE: 0.7106 RMSE: 0.9023\n",
      "Epoch 1 Step 598: Train 0.7942 Reg: 0.4424\n",
      "Test: 0.6925 MAE: 0.6669 RMSE: 0.8322\n",
      "Val: 0.8084 MAE: 0.7104 RMSE: 0.8991\n",
      "Epoch 2 Step 897: Train 0.7902 Reg: 0.3834\n",
      "Test: 0.6863 MAE: 0.6577 RMSE: 0.8284\n",
      "Val: 0.8066 MAE: 0.7080 RMSE: 0.8981\n",
      "Epoch 3 Step 1196: Train 0.7875 Reg: 0.3426\n",
      "Test: 0.6751 MAE: 0.6581 RMSE: 0.8216\n",
      "Val: 0.8069 MAE: 0.7094 RMSE: 0.8983\n",
      "Epoch 4 Step 1495: Train 0.7847 Reg: 0.3154\n",
      "Test: 0.6914 MAE: 0.6637 RMSE: 0.8315\n",
      "Val: 0.8040 MAE: 0.7060 RMSE: 0.8966\n",
      "Epoch 5 Step 1794: Train 0.7814 Reg: 0.2948\n",
      "Test: 0.6873 MAE: 0.6575 RMSE: 0.8290\n",
      "Val: 0.8003 MAE: 0.7055 RMSE: 0.8946\n",
      "Epoch 6 Step 2093: Train 0.7780 Reg: 0.2793\n",
      "Test: 0.6755 MAE: 0.6528 RMSE: 0.8219\n",
      "Val: 0.7938 MAE: 0.7017 RMSE: 0.8910\n",
      "Epoch 7 Step 2392: Train 0.7721 Reg: 0.2688\n",
      "Test: 0.6968 MAE: 0.6628 RMSE: 0.8347\n",
      "Val: 0.7909 MAE: 0.7011 RMSE: 0.8893\n",
      "Epoch 8 Step 2691: Train 0.7664 Reg: 0.2613\n",
      "Test: 0.6771 MAE: 0.6503 RMSE: 0.8229\n",
      "Val: 0.7833 MAE: 0.6947 RMSE: 0.8851\n",
      "Epoch 9 Step 2990: Train 0.7585 Reg: 0.2577\n",
      "Test: 0.6610 MAE: 0.6424 RMSE: 0.8130\n",
      "Val: 0.7769 MAE: 0.6908 RMSE: 0.8814\n",
      "Epoch 10 Step 3289: Train 0.7510 Reg: 0.2554\n",
      "Test: 0.6705 MAE: 0.6497 RMSE: 0.8188\n",
      "Val: 0.7691 MAE: 0.6877 RMSE: 0.8770\n",
      "Epoch 11 Step 3588: Train 0.7429 Reg: 0.2525\n",
      "Test: 0.6681 MAE: 0.6472 RMSE: 0.8174\n",
      "Val: 0.7650 MAE: 0.6832 RMSE: 0.8746\n",
      "Epoch 12 Step 3887: Train 0.7318 Reg: 0.2522\n",
      "Test: 0.6676 MAE: 0.6548 RMSE: 0.8170\n",
      "Val: 0.7515 MAE: 0.6798 RMSE: 0.8669\n",
      "Epoch 13 Step 4186: Train 0.7207 Reg: 0.2538\n",
      "Test: 0.6614 MAE: 0.6470 RMSE: 0.8133\n",
      "Val: 0.7468 MAE: 0.6736 RMSE: 0.8642\n",
      "Epoch 14 Step 4485: Train 0.7100 Reg: 0.2569\n",
      "Test: 0.6853 MAE: 0.6587 RMSE: 0.8278\n",
      "Val: 0.7411 MAE: 0.6734 RMSE: 0.8609\n",
      "Epoch 15 Step 4784: Train 0.6993 Reg: 0.2613\n",
      "Test: 0.6659 MAE: 0.6504 RMSE: 0.8160\n",
      "Val: 0.7377 MAE: 0.6686 RMSE: 0.8589\n",
      "Epoch 16 Step 5083: Train 0.6854 Reg: 0.2696\n",
      "Test: 0.6668 MAE: 0.6573 RMSE: 0.8166\n",
      "Val: 0.7306 MAE: 0.6680 RMSE: 0.8547\n",
      "Epoch 17 Step 5382: Train 0.6699 Reg: 0.2811\n",
      "Test: 0.6503 MAE: 0.6454 RMSE: 0.8064\n",
      "Val: 0.7289 MAE: 0.6655 RMSE: 0.8538\n",
      "Epoch 18 Step 5681: Train 0.6532 Reg: 0.2945\n",
      "Test: 0.6618 MAE: 0.6533 RMSE: 0.8135\n",
      "Val: 0.7277 MAE: 0.6655 RMSE: 0.8531\n",
      "Epoch 19 Step 5980: Train 0.6341 Reg: 0.3091\n",
      "Test: 0.6620 MAE: 0.6449 RMSE: 0.8136\n",
      "Val: 0.7275 MAE: 0.6639 RMSE: 0.8529\n",
      "Epoch 20 Step 6279: Train 0.6128 Reg: 0.3234\n",
      "Test: 0.6667 MAE: 0.6508 RMSE: 0.8165\n",
      "Val: 0.7271 MAE: 0.6637 RMSE: 0.8527\n",
      "Epoch 21 Step 6578: Train 0.5928 Reg: 0.3356\n",
      "Test: 0.6729 MAE: 0.6485 RMSE: 0.8203\n",
      "Val: 0.7310 MAE: 0.6634 RMSE: 0.8550\n",
      "Epoch 22 Step 6877: Train 0.5742 Reg: 0.3469\n",
      "Test: 0.6821 MAE: 0.6552 RMSE: 0.8259\n",
      "Val: 0.7333 MAE: 0.6666 RMSE: 0.8563\n",
      "Epoch 23 Step 7176: Train 0.5537 Reg: 0.3601\n",
      "Test: 0.6791 MAE: 0.6502 RMSE: 0.8241\n",
      "Val: 0.7390 MAE: 0.6671 RMSE: 0.8597\n",
      "Epoch 24 Step 7475: Train 0.5319 Reg: 0.3745\n",
      "Test: 0.6790 MAE: 0.6471 RMSE: 0.8240\n",
      "Val: 0.7482 MAE: 0.6692 RMSE: 0.8650\n",
      "Epoch 25 Step 7774: Train 0.5104 Reg: 0.3880\n",
      "Test: 0.6892 MAE: 0.6540 RMSE: 0.8302\n",
      "Val: 0.7564 MAE: 0.6724 RMSE: 0.8697\n",
      "Epoch 26 Step 8073: Train 0.4899 Reg: 0.3999\n",
      "Test: 0.7077 MAE: 0.6653 RMSE: 0.8413\n",
      "Val: 0.7674 MAE: 0.6780 RMSE: 0.8760\n",
      "Epoch 27 Step 8372: Train 0.4718 Reg: 0.4090\n",
      "Test: 0.7224 MAE: 0.6703 RMSE: 0.8500\n",
      "Val: 0.7798 MAE: 0.6838 RMSE: 0.8831\n",
      "Epoch 28 Step 8671: Train 0.4571 Reg: 0.4151\n",
      "Test: 0.7247 MAE: 0.6695 RMSE: 0.8513\n",
      "Val: 0.7909 MAE: 0.6866 RMSE: 0.8893\n",
      "Epoch 29 Step 8970: Train 0.4446 Reg: 0.4196\n",
      "Test: 0.7298 MAE: 0.6683 RMSE: 0.8543\n",
      "Val: 0.8015 MAE: 0.6907 RMSE: 0.8952\n",
      "Epoch 30 Step 9269: Train 0.4341 Reg: 0.4227\n",
      "Test: 0.7476 MAE: 0.6785 RMSE: 0.8646\n",
      "Val: 0.8116 MAE: 0.6955 RMSE: 0.9009\n",
      "Epoch 31 Step 9568: Train 0.4248 Reg: 0.4245\n",
      "Test: 0.7551 MAE: 0.6821 RMSE: 0.8690\n",
      "Val: 0.8208 MAE: 0.6993 RMSE: 0.9060\n",
      "Epoch 32 Step 9867: Train 0.4164 Reg: 0.4257\n",
      "Test: 0.7533 MAE: 0.6786 RMSE: 0.8679\n",
      "Val: 0.8286 MAE: 0.7011 RMSE: 0.9103\n",
      "Epoch 33 Step 10166: Train 0.4098 Reg: 0.4256\n",
      "Test: 0.7623 MAE: 0.6850 RMSE: 0.8731\n",
      "Val: 0.8368 MAE: 0.7048 RMSE: 0.9148\n",
      "Epoch 34 Step 10465: Train 0.4041 Reg: 0.4251\n",
      "Test: 0.7698 MAE: 0.6860 RMSE: 0.8774\n",
      "Val: 0.8452 MAE: 0.7077 RMSE: 0.9194\n",
      "Epoch 35 Step 10764: Train 0.3996 Reg: 0.4239\n",
      "Test: 0.7843 MAE: 0.6929 RMSE: 0.8856\n",
      "Val: 0.8515 MAE: 0.7107 RMSE: 0.9228\n",
      "Epoch 36 Step 11063: Train 0.3955 Reg: 0.4224\n",
      "Test: 0.7837 MAE: 0.6908 RMSE: 0.8853\n",
      "Val: 0.8592 MAE: 0.7129 RMSE: 0.9269\n",
      "Epoch 37 Step 11362: Train 0.3919 Reg: 0.4208\n",
      "Test: 0.7863 MAE: 0.6923 RMSE: 0.8867\n",
      "Val: 0.8649 MAE: 0.7148 RMSE: 0.9300\n",
      "Epoch 38 Step 11661: Train 0.3887 Reg: 0.4191\n",
      "Test: 0.7952 MAE: 0.6971 RMSE: 0.8917\n",
      "Val: 0.8699 MAE: 0.7174 RMSE: 0.9327\n",
      "Epoch 39 Step 11960: Train 0.3856 Reg: 0.4174\n",
      "Test: 0.8053 MAE: 0.7013 RMSE: 0.8974\n",
      "Val: 0.8751 MAE: 0.7187 RMSE: 0.9355\n",
      "Epoch 40 Step 12259: Train 0.3828 Reg: 0.4155\n",
      "Test: 0.8126 MAE: 0.7058 RMSE: 0.9014\n",
      "Val: 0.8806 MAE: 0.7210 RMSE: 0.9384\n",
      "Epoch 41 Step 12558: Train 0.3802 Reg: 0.4138\n",
      "Test: 0.8128 MAE: 0.7032 RMSE: 0.9016\n",
      "Val: 0.8849 MAE: 0.7221 RMSE: 0.9407\n",
      "Epoch 42 Step 12857: Train 0.3777 Reg: 0.4121\n",
      "Test: 0.8171 MAE: 0.7045 RMSE: 0.9040\n",
      "Val: 0.8901 MAE: 0.7236 RMSE: 0.9435\n",
      "Epoch 43 Step 13156: Train 0.3756 Reg: 0.4103\n",
      "Test: 0.8213 MAE: 0.7076 RMSE: 0.9063\n",
      "Val: 0.8937 MAE: 0.7253 RMSE: 0.9454\n",
      "Epoch 44 Step 13455: Train 0.3733 Reg: 0.4086\n",
      "Test: 0.8319 MAE: 0.7131 RMSE: 0.9121\n",
      "Val: 0.8991 MAE: 0.7275 RMSE: 0.9482\n",
      "Epoch 45 Step 13754: Train 0.3712 Reg: 0.4069\n",
      "Test: 0.8313 MAE: 0.7109 RMSE: 0.9117\n",
      "Val: 0.9030 MAE: 0.7284 RMSE: 0.9503\n",
      "Epoch 46 Step 14053: Train 0.3692 Reg: 0.4054\n",
      "Test: 0.8372 MAE: 0.7123 RMSE: 0.9150\n",
      "Val: 0.9064 MAE: 0.7293 RMSE: 0.9521\n",
      "Epoch 47 Step 14352: Train 0.3673 Reg: 0.4038\n",
      "Test: 0.8391 MAE: 0.7130 RMSE: 0.9160\n",
      "Val: 0.9085 MAE: 0.7304 RMSE: 0.9531\n",
      "Epoch 48 Step 14651: Train 0.3654 Reg: 0.4024\n",
      "Test: 0.8419 MAE: 0.7143 RMSE: 0.9176\n",
      "Val: 0.9130 MAE: 0.7318 RMSE: 0.9555\n",
      "Epoch 49 Step 14950: Train 0.3635 Reg: 0.4010\n",
      "Test: 0.8415 MAE: 0.7132 RMSE: 0.9173\n",
      "Val: 0.9168 MAE: 0.7325 RMSE: 0.9575\n",
      "Epoch 50 Step 15249: Train 0.3618 Reg: 0.3997\n",
      "Test: 0.8449 MAE: 0.7153 RMSE: 0.9192\n",
      "Val: 0.9199 MAE: 0.7336 RMSE: 0.9591\n",
      "Epoch 51 Step 15548: Train 0.3599 Reg: 0.3984\n",
      "Test: 0.8462 MAE: 0.7148 RMSE: 0.9199\n",
      "Val: 0.9235 MAE: 0.7346 RMSE: 0.9610\n",
      "Epoch 52 Step 15847: Train 0.3584 Reg: 0.3972\n",
      "Test: 0.8508 MAE: 0.7174 RMSE: 0.9224\n",
      "Val: 0.9259 MAE: 0.7357 RMSE: 0.9623\n",
      "Epoch 53 Step 16146: Train 0.3566 Reg: 0.3961\n",
      "Test: 0.8578 MAE: 0.7206 RMSE: 0.9262\n",
      "Val: 0.9287 MAE: 0.7370 RMSE: 0.9637\n",
      "Epoch 54 Step 16445: Train 0.3551 Reg: 0.3950\n",
      "Test: 0.8629 MAE: 0.7221 RMSE: 0.9289\n",
      "Val: 0.9316 MAE: 0.7380 RMSE: 0.9652\n",
      "Epoch 55 Step 16744: Train 0.3537 Reg: 0.3938\n",
      "Test: 0.8701 MAE: 0.7264 RMSE: 0.9328\n",
      "Val: 0.9359 MAE: 0.7402 RMSE: 0.9674\n",
      "Epoch 56 Step 17043: Train 0.3524 Reg: 0.3928\n",
      "Test: 0.8693 MAE: 0.7249 RMSE: 0.9324\n",
      "Val: 0.9372 MAE: 0.7402 RMSE: 0.9681\n",
      "Epoch 57 Step 17342: Train 0.3510 Reg: 0.3918\n",
      "Test: 0.8702 MAE: 0.7248 RMSE: 0.9329\n",
      "Val: 0.9398 MAE: 0.7407 RMSE: 0.9694\n",
      "Epoch 58 Step 17641: Train 0.3499 Reg: 0.3907\n",
      "Test: 0.8684 MAE: 0.7230 RMSE: 0.9319\n",
      "Val: 0.9423 MAE: 0.7410 RMSE: 0.9707\n",
      "Epoch 59 Step 17940: Train 0.3488 Reg: 0.3897\n",
      "Test: 0.8729 MAE: 0.7251 RMSE: 0.9343\n",
      "Val: 0.9438 MAE: 0.7417 RMSE: 0.9715\n",
      "Epoch 60 Step 18239: Train 0.3478 Reg: 0.3887\n",
      "Test: 0.8746 MAE: 0.7258 RMSE: 0.9352\n",
      "Val: 0.9454 MAE: 0.7425 RMSE: 0.9723\n",
      "Epoch 61 Step 18538: Train 0.3468 Reg: 0.3878\n",
      "Test: 0.8720 MAE: 0.7241 RMSE: 0.9338\n",
      "Val: 0.9478 MAE: 0.7427 RMSE: 0.9736\n",
      "Epoch 62 Step 18837: Train 0.3459 Reg: 0.3869\n",
      "Test: 0.8783 MAE: 0.7274 RMSE: 0.9372\n",
      "Val: 0.9496 MAE: 0.7438 RMSE: 0.9745\n",
      "Epoch 63 Step 19136: Train 0.3451 Reg: 0.3860\n",
      "Test: 0.8814 MAE: 0.7285 RMSE: 0.9388\n",
      "Val: 0.9517 MAE: 0.7448 RMSE: 0.9755\n",
      "Epoch 64 Step 19435: Train 0.3443 Reg: 0.3851\n",
      "Test: 0.8802 MAE: 0.7275 RMSE: 0.9382\n",
      "Val: 0.9533 MAE: 0.7450 RMSE: 0.9764\n",
      "Epoch 65 Step 19734: Train 0.3435 Reg: 0.3843\n",
      "Test: 0.8827 MAE: 0.7285 RMSE: 0.9395\n",
      "Val: 0.9549 MAE: 0.7455 RMSE: 0.9772\n",
      "Epoch 66 Step 20033: Train 0.3428 Reg: 0.3835\n",
      "Test: 0.8842 MAE: 0.7287 RMSE: 0.9403\n",
      "Val: 0.9565 MAE: 0.7460 RMSE: 0.9780\n",
      "Epoch 67 Step 20332: Train 0.3422 Reg: 0.3827\n",
      "Test: 0.8878 MAE: 0.7298 RMSE: 0.9422\n",
      "Val: 0.9578 MAE: 0.7466 RMSE: 0.9787\n",
      "Epoch 68 Step 20631: Train 0.3415 Reg: 0.3820\n",
      "Test: 0.8873 MAE: 0.7298 RMSE: 0.9420\n",
      "Val: 0.9595 MAE: 0.7471 RMSE: 0.9796\n",
      "Epoch 69 Step 20930: Train 0.3409 Reg: 0.3813\n",
      "Test: 0.8920 MAE: 0.7319 RMSE: 0.9444\n",
      "Val: 0.9606 MAE: 0.7476 RMSE: 0.9801\n",
      "Epoch 70 Step 21229: Train 0.3404 Reg: 0.3807\n",
      "Test: 0.8898 MAE: 0.7304 RMSE: 0.9433\n",
      "Val: 0.9619 MAE: 0.7476 RMSE: 0.9807\n",
      "Epoch 71 Step 21528: Train 0.3398 Reg: 0.3800\n",
      "Test: 0.8918 MAE: 0.7317 RMSE: 0.9444\n",
      "Val: 0.9632 MAE: 0.7483 RMSE: 0.9814\n",
      "Epoch 72 Step 21827: Train 0.3393 Reg: 0.3794\n",
      "Test: 0.8960 MAE: 0.7334 RMSE: 0.9466\n",
      "Val: 0.9642 MAE: 0.7490 RMSE: 0.9819\n",
      "Epoch 73 Step 22126: Train 0.3389 Reg: 0.3788\n",
      "Test: 0.8956 MAE: 0.7328 RMSE: 0.9464\n",
      "Val: 0.9651 MAE: 0.7490 RMSE: 0.9824\n",
      "Epoch 74 Step 22425: Train 0.3384 Reg: 0.3783\n",
      "Test: 0.8946 MAE: 0.7321 RMSE: 0.9458\n",
      "Val: 0.9663 MAE: 0.7492 RMSE: 0.9830\n",
      "Epoch 75 Step 22724: Train 0.3380 Reg: 0.3777\n",
      "Test: 0.8976 MAE: 0.7335 RMSE: 0.9474\n",
      "Val: 0.9672 MAE: 0.7498 RMSE: 0.9835\n",
      "Epoch 76 Step 23023: Train 0.3376 Reg: 0.3772\n",
      "Test: 0.8982 MAE: 0.7335 RMSE: 0.9477\n",
      "Val: 0.9678 MAE: 0.7498 RMSE: 0.9838\n",
      "Epoch 77 Step 23322: Train 0.3372 Reg: 0.3767\n",
      "Test: 0.8999 MAE: 0.7340 RMSE: 0.9486\n",
      "Val: 0.9688 MAE: 0.7502 RMSE: 0.9843\n",
      "Epoch 78 Step 23621: Train 0.3369 Reg: 0.3762\n",
      "Test: 0.9005 MAE: 0.7345 RMSE: 0.9489\n",
      "Val: 0.9696 MAE: 0.7505 RMSE: 0.9847\n",
      "Epoch 79 Step 23920: Train 0.3365 Reg: 0.3758\n",
      "Test: 0.8991 MAE: 0.7334 RMSE: 0.9482\n",
      "Val: 0.9703 MAE: 0.7505 RMSE: 0.9851\n",
      "Epoch 80 Step 24219: Train 0.3362 Reg: 0.3753\n",
      "Test: 0.9021 MAE: 0.7348 RMSE: 0.9498\n",
      "Val: 0.9710 MAE: 0.7509 RMSE: 0.9854\n",
      "Epoch 81 Step 24518: Train 0.3359 Reg: 0.3750\n",
      "Test: 0.9020 MAE: 0.7345 RMSE: 0.9497\n",
      "Val: 0.9719 MAE: 0.7511 RMSE: 0.9859\n",
      "Epoch 82 Step 24817: Train 0.3356 Reg: 0.3746\n",
      "Test: 0.9025 MAE: 0.7345 RMSE: 0.9500\n",
      "Val: 0.9725 MAE: 0.7513 RMSE: 0.9861\n",
      "Epoch 83 Step 25116: Train 0.3353 Reg: 0.3742\n",
      "Test: 0.9042 MAE: 0.7353 RMSE: 0.9509\n",
      "Val: 0.9732 MAE: 0.7515 RMSE: 0.9865\n",
      "Epoch 84 Step 25415: Train 0.3351 Reg: 0.3738\n",
      "Test: 0.9067 MAE: 0.7367 RMSE: 0.9522\n",
      "Val: 0.9741 MAE: 0.7521 RMSE: 0.9870\n",
      "Epoch 85 Step 25714: Train 0.3348 Reg: 0.3735\n",
      "Test: 0.9044 MAE: 0.7352 RMSE: 0.9510\n",
      "Val: 0.9745 MAE: 0.7518 RMSE: 0.9872\n",
      "Epoch 86 Step 26013: Train 0.3346 Reg: 0.3732\n",
      "Test: 0.9070 MAE: 0.7365 RMSE: 0.9524\n",
      "Val: 0.9750 MAE: 0.7523 RMSE: 0.9874\n",
      "Epoch 87 Step 26312: Train 0.3344 Reg: 0.3729\n",
      "Test: 0.9049 MAE: 0.7351 RMSE: 0.9513\n",
      "Val: 0.9754 MAE: 0.7520 RMSE: 0.9876\n",
      "Epoch 88 Step 26611: Train 0.3342 Reg: 0.3726\n",
      "Test: 0.9054 MAE: 0.7352 RMSE: 0.9515\n",
      "Val: 0.9758 MAE: 0.7522 RMSE: 0.9878\n",
      "Epoch 89 Step 26910: Train 0.3340 Reg: 0.3723\n",
      "Test: 0.9060 MAE: 0.7354 RMSE: 0.9518\n",
      "Val: 0.9762 MAE: 0.7523 RMSE: 0.9880\n",
      "Epoch 90 Step 27209: Train 0.3338 Reg: 0.3720\n",
      "Test: 0.9064 MAE: 0.7355 RMSE: 0.9521\n",
      "Val: 0.9768 MAE: 0.7525 RMSE: 0.9883\n",
      "Epoch 91 Step 27508: Train 0.3336 Reg: 0.3718\n",
      "Test: 0.9088 MAE: 0.7367 RMSE: 0.9533\n",
      "Val: 0.9772 MAE: 0.7528 RMSE: 0.9886\n",
      "Epoch 92 Step 27807: Train 0.3334 Reg: 0.3715\n",
      "Test: 0.9081 MAE: 0.7362 RMSE: 0.9529\n",
      "Val: 0.9776 MAE: 0.7528 RMSE: 0.9887\n",
      "Epoch 93 Step 28106: Train 0.3332 Reg: 0.3713\n",
      "Test: 0.9089 MAE: 0.7366 RMSE: 0.9534\n",
      "Val: 0.9780 MAE: 0.7529 RMSE: 0.9889\n",
      "Epoch 94 Step 28405: Train 0.3331 Reg: 0.3711\n",
      "Test: 0.9079 MAE: 0.7359 RMSE: 0.9529\n",
      "Val: 0.9782 MAE: 0.7529 RMSE: 0.9891\n",
      "Epoch 95 Step 28704: Train 0.3329 Reg: 0.3709\n",
      "Test: 0.9088 MAE: 0.7364 RMSE: 0.9533\n",
      "Val: 0.9786 MAE: 0.7530 RMSE: 0.9892\n",
      "Epoch 96 Step 29003: Train 0.3328 Reg: 0.3707\n",
      "Test: 0.9088 MAE: 0.7362 RMSE: 0.9533\n",
      "Val: 0.9789 MAE: 0.7531 RMSE: 0.9894\n",
      "Epoch 97 Step 29302: Train 0.3327 Reg: 0.3705\n",
      "Test: 0.9109 MAE: 0.7373 RMSE: 0.9544\n",
      "Val: 0.9793 MAE: 0.7534 RMSE: 0.9896\n",
      "Epoch 98 Step 29601: Train 0.3325 Reg: 0.3703\n",
      "Test: 0.9108 MAE: 0.7372 RMSE: 0.9544\n",
      "Val: 0.9796 MAE: 0.7535 RMSE: 0.9897\n",
      "Epoch 99 Step 29900: Train 0.3324 Reg: 0.3702\n",
      "Test: 0.9103 MAE: 0.7368 RMSE: 0.9541\n",
      "Val: 0.9798 MAE: 0.7535 RMSE: 0.9898\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 321973/19100\n",
      "test set size: support/query 523/809\n",
      "Epoch 0: TrainLoss 1.0571 RecLoss: 0.0000 (left: 0:33:42)\n",
      "TestLoss: 1.0762 MAE: 0.8208 RMSE: 1.0374\n",
      "ValLoss: 1.1268 MAE: 0.8486 RMSE: 1.0615\n",
      "Epoch 1: TrainLoss 1.0460 RecLoss: 0.0000 (left: 0:28:29)\n",
      "TestLoss: 1.0732 MAE: 0.8223 RMSE: 1.0360\n",
      "ValLoss: 1.1193 MAE: 0.8487 RMSE: 1.0580\n",
      "Epoch 2: TrainLoss 1.0401 RecLoss: 0.0000 (left: 0:26:41)\n",
      "TestLoss: 1.0722 MAE: 0.8240 RMSE: 1.0355\n",
      "ValLoss: 1.1151 MAE: 0.8490 RMSE: 1.0560\n",
      "Epoch 3: TrainLoss 1.0373 RecLoss: 0.0000 (left: 0:26:16)\n",
      "TestLoss: 1.0640 MAE: 0.8146 RMSE: 1.0315\n",
      "ValLoss: 1.1180 MAE: 0.8428 RMSE: 1.0574\n",
      "Epoch 4: TrainLoss 1.0337 RecLoss: 0.0000 (left: 0:26:18)\n",
      "TestLoss: 1.0657 MAE: 0.8221 RMSE: 1.0323\n",
      "ValLoss: 1.1093 MAE: 0.8473 RMSE: 1.0532\n",
      "Epoch 5: TrainLoss 1.0283 RecLoss: 0.0000 (left: 0:26:06)\n",
      "TestLoss: 1.0634 MAE: 0.8224 RMSE: 1.0312\n",
      "ValLoss: 1.1058 MAE: 0.8468 RMSE: 1.0516\n",
      "Epoch 6: TrainLoss 1.0231 RecLoss: 0.0000 (left: 0:25:48)\n",
      "TestLoss: 1.0556 MAE: 0.8123 RMSE: 1.0274\n",
      "ValLoss: 1.1066 MAE: 0.8401 RMSE: 1.0519\n",
      "Epoch 7: TrainLoss 1.0195 RecLoss: 0.0000 (left: 0:25:21)\n",
      "TestLoss: 1.0529 MAE: 0.8116 RMSE: 1.0261\n",
      "ValLoss: 1.1028 MAE: 0.8396 RMSE: 1.0501\n",
      "Epoch 8: TrainLoss 1.0166 RecLoss: 0.0000 (left: 0:25:08)\n",
      "TestLoss: 1.0528 MAE: 0.8156 RMSE: 1.0260\n",
      "ValLoss: 1.0972 MAE: 0.8412 RMSE: 1.0475\n",
      "Epoch 9: TrainLoss 1.0140 RecLoss: 0.0000 (left: 0:24:56)\n",
      "TestLoss: 1.0479 MAE: 0.8087 RMSE: 1.0237\n",
      "ValLoss: 1.0996 MAE: 0.8364 RMSE: 1.0486\n",
      "Epoch 10: TrainLoss 1.0091 RecLoss: 0.0000 (left: 0:24:32)\n",
      "TestLoss: 1.0456 MAE: 0.8105 RMSE: 1.0226\n",
      "ValLoss: 1.0928 MAE: 0.8369 RMSE: 1.0454\n",
      "Epoch 11: TrainLoss 1.0058 RecLoss: 0.0000 (left: 0:24:23)\n",
      "TestLoss: 1.0477 MAE: 0.8154 RMSE: 1.0236\n",
      "ValLoss: 1.0905 MAE: 0.8399 RMSE: 1.0443\n",
      "Epoch 12: TrainLoss 1.0026 RecLoss: 0.0000 (left: 0:23:57)\n",
      "TestLoss: 1.0419 MAE: 0.8106 RMSE: 1.0207\n",
      "ValLoss: 1.0874 MAE: 0.8360 RMSE: 1.0428\n",
      "Epoch 13: TrainLoss 0.9996 RecLoss: 0.0000 (left: 0:23:34)\n",
      "TestLoss: 1.0396 MAE: 0.8068 RMSE: 1.0196\n",
      "ValLoss: 1.0879 MAE: 0.8337 RMSE: 1.0430\n",
      "Epoch 14: TrainLoss 0.9970 RecLoss: 0.0000 (left: 0:23:01)\n",
      "TestLoss: 1.0407 MAE: 0.8129 RMSE: 1.0201\n",
      "ValLoss: 1.0832 MAE: 0.8368 RMSE: 1.0408\n",
      "Epoch 15: TrainLoss 0.9934 RecLoss: 0.0000 (left: 0:22:29)\n",
      "TestLoss: 1.0364 MAE: 0.8085 RMSE: 1.0180\n",
      "ValLoss: 1.0806 MAE: 0.8335 RMSE: 1.0395\n",
      "Epoch 16: TrainLoss 0.9911 RecLoss: 0.0000 (left: 0:22:06)\n",
      "TestLoss: 1.0363 MAE: 0.8109 RMSE: 1.0180\n",
      "ValLoss: 1.0785 MAE: 0.8349 RMSE: 1.0385\n",
      "Epoch 17: TrainLoss 0.9887 RecLoss: 0.0000 (left: 0:21:44)\n",
      "TestLoss: 1.0322 MAE: 0.8030 RMSE: 1.0160\n",
      "ValLoss: 1.0817 MAE: 0.8309 RMSE: 1.0400\n",
      "Epoch 18: TrainLoss 0.9863 RecLoss: 0.0000 (left: 0:21:32)\n",
      "TestLoss: 1.0306 MAE: 0.8042 RMSE: 1.0152\n",
      "ValLoss: 1.0773 MAE: 0.8304 RMSE: 1.0379\n",
      "Epoch 19: TrainLoss 0.9837 RecLoss: 0.0000 (left: 0:21:20)\n",
      "TestLoss: 1.0309 MAE: 0.8075 RMSE: 1.0153\n",
      "ValLoss: 1.0744 MAE: 0.8322 RMSE: 1.0365\n",
      "Epoch 20: TrainLoss 0.9814 RecLoss: 0.0000 (left: 0:21:00)\n",
      "TestLoss: 1.0276 MAE: 0.8038 RMSE: 1.0137\n",
      "ValLoss: 1.0731 MAE: 0.8293 RMSE: 1.0359\n",
      "Epoch 21: TrainLoss 0.9793 RecLoss: 0.0000 (left: 0:20:51)\n",
      "TestLoss: 1.0308 MAE: 0.8117 RMSE: 1.0153\n",
      "ValLoss: 1.0690 MAE: 0.8331 RMSE: 1.0339\n",
      "Epoch 22: TrainLoss 0.9776 RecLoss: 0.0000 (left: 0:20:22)\n",
      "TestLoss: 1.0252 MAE: 0.8037 RMSE: 1.0125\n",
      "ValLoss: 1.0692 MAE: 0.8284 RMSE: 1.0340\n",
      "Epoch 23: TrainLoss 0.9742 RecLoss: 0.0000 (left: 0:20:00)\n",
      "TestLoss: 1.0305 MAE: 0.8127 RMSE: 1.0151\n",
      "ValLoss: 1.0680 MAE: 0.8338 RMSE: 1.0334\n",
      "Epoch 24: TrainLoss 0.9749 RecLoss: 0.0000 (left: 0:19:38)\n",
      "TestLoss: 1.0245 MAE: 0.8069 RMSE: 1.0122\n",
      "ValLoss: 1.0655 MAE: 0.8301 RMSE: 1.0322\n",
      "Epoch 25: TrainLoss 0.9698 RecLoss: 0.0000 (left: 0:19:17)\n",
      "TestLoss: 1.0240 MAE: 0.8077 RMSE: 1.0119\n",
      "ValLoss: 1.0633 MAE: 0.8298 RMSE: 1.0312\n",
      "Epoch 26: TrainLoss 0.9691 RecLoss: 0.0000 (left: 0:18:50)\n",
      "TestLoss: 1.0229 MAE: 0.8070 RMSE: 1.0114\n",
      "ValLoss: 1.0625 MAE: 0.8293 RMSE: 1.0308\n",
      "Epoch 27: TrainLoss 0.9668 RecLoss: 0.0000 (left: 0:18:29)\n",
      "TestLoss: 1.0203 MAE: 0.8047 RMSE: 1.0101\n",
      "ValLoss: 1.0608 MAE: 0.8277 RMSE: 1.0299\n",
      "Epoch 28: TrainLoss 0.9653 RecLoss: 0.0000 (left: 0:18:10)\n",
      "TestLoss: 1.0211 MAE: 0.8068 RMSE: 1.0105\n",
      "ValLoss: 1.0600 MAE: 0.8287 RMSE: 1.0296\n",
      "Epoch 29: TrainLoss 0.9632 RecLoss: 0.0000 (left: 0:17:55)\n",
      "TestLoss: 1.0189 MAE: 0.8050 RMSE: 1.0094\n",
      "ValLoss: 1.0582 MAE: 0.8271 RMSE: 1.0287\n",
      "Epoch 30: TrainLoss 0.9622 RecLoss: 0.0000 (left: 0:17:35)\n",
      "TestLoss: 1.0158 MAE: 0.7988 RMSE: 1.0079\n",
      "ValLoss: 1.0608 MAE: 0.8248 RMSE: 1.0299\n",
      "Epoch 31: TrainLoss 0.9602 RecLoss: 0.0000 (left: 0:17:21)\n",
      "TestLoss: 1.0142 MAE: 0.7982 RMSE: 1.0071\n",
      "ValLoss: 1.0587 MAE: 0.8236 RMSE: 1.0289\n",
      "Epoch 32: TrainLoss 0.9580 RecLoss: 0.0000 (left: 0:17:03)\n",
      "TestLoss: 1.0138 MAE: 0.7998 RMSE: 1.0069\n",
      "ValLoss: 1.0563 MAE: 0.8243 RMSE: 1.0277\n",
      "Epoch 33: TrainLoss 0.9568 RecLoss: 0.0000 (left: 0:16:45)\n",
      "TestLoss: 1.0136 MAE: 0.8006 RMSE: 1.0068\n",
      "ValLoss: 1.0553 MAE: 0.8244 RMSE: 1.0273\n",
      "Epoch 34: TrainLoss 0.9562 RecLoss: 0.0000 (left: 0:16:24)\n",
      "TestLoss: 1.0122 MAE: 0.7998 RMSE: 1.0061\n",
      "ValLoss: 1.0537 MAE: 0.8234 RMSE: 1.0265\n",
      "Epoch 35: TrainLoss 0.9544 RecLoss: 0.0000 (left: 0:16:09)\n",
      "TestLoss: 1.0122 MAE: 0.8003 RMSE: 1.0061\n",
      "ValLoss: 1.0535 MAE: 0.8243 RMSE: 1.0264\n",
      "Epoch 36: TrainLoss 0.9524 RecLoss: 0.0000 (left: 0:15:49)\n",
      "TestLoss: 1.0136 MAE: 0.8040 RMSE: 1.0068\n",
      "ValLoss: 1.0515 MAE: 0.8257 RMSE: 1.0254\n",
      "Epoch 37: TrainLoss 0.9514 RecLoss: 0.0000 (left: 0:15:34)\n",
      "TestLoss: 1.0098 MAE: 0.7986 RMSE: 1.0049\n",
      "ValLoss: 1.0512 MAE: 0.8223 RMSE: 1.0253\n",
      "Epoch 38: TrainLoss 0.9496 RecLoss: 0.0000 (left: 0:15:22)\n",
      "TestLoss: 1.0102 MAE: 0.8006 RMSE: 1.0051\n",
      "ValLoss: 1.0498 MAE: 0.8236 RMSE: 1.0246\n",
      "Epoch 39: TrainLoss 0.9485 RecLoss: 0.0000 (left: 0:15:07)\n",
      "TestLoss: 1.0087 MAE: 0.7988 RMSE: 1.0043\n",
      "ValLoss: 1.0498 MAE: 0.8226 RMSE: 1.0246\n",
      "Epoch 40: TrainLoss 0.9470 RecLoss: 0.0000 (left: 0:14:53)\n",
      "TestLoss: 1.0079 MAE: 0.7975 RMSE: 1.0039\n",
      "ValLoss: 1.0500 MAE: 0.8218 RMSE: 1.0247\n",
      "Epoch 41: TrainLoss 0.9461 RecLoss: 0.0000 (left: 0:14:36)\n",
      "TestLoss: 1.0099 MAE: 0.8022 RMSE: 1.0049\n",
      "ValLoss: 1.0478 MAE: 0.8242 RMSE: 1.0236\n",
      "Epoch 42: TrainLoss 0.9454 RecLoss: 0.0000 (left: 0:14:16)\n",
      "TestLoss: 1.0066 MAE: 0.7976 RMSE: 1.0033\n",
      "ValLoss: 1.0476 MAE: 0.8214 RMSE: 1.0235\n",
      "Epoch 43: TrainLoss 0.9449 RecLoss: 0.0000 (left: 0:14:01)\n",
      "TestLoss: 1.0086 MAE: 0.8026 RMSE: 1.0043\n",
      "ValLoss: 1.0457 MAE: 0.8240 RMSE: 1.0226\n",
      "Epoch 44: TrainLoss 0.9442 RecLoss: 0.0000 (left: 0:13:47)\n",
      "TestLoss: 1.0102 MAE: 0.8046 RMSE: 1.0051\n",
      "ValLoss: 1.0455 MAE: 0.8246 RMSE: 1.0225\n",
      "Epoch 45: TrainLoss 0.9420 RecLoss: 0.0000 (left: 0:13:33)\n",
      "TestLoss: 1.0051 MAE: 0.7973 RMSE: 1.0026\n",
      "ValLoss: 1.0455 MAE: 0.8208 RMSE: 1.0225\n",
      "Epoch 46: TrainLoss 0.9408 RecLoss: 0.0000 (left: 0:13:15)\n",
      "TestLoss: 1.0060 MAE: 0.8003 RMSE: 1.0030\n",
      "ValLoss: 1.0439 MAE: 0.8224 RMSE: 1.0217\n",
      "Epoch 47: TrainLoss 0.9397 RecLoss: 0.0000 (left: 0:12:57)\n",
      "TestLoss: 1.0065 MAE: 0.8018 RMSE: 1.0032\n",
      "ValLoss: 1.0429 MAE: 0.8228 RMSE: 1.0212\n",
      "Epoch 48: TrainLoss 0.9410 RecLoss: 0.0000 (left: 0:12:41)\n",
      "TestLoss: 1.0059 MAE: 0.8014 RMSE: 1.0029\n",
      "ValLoss: 1.0422 MAE: 0.8223 RMSE: 1.0209\n",
      "Epoch 49: TrainLoss 0.9378 RecLoss: 0.0000 (left: 0:12:26)\n",
      "TestLoss: 1.0036 MAE: 0.7978 RMSE: 1.0018\n",
      "ValLoss: 1.0426 MAE: 0.8207 RMSE: 1.0211\n",
      "Epoch 50: TrainLoss 0.9373 RecLoss: 0.0000 (left: 0:12:13)\n",
      "TestLoss: 1.0026 MAE: 0.7960 RMSE: 1.0013\n",
      "ValLoss: 1.0431 MAE: 0.8198 RMSE: 1.0213\n",
      "Epoch 51: TrainLoss 0.9367 RecLoss: 0.0000 (left: 0:11:57)\n",
      "TestLoss: 1.0012 MAE: 0.7922 RMSE: 1.0006\n",
      "ValLoss: 1.0450 MAE: 0.8176 RMSE: 1.0222\n",
      "Epoch 52: TrainLoss 0.9351 RecLoss: 0.0000 (left: 0:11:40)\n",
      "TestLoss: 1.0011 MAE: 0.7942 RMSE: 1.0006\n",
      "ValLoss: 1.0426 MAE: 0.8184 RMSE: 1.0211\n",
      "Epoch 53: TrainLoss 0.9343 RecLoss: 0.0000 (left: 0:11:26)\n",
      "TestLoss: 1.0025 MAE: 0.7991 RMSE: 1.0013\n",
      "ValLoss: 1.0399 MAE: 0.8209 RMSE: 1.0197\n",
      "Epoch 54: TrainLoss 0.9335 RecLoss: 0.0000 (left: 0:11:10)\n",
      "TestLoss: 1.0003 MAE: 0.7946 RMSE: 1.0002\n",
      "ValLoss: 1.0406 MAE: 0.8182 RMSE: 1.0201\n",
      "Epoch 55: TrainLoss 0.9329 RecLoss: 0.0000 (left: 0:10:54)\n",
      "TestLoss: 1.0017 MAE: 0.7982 RMSE: 1.0009\n",
      "ValLoss: 1.0397 MAE: 0.8205 RMSE: 1.0196\n",
      "Epoch 56: TrainLoss 0.9324 RecLoss: 0.0000 (left: 0:10:39)\n",
      "TestLoss: 1.0051 MAE: 0.8034 RMSE: 1.0025\n",
      "ValLoss: 1.0397 MAE: 0.8233 RMSE: 1.0197\n",
      "Epoch 57: TrainLoss 0.9325 RecLoss: 0.0000 (left: 0:10:21)\n",
      "TestLoss: 1.0034 MAE: 0.8019 RMSE: 1.0017\n",
      "ValLoss: 1.0382 MAE: 0.8221 RMSE: 1.0189\n",
      "Epoch 58: TrainLoss 0.9316 RecLoss: 0.0000 (left: 0:10:06)\n",
      "TestLoss: 0.9990 MAE: 0.7943 RMSE: 0.9995\n",
      "ValLoss: 1.0389 MAE: 0.8178 RMSE: 1.0193\n",
      "Epoch 59: TrainLoss 0.9298 RecLoss: 0.0000 (left: 0:09:51)\n",
      "TestLoss: 0.9986 MAE: 0.7897 RMSE: 0.9993\n",
      "ValLoss: 1.0428 MAE: 0.8151 RMSE: 1.0212\n",
      "Epoch 60: TrainLoss 0.9294 RecLoss: 0.0000 (left: 0:09:36)\n",
      "TestLoss: 0.9986 MAE: 0.7946 RMSE: 0.9993\n",
      "ValLoss: 1.0384 MAE: 0.8181 RMSE: 1.0190\n",
      "Epoch 61: TrainLoss 0.9287 RecLoss: 0.0000 (left: 0:09:21)\n",
      "TestLoss: 0.9991 MAE: 0.7968 RMSE: 0.9995\n",
      "ValLoss: 1.0367 MAE: 0.8189 RMSE: 1.0182\n",
      "Epoch 62: TrainLoss 0.9279 RecLoss: 0.0000 (left: 0:09:06)\n",
      "TestLoss: 1.0001 MAE: 0.7992 RMSE: 1.0000\n",
      "ValLoss: 1.0359 MAE: 0.8200 RMSE: 1.0178\n",
      "Epoch 63: TrainLoss 0.9272 RecLoss: 0.0000 (left: 0:08:53)\n",
      "TestLoss: 0.9973 MAE: 0.7933 RMSE: 0.9987\n",
      "ValLoss: 1.0377 MAE: 0.8171 RMSE: 1.0187\n",
      "Epoch 64: TrainLoss 0.9267 RecLoss: 0.0000 (left: 0:08:39)\n",
      "TestLoss: 0.9976 MAE: 0.7950 RMSE: 0.9988\n",
      "ValLoss: 1.0367 MAE: 0.8180 RMSE: 1.0182\n",
      "Epoch 65: TrainLoss 0.9267 RecLoss: 0.0000 (left: 0:08:24)\n",
      "TestLoss: 0.9967 MAE: 0.7905 RMSE: 0.9984\n",
      "ValLoss: 1.0393 MAE: 0.8155 RMSE: 1.0195\n",
      "Epoch 66: TrainLoss 0.9257 RecLoss: 0.0000 (left: 0:08:10)\n",
      "TestLoss: 0.9976 MAE: 0.7962 RMSE: 0.9988\n",
      "ValLoss: 1.0352 MAE: 0.8183 RMSE: 1.0175\n",
      "Epoch 67: TrainLoss 0.9249 RecLoss: 0.0000 (left: 0:07:55)\n",
      "TestLoss: 1.0014 MAE: 0.8022 RMSE: 1.0007\n",
      "ValLoss: 1.0350 MAE: 0.8213 RMSE: 1.0173\n",
      "Epoch 68: TrainLoss 0.9249 RecLoss: 0.0000 (left: 0:07:41)\n",
      "TestLoss: 1.0001 MAE: 0.8006 RMSE: 1.0000\n",
      "ValLoss: 1.0343 MAE: 0.8204 RMSE: 1.0170\n",
      "Epoch 69: TrainLoss 0.9242 RecLoss: 0.0000 (left: 0:07:29)\n",
      "TestLoss: 0.9958 MAE: 0.7928 RMSE: 0.9979\n",
      "ValLoss: 1.0356 MAE: 0.8162 RMSE: 1.0177\n",
      "Epoch 70: TrainLoss 0.9236 RecLoss: 0.0000 (left: 0:07:15)\n",
      "TestLoss: 0.9955 MAE: 0.7899 RMSE: 0.9977\n",
      "ValLoss: 1.0379 MAE: 0.8145 RMSE: 1.0188\n",
      "Epoch 71: TrainLoss 0.9224 RecLoss: 0.0000 (left: 0:07:01)\n",
      "TestLoss: 0.9993 MAE: 0.8001 RMSE: 0.9996\n",
      "ValLoss: 1.0337 MAE: 0.8200 RMSE: 1.0167\n",
      "Epoch 72: TrainLoss 0.9224 RecLoss: 0.0000 (left: 0:06:47)\n",
      "TestLoss: 0.9950 MAE: 0.7900 RMSE: 0.9975\n",
      "ValLoss: 1.0371 MAE: 0.8145 RMSE: 1.0184\n",
      "Epoch 73: TrainLoss 0.9217 RecLoss: 0.0000 (left: 0:06:33)\n",
      "TestLoss: 0.9960 MAE: 0.7954 RMSE: 0.9980\n",
      "ValLoss: 1.0336 MAE: 0.8176 RMSE: 1.0167\n",
      "Epoch 74: TrainLoss 0.9221 RecLoss: 0.0000 (left: 0:06:19)\n",
      "TestLoss: 0.9949 MAE: 0.7929 RMSE: 0.9974\n",
      "ValLoss: 1.0339 MAE: 0.8158 RMSE: 1.0168\n",
      "Epoch 75: TrainLoss 0.9209 RecLoss: 0.0000 (left: 0:06:04)\n",
      "TestLoss: 0.9949 MAE: 0.7895 RMSE: 0.9975\n",
      "ValLoss: 1.0373 MAE: 0.8142 RMSE: 1.0185\n",
      "Epoch 76: TrainLoss 0.9200 RecLoss: 0.0000 (left: 0:05:49)\n",
      "TestLoss: 0.9953 MAE: 0.7945 RMSE: 0.9977\n",
      "ValLoss: 1.0330 MAE: 0.8165 RMSE: 1.0163\n",
      "Epoch 77: TrainLoss 0.9197 RecLoss: 0.0000 (left: 0:05:34)\n",
      "TestLoss: 0.9942 MAE: 0.7903 RMSE: 0.9971\n",
      "ValLoss: 1.0352 MAE: 0.8142 RMSE: 1.0174\n",
      "Epoch 78: TrainLoss 0.9195 RecLoss: 0.0000 (left: 0:05:18)\n",
      "TestLoss: 0.9952 MAE: 0.7953 RMSE: 0.9976\n",
      "ValLoss: 1.0324 MAE: 0.8170 RMSE: 1.0161\n",
      "Epoch 79: TrainLoss 0.9189 RecLoss: 0.0000 (left: 0:05:02)\n",
      "TestLoss: 0.9962 MAE: 0.7971 RMSE: 0.9981\n",
      "ValLoss: 1.0319 MAE: 0.8180 RMSE: 1.0158\n",
      "Epoch 80: TrainLoss 0.9182 RecLoss: 0.0000 (left: 0:04:47)\n",
      "TestLoss: 0.9940 MAE: 0.7896 RMSE: 0.9970\n",
      "ValLoss: 1.0360 MAE: 0.8140 RMSE: 1.0179\n",
      "Epoch 81: TrainLoss 0.9182 RecLoss: 0.0000 (left: 0:04:32)\n",
      "TestLoss: 0.9939 MAE: 0.7933 RMSE: 0.9970\n",
      "ValLoss: 1.0321 MAE: 0.8156 RMSE: 1.0159\n",
      "Epoch 82: TrainLoss 0.9185 RecLoss: 0.0000 (left: 0:04:17)\n",
      "TestLoss: 0.9950 MAE: 0.7960 RMSE: 0.9975\n",
      "ValLoss: 1.0315 MAE: 0.8173 RMSE: 1.0156\n",
      "Epoch 83: TrainLoss 0.9176 RecLoss: 0.0000 (left: 0:04:03)\n",
      "TestLoss: 0.9961 MAE: 0.7979 RMSE: 0.9981\n",
      "ValLoss: 1.0313 MAE: 0.8182 RMSE: 1.0155\n",
      "Epoch 84: TrainLoss 0.9170 RecLoss: 0.0000 (left: 0:03:48)\n",
      "TestLoss: 0.9940 MAE: 0.7939 RMSE: 0.9970\n",
      "ValLoss: 1.0320 MAE: 0.8160 RMSE: 1.0159\n",
      "Epoch 85: TrainLoss 0.9170 RecLoss: 0.0000 (left: 0:03:34)\n",
      "TestLoss: 0.9948 MAE: 0.7958 RMSE: 0.9974\n",
      "ValLoss: 1.0311 MAE: 0.8171 RMSE: 1.0154\n",
      "Epoch 86: TrainLoss 0.9165 RecLoss: 0.0000 (left: 0:03:19)\n",
      "TestLoss: 0.9933 MAE: 0.7924 RMSE: 0.9966\n",
      "ValLoss: 1.0318 MAE: 0.8148 RMSE: 1.0158\n",
      "Epoch 87: TrainLoss 0.9155 RecLoss: 0.0000 (left: 0:03:05)\n",
      "TestLoss: 0.9950 MAE: 0.7970 RMSE: 0.9975\n",
      "ValLoss: 1.0304 MAE: 0.8176 RMSE: 1.0151\n",
      "Epoch 88: TrainLoss 0.9157 RecLoss: 0.0000 (left: 0:02:50)\n",
      "TestLoss: 0.9927 MAE: 0.7908 RMSE: 0.9964\n",
      "ValLoss: 1.0326 MAE: 0.8139 RMSE: 1.0162\n",
      "Epoch 89: TrainLoss 0.9150 RecLoss: 0.0000 (left: 0:02:36)\n",
      "TestLoss: 0.9927 MAE: 0.7910 RMSE: 0.9963\n",
      "ValLoss: 1.0323 MAE: 0.8140 RMSE: 1.0160\n",
      "Epoch 90: TrainLoss 0.9149 RecLoss: 0.0000 (left: 0:02:21)\n",
      "TestLoss: 0.9925 MAE: 0.7905 RMSE: 0.9963\n",
      "ValLoss: 1.0327 MAE: 0.8137 RMSE: 1.0162\n",
      "Epoch 91: TrainLoss 0.9146 RecLoss: 0.0000 (left: 0:02:07)\n",
      "TestLoss: 0.9924 MAE: 0.7883 RMSE: 0.9962\n",
      "ValLoss: 1.0341 MAE: 0.8123 RMSE: 1.0169\n",
      "Epoch 92: TrainLoss 0.9150 RecLoss: 0.0000 (left: 0:01:53)\n",
      "TestLoss: 0.9922 MAE: 0.7900 RMSE: 0.9961\n",
      "ValLoss: 1.0326 MAE: 0.8136 RMSE: 1.0162\n",
      "Epoch 93: TrainLoss 0.9136 RecLoss: 0.0000 (left: 0:01:39)\n",
      "TestLoss: 0.9927 MAE: 0.7931 RMSE: 0.9963\n",
      "ValLoss: 1.0306 MAE: 0.8152 RMSE: 1.0152\n",
      "Epoch 94: TrainLoss 0.9136 RecLoss: 0.0000 (left: 0:01:24)\n",
      "TestLoss: 0.9928 MAE: 0.7935 RMSE: 0.9964\n",
      "ValLoss: 1.0302 MAE: 0.8152 RMSE: 1.0150\n",
      "Epoch 95: TrainLoss 0.9132 RecLoss: 0.0000 (left: 0:01:10)\n",
      "TestLoss: 0.9933 MAE: 0.7945 RMSE: 0.9966\n",
      "ValLoss: 1.0301 MAE: 0.8160 RMSE: 1.0149\n",
      "Epoch 96: TrainLoss 0.9129 RecLoss: 0.0000 (left: 0:00:56)\n",
      "TestLoss: 0.9921 MAE: 0.7917 RMSE: 0.9961\n",
      "ValLoss: 1.0309 MAE: 0.8143 RMSE: 1.0153\n",
      "Epoch 97: TrainLoss 0.9128 RecLoss: 0.0000 (left: 0:00:42)\n",
      "TestLoss: 0.9931 MAE: 0.7944 RMSE: 0.9965\n",
      "ValLoss: 1.0298 MAE: 0.8158 RMSE: 1.0148\n",
      "Epoch 98: TrainLoss 0.9122 RecLoss: 0.0000 (left: 0:00:28)\n",
      "TestLoss: 0.9920 MAE: 0.7917 RMSE: 0.9960\n",
      "ValLoss: 1.0308 MAE: 0.8141 RMSE: 1.0153\n",
      "Epoch 99: TrainLoss 0.9122 RecLoss: 0.0000 (left: 0:00:14)\n",
      "TestLoss: 0.9915 MAE: 0.7887 RMSE: 0.9958\n",
      "ValLoss: 1.0326 MAE: 0.8124 RMSE: 1.0162\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 321973/19100\n",
      "test set size: support/query 523/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.6508 RMSE: 0.8165 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7944 RMSE: 0.9965 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7380 RMSE: 0.9300 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20% optimal cur to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 508216/19100\n",
      "test set size: support/query 1046/809\n",
      "Epoch 0 Step 472: Train 1.8475 Reg: 0.5739\n",
      "Test: 0.7647 MAE: 0.6982 RMSE: 0.8745\n",
      "Val: 0.8158 MAE: 0.7139 RMSE: 0.9032\n",
      "Epoch 1 Step 944: Train 0.8043 Reg: 0.4398\n",
      "Test: 0.7866 MAE: 0.7040 RMSE: 0.8869\n",
      "Val: 0.8094 MAE: 0.7112 RMSE: 0.8996\n",
      "Epoch 2 Step 1416: Train 0.8003 Reg: 0.3541\n",
      "Test: 0.7623 MAE: 0.6944 RMSE: 0.8731\n",
      "Val: 0.8032 MAE: 0.7077 RMSE: 0.8962\n",
      "Epoch 3 Step 1888: Train 0.7965 Reg: 0.3092\n",
      "Test: 0.7586 MAE: 0.6926 RMSE: 0.8710\n",
      "Val: 0.7998 MAE: 0.7072 RMSE: 0.8943\n",
      "Epoch 4 Step 2360: Train 0.7904 Reg: 0.2852\n",
      "Test: 0.7573 MAE: 0.6866 RMSE: 0.8702\n",
      "Val: 0.7915 MAE: 0.7026 RMSE: 0.8896\n",
      "Epoch 5 Step 2832: Train 0.7771 Reg: 0.2790\n",
      "Test: 0.7407 MAE: 0.6832 RMSE: 0.8606\n",
      "Val: 0.7753 MAE: 0.6938 RMSE: 0.8805\n",
      "Epoch 6 Step 3304: Train 0.7605 Reg: 0.2787\n",
      "Test: 0.7327 MAE: 0.6782 RMSE: 0.8560\n",
      "Val: 0.7632 MAE: 0.6872 RMSE: 0.8736\n",
      "Epoch 7 Step 3776: Train 0.7444 Reg: 0.2756\n",
      "Test: 0.7214 MAE: 0.6740 RMSE: 0.8494\n",
      "Val: 0.7498 MAE: 0.6847 RMSE: 0.8659\n",
      "Epoch 8 Step 4248: Train 0.7286 Reg: 0.2839\n",
      "Test: 0.7210 MAE: 0.6730 RMSE: 0.8491\n",
      "Val: 0.7364 MAE: 0.6741 RMSE: 0.8581\n",
      "Epoch 9 Step 4720: Train 0.7120 Reg: 0.3042\n",
      "Test: 0.7083 MAE: 0.6716 RMSE: 0.8416\n",
      "Val: 0.7208 MAE: 0.6669 RMSE: 0.8490\n",
      "Epoch 10 Step 5192: Train 0.6947 Reg: 0.3255\n",
      "Test: 0.7046 MAE: 0.6621 RMSE: 0.8394\n",
      "Val: 0.7099 MAE: 0.6609 RMSE: 0.8426\n",
      "Epoch 11 Step 5664: Train 0.6771 Reg: 0.3386\n",
      "Test: 0.7036 MAE: 0.6640 RMSE: 0.8388\n",
      "Val: 0.7017 MAE: 0.6572 RMSE: 0.8376\n",
      "Epoch 12 Step 6136: Train 0.6579 Reg: 0.3624\n",
      "Test: 0.7005 MAE: 0.6579 RMSE: 0.8369\n",
      "Val: 0.6913 MAE: 0.6481 RMSE: 0.8314\n",
      "Epoch 13 Step 6608: Train 0.6375 Reg: 0.3842\n",
      "Test: 0.7013 MAE: 0.6543 RMSE: 0.8375\n",
      "Val: 0.6843 MAE: 0.6461 RMSE: 0.8272\n",
      "Epoch 14 Step 7080: Train 0.6187 Reg: 0.4043\n",
      "Test: 0.6989 MAE: 0.6522 RMSE: 0.8360\n",
      "Val: 0.6834 MAE: 0.6465 RMSE: 0.8267\n",
      "Epoch 15 Step 7552: Train 0.5999 Reg: 0.4268\n",
      "Test: 0.7016 MAE: 0.6564 RMSE: 0.8376\n",
      "Val: 0.6838 MAE: 0.6451 RMSE: 0.8269\n",
      "Epoch 16 Step 8024: Train 0.5789 Reg: 0.4542\n",
      "Test: 0.7000 MAE: 0.6527 RMSE: 0.8366\n",
      "Val: 0.6867 MAE: 0.6459 RMSE: 0.8287\n",
      "Epoch 17 Step 8496: Train 0.5555 Reg: 0.4808\n",
      "Test: 0.7006 MAE: 0.6497 RMSE: 0.8370\n",
      "Val: 0.6947 MAE: 0.6482 RMSE: 0.8335\n",
      "Epoch 18 Step 8968: Train 0.5345 Reg: 0.4962\n",
      "Test: 0.7055 MAE: 0.6520 RMSE: 0.8399\n",
      "Val: 0.7027 MAE: 0.6516 RMSE: 0.8383\n",
      "Epoch 19 Step 9440: Train 0.5185 Reg: 0.5063\n",
      "Test: 0.7163 MAE: 0.6582 RMSE: 0.8463\n",
      "Val: 0.7115 MAE: 0.6539 RMSE: 0.8435\n",
      "Epoch 20 Step 9912: Train 0.5046 Reg: 0.5144\n",
      "Test: 0.7210 MAE: 0.6580 RMSE: 0.8491\n",
      "Val: 0.7220 MAE: 0.6580 RMSE: 0.8497\n",
      "Epoch 21 Step 10384: Train 0.4921 Reg: 0.5199\n",
      "Test: 0.7344 MAE: 0.6694 RMSE: 0.8570\n",
      "Val: 0.7289 MAE: 0.6608 RMSE: 0.8537\n",
      "Epoch 22 Step 10856: Train 0.4808 Reg: 0.5243\n",
      "Test: 0.7456 MAE: 0.6683 RMSE: 0.8635\n",
      "Val: 0.7390 MAE: 0.6650 RMSE: 0.8597\n",
      "Epoch 23 Step 11328: Train 0.4716 Reg: 0.5250\n",
      "Test: 0.7494 MAE: 0.6711 RMSE: 0.8657\n",
      "Val: 0.7484 MAE: 0.6687 RMSE: 0.8651\n",
      "Epoch 24 Step 11800: Train 0.4642 Reg: 0.5229\n",
      "Test: 0.7529 MAE: 0.6723 RMSE: 0.8677\n",
      "Val: 0.7558 MAE: 0.6712 RMSE: 0.8693\n",
      "Epoch 25 Step 12272: Train 0.4585 Reg: 0.5200\n",
      "Test: 0.7662 MAE: 0.6800 RMSE: 0.8753\n",
      "Val: 0.7639 MAE: 0.6756 RMSE: 0.8740\n",
      "Epoch 26 Step 12744: Train 0.4537 Reg: 0.5166\n",
      "Test: 0.7741 MAE: 0.6788 RMSE: 0.8798\n",
      "Val: 0.7683 MAE: 0.6758 RMSE: 0.8765\n",
      "Epoch 27 Step 13216: Train 0.4493 Reg: 0.5124\n",
      "Test: 0.7761 MAE: 0.6854 RMSE: 0.8810\n",
      "Val: 0.7744 MAE: 0.6790 RMSE: 0.8800\n",
      "Epoch 28 Step 13688: Train 0.4455 Reg: 0.5088\n",
      "Test: 0.7775 MAE: 0.6823 RMSE: 0.8818\n",
      "Val: 0.7784 MAE: 0.6794 RMSE: 0.8823\n",
      "Epoch 29 Step 14160: Train 0.4410 Reg: 0.5055\n",
      "Test: 0.7877 MAE: 0.6853 RMSE: 0.8875\n",
      "Val: 0.7864 MAE: 0.6819 RMSE: 0.8868\n",
      "Epoch 30 Step 14632: Train 0.4368 Reg: 0.5024\n",
      "Test: 0.7934 MAE: 0.6860 RMSE: 0.8907\n",
      "Val: 0.7891 MAE: 0.6834 RMSE: 0.8883\n",
      "Epoch 31 Step 15104: Train 0.4329 Reg: 0.4987\n",
      "Test: 0.8081 MAE: 0.6928 RMSE: 0.8990\n",
      "Val: 0.7977 MAE: 0.6871 RMSE: 0.8931\n",
      "Epoch 32 Step 15576: Train 0.4298 Reg: 0.4949\n",
      "Test: 0.8088 MAE: 0.6890 RMSE: 0.8993\n",
      "Val: 0.8005 MAE: 0.6875 RMSE: 0.8947\n",
      "Epoch 33 Step 16048: Train 0.4268 Reg: 0.4909\n",
      "Test: 0.8194 MAE: 0.6937 RMSE: 0.9052\n",
      "Val: 0.8071 MAE: 0.6905 RMSE: 0.8984\n",
      "Epoch 34 Step 16520: Train 0.4240 Reg: 0.4869\n",
      "Test: 0.8162 MAE: 0.6921 RMSE: 0.9035\n",
      "Val: 0.8093 MAE: 0.6904 RMSE: 0.8996\n",
      "Epoch 35 Step 16992: Train 0.4215 Reg: 0.4828\n",
      "Test: 0.8253 MAE: 0.6956 RMSE: 0.9085\n",
      "Val: 0.8137 MAE: 0.6917 RMSE: 0.9021\n",
      "Epoch 36 Step 17464: Train 0.4190 Reg: 0.4789\n",
      "Test: 0.8238 MAE: 0.6977 RMSE: 0.9076\n",
      "Val: 0.8170 MAE: 0.6937 RMSE: 0.9039\n",
      "Epoch 37 Step 17936: Train 0.4169 Reg: 0.4748\n",
      "Test: 0.8276 MAE: 0.6964 RMSE: 0.9097\n",
      "Val: 0.8209 MAE: 0.6947 RMSE: 0.9060\n",
      "Epoch 38 Step 18408: Train 0.4147 Reg: 0.4711\n",
      "Test: 0.8349 MAE: 0.6989 RMSE: 0.9137\n",
      "Val: 0.8235 MAE: 0.6957 RMSE: 0.9075\n",
      "Epoch 39 Step 18880: Train 0.4129 Reg: 0.4673\n",
      "Test: 0.8401 MAE: 0.7014 RMSE: 0.9166\n",
      "Val: 0.8284 MAE: 0.6971 RMSE: 0.9102\n",
      "Epoch 40 Step 19352: Train 0.4109 Reg: 0.4637\n",
      "Test: 0.8452 MAE: 0.7035 RMSE: 0.9194\n",
      "Val: 0.8307 MAE: 0.6981 RMSE: 0.9114\n",
      "Epoch 41 Step 19824: Train 0.4091 Reg: 0.4602\n",
      "Test: 0.8460 MAE: 0.7027 RMSE: 0.9198\n",
      "Val: 0.8339 MAE: 0.6990 RMSE: 0.9132\n",
      "Epoch 42 Step 20296: Train 0.4073 Reg: 0.4568\n",
      "Test: 0.8532 MAE: 0.7045 RMSE: 0.9237\n",
      "Val: 0.8376 MAE: 0.7001 RMSE: 0.9152\n",
      "Epoch 43 Step 20768: Train 0.4058 Reg: 0.4536\n",
      "Test: 0.8528 MAE: 0.7041 RMSE: 0.9235\n",
      "Val: 0.8407 MAE: 0.7009 RMSE: 0.9169\n",
      "Epoch 44 Step 21240: Train 0.4042 Reg: 0.4504\n",
      "Test: 0.8517 MAE: 0.7048 RMSE: 0.9229\n",
      "Val: 0.8435 MAE: 0.7021 RMSE: 0.9184\n",
      "Epoch 45 Step 21712: Train 0.4027 Reg: 0.4475\n",
      "Test: 0.8551 MAE: 0.7064 RMSE: 0.9247\n",
      "Val: 0.8460 MAE: 0.7034 RMSE: 0.9198\n",
      "Epoch 46 Step 22184: Train 0.4012 Reg: 0.4446\n",
      "Test: 0.8574 MAE: 0.7066 RMSE: 0.9259\n",
      "Val: 0.8480 MAE: 0.7037 RMSE: 0.9209\n",
      "Epoch 47 Step 22656: Train 0.3999 Reg: 0.4416\n",
      "Test: 0.8644 MAE: 0.7097 RMSE: 0.9298\n",
      "Val: 0.8511 MAE: 0.7052 RMSE: 0.9225\n",
      "Epoch 48 Step 23128: Train 0.3985 Reg: 0.4390\n",
      "Test: 0.8661 MAE: 0.7095 RMSE: 0.9307\n",
      "Val: 0.8542 MAE: 0.7058 RMSE: 0.9242\n",
      "Epoch 49 Step 23600: Train 0.3972 Reg: 0.4364\n",
      "Test: 0.8675 MAE: 0.7096 RMSE: 0.9314\n",
      "Val: 0.8558 MAE: 0.7058 RMSE: 0.9251\n",
      "Epoch 50 Step 24072: Train 0.3961 Reg: 0.4339\n",
      "Test: 0.8748 MAE: 0.7140 RMSE: 0.9353\n",
      "Val: 0.8602 MAE: 0.7087 RMSE: 0.9274\n",
      "Epoch 51 Step 24544: Train 0.3948 Reg: 0.4314\n",
      "Test: 0.8724 MAE: 0.7115 RMSE: 0.9340\n",
      "Val: 0.8607 MAE: 0.7083 RMSE: 0.9277\n",
      "Epoch 52 Step 25016: Train 0.3938 Reg: 0.4291\n",
      "Test: 0.8728 MAE: 0.7123 RMSE: 0.9343\n",
      "Val: 0.8608 MAE: 0.7078 RMSE: 0.9278\n",
      "Epoch 53 Step 25488: Train 0.3927 Reg: 0.4269\n",
      "Test: 0.8760 MAE: 0.7134 RMSE: 0.9359\n",
      "Val: 0.8649 MAE: 0.7101 RMSE: 0.9300\n",
      "Epoch 54 Step 25960: Train 0.3916 Reg: 0.4248\n",
      "Test: 0.8779 MAE: 0.7137 RMSE: 0.9369\n",
      "Val: 0.8655 MAE: 0.7097 RMSE: 0.9303\n",
      "Epoch 55 Step 26432: Train 0.3907 Reg: 0.4227\n",
      "Test: 0.8802 MAE: 0.7149 RMSE: 0.9382\n",
      "Val: 0.8675 MAE: 0.7103 RMSE: 0.9314\n",
      "Epoch 56 Step 26904: Train 0.3897 Reg: 0.4208\n",
      "Test: 0.8830 MAE: 0.7154 RMSE: 0.9397\n",
      "Val: 0.8698 MAE: 0.7110 RMSE: 0.9326\n",
      "Epoch 57 Step 27376: Train 0.3888 Reg: 0.4188\n",
      "Test: 0.8846 MAE: 0.7162 RMSE: 0.9405\n",
      "Val: 0.8711 MAE: 0.7115 RMSE: 0.9333\n",
      "Epoch 58 Step 27848: Train 0.3880 Reg: 0.4171\n",
      "Test: 0.8861 MAE: 0.7166 RMSE: 0.9413\n",
      "Val: 0.8722 MAE: 0.7116 RMSE: 0.9339\n",
      "Epoch 59 Step 28320: Train 0.3872 Reg: 0.4154\n",
      "Test: 0.8874 MAE: 0.7180 RMSE: 0.9420\n",
      "Val: 0.8743 MAE: 0.7131 RMSE: 0.9350\n",
      "Epoch 60 Step 28792: Train 0.3864 Reg: 0.4137\n",
      "Test: 0.8877 MAE: 0.7176 RMSE: 0.9422\n",
      "Val: 0.8752 MAE: 0.7128 RMSE: 0.9355\n",
      "Epoch 61 Step 29264: Train 0.3856 Reg: 0.4122\n",
      "Test: 0.8901 MAE: 0.7183 RMSE: 0.9434\n",
      "Val: 0.8763 MAE: 0.7129 RMSE: 0.9361\n",
      "Epoch 62 Step 29736: Train 0.3849 Reg: 0.4106\n",
      "Test: 0.8925 MAE: 0.7197 RMSE: 0.9447\n",
      "Val: 0.8777 MAE: 0.7137 RMSE: 0.9369\n",
      "Epoch 63 Step 30208: Train 0.3842 Reg: 0.4092\n",
      "Test: 0.8943 MAE: 0.7196 RMSE: 0.9457\n",
      "Val: 0.8790 MAE: 0.7139 RMSE: 0.9375\n",
      "Epoch 64 Step 30680: Train 0.3836 Reg: 0.4078\n",
      "Test: 0.8948 MAE: 0.7200 RMSE: 0.9459\n",
      "Val: 0.8800 MAE: 0.7142 RMSE: 0.9381\n",
      "Epoch 65 Step 31152: Train 0.3829 Reg: 0.4065\n",
      "Test: 0.8983 MAE: 0.7216 RMSE: 0.9478\n",
      "Val: 0.8818 MAE: 0.7151 RMSE: 0.9390\n",
      "Epoch 66 Step 31624: Train 0.3823 Reg: 0.4053\n",
      "Test: 0.8974 MAE: 0.7216 RMSE: 0.9473\n",
      "Val: 0.8823 MAE: 0.7153 RMSE: 0.9393\n",
      "Epoch 67 Step 32096: Train 0.3817 Reg: 0.4041\n",
      "Test: 0.8994 MAE: 0.7214 RMSE: 0.9484\n",
      "Val: 0.8834 MAE: 0.7152 RMSE: 0.9399\n",
      "Epoch 68 Step 32568: Train 0.3812 Reg: 0.4029\n",
      "Test: 0.9001 MAE: 0.7216 RMSE: 0.9488\n",
      "Val: 0.8846 MAE: 0.7158 RMSE: 0.9405\n",
      "Epoch 69 Step 33040: Train 0.3807 Reg: 0.4019\n",
      "Test: 0.9011 MAE: 0.7220 RMSE: 0.9493\n",
      "Val: 0.8853 MAE: 0.7160 RMSE: 0.9409\n",
      "Epoch 70 Step 33512: Train 0.3802 Reg: 0.4008\n",
      "Test: 0.9024 MAE: 0.7229 RMSE: 0.9499\n",
      "Val: 0.8862 MAE: 0.7165 RMSE: 0.9414\n",
      "Epoch 71 Step 33984: Train 0.3797 Reg: 0.3998\n",
      "Test: 0.9033 MAE: 0.7228 RMSE: 0.9504\n",
      "Val: 0.8869 MAE: 0.7165 RMSE: 0.9417\n",
      "Epoch 72 Step 34456: Train 0.3792 Reg: 0.3989\n",
      "Test: 0.9049 MAE: 0.7239 RMSE: 0.9513\n",
      "Val: 0.8890 MAE: 0.7180 RMSE: 0.9429\n",
      "Epoch 73 Step 34928: Train 0.3788 Reg: 0.3980\n",
      "Test: 0.9055 MAE: 0.7238 RMSE: 0.9516\n",
      "Val: 0.8889 MAE: 0.7174 RMSE: 0.9428\n",
      "Epoch 74 Step 35400: Train 0.3784 Reg: 0.3971\n",
      "Test: 0.9059 MAE: 0.7240 RMSE: 0.9518\n",
      "Val: 0.8894 MAE: 0.7174 RMSE: 0.9431\n",
      "Epoch 75 Step 35872: Train 0.3780 Reg: 0.3963\n",
      "Test: 0.9064 MAE: 0.7246 RMSE: 0.9521\n",
      "Val: 0.8906 MAE: 0.7181 RMSE: 0.9437\n",
      "Epoch 76 Step 36344: Train 0.3776 Reg: 0.3955\n",
      "Test: 0.9085 MAE: 0.7250 RMSE: 0.9532\n",
      "Val: 0.8918 MAE: 0.7187 RMSE: 0.9443\n",
      "Epoch 77 Step 36816: Train 0.3772 Reg: 0.3948\n",
      "Test: 0.9080 MAE: 0.7246 RMSE: 0.9529\n",
      "Val: 0.8915 MAE: 0.7180 RMSE: 0.9442\n",
      "Epoch 78 Step 37288: Train 0.3768 Reg: 0.3941\n",
      "Test: 0.9091 MAE: 0.7250 RMSE: 0.9535\n",
      "Val: 0.8922 MAE: 0.7183 RMSE: 0.9446\n",
      "Epoch 79 Step 37760: Train 0.3765 Reg: 0.3934\n",
      "Test: 0.9104 MAE: 0.7259 RMSE: 0.9541\n",
      "Val: 0.8933 MAE: 0.7192 RMSE: 0.9452\n",
      "Epoch 80 Step 38232: Train 0.3762 Reg: 0.3927\n",
      "Test: 0.9103 MAE: 0.7255 RMSE: 0.9541\n",
      "Val: 0.8936 MAE: 0.7189 RMSE: 0.9453\n",
      "Epoch 81 Step 38704: Train 0.3759 Reg: 0.3921\n",
      "Test: 0.9109 MAE: 0.7257 RMSE: 0.9544\n",
      "Val: 0.8940 MAE: 0.7190 RMSE: 0.9455\n",
      "Epoch 82 Step 39176: Train 0.3756 Reg: 0.3915\n",
      "Test: 0.9116 MAE: 0.7260 RMSE: 0.9548\n",
      "Val: 0.8947 MAE: 0.7193 RMSE: 0.9459\n",
      "Epoch 83 Step 39648: Train 0.3753 Reg: 0.3910\n",
      "Test: 0.9129 MAE: 0.7266 RMSE: 0.9555\n",
      "Val: 0.8956 MAE: 0.7199 RMSE: 0.9463\n",
      "Epoch 84 Step 40120: Train 0.3751 Reg: 0.3904\n",
      "Test: 0.9130 MAE: 0.7267 RMSE: 0.9555\n",
      "Val: 0.8959 MAE: 0.7199 RMSE: 0.9465\n",
      "Epoch 85 Step 40592: Train 0.3748 Reg: 0.3899\n",
      "Test: 0.9129 MAE: 0.7264 RMSE: 0.9555\n",
      "Val: 0.8958 MAE: 0.7196 RMSE: 0.9465\n",
      "Epoch 86 Step 41064: Train 0.3746 Reg: 0.3894\n",
      "Test: 0.9138 MAE: 0.7266 RMSE: 0.9559\n",
      "Val: 0.8963 MAE: 0.7198 RMSE: 0.9467\n",
      "Epoch 87 Step 41536: Train 0.3744 Reg: 0.3890\n",
      "Test: 0.9144 MAE: 0.7270 RMSE: 0.9562\n",
      "Val: 0.8969 MAE: 0.7201 RMSE: 0.9471\n",
      "Epoch 88 Step 42008: Train 0.3742 Reg: 0.3885\n",
      "Test: 0.9146 MAE: 0.7271 RMSE: 0.9564\n",
      "Val: 0.8972 MAE: 0.7202 RMSE: 0.9472\n",
      "Epoch 89 Step 42480: Train 0.3740 Reg: 0.3881\n",
      "Test: 0.9151 MAE: 0.7274 RMSE: 0.9566\n",
      "Val: 0.8978 MAE: 0.7205 RMSE: 0.9475\n",
      "Epoch 90 Step 42952: Train 0.3738 Reg: 0.3877\n",
      "Test: 0.9158 MAE: 0.7275 RMSE: 0.9569\n",
      "Val: 0.8982 MAE: 0.7206 RMSE: 0.9477\n",
      "Epoch 91 Step 43424: Train 0.3736 Reg: 0.3874\n",
      "Test: 0.9161 MAE: 0.7278 RMSE: 0.9571\n",
      "Val: 0.8985 MAE: 0.7208 RMSE: 0.9479\n",
      "Epoch 92 Step 43896: Train 0.3734 Reg: 0.3870\n",
      "Test: 0.9163 MAE: 0.7276 RMSE: 0.9573\n",
      "Val: 0.8985 MAE: 0.7205 RMSE: 0.9479\n",
      "Epoch 93 Step 44368: Train 0.3732 Reg: 0.3867\n",
      "Test: 0.9170 MAE: 0.7280 RMSE: 0.9576\n",
      "Val: 0.8991 MAE: 0.7210 RMSE: 0.9482\n",
      "Epoch 94 Step 44840: Train 0.3731 Reg: 0.3864\n",
      "Test: 0.9169 MAE: 0.7278 RMSE: 0.9576\n",
      "Val: 0.8990 MAE: 0.7207 RMSE: 0.9482\n",
      "Epoch 95 Step 45312: Train 0.3729 Reg: 0.3861\n",
      "Test: 0.9172 MAE: 0.7279 RMSE: 0.9577\n",
      "Val: 0.8994 MAE: 0.7209 RMSE: 0.9484\n",
      "Epoch 96 Step 45784: Train 0.3728 Reg: 0.3858\n",
      "Test: 0.9180 MAE: 0.7282 RMSE: 0.9581\n",
      "Val: 0.8999 MAE: 0.7211 RMSE: 0.9486\n",
      "Epoch 97 Step 46256: Train 0.3726 Reg: 0.3855\n",
      "Test: 0.9182 MAE: 0.7282 RMSE: 0.9582\n",
      "Val: 0.8998 MAE: 0.7209 RMSE: 0.9486\n",
      "Epoch 98 Step 46728: Train 0.3725 Reg: 0.3852\n",
      "Test: 0.9184 MAE: 0.7283 RMSE: 0.9583\n",
      "Val: 0.9002 MAE: 0.7212 RMSE: 0.9488\n",
      "Epoch 99 Step 47200: Train 0.3724 Reg: 0.3849\n",
      "Test: 0.9185 MAE: 0.7283 RMSE: 0.9584\n",
      "Val: 0.9003 MAE: 0.7211 RMSE: 0.9488\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 508216/19100\n",
      "test set size: support/query 1046/809\n",
      "Epoch 0: TrainLoss 1.0541 RecLoss: 0.0000 (left: 0:08:03)\n",
      "TestLoss: 1.0720 MAE: 0.8171 RMSE: 1.0354\n",
      "ValLoss: 1.1308 MAE: 0.8493 RMSE: 1.0634\n",
      "Epoch 1: TrainLoss 1.0413 RecLoss: 0.0000 (left: 0:08:12)\n",
      "TestLoss: 1.0687 MAE: 0.8220 RMSE: 1.0338\n",
      "ValLoss: 1.1232 MAE: 0.8513 RMSE: 1.0598\n",
      "Epoch 2: TrainLoss 1.0354 RecLoss: 0.0000 (left: 0:07:45)\n",
      "TestLoss: 1.0682 MAE: 0.8266 RMSE: 1.0335\n",
      "ValLoss: 1.1200 MAE: 0.8533 RMSE: 1.0583\n",
      "Epoch 3: TrainLoss 1.0329 RecLoss: 0.0000 (left: 0:07:33)\n",
      "TestLoss: 1.0613 MAE: 0.8127 RMSE: 1.0302\n",
      "ValLoss: 1.1226 MAE: 0.8452 RMSE: 1.0595\n",
      "Epoch 4: TrainLoss 1.0287 RecLoss: 0.0000 (left: 0:07:15)\n",
      "TestLoss: 1.0614 MAE: 0.8237 RMSE: 1.0303\n",
      "ValLoss: 1.1149 MAE: 0.8509 RMSE: 1.0559\n",
      "Epoch 5: TrainLoss 1.0238 RecLoss: 0.0000 (left: 0:07:18)\n",
      "TestLoss: 1.0588 MAE: 0.8232 RMSE: 1.0290\n",
      "ValLoss: 1.1111 MAE: 0.8501 RMSE: 1.0541\n",
      "Epoch 6: TrainLoss 1.0185 RecLoss: 0.0000 (left: 0:07:13)\n",
      "TestLoss: 1.0523 MAE: 0.8105 RMSE: 1.0258\n",
      "ValLoss: 1.1120 MAE: 0.8428 RMSE: 1.0545\n",
      "Epoch 7: TrainLoss 1.0152 RecLoss: 0.0000 (left: 0:07:06)\n",
      "TestLoss: 1.0496 MAE: 0.8114 RMSE: 1.0245\n",
      "ValLoss: 1.1072 MAE: 0.8426 RMSE: 1.0522\n",
      "Epoch 8: TrainLoss 1.0119 RecLoss: 0.0000 (left: 0:07:02)\n",
      "TestLoss: 1.0487 MAE: 0.8162 RMSE: 1.0241\n",
      "ValLoss: 1.1032 MAE: 0.8448 RMSE: 1.0504\n",
      "Epoch 9: TrainLoss 1.0093 RecLoss: 0.0000 (left: 0:07:05)\n",
      "TestLoss: 1.0461 MAE: 0.8064 RMSE: 1.0228\n",
      "ValLoss: 1.1063 MAE: 0.8391 RMSE: 1.0518\n",
      "Epoch 10: TrainLoss 1.0046 RecLoss: 0.0000 (left: 0:06:58)\n",
      "TestLoss: 1.0421 MAE: 0.8095 RMSE: 1.0208\n",
      "ValLoss: 1.0985 MAE: 0.8399 RMSE: 1.0481\n",
      "Epoch 11: TrainLoss 1.0012 RecLoss: 0.0000 (left: 0:06:57)\n",
      "TestLoss: 1.0432 MAE: 0.8158 RMSE: 1.0214\n",
      "ValLoss: 1.0963 MAE: 0.8436 RMSE: 1.0470\n",
      "Epoch 12: TrainLoss 0.9982 RecLoss: 0.0000 (left: 0:06:58)\n",
      "TestLoss: 1.0383 MAE: 0.8087 RMSE: 1.0190\n",
      "ValLoss: 1.0943 MAE: 0.8393 RMSE: 1.0461\n",
      "Epoch 13: TrainLoss 0.9955 RecLoss: 0.0000 (left: 0:06:54)\n",
      "TestLoss: 1.0364 MAE: 0.8047 RMSE: 1.0180\n",
      "ValLoss: 1.0944 MAE: 0.8363 RMSE: 1.0461\n",
      "Epoch 14: TrainLoss 0.9924 RecLoss: 0.0000 (left: 0:06:50)\n",
      "TestLoss: 1.0370 MAE: 0.8128 RMSE: 1.0183\n",
      "ValLoss: 1.0892 MAE: 0.8409 RMSE: 1.0437\n",
      "Epoch 15: TrainLoss 0.9888 RecLoss: 0.0000 (left: 0:06:47)\n",
      "TestLoss: 1.0324 MAE: 0.8068 RMSE: 1.0161\n",
      "ValLoss: 1.0873 MAE: 0.8369 RMSE: 1.0427\n",
      "Epoch 16: TrainLoss 0.9864 RecLoss: 0.0000 (left: 0:06:43)\n",
      "TestLoss: 1.0319 MAE: 0.8093 RMSE: 1.0158\n",
      "ValLoss: 1.0847 MAE: 0.8381 RMSE: 1.0415\n",
      "Epoch 17: TrainLoss 0.9843 RecLoss: 0.0000 (left: 0:06:36)\n",
      "TestLoss: 1.0298 MAE: 0.8014 RMSE: 1.0148\n",
      "ValLoss: 1.0879 MAE: 0.8336 RMSE: 1.0430\n",
      "Epoch 18: TrainLoss 0.9821 RecLoss: 0.0000 (left: 0:06:33)\n",
      "TestLoss: 1.0275 MAE: 0.8036 RMSE: 1.0136\n",
      "ValLoss: 1.0830 MAE: 0.8339 RMSE: 1.0407\n",
      "Epoch 19: TrainLoss 0.9793 RecLoss: 0.0000 (left: 0:06:31)\n",
      "TestLoss: 1.0274 MAE: 0.8072 RMSE: 1.0136\n",
      "ValLoss: 1.0802 MAE: 0.8364 RMSE: 1.0393\n",
      "Epoch 20: TrainLoss 0.9769 RecLoss: 0.0000 (left: 0:06:25)\n",
      "TestLoss: 1.0245 MAE: 0.8019 RMSE: 1.0122\n",
      "ValLoss: 1.0801 MAE: 0.8327 RMSE: 1.0393\n",
      "Epoch 21: TrainLoss 0.9747 RecLoss: 0.0000 (left: 0:06:21)\n",
      "TestLoss: 1.0261 MAE: 0.8104 RMSE: 1.0130\n",
      "ValLoss: 1.0757 MAE: 0.8374 RMSE: 1.0372\n",
      "Epoch 22: TrainLoss 0.9734 RecLoss: 0.0000 (left: 0:06:13)\n",
      "TestLoss: 1.0217 MAE: 0.8015 RMSE: 1.0108\n",
      "ValLoss: 1.0760 MAE: 0.8316 RMSE: 1.0373\n",
      "Epoch 23: TrainLoss 0.9702 RecLoss: 0.0000 (left: 0:06:07)\n",
      "TestLoss: 1.0265 MAE: 0.8124 RMSE: 1.0131\n",
      "ValLoss: 1.0747 MAE: 0.8388 RMSE: 1.0367\n",
      "Epoch 24: TrainLoss 0.9704 RecLoss: 0.0000 (left: 0:06:02)\n",
      "TestLoss: 1.0206 MAE: 0.8052 RMSE: 1.0102\n",
      "ValLoss: 1.0714 MAE: 0.8337 RMSE: 1.0351\n",
      "Epoch 25: TrainLoss 0.9657 RecLoss: 0.0000 (left: 0:05:55)\n",
      "TestLoss: 1.0203 MAE: 0.8064 RMSE: 1.0101\n",
      "ValLoss: 1.0699 MAE: 0.8340 RMSE: 1.0343\n",
      "Epoch 26: TrainLoss 0.9643 RecLoss: 0.0000 (left: 0:05:48)\n",
      "TestLoss: 1.0192 MAE: 0.8056 RMSE: 1.0095\n",
      "ValLoss: 1.0690 MAE: 0.8336 RMSE: 1.0339\n",
      "Epoch 27: TrainLoss 0.9626 RecLoss: 0.0000 (left: 0:05:45)\n",
      "TestLoss: 1.0165 MAE: 0.8029 RMSE: 1.0082\n",
      "ValLoss: 1.0677 MAE: 0.8317 RMSE: 1.0333\n",
      "Epoch 28: TrainLoss 0.9609 RecLoss: 0.0000 (left: 0:05:41)\n",
      "TestLoss: 1.0169 MAE: 0.8048 RMSE: 1.0084\n",
      "ValLoss: 1.0665 MAE: 0.8329 RMSE: 1.0327\n",
      "Epoch 29: TrainLoss 0.9593 RecLoss: 0.0000 (left: 0:05:36)\n",
      "TestLoss: 1.0153 MAE: 0.8028 RMSE: 1.0076\n",
      "ValLoss: 1.0654 MAE: 0.8314 RMSE: 1.0322\n",
      "Epoch 30: TrainLoss 0.9578 RecLoss: 0.0000 (left: 0:05:32)\n",
      "TestLoss: 1.0130 MAE: 0.7966 RMSE: 1.0065\n",
      "ValLoss: 1.0675 MAE: 0.8277 RMSE: 1.0332\n",
      "Epoch 31: TrainLoss 0.9558 RecLoss: 0.0000 (left: 0:05:27)\n",
      "TestLoss: 1.0119 MAE: 0.7961 RMSE: 1.0059\n",
      "ValLoss: 1.0651 MAE: 0.8266 RMSE: 1.0320\n",
      "Epoch 32: TrainLoss 0.9537 RecLoss: 0.0000 (left: 0:05:21)\n",
      "TestLoss: 1.0109 MAE: 0.7983 RMSE: 1.0054\n",
      "ValLoss: 1.0627 MAE: 0.8281 RMSE: 1.0309\n",
      "Epoch 33: TrainLoss 0.9528 RecLoss: 0.0000 (left: 0:05:16)\n",
      "TestLoss: 1.0107 MAE: 0.7989 RMSE: 1.0053\n",
      "ValLoss: 1.0619 MAE: 0.8283 RMSE: 1.0305\n",
      "Epoch 34: TrainLoss 0.9518 RecLoss: 0.0000 (left: 0:05:12)\n",
      "TestLoss: 1.0093 MAE: 0.7969 RMSE: 1.0046\n",
      "ValLoss: 1.0610 MAE: 0.8267 RMSE: 1.0300\n",
      "Epoch 35: TrainLoss 0.9498 RecLoss: 0.0000 (left: 0:05:06)\n",
      "TestLoss: 1.0088 MAE: 0.7973 RMSE: 1.0044\n",
      "ValLoss: 1.0598 MAE: 0.8269 RMSE: 1.0295\n",
      "Epoch 36: TrainLoss 0.9481 RecLoss: 0.0000 (left: 0:05:02)\n",
      "TestLoss: 1.0094 MAE: 0.8010 RMSE: 1.0047\n",
      "ValLoss: 1.0581 MAE: 0.8294 RMSE: 1.0287\n",
      "Epoch 37: TrainLoss 0.9467 RecLoss: 0.0000 (left: 0:04:58)\n",
      "TestLoss: 1.0070 MAE: 0.7962 RMSE: 1.0035\n",
      "ValLoss: 1.0582 MAE: 0.8259 RMSE: 1.0287\n",
      "Epoch 38: TrainLoss 0.9457 RecLoss: 0.0000 (left: 0:04:52)\n",
      "TestLoss: 1.0074 MAE: 0.7986 RMSE: 1.0037\n",
      "ValLoss: 1.0569 MAE: 0.8277 RMSE: 1.0281\n",
      "Epoch 39: TrainLoss 0.9443 RecLoss: 0.0000 (left: 0:04:47)\n",
      "TestLoss: 1.0061 MAE: 0.7965 RMSE: 1.0030\n",
      "ValLoss: 1.0563 MAE: 0.8260 RMSE: 1.0278\n",
      "Epoch 40: TrainLoss 0.9427 RecLoss: 0.0000 (left: 0:04:42)\n",
      "TestLoss: 1.0055 MAE: 0.7954 RMSE: 1.0028\n",
      "ValLoss: 1.0563 MAE: 0.8251 RMSE: 1.0278\n",
      "Epoch 41: TrainLoss 0.9415 RecLoss: 0.0000 (left: 0:04:38)\n",
      "TestLoss: 1.0063 MAE: 0.7996 RMSE: 1.0031\n",
      "ValLoss: 1.0544 MAE: 0.8280 RMSE: 1.0268\n",
      "Epoch 42: TrainLoss 0.9411 RecLoss: 0.0000 (left: 0:04:33)\n",
      "TestLoss: 1.0045 MAE: 0.7963 RMSE: 1.0022\n",
      "ValLoss: 1.0541 MAE: 0.8257 RMSE: 1.0267\n",
      "Epoch 43: TrainLoss 0.9404 RecLoss: 0.0000 (left: 0:04:28)\n",
      "TestLoss: 1.0057 MAE: 0.8004 RMSE: 1.0029\n",
      "ValLoss: 1.0523 MAE: 0.8282 RMSE: 1.0258\n",
      "Epoch 44: TrainLoss 0.9397 RecLoss: 0.0000 (left: 0:04:23)\n",
      "TestLoss: 1.0058 MAE: 0.8010 RMSE: 1.0029\n",
      "ValLoss: 1.0525 MAE: 0.8284 RMSE: 1.0259\n",
      "Epoch 45: TrainLoss 0.9373 RecLoss: 0.0000 (left: 0:04:18)\n",
      "TestLoss: 1.0024 MAE: 0.7946 RMSE: 1.0012\n",
      "ValLoss: 1.0521 MAE: 0.8240 RMSE: 1.0257\n",
      "Epoch 46: TrainLoss 0.9363 RecLoss: 0.0000 (left: 0:04:13)\n",
      "TestLoss: 1.0033 MAE: 0.7977 RMSE: 1.0016\n",
      "ValLoss: 1.0508 MAE: 0.8261 RMSE: 1.0251\n",
      "Epoch 47: TrainLoss 0.9355 RecLoss: 0.0000 (left: 0:04:08)\n",
      "TestLoss: 1.0039 MAE: 0.7997 RMSE: 1.0019\n",
      "ValLoss: 1.0499 MAE: 0.8272 RMSE: 1.0246\n",
      "Epoch 48: TrainLoss 0.9368 RecLoss: 0.0000 (left: 0:04:03)\n",
      "TestLoss: 1.0028 MAE: 0.7987 RMSE: 1.0014\n",
      "ValLoss: 1.0496 MAE: 0.8266 RMSE: 1.0245\n",
      "Epoch 49: TrainLoss 0.9336 RecLoss: 0.0000 (left: 0:03:59)\n",
      "TestLoss: 1.0009 MAE: 0.7955 RMSE: 1.0004\n",
      "ValLoss: 1.0489 MAE: 0.8242 RMSE: 1.0241\n",
      "Epoch 50: TrainLoss 0.9326 RecLoss: 0.0000 (left: 0:03:53)\n",
      "TestLoss: 1.0002 MAE: 0.7938 RMSE: 1.0001\n",
      "ValLoss: 1.0492 MAE: 0.8230 RMSE: 1.0243\n",
      "Epoch 51: TrainLoss 0.9326 RecLoss: 0.0000 (left: 0:03:49)\n",
      "TestLoss: 0.9998 MAE: 0.7906 RMSE: 0.9999\n",
      "ValLoss: 1.0505 MAE: 0.8207 RMSE: 1.0250\n",
      "Epoch 52: TrainLoss 0.9309 RecLoss: 0.0000 (left: 0:03:45)\n",
      "TestLoss: 0.9994 MAE: 0.7922 RMSE: 0.9997\n",
      "ValLoss: 1.0489 MAE: 0.8217 RMSE: 1.0241\n",
      "Epoch 53: TrainLoss 0.9297 RecLoss: 0.0000 (left: 0:03:40)\n",
      "TestLoss: 1.0003 MAE: 0.7967 RMSE: 1.0001\n",
      "ValLoss: 1.0470 MAE: 0.8249 RMSE: 1.0232\n",
      "Epoch 54: TrainLoss 0.9293 RecLoss: 0.0000 (left: 0:03:36)\n",
      "TestLoss: 0.9981 MAE: 0.7924 RMSE: 0.9991\n",
      "ValLoss: 1.0471 MAE: 0.8216 RMSE: 1.0233\n",
      "Epoch 55: TrainLoss 0.9286 RecLoss: 0.0000 (left: 0:03:31)\n",
      "TestLoss: 0.9996 MAE: 0.7959 RMSE: 0.9998\n",
      "ValLoss: 1.0461 MAE: 0.8242 RMSE: 1.0228\n",
      "Epoch 56: TrainLoss 0.9281 RecLoss: 0.0000 (left: 0:03:26)\n",
      "TestLoss: 1.0017 MAE: 0.8004 RMSE: 1.0009\n",
      "ValLoss: 1.0461 MAE: 0.8272 RMSE: 1.0228\n",
      "Epoch 57: TrainLoss 0.9281 RecLoss: 0.0000 (left: 0:03:21)\n",
      "TestLoss: 1.0003 MAE: 0.7986 RMSE: 1.0002\n",
      "ValLoss: 1.0454 MAE: 0.8259 RMSE: 1.0224\n",
      "Epoch 58: TrainLoss 0.9272 RecLoss: 0.0000 (left: 0:03:17)\n",
      "TestLoss: 0.9971 MAE: 0.7915 RMSE: 0.9986\n",
      "ValLoss: 1.0459 MAE: 0.8207 RMSE: 1.0227\n",
      "Epoch 59: TrainLoss 0.9254 RecLoss: 0.0000 (left: 0:03:12)\n",
      "TestLoss: 0.9974 MAE: 0.7873 RMSE: 0.9987\n",
      "ValLoss: 1.0492 MAE: 0.8177 RMSE: 1.0243\n",
      "Epoch 60: TrainLoss 0.9249 RecLoss: 0.0000 (left: 0:03:07)\n",
      "TestLoss: 0.9966 MAE: 0.7914 RMSE: 0.9983\n",
      "ValLoss: 1.0452 MAE: 0.8205 RMSE: 1.0223\n",
      "Epoch 61: TrainLoss 0.9242 RecLoss: 0.0000 (left: 0:03:02)\n",
      "TestLoss: 0.9966 MAE: 0.7935 RMSE: 0.9983\n",
      "ValLoss: 1.0437 MAE: 0.8219 RMSE: 1.0216\n",
      "Epoch 62: TrainLoss 0.9234 RecLoss: 0.0000 (left: 0:02:58)\n",
      "TestLoss: 0.9976 MAE: 0.7963 RMSE: 0.9988\n",
      "ValLoss: 1.0430 MAE: 0.8238 RMSE: 1.0213\n",
      "Epoch 63: TrainLoss 0.9227 RecLoss: 0.0000 (left: 0:02:53)\n",
      "TestLoss: 0.9957 MAE: 0.7904 RMSE: 0.9978\n",
      "ValLoss: 1.0444 MAE: 0.8197 RMSE: 1.0220\n",
      "Epoch 64: TrainLoss 0.9223 RecLoss: 0.0000 (left: 0:02:48)\n",
      "TestLoss: 0.9959 MAE: 0.7924 RMSE: 0.9979\n",
      "ValLoss: 1.0435 MAE: 0.8211 RMSE: 1.0215\n",
      "Epoch 65: TrainLoss 0.9221 RecLoss: 0.0000 (left: 0:02:43)\n",
      "TestLoss: 0.9958 MAE: 0.7876 RMSE: 0.9979\n",
      "ValLoss: 1.0461 MAE: 0.8177 RMSE: 1.0228\n",
      "Epoch 66: TrainLoss 0.9216 RecLoss: 0.0000 (left: 0:02:39)\n",
      "TestLoss: 0.9952 MAE: 0.7923 RMSE: 0.9976\n",
      "ValLoss: 1.0423 MAE: 0.8209 RMSE: 1.0209\n",
      "Epoch 67: TrainLoss 0.9206 RecLoss: 0.0000 (left: 0:02:34)\n",
      "TestLoss: 0.9982 MAE: 0.7988 RMSE: 0.9991\n",
      "ValLoss: 1.0420 MAE: 0.8252 RMSE: 1.0208\n",
      "Epoch 68: TrainLoss 0.9205 RecLoss: 0.0000 (left: 0:02:29)\n",
      "TestLoss: 0.9977 MAE: 0.7981 RMSE: 0.9989\n",
      "ValLoss: 1.0414 MAE: 0.8245 RMSE: 1.0205\n",
      "Epoch 69: TrainLoss 0.9197 RecLoss: 0.0000 (left: 0:02:25)\n",
      "TestLoss: 0.9943 MAE: 0.7900 RMSE: 0.9971\n",
      "ValLoss: 1.0424 MAE: 0.8191 RMSE: 1.0210\n",
      "Epoch 70: TrainLoss 0.9192 RecLoss: 0.0000 (left: 0:02:20)\n",
      "TestLoss: 0.9943 MAE: 0.7871 RMSE: 0.9972\n",
      "ValLoss: 1.0442 MAE: 0.8170 RMSE: 1.0219\n",
      "Epoch 71: TrainLoss 0.9179 RecLoss: 0.0000 (left: 0:02:15)\n",
      "TestLoss: 0.9966 MAE: 0.7972 RMSE: 0.9983\n",
      "ValLoss: 1.0406 MAE: 0.8238 RMSE: 1.0201\n",
      "Epoch 72: TrainLoss 0.9181 RecLoss: 0.0000 (left: 0:02:11)\n",
      "TestLoss: 0.9940 MAE: 0.7877 RMSE: 0.9970\n",
      "ValLoss: 1.0432 MAE: 0.8173 RMSE: 1.0214\n",
      "Epoch 73: TrainLoss 0.9174 RecLoss: 0.0000 (left: 0:02:06)\n",
      "TestLoss: 0.9939 MAE: 0.7926 RMSE: 0.9970\n",
      "ValLoss: 1.0401 MAE: 0.8207 RMSE: 1.0199\n",
      "Epoch 74: TrainLoss 0.9176 RecLoss: 0.0000 (left: 0:02:01)\n",
      "TestLoss: 0.9932 MAE: 0.7902 RMSE: 0.9966\n",
      "ValLoss: 1.0406 MAE: 0.8189 RMSE: 1.0201\n",
      "Epoch 75: TrainLoss 0.9168 RecLoss: 0.0000 (left: 0:01:57)\n",
      "TestLoss: 0.9939 MAE: 0.7869 RMSE: 0.9970\n",
      "ValLoss: 1.0433 MAE: 0.8167 RMSE: 1.0214\n",
      "Epoch 76: TrainLoss 0.9158 RecLoss: 0.0000 (left: 0:01:52)\n",
      "TestLoss: 0.9935 MAE: 0.7913 RMSE: 0.9967\n",
      "ValLoss: 1.0401 MAE: 0.8195 RMSE: 1.0198\n",
      "Epoch 77: TrainLoss 0.9157 RecLoss: 0.0000 (left: 0:01:47)\n",
      "TestLoss: 0.9931 MAE: 0.7873 RMSE: 0.9965\n",
      "ValLoss: 1.0420 MAE: 0.8168 RMSE: 1.0208\n",
      "Epoch 78: TrainLoss 0.9151 RecLoss: 0.0000 (left: 0:01:42)\n",
      "TestLoss: 0.9934 MAE: 0.7924 RMSE: 0.9967\n",
      "ValLoss: 1.0391 MAE: 0.8202 RMSE: 1.0194\n",
      "Epoch 79: TrainLoss 0.9147 RecLoss: 0.0000 (left: 0:01:37)\n",
      "TestLoss: 0.9942 MAE: 0.7938 RMSE: 0.9971\n",
      "ValLoss: 1.0387 MAE: 0.8210 RMSE: 1.0192\n",
      "Epoch 80: TrainLoss 0.9139 RecLoss: 0.0000 (left: 0:01:33)\n",
      "TestLoss: 0.9933 MAE: 0.7871 RMSE: 0.9966\n",
      "ValLoss: 1.0420 MAE: 0.8166 RMSE: 1.0208\n",
      "Epoch 81: TrainLoss 0.9138 RecLoss: 0.0000 (left: 0:01:28)\n",
      "TestLoss: 0.9923 MAE: 0.7898 RMSE: 0.9961\n",
      "ValLoss: 1.0393 MAE: 0.8183 RMSE: 1.0194\n",
      "Epoch 82: TrainLoss 0.9143 RecLoss: 0.0000 (left: 0:01:23)\n",
      "TestLoss: 0.9929 MAE: 0.7927 RMSE: 0.9965\n",
      "ValLoss: 1.0381 MAE: 0.8203 RMSE: 1.0189\n",
      "Epoch 83: TrainLoss 0.9129 RecLoss: 0.0000 (left: 0:01:19)\n",
      "TestLoss: 0.9936 MAE: 0.7948 RMSE: 0.9968\n",
      "ValLoss: 1.0379 MAE: 0.8217 RMSE: 1.0188\n",
      "Epoch 84: TrainLoss 0.9128 RecLoss: 0.0000 (left: 0:01:14)\n",
      "TestLoss: 0.9924 MAE: 0.7913 RMSE: 0.9962\n",
      "ValLoss: 1.0385 MAE: 0.8193 RMSE: 1.0190\n",
      "Epoch 85: TrainLoss 0.9125 RecLoss: 0.0000 (left: 0:01:09)\n",
      "TestLoss: 0.9927 MAE: 0.7926 RMSE: 0.9964\n",
      "ValLoss: 1.0379 MAE: 0.8202 RMSE: 1.0188\n",
      "Epoch 86: TrainLoss 0.9121 RecLoss: 0.0000 (left: 0:01:05)\n",
      "TestLoss: 0.9919 MAE: 0.7892 RMSE: 0.9959\n",
      "ValLoss: 1.0386 MAE: 0.8175 RMSE: 1.0191\n",
      "Epoch 87: TrainLoss 0.9111 RecLoss: 0.0000 (left: 0:01:00)\n",
      "TestLoss: 0.9930 MAE: 0.7941 RMSE: 0.9965\n",
      "ValLoss: 1.0371 MAE: 0.8210 RMSE: 1.0184\n",
      "Epoch 88: TrainLoss 0.9114 RecLoss: 0.0000 (left: 0:00:55)\n",
      "TestLoss: 0.9915 MAE: 0.7880 RMSE: 0.9958\n",
      "ValLoss: 1.0390 MAE: 0.8167 RMSE: 1.0193\n",
      "Epoch 89: TrainLoss 0.9109 RecLoss: 0.0000 (left: 0:00:51)\n",
      "TestLoss: 0.9913 MAE: 0.7887 RMSE: 0.9956\n",
      "ValLoss: 1.0385 MAE: 0.8172 RMSE: 1.0191\n",
      "Epoch 90: TrainLoss 0.9105 RecLoss: 0.0000 (left: 0:00:46)\n",
      "TestLoss: 0.9913 MAE: 0.7879 RMSE: 0.9957\n",
      "ValLoss: 1.0390 MAE: 0.8167 RMSE: 1.0193\n",
      "Epoch 91: TrainLoss 0.9102 RecLoss: 0.0000 (left: 0:00:41)\n",
      "TestLoss: 0.9919 MAE: 0.7850 RMSE: 0.9960\n",
      "ValLoss: 1.0413 MAE: 0.8148 RMSE: 1.0205\n",
      "Epoch 92: TrainLoss 0.9110 RecLoss: 0.0000 (left: 0:00:37)\n",
      "TestLoss: 0.9915 MAE: 0.7870 RMSE: 0.9957\n",
      "ValLoss: 1.0392 MAE: 0.8161 RMSE: 1.0194\n",
      "Epoch 93: TrainLoss 0.9096 RecLoss: 0.0000 (left: 0:00:32)\n",
      "TestLoss: 0.9914 MAE: 0.7903 RMSE: 0.9957\n",
      "ValLoss: 1.0373 MAE: 0.8183 RMSE: 1.0185\n",
      "Epoch 94: TrainLoss 0.9094 RecLoss: 0.0000 (left: 0:00:27)\n",
      "TestLoss: 0.9913 MAE: 0.7903 RMSE: 0.9956\n",
      "ValLoss: 1.0369 MAE: 0.8181 RMSE: 1.0183\n",
      "Epoch 95: TrainLoss 0.9090 RecLoss: 0.0000 (left: 0:00:23)\n",
      "TestLoss: 0.9916 MAE: 0.7915 RMSE: 0.9958\n",
      "ValLoss: 1.0366 MAE: 0.8190 RMSE: 1.0181\n",
      "Epoch 96: TrainLoss 0.9086 RecLoss: 0.0000 (left: 0:00:18)\n",
      "TestLoss: 0.9910 MAE: 0.7887 RMSE: 0.9955\n",
      "ValLoss: 1.0375 MAE: 0.8171 RMSE: 1.0186\n",
      "Epoch 97: TrainLoss 0.9083 RecLoss: 0.0000 (left: 0:00:13)\n",
      "TestLoss: 0.9915 MAE: 0.7913 RMSE: 0.9957\n",
      "ValLoss: 1.0365 MAE: 0.8189 RMSE: 1.0181\n",
      "Epoch 98: TrainLoss 0.9080 RecLoss: 0.0000 (left: 0:00:09)\n",
      "TestLoss: 0.9910 MAE: 0.7890 RMSE: 0.9955\n",
      "ValLoss: 1.0372 MAE: 0.8172 RMSE: 1.0184\n",
      "Epoch 99: TrainLoss 0.9080 RecLoss: 0.0000 (left: 0:00:04)\n",
      "TestLoss: 0.9910 MAE: 0.7860 RMSE: 0.9955\n",
      "ValLoss: 1.0390 MAE: 0.8152 RMSE: 1.0193\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 508216/19100\n",
      "test set size: support/query 1046/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.6522 RMSE: 0.8360 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7913 RMSE: 0.9957 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7129 RMSE: 0.9091 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 40% optimal cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 726169/19100\n",
      "test set size: support/query 2092/809\n",
      "Epoch 0 Step 674: Train 1.6229 Reg: 0.6160\n",
      "Test: 0.8437 MAE: 0.7339 RMSE: 0.9185\n",
      "Val: 0.8446 MAE: 0.7291 RMSE: 0.9190\n",
      "Epoch 1 Step 1348: Train 0.8316 Reg: 0.3984\n",
      "Test: 0.8348 MAE: 0.7274 RMSE: 0.9137\n",
      "Val: 0.8389 MAE: 0.7260 RMSE: 0.9159\n",
      "Epoch 2 Step 2022: Train 0.8271 Reg: 0.3340\n",
      "Test: 0.8556 MAE: 0.7398 RMSE: 0.9250\n",
      "Val: 0.8344 MAE: 0.7224 RMSE: 0.9135\n",
      "Epoch 3 Step 2696: Train 0.8221 Reg: 0.3043\n",
      "Test: 0.8390 MAE: 0.7278 RMSE: 0.9159\n",
      "Val: 0.8288 MAE: 0.7215 RMSE: 0.9104\n",
      "Epoch 4 Step 3370: Train 0.8126 Reg: 0.2827\n",
      "Test: 0.8299 MAE: 0.7243 RMSE: 0.9110\n",
      "Val: 0.8140 MAE: 0.7139 RMSE: 0.9022\n",
      "Epoch 5 Step 4044: Train 0.7972 Reg: 0.2694\n",
      "Test: 0.8172 MAE: 0.7113 RMSE: 0.9040\n",
      "Val: 0.8033 MAE: 0.7062 RMSE: 0.8963\n",
      "Epoch 6 Step 4718: Train 0.7865 Reg: 0.2498\n",
      "Test: 0.8197 MAE: 0.7148 RMSE: 0.9054\n",
      "Val: 0.7946 MAE: 0.7026 RMSE: 0.8914\n",
      "Epoch 7 Step 5392: Train 0.7758 Reg: 0.2499\n",
      "Test: 0.8091 MAE: 0.7096 RMSE: 0.8995\n",
      "Val: 0.7789 MAE: 0.6947 RMSE: 0.8826\n",
      "Epoch 8 Step 6066: Train 0.7545 Reg: 0.2883\n",
      "Test: 0.7897 MAE: 0.7070 RMSE: 0.8887\n",
      "Val: 0.7604 MAE: 0.6872 RMSE: 0.8720\n",
      "Epoch 9 Step 6740: Train 0.7314 Reg: 0.3237\n",
      "Test: 0.7779 MAE: 0.7045 RMSE: 0.8820\n",
      "Val: 0.7432 MAE: 0.6802 RMSE: 0.8621\n",
      "Epoch 10 Step 7414: Train 0.7090 Reg: 0.3614\n",
      "Test: 0.7601 MAE: 0.6949 RMSE: 0.8719\n",
      "Val: 0.7290 MAE: 0.6717 RMSE: 0.8538\n",
      "Epoch 11 Step 8088: Train 0.6880 Reg: 0.3990\n",
      "Test: 0.7322 MAE: 0.6731 RMSE: 0.8557\n",
      "Val: 0.7164 MAE: 0.6636 RMSE: 0.8464\n",
      "Epoch 12 Step 8762: Train 0.6672 Reg: 0.4308\n",
      "Test: 0.7210 MAE: 0.6724 RMSE: 0.8491\n",
      "Val: 0.7100 MAE: 0.6581 RMSE: 0.8426\n",
      "Epoch 13 Step 9436: Train 0.6508 Reg: 0.4537\n",
      "Test: 0.7236 MAE: 0.6690 RMSE: 0.8506\n",
      "Val: 0.7060 MAE: 0.6565 RMSE: 0.8402\n",
      "Epoch 14 Step 10110: Train 0.6344 Reg: 0.4778\n",
      "Test: 0.7183 MAE: 0.6656 RMSE: 0.8475\n",
      "Val: 0.7048 MAE: 0.6555 RMSE: 0.8395\n",
      "Epoch 15 Step 10784: Train 0.6193 Reg: 0.4944\n",
      "Test: 0.7207 MAE: 0.6665 RMSE: 0.8490\n",
      "Val: 0.7044 MAE: 0.6542 RMSE: 0.8393\n",
      "Epoch 16 Step 11458: Train 0.6050 Reg: 0.5147\n",
      "Test: 0.7331 MAE: 0.6732 RMSE: 0.8562\n",
      "Val: 0.7051 MAE: 0.6549 RMSE: 0.8397\n",
      "Epoch 17 Step 12132: Train 0.5901 Reg: 0.5302\n",
      "Test: 0.7314 MAE: 0.6733 RMSE: 0.8552\n",
      "Val: 0.7100 MAE: 0.6568 RMSE: 0.8426\n",
      "Epoch 18 Step 12806: Train 0.5762 Reg: 0.5456\n",
      "Test: 0.7292 MAE: 0.6681 RMSE: 0.8539\n",
      "Val: 0.7164 MAE: 0.6574 RMSE: 0.8464\n",
      "Epoch 19 Step 13480: Train 0.5609 Reg: 0.5633\n",
      "Test: 0.7342 MAE: 0.6705 RMSE: 0.8568\n",
      "Val: 0.7223 MAE: 0.6602 RMSE: 0.8499\n",
      "Epoch 20 Step 14154: Train 0.5451 Reg: 0.5770\n",
      "Test: 0.7348 MAE: 0.6719 RMSE: 0.8572\n",
      "Val: 0.7315 MAE: 0.6660 RMSE: 0.8553\n",
      "Epoch 21 Step 14828: Train 0.5318 Reg: 0.5838\n",
      "Test: 0.7464 MAE: 0.6756 RMSE: 0.8640\n",
      "Val: 0.7399 MAE: 0.6693 RMSE: 0.8602\n",
      "Epoch 22 Step 15502: Train 0.5214 Reg: 0.5874\n",
      "Test: 0.7517 MAE: 0.6825 RMSE: 0.8670\n",
      "Val: 0.7459 MAE: 0.6720 RMSE: 0.8637\n",
      "Epoch 23 Step 16176: Train 0.5122 Reg: 0.5879\n",
      "Test: 0.7525 MAE: 0.6764 RMSE: 0.8675\n",
      "Val: 0.7530 MAE: 0.6738 RMSE: 0.8678\n",
      "Epoch 24 Step 16850: Train 0.5047 Reg: 0.5864\n",
      "Test: 0.7583 MAE: 0.6799 RMSE: 0.8708\n",
      "Val: 0.7624 MAE: 0.6784 RMSE: 0.8732\n",
      "Epoch 25 Step 17524: Train 0.4985 Reg: 0.5842\n",
      "Test: 0.7672 MAE: 0.6808 RMSE: 0.8759\n",
      "Val: 0.7681 MAE: 0.6787 RMSE: 0.8764\n",
      "Epoch 26 Step 18198: Train 0.4919 Reg: 0.5821\n",
      "Test: 0.7793 MAE: 0.6873 RMSE: 0.8828\n",
      "Val: 0.7727 MAE: 0.6798 RMSE: 0.8791\n",
      "Epoch 27 Step 18872: Train 0.4861 Reg: 0.5782\n",
      "Test: 0.7845 MAE: 0.6875 RMSE: 0.8857\n",
      "Val: 0.7796 MAE: 0.6835 RMSE: 0.8830\n",
      "Epoch 28 Step 19546: Train 0.4814 Reg: 0.5737\n",
      "Test: 0.7826 MAE: 0.6875 RMSE: 0.8847\n",
      "Val: 0.7848 MAE: 0.6852 RMSE: 0.8859\n",
      "Epoch 29 Step 20220: Train 0.4770 Reg: 0.5686\n",
      "Test: 0.7909 MAE: 0.6913 RMSE: 0.8893\n",
      "Val: 0.7888 MAE: 0.6868 RMSE: 0.8881\n",
      "Epoch 30 Step 20894: Train 0.4731 Reg: 0.5631\n",
      "Test: 0.7963 MAE: 0.6910 RMSE: 0.8924\n",
      "Val: 0.7957 MAE: 0.6877 RMSE: 0.8920\n",
      "Epoch 31 Step 21568: Train 0.4695 Reg: 0.5577\n",
      "Test: 0.8043 MAE: 0.6937 RMSE: 0.8968\n",
      "Val: 0.7982 MAE: 0.6889 RMSE: 0.8934\n",
      "Epoch 32 Step 22242: Train 0.4661 Reg: 0.5521\n",
      "Test: 0.8032 MAE: 0.6936 RMSE: 0.8962\n",
      "Val: 0.8019 MAE: 0.6917 RMSE: 0.8955\n",
      "Epoch 33 Step 22916: Train 0.4629 Reg: 0.5466\n",
      "Test: 0.8107 MAE: 0.6940 RMSE: 0.9004\n",
      "Val: 0.8068 MAE: 0.6930 RMSE: 0.8982\n",
      "Epoch 34 Step 23590: Train 0.4600 Reg: 0.5411\n",
      "Test: 0.8130 MAE: 0.6957 RMSE: 0.9016\n",
      "Val: 0.8100 MAE: 0.6935 RMSE: 0.9000\n",
      "Epoch 35 Step 24264: Train 0.4574 Reg: 0.5356\n",
      "Test: 0.8170 MAE: 0.6970 RMSE: 0.9039\n",
      "Val: 0.8138 MAE: 0.6941 RMSE: 0.9021\n",
      "Epoch 36 Step 24938: Train 0.4545 Reg: 0.5301\n",
      "Test: 0.8258 MAE: 0.7024 RMSE: 0.9088\n",
      "Val: 0.8183 MAE: 0.6974 RMSE: 0.9046\n",
      "Epoch 37 Step 25612: Train 0.4519 Reg: 0.5249\n",
      "Test: 0.8316 MAE: 0.7033 RMSE: 0.9119\n",
      "Val: 0.8212 MAE: 0.6972 RMSE: 0.9062\n",
      "Epoch 38 Step 26286: Train 0.4494 Reg: 0.5201\n",
      "Test: 0.8323 MAE: 0.7002 RMSE: 0.9123\n",
      "Val: 0.8261 MAE: 0.6978 RMSE: 0.9089\n",
      "Epoch 39 Step 26960: Train 0.4471 Reg: 0.5150\n",
      "Test: 0.8374 MAE: 0.7037 RMSE: 0.9151\n",
      "Val: 0.8286 MAE: 0.6994 RMSE: 0.9102\n",
      "Epoch 40 Step 27634: Train 0.4449 Reg: 0.5102\n",
      "Test: 0.8400 MAE: 0.7059 RMSE: 0.9165\n",
      "Val: 0.8309 MAE: 0.7008 RMSE: 0.9115\n",
      "Epoch 41 Step 28308: Train 0.4427 Reg: 0.5053\n",
      "Test: 0.8449 MAE: 0.7079 RMSE: 0.9192\n",
      "Val: 0.8340 MAE: 0.7022 RMSE: 0.9132\n",
      "Epoch 42 Step 28982: Train 0.4406 Reg: 0.5007\n",
      "Test: 0.8528 MAE: 0.7092 RMSE: 0.9235\n",
      "Val: 0.8387 MAE: 0.7030 RMSE: 0.9158\n",
      "Epoch 43 Step 29656: Train 0.4386 Reg: 0.4963\n",
      "Test: 0.8551 MAE: 0.7092 RMSE: 0.9247\n",
      "Val: 0.8416 MAE: 0.7037 RMSE: 0.9174\n",
      "Epoch 44 Step 30330: Train 0.4367 Reg: 0.4922\n",
      "Test: 0.8594 MAE: 0.7114 RMSE: 0.9270\n",
      "Val: 0.8435 MAE: 0.7045 RMSE: 0.9184\n",
      "Epoch 45 Step 31004: Train 0.4349 Reg: 0.4880\n",
      "Test: 0.8637 MAE: 0.7131 RMSE: 0.9293\n",
      "Val: 0.8462 MAE: 0.7060 RMSE: 0.9199\n",
      "Epoch 46 Step 31678: Train 0.4330 Reg: 0.4840\n",
      "Test: 0.8693 MAE: 0.7160 RMSE: 0.9323\n",
      "Val: 0.8494 MAE: 0.7070 RMSE: 0.9216\n",
      "Epoch 47 Step 32352: Train 0.4314 Reg: 0.4802\n",
      "Test: 0.8733 MAE: 0.7157 RMSE: 0.9345\n",
      "Val: 0.8519 MAE: 0.7074 RMSE: 0.9230\n",
      "Epoch 48 Step 33026: Train 0.4297 Reg: 0.4765\n",
      "Test: 0.8740 MAE: 0.7167 RMSE: 0.9349\n",
      "Val: 0.8544 MAE: 0.7081 RMSE: 0.9244\n",
      "Epoch 49 Step 33700: Train 0.4282 Reg: 0.4729\n",
      "Test: 0.8800 MAE: 0.7198 RMSE: 0.9381\n",
      "Val: 0.8562 MAE: 0.7094 RMSE: 0.9253\n",
      "Epoch 50 Step 34374: Train 0.4266 Reg: 0.4694\n",
      "Test: 0.8819 MAE: 0.7195 RMSE: 0.9391\n",
      "Val: 0.8594 MAE: 0.7101 RMSE: 0.9271\n",
      "Epoch 51 Step 35048: Train 0.4252 Reg: 0.4661\n",
      "Test: 0.8852 MAE: 0.7189 RMSE: 0.9408\n",
      "Val: 0.8620 MAE: 0.7103 RMSE: 0.9285\n",
      "Epoch 52 Step 35722: Train 0.4237 Reg: 0.4630\n",
      "Test: 0.8885 MAE: 0.7200 RMSE: 0.9426\n",
      "Val: 0.8639 MAE: 0.7113 RMSE: 0.9295\n",
      "Epoch 53 Step 36396: Train 0.4224 Reg: 0.4600\n",
      "Test: 0.8916 MAE: 0.7218 RMSE: 0.9442\n",
      "Val: 0.8656 MAE: 0.7123 RMSE: 0.9304\n",
      "Epoch 54 Step 37070: Train 0.4211 Reg: 0.4570\n",
      "Test: 0.8958 MAE: 0.7239 RMSE: 0.9465\n",
      "Val: 0.8683 MAE: 0.7133 RMSE: 0.9318\n",
      "Epoch 55 Step 37744: Train 0.4198 Reg: 0.4542\n",
      "Test: 0.9002 MAE: 0.7248 RMSE: 0.9488\n",
      "Val: 0.8701 MAE: 0.7132 RMSE: 0.9328\n",
      "Epoch 56 Step 38418: Train 0.4186 Reg: 0.4515\n",
      "Test: 0.9022 MAE: 0.7261 RMSE: 0.9498\n",
      "Val: 0.8718 MAE: 0.7141 RMSE: 0.9337\n",
      "Epoch 57 Step 39092: Train 0.4175 Reg: 0.4490\n",
      "Test: 0.9050 MAE: 0.7268 RMSE: 0.9513\n",
      "Val: 0.8740 MAE: 0.7145 RMSE: 0.9349\n",
      "Epoch 58 Step 39766: Train 0.4164 Reg: 0.4465\n",
      "Test: 0.9068 MAE: 0.7274 RMSE: 0.9523\n",
      "Val: 0.8749 MAE: 0.7151 RMSE: 0.9353\n",
      "Epoch 59 Step 40440: Train 0.4152 Reg: 0.4442\n",
      "Test: 0.9107 MAE: 0.7284 RMSE: 0.9543\n",
      "Val: 0.8761 MAE: 0.7152 RMSE: 0.9360\n",
      "Epoch 60 Step 41114: Train 0.4143 Reg: 0.4418\n",
      "Test: 0.9138 MAE: 0.7307 RMSE: 0.9559\n",
      "Val: 0.8792 MAE: 0.7171 RMSE: 0.9377\n",
      "Epoch 61 Step 41788: Train 0.4132 Reg: 0.4398\n",
      "Test: 0.9163 MAE: 0.7320 RMSE: 0.9572\n",
      "Val: 0.8801 MAE: 0.7178 RMSE: 0.9381\n",
      "Epoch 62 Step 42462: Train 0.4123 Reg: 0.4376\n",
      "Test: 0.9175 MAE: 0.7316 RMSE: 0.9579\n",
      "Val: 0.8814 MAE: 0.7175 RMSE: 0.9388\n",
      "Epoch 63 Step 43136: Train 0.4114 Reg: 0.4357\n",
      "Test: 0.9199 MAE: 0.7327 RMSE: 0.9591\n",
      "Val: 0.8836 MAE: 0.7184 RMSE: 0.9400\n",
      "Epoch 64 Step 43810: Train 0.4106 Reg: 0.4338\n",
      "Test: 0.9239 MAE: 0.7344 RMSE: 0.9612\n",
      "Val: 0.8849 MAE: 0.7191 RMSE: 0.9407\n",
      "Epoch 65 Step 44484: Train 0.4097 Reg: 0.4320\n",
      "Test: 0.9240 MAE: 0.7330 RMSE: 0.9613\n",
      "Val: 0.8858 MAE: 0.7184 RMSE: 0.9412\n",
      "Epoch 66 Step 45158: Train 0.4089 Reg: 0.4303\n",
      "Test: 0.9264 MAE: 0.7348 RMSE: 0.9625\n",
      "Val: 0.8870 MAE: 0.7194 RMSE: 0.9418\n",
      "Epoch 67 Step 45832: Train 0.4081 Reg: 0.4287\n",
      "Test: 0.9270 MAE: 0.7348 RMSE: 0.9628\n",
      "Val: 0.8881 MAE: 0.7194 RMSE: 0.9424\n",
      "Epoch 68 Step 46506: Train 0.4073 Reg: 0.4271\n",
      "Test: 0.9291 MAE: 0.7350 RMSE: 0.9639\n",
      "Val: 0.8889 MAE: 0.7196 RMSE: 0.9428\n",
      "Epoch 69 Step 47180: Train 0.4066 Reg: 0.4255\n",
      "Test: 0.9319 MAE: 0.7363 RMSE: 0.9654\n",
      "Val: 0.8901 MAE: 0.7201 RMSE: 0.9435\n",
      "Epoch 70 Step 47854: Train 0.4060 Reg: 0.4241\n",
      "Test: 0.9328 MAE: 0.7365 RMSE: 0.9658\n",
      "Val: 0.8913 MAE: 0.7204 RMSE: 0.9441\n",
      "Epoch 71 Step 48528: Train 0.4053 Reg: 0.4227\n",
      "Test: 0.9340 MAE: 0.7370 RMSE: 0.9665\n",
      "Val: 0.8922 MAE: 0.7208 RMSE: 0.9445\n",
      "Epoch 72 Step 49202: Train 0.4047 Reg: 0.4214\n",
      "Test: 0.9356 MAE: 0.7371 RMSE: 0.9673\n",
      "Val: 0.8933 MAE: 0.7210 RMSE: 0.9451\n",
      "Epoch 73 Step 49876: Train 0.4041 Reg: 0.4202\n",
      "Test: 0.9376 MAE: 0.7384 RMSE: 0.9683\n",
      "Val: 0.8940 MAE: 0.7216 RMSE: 0.9455\n",
      "Epoch 74 Step 50550: Train 0.4035 Reg: 0.4190\n",
      "Test: 0.9378 MAE: 0.7376 RMSE: 0.9684\n",
      "Val: 0.8949 MAE: 0.7213 RMSE: 0.9460\n",
      "Epoch 75 Step 51224: Train 0.4030 Reg: 0.4178\n",
      "Test: 0.9396 MAE: 0.7393 RMSE: 0.9693\n",
      "Val: 0.8959 MAE: 0.7224 RMSE: 0.9465\n",
      "Epoch 76 Step 51898: Train 0.4025 Reg: 0.4168\n",
      "Test: 0.9407 MAE: 0.7393 RMSE: 0.9699\n",
      "Val: 0.8963 MAE: 0.7220 RMSE: 0.9467\n",
      "Epoch 77 Step 52572: Train 0.4020 Reg: 0.4158\n",
      "Test: 0.9415 MAE: 0.7396 RMSE: 0.9703\n",
      "Val: 0.8971 MAE: 0.7225 RMSE: 0.9472\n",
      "Epoch 78 Step 53246: Train 0.4015 Reg: 0.4148\n",
      "Test: 0.9434 MAE: 0.7399 RMSE: 0.9713\n",
      "Val: 0.8977 MAE: 0.7225 RMSE: 0.9475\n",
      "Epoch 79 Step 53920: Train 0.4011 Reg: 0.4138\n",
      "Test: 0.9440 MAE: 0.7406 RMSE: 0.9716\n",
      "Val: 0.8986 MAE: 0.7232 RMSE: 0.9480\n",
      "Epoch 80 Step 54594: Train 0.4006 Reg: 0.4129\n",
      "Test: 0.9449 MAE: 0.7407 RMSE: 0.9721\n",
      "Val: 0.8992 MAE: 0.7231 RMSE: 0.9483\n",
      "Epoch 81 Step 55268: Train 0.4002 Reg: 0.4121\n",
      "Test: 0.9468 MAE: 0.7413 RMSE: 0.9731\n",
      "Val: 0.8999 MAE: 0.7235 RMSE: 0.9486\n",
      "Epoch 82 Step 55942: Train 0.3998 Reg: 0.4113\n",
      "Test: 0.9467 MAE: 0.7408 RMSE: 0.9730\n",
      "Val: 0.9003 MAE: 0.7233 RMSE: 0.9488\n",
      "Epoch 83 Step 56616: Train 0.3994 Reg: 0.4105\n",
      "Test: 0.9474 MAE: 0.7410 RMSE: 0.9733\n",
      "Val: 0.9009 MAE: 0.7234 RMSE: 0.9491\n",
      "Epoch 84 Step 57290: Train 0.3991 Reg: 0.4098\n",
      "Test: 0.9485 MAE: 0.7412 RMSE: 0.9739\n",
      "Val: 0.9013 MAE: 0.7234 RMSE: 0.9494\n",
      "Epoch 85 Step 57964: Train 0.3987 Reg: 0.4091\n",
      "Test: 0.9492 MAE: 0.7416 RMSE: 0.9743\n",
      "Val: 0.9019 MAE: 0.7237 RMSE: 0.9497\n",
      "Epoch 86 Step 58638: Train 0.3984 Reg: 0.4084\n",
      "Test: 0.9502 MAE: 0.7421 RMSE: 0.9748\n",
      "Val: 0.9026 MAE: 0.7241 RMSE: 0.9500\n",
      "Epoch 87 Step 59312: Train 0.3981 Reg: 0.4078\n",
      "Test: 0.9513 MAE: 0.7430 RMSE: 0.9753\n",
      "Val: 0.9032 MAE: 0.7247 RMSE: 0.9504\n",
      "Epoch 88 Step 59986: Train 0.3978 Reg: 0.4072\n",
      "Test: 0.9511 MAE: 0.7423 RMSE: 0.9752\n",
      "Val: 0.9033 MAE: 0.7242 RMSE: 0.9504\n",
      "Epoch 89 Step 60660: Train 0.3975 Reg: 0.4066\n",
      "Test: 0.9525 MAE: 0.7432 RMSE: 0.9760\n",
      "Val: 0.9040 MAE: 0.7248 RMSE: 0.9508\n",
      "Epoch 90 Step 61334: Train 0.3972 Reg: 0.4061\n",
      "Test: 0.9526 MAE: 0.7426 RMSE: 0.9760\n",
      "Val: 0.9043 MAE: 0.7244 RMSE: 0.9509\n",
      "Epoch 91 Step 62008: Train 0.3969 Reg: 0.4056\n",
      "Test: 0.9531 MAE: 0.7429 RMSE: 0.9763\n",
      "Val: 0.9046 MAE: 0.7246 RMSE: 0.9511\n",
      "Epoch 92 Step 62682: Train 0.3967 Reg: 0.4051\n",
      "Test: 0.9539 MAE: 0.7431 RMSE: 0.9767\n",
      "Val: 0.9050 MAE: 0.7247 RMSE: 0.9513\n",
      "Epoch 93 Step 63356: Train 0.3965 Reg: 0.4046\n",
      "Test: 0.9545 MAE: 0.7436 RMSE: 0.9770\n",
      "Val: 0.9054 MAE: 0.7251 RMSE: 0.9515\n",
      "Epoch 94 Step 64030: Train 0.3962 Reg: 0.4042\n",
      "Test: 0.9548 MAE: 0.7437 RMSE: 0.9771\n",
      "Val: 0.9056 MAE: 0.7252 RMSE: 0.9516\n",
      "Epoch 95 Step 64704: Train 0.3960 Reg: 0.4037\n",
      "Test: 0.9552 MAE: 0.7435 RMSE: 0.9774\n",
      "Val: 0.9060 MAE: 0.7250 RMSE: 0.9518\n",
      "Epoch 96 Step 65378: Train 0.3958 Reg: 0.4033\n",
      "Test: 0.9562 MAE: 0.7442 RMSE: 0.9779\n",
      "Val: 0.9063 MAE: 0.7255 RMSE: 0.9520\n",
      "Epoch 97 Step 66052: Train 0.3956 Reg: 0.4030\n",
      "Test: 0.9565 MAE: 0.7442 RMSE: 0.9780\n",
      "Val: 0.9065 MAE: 0.7254 RMSE: 0.9521\n",
      "Epoch 98 Step 66726: Train 0.3954 Reg: 0.4026\n",
      "Test: 0.9566 MAE: 0.7437 RMSE: 0.9781\n",
      "Val: 0.9069 MAE: 0.7251 RMSE: 0.9523\n",
      "Epoch 99 Step 67400: Train 0.3953 Reg: 0.4022\n",
      "Test: 0.9572 MAE: 0.7443 RMSE: 0.9784\n",
      "Val: 0.9071 MAE: 0.7255 RMSE: 0.9524\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 726169/19100\n",
      "test set size: support/query 2092/809\n",
      "Epoch 0: TrainLoss 1.0457 RecLoss: 0.0000 (left: 0:09:12)\n",
      "TestLoss: 1.0695 MAE: 0.8146 RMSE: 1.0342\n",
      "ValLoss: 1.1218 MAE: 0.8448 RMSE: 1.0592\n",
      "Epoch 1: TrainLoss 1.0342 RecLoss: 0.0000 (left: 0:09:20)\n",
      "TestLoss: 1.0652 MAE: 0.8174 RMSE: 1.0321\n",
      "ValLoss: 1.1146 MAE: 0.8457 RMSE: 1.0557\n",
      "Epoch 2: TrainLoss 1.0284 RecLoss: 0.0000 (left: 0:08:55)\n",
      "TestLoss: 1.0622 MAE: 0.8195 RMSE: 1.0306\n",
      "ValLoss: 1.1113 MAE: 0.8465 RMSE: 1.0542\n",
      "Epoch 3: TrainLoss 1.0254 RecLoss: 0.0000 (left: 0:08:54)\n",
      "TestLoss: 1.0592 MAE: 0.8089 RMSE: 1.0292\n",
      "ValLoss: 1.1141 MAE: 0.8412 RMSE: 1.0555\n",
      "Epoch 4: TrainLoss 1.0217 RecLoss: 0.0000 (left: 0:08:50)\n",
      "TestLoss: 1.0571 MAE: 0.8197 RMSE: 1.0282\n",
      "ValLoss: 1.1065 MAE: 0.8457 RMSE: 1.0519\n",
      "Epoch 5: TrainLoss 1.0172 RecLoss: 0.0000 (left: 0:08:35)\n",
      "TestLoss: 1.0532 MAE: 0.8166 RMSE: 1.0263\n",
      "ValLoss: 1.1028 MAE: 0.8435 RMSE: 1.0501\n",
      "Epoch 6: TrainLoss 1.0117 RecLoss: 0.0000 (left: 0:08:31)\n",
      "TestLoss: 1.0510 MAE: 0.8060 RMSE: 1.0252\n",
      "ValLoss: 1.1039 MAE: 0.8380 RMSE: 1.0507\n",
      "Epoch 7: TrainLoss 1.0084 RecLoss: 0.0000 (left: 0:08:20)\n",
      "TestLoss: 1.0470 MAE: 0.8080 RMSE: 1.0232\n",
      "ValLoss: 1.0985 MAE: 0.8385 RMSE: 1.0481\n",
      "Epoch 8: TrainLoss 1.0057 RecLoss: 0.0000 (left: 0:08:13)\n",
      "TestLoss: 1.0449 MAE: 0.8112 RMSE: 1.0222\n",
      "ValLoss: 1.0954 MAE: 0.8395 RMSE: 1.0466\n",
      "Epoch 9: TrainLoss 1.0030 RecLoss: 0.0000 (left: 0:08:01)\n",
      "TestLoss: 1.0467 MAE: 0.8019 RMSE: 1.0231\n",
      "ValLoss: 1.1007 MAE: 0.8348 RMSE: 1.0491\n",
      "Epoch 10: TrainLoss 0.9977 RecLoss: 0.0000 (left: 0:07:55)\n",
      "TestLoss: 1.0400 MAE: 0.8050 RMSE: 1.0198\n",
      "ValLoss: 1.0907 MAE: 0.8347 RMSE: 1.0444\n",
      "Epoch 11: TrainLoss 0.9947 RecLoss: 0.0000 (left: 0:07:49)\n",
      "TestLoss: 1.0394 MAE: 0.8116 RMSE: 1.0195\n",
      "ValLoss: 1.0883 MAE: 0.8384 RMSE: 1.0432\n",
      "Epoch 12: TrainLoss 0.9918 RecLoss: 0.0000 (left: 0:07:43)\n",
      "TestLoss: 1.0359 MAE: 0.8044 RMSE: 1.0178\n",
      "ValLoss: 1.0859 MAE: 0.8338 RMSE: 1.0421\n",
      "Epoch 13: TrainLoss 0.9890 RecLoss: 0.0000 (left: 0:07:43)\n",
      "TestLoss: 1.0356 MAE: 0.8012 RMSE: 1.0176\n",
      "ValLoss: 1.0865 MAE: 0.8318 RMSE: 1.0423\n",
      "Epoch 14: TrainLoss 0.9854 RecLoss: 0.0000 (left: 0:07:38)\n",
      "TestLoss: 1.0332 MAE: 0.8080 RMSE: 1.0165\n",
      "ValLoss: 1.0817 MAE: 0.8355 RMSE: 1.0400\n",
      "Epoch 15: TrainLoss 0.9823 RecLoss: 0.0000 (left: 0:07:34)\n",
      "TestLoss: 1.0300 MAE: 0.8028 RMSE: 1.0149\n",
      "ValLoss: 1.0801 MAE: 0.8319 RMSE: 1.0393\n",
      "Epoch 16: TrainLoss 0.9796 RecLoss: 0.0000 (left: 0:07:28)\n",
      "TestLoss: 1.0287 MAE: 0.8048 RMSE: 1.0143\n",
      "ValLoss: 1.0767 MAE: 0.8326 RMSE: 1.0376\n",
      "Epoch 17: TrainLoss 0.9776 RecLoss: 0.0000 (left: 0:07:22)\n",
      "TestLoss: 1.0285 MAE: 0.7977 RMSE: 1.0141\n",
      "ValLoss: 1.0805 MAE: 0.8291 RMSE: 1.0395\n",
      "Epoch 18: TrainLoss 0.9748 RecLoss: 0.0000 (left: 0:07:17)\n",
      "TestLoss: 1.0257 MAE: 0.8002 RMSE: 1.0128\n",
      "ValLoss: 1.0749 MAE: 0.8290 RMSE: 1.0368\n",
      "Epoch 19: TrainLoss 0.9727 RecLoss: 0.0000 (left: 0:07:09)\n",
      "TestLoss: 1.0240 MAE: 0.8033 RMSE: 1.0119\n",
      "ValLoss: 1.0721 MAE: 0.8313 RMSE: 1.0354\n",
      "Epoch 20: TrainLoss 0.9703 RecLoss: 0.0000 (left: 0:07:01)\n",
      "TestLoss: 1.0228 MAE: 0.7980 RMSE: 1.0113\n",
      "ValLoss: 1.0724 MAE: 0.8280 RMSE: 1.0356\n",
      "Epoch 21: TrainLoss 0.9677 RecLoss: 0.0000 (left: 0:06:56)\n",
      "TestLoss: 1.0232 MAE: 0.8062 RMSE: 1.0115\n",
      "ValLoss: 1.0681 MAE: 0.8321 RMSE: 1.0335\n",
      "Epoch 22: TrainLoss 0.9669 RecLoss: 0.0000 (left: 0:06:50)\n",
      "TestLoss: 1.0202 MAE: 0.7974 RMSE: 1.0100\n",
      "ValLoss: 1.0688 MAE: 0.8266 RMSE: 1.0338\n",
      "Epoch 23: TrainLoss 0.9634 RecLoss: 0.0000 (left: 0:06:45)\n",
      "TestLoss: 1.0222 MAE: 0.8076 RMSE: 1.0111\n",
      "ValLoss: 1.0672 MAE: 0.8333 RMSE: 1.0330\n",
      "Epoch 24: TrainLoss 0.9639 RecLoss: 0.0000 (left: 0:06:41)\n",
      "TestLoss: 1.0176 MAE: 0.8005 RMSE: 1.0088\n",
      "ValLoss: 1.0637 MAE: 0.8279 RMSE: 1.0314\n",
      "Epoch 25: TrainLoss 0.9590 RecLoss: 0.0000 (left: 0:06:37)\n",
      "TestLoss: 1.0174 MAE: 0.8019 RMSE: 1.0087\n",
      "ValLoss: 1.0618 MAE: 0.8281 RMSE: 1.0304\n",
      "Epoch 26: TrainLoss 0.9581 RecLoss: 0.0000 (left: 0:06:33)\n",
      "TestLoss: 1.0158 MAE: 0.8014 RMSE: 1.0079\n",
      "ValLoss: 1.0615 MAE: 0.8284 RMSE: 1.0303\n",
      "Epoch 27: TrainLoss 0.9554 RecLoss: 0.0000 (left: 0:06:27)\n",
      "TestLoss: 1.0134 MAE: 0.7988 RMSE: 1.0067\n",
      "ValLoss: 1.0605 MAE: 0.8267 RMSE: 1.0298\n",
      "Epoch 28: TrainLoss 0.9546 RecLoss: 0.0000 (left: 0:06:23)\n",
      "TestLoss: 1.0136 MAE: 0.8004 RMSE: 1.0068\n",
      "ValLoss: 1.0587 MAE: 0.8272 RMSE: 1.0289\n",
      "Epoch 29: TrainLoss 0.9520 RecLoss: 0.0000 (left: 0:06:20)\n",
      "TestLoss: 1.0119 MAE: 0.7981 RMSE: 1.0059\n",
      "ValLoss: 1.0574 MAE: 0.8254 RMSE: 1.0283\n",
      "Epoch 30: TrainLoss 0.9513 RecLoss: 0.0000 (left: 0:06:15)\n",
      "TestLoss: 1.0115 MAE: 0.7923 RMSE: 1.0057\n",
      "ValLoss: 1.0616 MAE: 0.8221 RMSE: 1.0303\n",
      "Epoch 31: TrainLoss 0.9496 RecLoss: 0.0000 (left: 0:06:10)\n",
      "TestLoss: 1.0105 MAE: 0.7930 RMSE: 1.0052\n",
      "ValLoss: 1.0580 MAE: 0.8219 RMSE: 1.0286\n",
      "Epoch 32: TrainLoss 0.9469 RecLoss: 0.0000 (left: 0:06:04)\n",
      "TestLoss: 1.0088 MAE: 0.7951 RMSE: 1.0044\n",
      "ValLoss: 1.0553 MAE: 0.8232 RMSE: 1.0273\n",
      "Epoch 33: TrainLoss 0.9454 RecLoss: 0.0000 (left: 0:06:00)\n",
      "TestLoss: 1.0082 MAE: 0.7951 RMSE: 1.0041\n",
      "ValLoss: 1.0541 MAE: 0.8229 RMSE: 1.0267\n",
      "Epoch 34: TrainLoss 0.9448 RecLoss: 0.0000 (left: 0:05:54)\n",
      "TestLoss: 1.0073 MAE: 0.7929 RMSE: 1.0036\n",
      "ValLoss: 1.0540 MAE: 0.8212 RMSE: 1.0267\n",
      "Epoch 35: TrainLoss 0.9436 RecLoss: 0.0000 (left: 0:05:48)\n",
      "TestLoss: 1.0064 MAE: 0.7933 RMSE: 1.0032\n",
      "ValLoss: 1.0530 MAE: 0.8214 RMSE: 1.0262\n",
      "Epoch 36: TrainLoss 0.9413 RecLoss: 0.0000 (left: 0:05:42)\n",
      "TestLoss: 1.0063 MAE: 0.7970 RMSE: 1.0032\n",
      "ValLoss: 1.0511 MAE: 0.8237 RMSE: 1.0252\n",
      "Epoch 37: TrainLoss 0.9401 RecLoss: 0.0000 (left: 0:05:36)\n",
      "TestLoss: 1.0052 MAE: 0.7927 RMSE: 1.0026\n",
      "ValLoss: 1.0510 MAE: 0.8203 RMSE: 1.0252\n",
      "Epoch 38: TrainLoss 0.9388 RecLoss: 0.0000 (left: 0:05:30)\n",
      "TestLoss: 1.0043 MAE: 0.7948 RMSE: 1.0022\n",
      "ValLoss: 1.0494 MAE: 0.8220 RMSE: 1.0244\n",
      "Epoch 39: TrainLoss 0.9376 RecLoss: 0.0000 (left: 0:05:25)\n",
      "TestLoss: 1.0033 MAE: 0.7932 RMSE: 1.0017\n",
      "ValLoss: 1.0487 MAE: 0.8204 RMSE: 1.0241\n",
      "Epoch 40: TrainLoss 0.9359 RecLoss: 0.0000 (left: 0:05:21)\n",
      "TestLoss: 1.0030 MAE: 0.7917 RMSE: 1.0015\n",
      "ValLoss: 1.0491 MAE: 0.8194 RMSE: 1.0242\n",
      "Epoch 41: TrainLoss 0.9347 RecLoss: 0.0000 (left: 0:05:15)\n",
      "TestLoss: 1.0026 MAE: 0.7951 RMSE: 1.0013\n",
      "ValLoss: 1.0470 MAE: 0.8219 RMSE: 1.0232\n",
      "Epoch 42: TrainLoss 0.9345 RecLoss: 0.0000 (left: 0:05:08)\n",
      "TestLoss: 1.0017 MAE: 0.7930 RMSE: 1.0008\n",
      "ValLoss: 1.0470 MAE: 0.8202 RMSE: 1.0232\n",
      "Epoch 43: TrainLoss 0.9341 RecLoss: 0.0000 (left: 0:05:01)\n",
      "TestLoss: 1.0028 MAE: 0.7974 RMSE: 1.0014\n",
      "ValLoss: 1.0451 MAE: 0.8231 RMSE: 1.0223\n",
      "Epoch 44: TrainLoss 0.9331 RecLoss: 0.0000 (left: 0:04:56)\n",
      "TestLoss: 1.0026 MAE: 0.7969 RMSE: 1.0013\n",
      "ValLoss: 1.0450 MAE: 0.8224 RMSE: 1.0222\n",
      "Epoch 45: TrainLoss 0.9306 RecLoss: 0.0000 (left: 0:04:51)\n",
      "TestLoss: 1.0000 MAE: 0.7911 RMSE: 1.0000\n",
      "ValLoss: 1.0454 MAE: 0.8182 RMSE: 1.0225\n",
      "Epoch 46: TrainLoss 0.9293 RecLoss: 0.0000 (left: 0:04:45)\n",
      "TestLoss: 0.9997 MAE: 0.7937 RMSE: 0.9998\n",
      "ValLoss: 1.0434 MAE: 0.8199 RMSE: 1.0215\n",
      "Epoch 47: TrainLoss 0.9289 RecLoss: 0.0000 (left: 0:04:39)\n",
      "TestLoss: 1.0001 MAE: 0.7952 RMSE: 1.0000\n",
      "ValLoss: 1.0424 MAE: 0.8209 RMSE: 1.0210\n",
      "Epoch 48: TrainLoss 0.9302 RecLoss: 0.0000 (left: 0:04:34)\n",
      "TestLoss: 0.9987 MAE: 0.7930 RMSE: 0.9993\n",
      "ValLoss: 1.0421 MAE: 0.8193 RMSE: 1.0208\n",
      "Epoch 49: TrainLoss 0.9275 RecLoss: 0.0000 (left: 0:04:29)\n",
      "TestLoss: 0.9980 MAE: 0.7913 RMSE: 0.9990\n",
      "ValLoss: 1.0421 MAE: 0.8178 RMSE: 1.0208\n",
      "Epoch 50: TrainLoss 0.9258 RecLoss: 0.0000 (left: 0:04:25)\n",
      "TestLoss: 0.9981 MAE: 0.7913 RMSE: 0.9990\n",
      "ValLoss: 1.0415 MAE: 0.8174 RMSE: 1.0205\n",
      "Epoch 51: TrainLoss 0.9260 RecLoss: 0.0000 (left: 0:04:20)\n",
      "TestLoss: 0.9977 MAE: 0.7883 RMSE: 0.9988\n",
      "ValLoss: 1.0429 MAE: 0.8157 RMSE: 1.0212\n",
      "Epoch 52: TrainLoss 0.9238 RecLoss: 0.0000 (left: 0:04:15)\n",
      "TestLoss: 0.9966 MAE: 0.7899 RMSE: 0.9983\n",
      "ValLoss: 1.0415 MAE: 0.8168 RMSE: 1.0205\n",
      "Epoch 53: TrainLoss 0.9232 RecLoss: 0.0000 (left: 0:04:09)\n",
      "TestLoss: 0.9965 MAE: 0.7927 RMSE: 0.9982\n",
      "ValLoss: 1.0400 MAE: 0.8189 RMSE: 1.0198\n",
      "Epoch 54: TrainLoss 0.9226 RecLoss: 0.0000 (left: 0:04:04)\n",
      "TestLoss: 0.9956 MAE: 0.7894 RMSE: 0.9978\n",
      "ValLoss: 1.0398 MAE: 0.8161 RMSE: 1.0197\n",
      "Epoch 55: TrainLoss 0.9216 RecLoss: 0.0000 (left: 0:03:58)\n",
      "TestLoss: 0.9961 MAE: 0.7929 RMSE: 0.9981\n",
      "ValLoss: 1.0390 MAE: 0.8189 RMSE: 1.0193\n",
      "Epoch 56: TrainLoss 0.9215 RecLoss: 0.0000 (left: 0:03:53)\n",
      "TestLoss: 0.9978 MAE: 0.7965 RMSE: 0.9989\n",
      "ValLoss: 1.0394 MAE: 0.8217 RMSE: 1.0195\n",
      "Epoch 57: TrainLoss 0.9217 RecLoss: 0.0000 (left: 0:03:47)\n",
      "TestLoss: 0.9967 MAE: 0.7949 RMSE: 0.9983\n",
      "ValLoss: 1.0381 MAE: 0.8201 RMSE: 1.0189\n",
      "Epoch 58: TrainLoss 0.9210 RecLoss: 0.0000 (left: 0:03:41)\n",
      "TestLoss: 0.9950 MAE: 0.7881 RMSE: 0.9975\n",
      "ValLoss: 1.0390 MAE: 0.8148 RMSE: 1.0193\n",
      "Epoch 59: TrainLoss 0.9190 RecLoss: 0.0000 (left: 0:03:36)\n",
      "TestLoss: 0.9964 MAE: 0.7845 RMSE: 0.9982\n",
      "ValLoss: 1.0432 MAE: 0.8128 RMSE: 1.0214\n",
      "Epoch 60: TrainLoss 0.9188 RecLoss: 0.0000 (left: 0:03:31)\n",
      "TestLoss: 0.9943 MAE: 0.7887 RMSE: 0.9971\n",
      "ValLoss: 1.0377 MAE: 0.8151 RMSE: 1.0187\n",
      "Epoch 61: TrainLoss 0.9174 RecLoss: 0.0000 (left: 0:03:25)\n",
      "TestLoss: 0.9935 MAE: 0.7899 RMSE: 0.9967\n",
      "ValLoss: 1.0365 MAE: 0.8159 RMSE: 1.0181\n",
      "Epoch 62: TrainLoss 0.9171 RecLoss: 0.0000 (left: 0:03:20)\n",
      "TestLoss: 0.9936 MAE: 0.7916 RMSE: 0.9968\n",
      "ValLoss: 1.0357 MAE: 0.8171 RMSE: 1.0177\n",
      "Epoch 63: TrainLoss 0.9158 RecLoss: 0.0000 (left: 0:03:14)\n",
      "TestLoss: 0.9931 MAE: 0.7875 RMSE: 0.9965\n",
      "ValLoss: 1.0371 MAE: 0.8143 RMSE: 1.0184\n",
      "Epoch 64: TrainLoss 0.9154 RecLoss: 0.0000 (left: 0:03:08)\n",
      "TestLoss: 0.9928 MAE: 0.7890 RMSE: 0.9964\n",
      "ValLoss: 1.0364 MAE: 0.8155 RMSE: 1.0180\n",
      "Epoch 65: TrainLoss 0.9156 RecLoss: 0.0000 (left: 0:03:03)\n",
      "TestLoss: 0.9944 MAE: 0.7850 RMSE: 0.9972\n",
      "ValLoss: 1.0394 MAE: 0.8124 RMSE: 1.0195\n",
      "Epoch 66: TrainLoss 0.9148 RecLoss: 0.0000 (left: 0:02:58)\n",
      "TestLoss: 0.9920 MAE: 0.7883 RMSE: 0.9960\n",
      "ValLoss: 1.0352 MAE: 0.8146 RMSE: 1.0174\n",
      "Epoch 67: TrainLoss 0.9138 RecLoss: 0.0000 (left: 0:02:53)\n",
      "TestLoss: 0.9939 MAE: 0.7942 RMSE: 0.9969\n",
      "ValLoss: 1.0350 MAE: 0.8191 RMSE: 1.0173\n",
      "Epoch 68: TrainLoss 0.9140 RecLoss: 0.0000 (left: 0:02:47)\n",
      "TestLoss: 0.9936 MAE: 0.7936 RMSE: 0.9968\n",
      "ValLoss: 1.0343 MAE: 0.8183 RMSE: 1.0170\n",
      "Epoch 69: TrainLoss 0.9129 RecLoss: 0.0000 (left: 0:02:42)\n",
      "TestLoss: 0.9917 MAE: 0.7875 RMSE: 0.9958\n",
      "ValLoss: 1.0350 MAE: 0.8139 RMSE: 1.0174\n",
      "Epoch 70: TrainLoss 0.9127 RecLoss: 0.0000 (left: 0:02:37)\n",
      "TestLoss: 0.9921 MAE: 0.7854 RMSE: 0.9960\n",
      "ValLoss: 1.0364 MAE: 0.8124 RMSE: 1.0180\n",
      "Epoch 71: TrainLoss 0.9116 RecLoss: 0.0000 (left: 0:02:32)\n",
      "TestLoss: 0.9931 MAE: 0.7938 RMSE: 0.9966\n",
      "ValLoss: 1.0339 MAE: 0.8185 RMSE: 1.0168\n",
      "Epoch 72: TrainLoss 0.9115 RecLoss: 0.0000 (left: 0:02:26)\n",
      "TestLoss: 0.9914 MAE: 0.7856 RMSE: 0.9957\n",
      "ValLoss: 1.0356 MAE: 0.8125 RMSE: 1.0176\n",
      "Epoch 73: TrainLoss 0.9108 RecLoss: 0.0000 (left: 0:02:21)\n",
      "TestLoss: 0.9910 MAE: 0.7896 RMSE: 0.9955\n",
      "ValLoss: 1.0331 MAE: 0.8152 RMSE: 1.0164\n",
      "Epoch 74: TrainLoss 0.9110 RecLoss: 0.0000 (left: 0:02:15)\n",
      "TestLoss: 0.9904 MAE: 0.7880 RMSE: 0.9952\n",
      "ValLoss: 1.0330 MAE: 0.8139 RMSE: 1.0164\n",
      "Epoch 75: TrainLoss 0.9101 RecLoss: 0.0000 (left: 0:02:10)\n",
      "TestLoss: 0.9916 MAE: 0.7848 RMSE: 0.9958\n",
      "ValLoss: 1.0358 MAE: 0.8118 RMSE: 1.0178\n",
      "Epoch 76: TrainLoss 0.9092 RecLoss: 0.0000 (left: 0:02:05)\n",
      "TestLoss: 0.9905 MAE: 0.7881 RMSE: 0.9953\n",
      "ValLoss: 1.0330 MAE: 0.8139 RMSE: 1.0164\n",
      "Epoch 77: TrainLoss 0.9087 RecLoss: 0.0000 (left: 0:01:59)\n",
      "TestLoss: 0.9910 MAE: 0.7851 RMSE: 0.9955\n",
      "ValLoss: 1.0344 MAE: 0.8117 RMSE: 1.0171\n",
      "Epoch 78: TrainLoss 0.9086 RecLoss: 0.0000 (left: 0:01:54)\n",
      "TestLoss: 0.9901 MAE: 0.7884 RMSE: 0.9950\n",
      "ValLoss: 1.0323 MAE: 0.8141 RMSE: 1.0160\n",
      "Epoch 79: TrainLoss 0.9081 RecLoss: 0.0000 (left: 0:01:49)\n",
      "TestLoss: 0.9905 MAE: 0.7898 RMSE: 0.9952\n",
      "ValLoss: 1.0319 MAE: 0.8150 RMSE: 1.0158\n",
      "Epoch 80: TrainLoss 0.9073 RecLoss: 0.0000 (left: 0:01:44)\n",
      "TestLoss: 0.9911 MAE: 0.7841 RMSE: 0.9955\n",
      "ValLoss: 1.0352 MAE: 0.8113 RMSE: 1.0175\n",
      "Epoch 81: TrainLoss 0.9073 RecLoss: 0.0000 (left: 0:01:38)\n",
      "TestLoss: 0.9897 MAE: 0.7862 RMSE: 0.9948\n",
      "ValLoss: 1.0327 MAE: 0.8124 RMSE: 1.0162\n",
      "Epoch 82: TrainLoss 0.9078 RecLoss: 0.0000 (left: 0:01:33)\n",
      "TestLoss: 0.9894 MAE: 0.7883 RMSE: 0.9947\n",
      "ValLoss: 1.0314 MAE: 0.8138 RMSE: 1.0156\n",
      "Epoch 83: TrainLoss 0.9064 RecLoss: 0.0000 (left: 0:01:28)\n",
      "TestLoss: 0.9898 MAE: 0.7906 RMSE: 0.9949\n",
      "ValLoss: 1.0313 MAE: 0.8157 RMSE: 1.0155\n",
      "Epoch 84: TrainLoss 0.9062 RecLoss: 0.0000 (left: 0:01:23)\n",
      "TestLoss: 0.9894 MAE: 0.7884 RMSE: 0.9947\n",
      "ValLoss: 1.0315 MAE: 0.8139 RMSE: 1.0156\n",
      "Epoch 85: TrainLoss 0.9061 RecLoss: 0.0000 (left: 0:01:17)\n",
      "TestLoss: 0.9893 MAE: 0.7891 RMSE: 0.9947\n",
      "ValLoss: 1.0310 MAE: 0.8145 RMSE: 1.0154\n",
      "Epoch 86: TrainLoss 0.9054 RecLoss: 0.0000 (left: 0:01:12)\n",
      "TestLoss: 0.9892 MAE: 0.7863 RMSE: 0.9946\n",
      "ValLoss: 1.0318 MAE: 0.8121 RMSE: 1.0158\n",
      "Epoch 87: TrainLoss 0.9046 RecLoss: 0.0000 (left: 0:01:07)\n",
      "TestLoss: 0.9897 MAE: 0.7908 RMSE: 0.9949\n",
      "ValLoss: 1.0302 MAE: 0.8154 RMSE: 1.0150\n",
      "Epoch 88: TrainLoss 0.9050 RecLoss: 0.0000 (left: 0:01:02)\n",
      "TestLoss: 0.9891 MAE: 0.7853 RMSE: 0.9946\n",
      "ValLoss: 1.0320 MAE: 0.8114 RMSE: 1.0159\n",
      "Epoch 89: TrainLoss 0.9040 RecLoss: 0.0000 (left: 0:00:57)\n",
      "TestLoss: 0.9886 MAE: 0.7857 RMSE: 0.9943\n",
      "ValLoss: 1.0315 MAE: 0.8118 RMSE: 1.0156\n",
      "Epoch 90: TrainLoss 0.9042 RecLoss: 0.0000 (left: 0:00:51)\n",
      "TestLoss: 0.9886 MAE: 0.7851 RMSE: 0.9943\n",
      "ValLoss: 1.0321 MAE: 0.8115 RMSE: 1.0159\n",
      "Epoch 91: TrainLoss 0.9036 RecLoss: 0.0000 (left: 0:00:46)\n",
      "TestLoss: 0.9910 MAE: 0.7819 RMSE: 0.9955\n",
      "ValLoss: 1.0359 MAE: 0.8093 RMSE: 1.0178\n",
      "Epoch 92: TrainLoss 0.9047 RecLoss: 0.0000 (left: 0:00:41)\n",
      "TestLoss: 0.9898 MAE: 0.7836 RMSE: 0.9949\n",
      "ValLoss: 1.0333 MAE: 0.8103 RMSE: 1.0165\n",
      "Epoch 93: TrainLoss 0.9031 RecLoss: 0.0000 (left: 0:00:36)\n",
      "TestLoss: 0.9883 MAE: 0.7866 RMSE: 0.9941\n",
      "ValLoss: 1.0306 MAE: 0.8124 RMSE: 1.0152\n",
      "Epoch 94: TrainLoss 0.9028 RecLoss: 0.0000 (left: 0:00:31)\n",
      "TestLoss: 0.9882 MAE: 0.7867 RMSE: 0.9941\n",
      "ValLoss: 1.0302 MAE: 0.8121 RMSE: 1.0150\n",
      "Epoch 95: TrainLoss 0.9024 RecLoss: 0.0000 (left: 0:00:26)\n",
      "TestLoss: 0.9883 MAE: 0.7885 RMSE: 0.9941\n",
      "ValLoss: 1.0298 MAE: 0.8137 RMSE: 1.0148\n",
      "Epoch 96: TrainLoss 0.9021 RecLoss: 0.0000 (left: 0:00:20)\n",
      "TestLoss: 0.9880 MAE: 0.7859 RMSE: 0.9940\n",
      "ValLoss: 1.0304 MAE: 0.8118 RMSE: 1.0151\n",
      "Epoch 97: TrainLoss 0.9015 RecLoss: 0.0000 (left: 0:00:15)\n",
      "TestLoss: 0.9881 MAE: 0.7880 RMSE: 0.9940\n",
      "ValLoss: 1.0297 MAE: 0.8133 RMSE: 1.0147\n",
      "Epoch 98: TrainLoss 0.9013 RecLoss: 0.0000 (left: 0:00:10)\n",
      "TestLoss: 0.9880 MAE: 0.7859 RMSE: 0.9940\n",
      "ValLoss: 1.0304 MAE: 0.8116 RMSE: 1.0151\n",
      "Epoch 99: TrainLoss 0.9015 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 0.9891 MAE: 0.7832 RMSE: 0.9945\n",
      "ValLoss: 1.0326 MAE: 0.8098 RMSE: 1.0162\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 726169/19100\n",
      "test set size: support/query 2092/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.6665 RMSE: 0.8490 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7880 RMSE: 0.9940 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7003 RMSE: 0.8918 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 60% optimal cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 838282/19100\n",
      "test set size: support/query 3138/809\n",
      "Epoch 0 Step 778: Train 1.5637 Reg: 0.6184\n",
      "Test: 0.9154 MAE: 0.7569 RMSE: 0.9568\n",
      "Val: 0.8492 MAE: 0.7298 RMSE: 0.9215\n",
      "Epoch 1 Step 1556: Train 0.8439 Reg: 0.4015\n",
      "Test: 0.9039 MAE: 0.7536 RMSE: 0.9507\n",
      "Val: 0.8439 MAE: 0.7266 RMSE: 0.9186\n",
      "Epoch 2 Step 2334: Train 0.8379 Reg: 0.3468\n",
      "Test: 0.8898 MAE: 0.7505 RMSE: 0.9433\n",
      "Val: 0.8397 MAE: 0.7252 RMSE: 0.9164\n",
      "Epoch 3 Step 3112: Train 0.8295 Reg: 0.2993\n",
      "Test: 0.8890 MAE: 0.7428 RMSE: 0.9429\n",
      "Val: 0.8290 MAE: 0.7180 RMSE: 0.9105\n",
      "Epoch 4 Step 3890: Train 0.8177 Reg: 0.2650\n",
      "Test: 0.8788 MAE: 0.7414 RMSE: 0.9374\n",
      "Val: 0.8171 MAE: 0.7142 RMSE: 0.9040\n",
      "Epoch 5 Step 4668: Train 0.8038 Reg: 0.2564\n",
      "Test: 0.8772 MAE: 0.7357 RMSE: 0.9366\n",
      "Val: 0.8036 MAE: 0.7058 RMSE: 0.8964\n",
      "Epoch 6 Step 5446: Train 0.7915 Reg: 0.2587\n",
      "Test: 0.8626 MAE: 0.7313 RMSE: 0.9287\n",
      "Val: 0.7969 MAE: 0.7028 RMSE: 0.8927\n",
      "Epoch 7 Step 6224: Train 0.7793 Reg: 0.2778\n",
      "Test: 0.8553 MAE: 0.7286 RMSE: 0.9248\n",
      "Val: 0.7830 MAE: 0.6974 RMSE: 0.8849\n",
      "Epoch 8 Step 7002: Train 0.7597 Reg: 0.3237\n",
      "Test: 0.8294 MAE: 0.7190 RMSE: 0.9107\n",
      "Val: 0.7606 MAE: 0.6854 RMSE: 0.8721\n",
      "Epoch 9 Step 7780: Train 0.7347 Reg: 0.3746\n",
      "Test: 0.8092 MAE: 0.7108 RMSE: 0.8996\n",
      "Val: 0.7462 MAE: 0.6790 RMSE: 0.8638\n",
      "Epoch 10 Step 8558: Train 0.7110 Reg: 0.4248\n",
      "Test: 0.7861 MAE: 0.6976 RMSE: 0.8866\n",
      "Val: 0.7297 MAE: 0.6698 RMSE: 0.8542\n",
      "Epoch 11 Step 9336: Train 0.6903 Reg: 0.4602\n",
      "Test: 0.7727 MAE: 0.6901 RMSE: 0.8790\n",
      "Val: 0.7174 MAE: 0.6636 RMSE: 0.8470\n",
      "Epoch 12 Step 10114: Train 0.6735 Reg: 0.4836\n",
      "Test: 0.7578 MAE: 0.6824 RMSE: 0.8705\n",
      "Val: 0.7109 MAE: 0.6594 RMSE: 0.8431\n",
      "Epoch 13 Step 10892: Train 0.6603 Reg: 0.4972\n",
      "Test: 0.7598 MAE: 0.6864 RMSE: 0.8717\n",
      "Val: 0.7070 MAE: 0.6582 RMSE: 0.8408\n",
      "Epoch 14 Step 11670: Train 0.6499 Reg: 0.5072\n",
      "Test: 0.7615 MAE: 0.6842 RMSE: 0.8726\n",
      "Val: 0.7067 MAE: 0.6564 RMSE: 0.8406\n",
      "Epoch 15 Step 12448: Train 0.6391 Reg: 0.5206\n",
      "Test: 0.7585 MAE: 0.6797 RMSE: 0.8709\n",
      "Val: 0.7047 MAE: 0.6553 RMSE: 0.8395\n",
      "Epoch 16 Step 13226: Train 0.6281 Reg: 0.5312\n",
      "Test: 0.7698 MAE: 0.6890 RMSE: 0.8774\n",
      "Val: 0.7046 MAE: 0.6565 RMSE: 0.8394\n",
      "Epoch 17 Step 14004: Train 0.6176 Reg: 0.5393\n",
      "Test: 0.7689 MAE: 0.6852 RMSE: 0.8769\n",
      "Val: 0.7048 MAE: 0.6560 RMSE: 0.8395\n",
      "Epoch 18 Step 14782: Train 0.6082 Reg: 0.5476\n",
      "Test: 0.7679 MAE: 0.6834 RMSE: 0.8763\n",
      "Val: 0.7059 MAE: 0.6551 RMSE: 0.8402\n",
      "Epoch 19 Step 15560: Train 0.5976 Reg: 0.5586\n",
      "Test: 0.7719 MAE: 0.6823 RMSE: 0.8786\n",
      "Val: 0.7079 MAE: 0.6539 RMSE: 0.8414\n",
      "Epoch 20 Step 16338: Train 0.5869 Reg: 0.5677\n",
      "Test: 0.7779 MAE: 0.6879 RMSE: 0.8820\n",
      "Val: 0.7094 MAE: 0.6572 RMSE: 0.8422\n",
      "Epoch 21 Step 17116: Train 0.5771 Reg: 0.5738\n",
      "Test: 0.7787 MAE: 0.6833 RMSE: 0.8825\n",
      "Val: 0.7146 MAE: 0.6578 RMSE: 0.8453\n",
      "Epoch 22 Step 17894: Train 0.5664 Reg: 0.5833\n",
      "Test: 0.7951 MAE: 0.6927 RMSE: 0.8917\n",
      "Val: 0.7184 MAE: 0.6593 RMSE: 0.8476\n",
      "Epoch 23 Step 18672: Train 0.5546 Reg: 0.5949\n",
      "Test: 0.7926 MAE: 0.6875 RMSE: 0.8903\n",
      "Val: 0.7227 MAE: 0.6602 RMSE: 0.8501\n",
      "Epoch 24 Step 19450: Train 0.5431 Reg: 0.6005\n",
      "Test: 0.8025 MAE: 0.6902 RMSE: 0.8958\n",
      "Val: 0.7278 MAE: 0.6616 RMSE: 0.8531\n",
      "Epoch 25 Step 20228: Train 0.5337 Reg: 0.6023\n",
      "Test: 0.8117 MAE: 0.6946 RMSE: 0.9010\n",
      "Val: 0.7336 MAE: 0.6644 RMSE: 0.8565\n",
      "Epoch 26 Step 21006: Train 0.5260 Reg: 0.6022\n",
      "Test: 0.8205 MAE: 0.7007 RMSE: 0.9058\n",
      "Val: 0.7406 MAE: 0.6683 RMSE: 0.8606\n",
      "Epoch 27 Step 21784: Train 0.5191 Reg: 0.6008\n",
      "Test: 0.8258 MAE: 0.6988 RMSE: 0.9087\n",
      "Val: 0.7444 MAE: 0.6688 RMSE: 0.8628\n",
      "Epoch 28 Step 22562: Train 0.5129 Reg: 0.5983\n",
      "Test: 0.8314 MAE: 0.6983 RMSE: 0.9118\n",
      "Val: 0.7500 MAE: 0.6690 RMSE: 0.8660\n",
      "Epoch 29 Step 23340: Train 0.5076 Reg: 0.5945\n",
      "Test: 0.8439 MAE: 0.7051 RMSE: 0.9187\n",
      "Val: 0.7565 MAE: 0.6738 RMSE: 0.8697\n",
      "Epoch 30 Step 24118: Train 0.5020 Reg: 0.5926\n",
      "Test: 0.8469 MAE: 0.7076 RMSE: 0.9203\n",
      "Val: 0.7594 MAE: 0.6741 RMSE: 0.8714\n",
      "Epoch 31 Step 24896: Train 0.4959 Reg: 0.5910\n",
      "Test: 0.8545 MAE: 0.7083 RMSE: 0.9244\n",
      "Val: 0.7665 MAE: 0.6764 RMSE: 0.8755\n",
      "Epoch 32 Step 25674: Train 0.4896 Reg: 0.5893\n",
      "Test: 0.8624 MAE: 0.7109 RMSE: 0.9287\n",
      "Val: 0.7702 MAE: 0.6771 RMSE: 0.8776\n",
      "Epoch 33 Step 26452: Train 0.4838 Reg: 0.5869\n",
      "Test: 0.8831 MAE: 0.7233 RMSE: 0.9397\n",
      "Val: 0.7803 MAE: 0.6842 RMSE: 0.8834\n",
      "Epoch 34 Step 27230: Train 0.4785 Reg: 0.5835\n",
      "Test: 0.8818 MAE: 0.7202 RMSE: 0.9390\n",
      "Val: 0.7815 MAE: 0.6825 RMSE: 0.8840\n",
      "Epoch 35 Step 28008: Train 0.4740 Reg: 0.5793\n",
      "Test: 0.8853 MAE: 0.7194 RMSE: 0.9409\n",
      "Val: 0.7851 MAE: 0.6820 RMSE: 0.8860\n",
      "Epoch 36 Step 28786: Train 0.4701 Reg: 0.5745\n",
      "Test: 0.8916 MAE: 0.7241 RMSE: 0.9442\n",
      "Val: 0.7906 MAE: 0.6859 RMSE: 0.8892\n",
      "Epoch 37 Step 29564: Train 0.4665 Reg: 0.5695\n",
      "Test: 0.9046 MAE: 0.7286 RMSE: 0.9511\n",
      "Val: 0.7949 MAE: 0.6877 RMSE: 0.8916\n",
      "Epoch 38 Step 30342: Train 0.4633 Reg: 0.5645\n",
      "Test: 0.9048 MAE: 0.7262 RMSE: 0.9512\n",
      "Val: 0.7982 MAE: 0.6877 RMSE: 0.8934\n",
      "Epoch 39 Step 31120: Train 0.4602 Reg: 0.5592\n",
      "Test: 0.9129 MAE: 0.7302 RMSE: 0.9555\n",
      "Val: 0.8023 MAE: 0.6897 RMSE: 0.8957\n",
      "Epoch 40 Step 31898: Train 0.4573 Reg: 0.5540\n",
      "Test: 0.9166 MAE: 0.7327 RMSE: 0.9574\n",
      "Val: 0.8067 MAE: 0.6910 RMSE: 0.8981\n",
      "Epoch 41 Step 32676: Train 0.4546 Reg: 0.5490\n",
      "Test: 0.9243 MAE: 0.7346 RMSE: 0.9614\n",
      "Val: 0.8090 MAE: 0.6913 RMSE: 0.8995\n",
      "Epoch 42 Step 33454: Train 0.4522 Reg: 0.5438\n",
      "Test: 0.9312 MAE: 0.7373 RMSE: 0.9650\n",
      "Val: 0.8134 MAE: 0.6930 RMSE: 0.9019\n",
      "Epoch 43 Step 34232: Train 0.4496 Reg: 0.5389\n",
      "Test: 0.9340 MAE: 0.7372 RMSE: 0.9664\n",
      "Val: 0.8163 MAE: 0.6944 RMSE: 0.9035\n",
      "Epoch 44 Step 35010: Train 0.4473 Reg: 0.5340\n",
      "Test: 0.9409 MAE: 0.7396 RMSE: 0.9700\n",
      "Val: 0.8204 MAE: 0.6958 RMSE: 0.9057\n",
      "Epoch 45 Step 35788: Train 0.4451 Reg: 0.5293\n",
      "Test: 0.9432 MAE: 0.7398 RMSE: 0.9712\n",
      "Val: 0.8231 MAE: 0.6963 RMSE: 0.9073\n",
      "Epoch 46 Step 36566: Train 0.4430 Reg: 0.5249\n",
      "Test: 0.9504 MAE: 0.7412 RMSE: 0.9749\n",
      "Val: 0.8244 MAE: 0.6963 RMSE: 0.9080\n",
      "Epoch 47 Step 37344: Train 0.4409 Reg: 0.5205\n",
      "Test: 0.9574 MAE: 0.7451 RMSE: 0.9785\n",
      "Val: 0.8301 MAE: 0.6987 RMSE: 0.9111\n",
      "Epoch 48 Step 38122: Train 0.4388 Reg: 0.5162\n",
      "Test: 0.9608 MAE: 0.7466 RMSE: 0.9802\n",
      "Val: 0.8322 MAE: 0.6994 RMSE: 0.9123\n",
      "Epoch 49 Step 38900: Train 0.4370 Reg: 0.5121\n",
      "Test: 0.9648 MAE: 0.7473 RMSE: 0.9822\n",
      "Val: 0.8344 MAE: 0.7003 RMSE: 0.9135\n",
      "Epoch 50 Step 39678: Train 0.4352 Reg: 0.5081\n",
      "Test: 0.9680 MAE: 0.7479 RMSE: 0.9839\n",
      "Val: 0.8374 MAE: 0.7017 RMSE: 0.9151\n",
      "Epoch 51 Step 40456: Train 0.4333 Reg: 0.5043\n",
      "Test: 0.9696 MAE: 0.7475 RMSE: 0.9847\n",
      "Val: 0.8391 MAE: 0.7011 RMSE: 0.9160\n",
      "Epoch 52 Step 41234: Train 0.4316 Reg: 0.5006\n",
      "Test: 0.9737 MAE: 0.7500 RMSE: 0.9867\n",
      "Val: 0.8416 MAE: 0.7022 RMSE: 0.9174\n",
      "Epoch 53 Step 42012: Train 0.4301 Reg: 0.4970\n",
      "Test: 0.9809 MAE: 0.7534 RMSE: 0.9904\n",
      "Val: 0.8458 MAE: 0.7051 RMSE: 0.9197\n",
      "Epoch 54 Step 42790: Train 0.4285 Reg: 0.4936\n",
      "Test: 0.9853 MAE: 0.7559 RMSE: 0.9926\n",
      "Val: 0.8484 MAE: 0.7064 RMSE: 0.9211\n",
      "Epoch 55 Step 43568: Train 0.4270 Reg: 0.4903\n",
      "Test: 0.9856 MAE: 0.7526 RMSE: 0.9928\n",
      "Val: 0.8489 MAE: 0.7040 RMSE: 0.9214\n",
      "Epoch 56 Step 44346: Train 0.4255 Reg: 0.4872\n",
      "Test: 0.9904 MAE: 0.7546 RMSE: 0.9952\n",
      "Val: 0.8511 MAE: 0.7055 RMSE: 0.9225\n",
      "Epoch 57 Step 45124: Train 0.4242 Reg: 0.4841\n",
      "Test: 0.9936 MAE: 0.7558 RMSE: 0.9968\n",
      "Val: 0.8533 MAE: 0.7062 RMSE: 0.9237\n",
      "Epoch 58 Step 45902: Train 0.4228 Reg: 0.4812\n",
      "Test: 0.9955 MAE: 0.7564 RMSE: 0.9978\n",
      "Val: 0.8549 MAE: 0.7066 RMSE: 0.9246\n",
      "Epoch 59 Step 46680: Train 0.4215 Reg: 0.4784\n",
      "Test: 0.9996 MAE: 0.7572 RMSE: 0.9998\n",
      "Val: 0.8570 MAE: 0.7071 RMSE: 0.9258\n",
      "Epoch 60 Step 47458: Train 0.4203 Reg: 0.4757\n",
      "Test: 1.0039 MAE: 0.7586 RMSE: 1.0020\n",
      "Val: 0.8590 MAE: 0.7080 RMSE: 0.9268\n",
      "Epoch 61 Step 48236: Train 0.4191 Reg: 0.4732\n",
      "Test: 1.0043 MAE: 0.7595 RMSE: 1.0022\n",
      "Val: 0.8610 MAE: 0.7087 RMSE: 0.9279\n",
      "Epoch 62 Step 49014: Train 0.4180 Reg: 0.4707\n",
      "Test: 1.0095 MAE: 0.7616 RMSE: 1.0047\n",
      "Val: 0.8624 MAE: 0.7097 RMSE: 0.9286\n",
      "Epoch 63 Step 49792: Train 0.4169 Reg: 0.4683\n",
      "Test: 1.0111 MAE: 0.7619 RMSE: 1.0055\n",
      "Val: 0.8645 MAE: 0.7103 RMSE: 0.9298\n",
      "Epoch 64 Step 50570: Train 0.4158 Reg: 0.4661\n",
      "Test: 1.0142 MAE: 0.7626 RMSE: 1.0071\n",
      "Val: 0.8658 MAE: 0.7105 RMSE: 0.9305\n",
      "Epoch 65 Step 51348: Train 0.4148 Reg: 0.4639\n",
      "Test: 1.0170 MAE: 0.7626 RMSE: 1.0084\n",
      "Val: 0.8674 MAE: 0.7104 RMSE: 0.9313\n",
      "Epoch 66 Step 52126: Train 0.4138 Reg: 0.4619\n",
      "Test: 1.0187 MAE: 0.7651 RMSE: 1.0093\n",
      "Val: 0.8692 MAE: 0.7123 RMSE: 0.9323\n",
      "Epoch 67 Step 52904: Train 0.4129 Reg: 0.4599\n",
      "Test: 1.0197 MAE: 0.7649 RMSE: 1.0098\n",
      "Val: 0.8704 MAE: 0.7124 RMSE: 0.9330\n",
      "Epoch 68 Step 53682: Train 0.4120 Reg: 0.4580\n",
      "Test: 1.0228 MAE: 0.7652 RMSE: 1.0113\n",
      "Val: 0.8714 MAE: 0.7123 RMSE: 0.9335\n",
      "Epoch 69 Step 54460: Train 0.4111 Reg: 0.4563\n",
      "Test: 1.0257 MAE: 0.7674 RMSE: 1.0128\n",
      "Val: 0.8732 MAE: 0.7136 RMSE: 0.9345\n",
      "Epoch 70 Step 55238: Train 0.4103 Reg: 0.4545\n",
      "Test: 1.0265 MAE: 0.7670 RMSE: 1.0132\n",
      "Val: 0.8743 MAE: 0.7137 RMSE: 0.9350\n",
      "Epoch 71 Step 56016: Train 0.4095 Reg: 0.4529\n",
      "Test: 1.0294 MAE: 0.7680 RMSE: 1.0146\n",
      "Val: 0.8753 MAE: 0.7142 RMSE: 0.9356\n",
      "Epoch 72 Step 56794: Train 0.4088 Reg: 0.4513\n",
      "Test: 1.0302 MAE: 0.7673 RMSE: 1.0150\n",
      "Val: 0.8766 MAE: 0.7140 RMSE: 0.9363\n",
      "Epoch 73 Step 57572: Train 0.4081 Reg: 0.4499\n",
      "Test: 1.0332 MAE: 0.7699 RMSE: 1.0165\n",
      "Val: 0.8781 MAE: 0.7156 RMSE: 0.9371\n",
      "Epoch 74 Step 58350: Train 0.4074 Reg: 0.4484\n",
      "Test: 1.0342 MAE: 0.7687 RMSE: 1.0170\n",
      "Val: 0.8781 MAE: 0.7146 RMSE: 0.9371\n",
      "Epoch 75 Step 59128: Train 0.4067 Reg: 0.4471\n",
      "Test: 1.0356 MAE: 0.7686 RMSE: 1.0176\n",
      "Val: 0.8791 MAE: 0.7148 RMSE: 0.9376\n",
      "Epoch 76 Step 59906: Train 0.4061 Reg: 0.4457\n",
      "Test: 1.0393 MAE: 0.7720 RMSE: 1.0195\n",
      "Val: 0.8814 MAE: 0.7169 RMSE: 0.9388\n",
      "Epoch 77 Step 60684: Train 0.4055 Reg: 0.4446\n",
      "Test: 1.0394 MAE: 0.7706 RMSE: 1.0195\n",
      "Val: 0.8813 MAE: 0.7159 RMSE: 0.9388\n",
      "Epoch 78 Step 61462: Train 0.4049 Reg: 0.4434\n",
      "Test: 1.0411 MAE: 0.7715 RMSE: 1.0203\n",
      "Val: 0.8819 MAE: 0.7162 RMSE: 0.9391\n",
      "Epoch 79 Step 62240: Train 0.4043 Reg: 0.4423\n",
      "Test: 1.0420 MAE: 0.7713 RMSE: 1.0208\n",
      "Val: 0.8825 MAE: 0.7162 RMSE: 0.9394\n",
      "Epoch 80 Step 63018: Train 0.4038 Reg: 0.4412\n",
      "Test: 1.0430 MAE: 0.7714 RMSE: 1.0213\n",
      "Val: 0.8833 MAE: 0.7164 RMSE: 0.9399\n",
      "Epoch 81 Step 63796: Train 0.4033 Reg: 0.4402\n",
      "Test: 1.0448 MAE: 0.7722 RMSE: 1.0222\n",
      "Val: 0.8842 MAE: 0.7168 RMSE: 0.9403\n",
      "Epoch 82 Step 64574: Train 0.4028 Reg: 0.4392\n",
      "Test: 1.0457 MAE: 0.7725 RMSE: 1.0226\n",
      "Val: 0.8849 MAE: 0.7169 RMSE: 0.9407\n",
      "Epoch 83 Step 65352: Train 0.4023 Reg: 0.4383\n",
      "Test: 1.0472 MAE: 0.7726 RMSE: 1.0233\n",
      "Val: 0.8854 MAE: 0.7168 RMSE: 0.9410\n",
      "Epoch 84 Step 66130: Train 0.4019 Reg: 0.4374\n",
      "Test: 1.0489 MAE: 0.7739 RMSE: 1.0242\n",
      "Val: 0.8863 MAE: 0.7177 RMSE: 0.9414\n",
      "Epoch 85 Step 66908: Train 0.4015 Reg: 0.4366\n",
      "Test: 1.0495 MAE: 0.7735 RMSE: 1.0244\n",
      "Val: 0.8867 MAE: 0.7175 RMSE: 0.9416\n",
      "Epoch 86 Step 67686: Train 0.4011 Reg: 0.4358\n",
      "Test: 1.0506 MAE: 0.7743 RMSE: 1.0250\n",
      "Val: 0.8874 MAE: 0.7179 RMSE: 0.9420\n",
      "Epoch 87 Step 68464: Train 0.4007 Reg: 0.4350\n",
      "Test: 1.0515 MAE: 0.7748 RMSE: 1.0254\n",
      "Val: 0.8881 MAE: 0.7184 RMSE: 0.9424\n",
      "Epoch 88 Step 69242: Train 0.4003 Reg: 0.4343\n",
      "Test: 1.0524 MAE: 0.7751 RMSE: 1.0259\n",
      "Val: 0.8890 MAE: 0.7188 RMSE: 0.9428\n",
      "Epoch 89 Step 70020: Train 0.4000 Reg: 0.4336\n",
      "Test: 1.0527 MAE: 0.7748 RMSE: 1.0260\n",
      "Val: 0.8890 MAE: 0.7184 RMSE: 0.9429\n",
      "Epoch 90 Step 70798: Train 0.3996 Reg: 0.4329\n",
      "Test: 1.0535 MAE: 0.7748 RMSE: 1.0264\n",
      "Val: 0.8894 MAE: 0.7184 RMSE: 0.9431\n",
      "Epoch 91 Step 71576: Train 0.3993 Reg: 0.4323\n",
      "Test: 1.0547 MAE: 0.7754 RMSE: 1.0270\n",
      "Val: 0.8900 MAE: 0.7187 RMSE: 0.9434\n",
      "Epoch 92 Step 72354: Train 0.3990 Reg: 0.4317\n",
      "Test: 1.0554 MAE: 0.7754 RMSE: 1.0273\n",
      "Val: 0.8903 MAE: 0.7188 RMSE: 0.9435\n",
      "Epoch 93 Step 73132: Train 0.3987 Reg: 0.4311\n",
      "Test: 1.0563 MAE: 0.7759 RMSE: 1.0278\n",
      "Val: 0.8908 MAE: 0.7191 RMSE: 0.9438\n",
      "Epoch 94 Step 73910: Train 0.3984 Reg: 0.4306\n",
      "Test: 1.0569 MAE: 0.7758 RMSE: 1.0281\n",
      "Val: 0.8911 MAE: 0.7189 RMSE: 0.9440\n",
      "Epoch 95 Step 74688: Train 0.3982 Reg: 0.4301\n",
      "Test: 1.0574 MAE: 0.7755 RMSE: 1.0283\n",
      "Val: 0.8915 MAE: 0.7188 RMSE: 0.9442\n",
      "Epoch 96 Step 75466: Train 0.3979 Reg: 0.4296\n",
      "Test: 1.0583 MAE: 0.7765 RMSE: 1.0287\n",
      "Val: 0.8920 MAE: 0.7195 RMSE: 0.9445\n",
      "Epoch 97 Step 76244: Train 0.3977 Reg: 0.4291\n",
      "Test: 1.0584 MAE: 0.7759 RMSE: 1.0288\n",
      "Val: 0.8921 MAE: 0.7191 RMSE: 0.9445\n",
      "Epoch 98 Step 77022: Train 0.3975 Reg: 0.4287\n",
      "Test: 1.0593 MAE: 0.7768 RMSE: 1.0292\n",
      "Val: 0.8927 MAE: 0.7198 RMSE: 0.9448\n",
      "Epoch 99 Step 77800: Train 0.3972 Reg: 0.4283\n",
      "Test: 1.0598 MAE: 0.7768 RMSE: 1.0295\n",
      "Val: 0.8929 MAE: 0.7197 RMSE: 0.9449\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 838282/19100\n",
      "test set size: support/query 3138/809\n",
      "Epoch 0: TrainLoss 1.0450 RecLoss: 0.0000 (left: 0:09:11)\n",
      "TestLoss: 1.0658 MAE: 0.8152 RMSE: 1.0324\n",
      "ValLoss: 1.1267 MAE: 0.8493 RMSE: 1.0614\n",
      "Epoch 1: TrainLoss 1.0338 RecLoss: 0.0000 (left: 0:08:07)\n",
      "TestLoss: 1.0621 MAE: 0.8174 RMSE: 1.0306\n",
      "ValLoss: 1.1236 MAE: 0.8503 RMSE: 1.0600\n",
      "Epoch 2: TrainLoss 1.0279 RecLoss: 0.0000 (left: 0:07:39)\n",
      "TestLoss: 1.0597 MAE: 0.8196 RMSE: 1.0294\n",
      "ValLoss: 1.1205 MAE: 0.8510 RMSE: 1.0586\n",
      "Epoch 3: TrainLoss 1.0252 RecLoss: 0.0000 (left: 0:07:35)\n",
      "TestLoss: 1.0558 MAE: 0.8095 RMSE: 1.0275\n",
      "ValLoss: 1.1226 MAE: 0.8457 RMSE: 1.0595\n",
      "Epoch 4: TrainLoss 1.0206 RecLoss: 0.0000 (left: 0:07:32)\n",
      "TestLoss: 1.0556 MAE: 0.8207 RMSE: 1.0274\n",
      "ValLoss: 1.1166 MAE: 0.8512 RMSE: 1.0567\n",
      "Epoch 5: TrainLoss 1.0167 RecLoss: 0.0000 (left: 0:07:33)\n",
      "TestLoss: 1.0497 MAE: 0.8153 RMSE: 1.0245\n",
      "ValLoss: 1.1121 MAE: 0.8478 RMSE: 1.0545\n",
      "Epoch 6: TrainLoss 1.0116 RecLoss: 0.0000 (left: 0:07:45)\n",
      "TestLoss: 1.0469 MAE: 0.8059 RMSE: 1.0232\n",
      "ValLoss: 1.1140 MAE: 0.8429 RMSE: 1.0555\n",
      "Epoch 7: TrainLoss 1.0078 RecLoss: 0.0000 (left: 0:07:39)\n",
      "TestLoss: 1.0430 MAE: 0.8087 RMSE: 1.0213\n",
      "ValLoss: 1.1081 MAE: 0.8437 RMSE: 1.0527\n",
      "Epoch 8: TrainLoss 1.0049 RecLoss: 0.0000 (left: 0:07:22)\n",
      "TestLoss: 1.0412 MAE: 0.8108 RMSE: 1.0204\n",
      "ValLoss: 1.1047 MAE: 0.8441 RMSE: 1.0511\n",
      "Epoch 9: TrainLoss 1.0027 RecLoss: 0.0000 (left: 0:07:21)\n",
      "TestLoss: 1.0431 MAE: 0.8012 RMSE: 1.0213\n",
      "ValLoss: 1.1121 MAE: 0.8395 RMSE: 1.0546\n",
      "Epoch 10: TrainLoss 0.9978 RecLoss: 0.0000 (left: 0:07:09)\n",
      "TestLoss: 1.0359 MAE: 0.8042 RMSE: 1.0178\n",
      "ValLoss: 1.1006 MAE: 0.8392 RMSE: 1.0491\n",
      "Epoch 11: TrainLoss 0.9943 RecLoss: 0.0000 (left: 0:06:56)\n",
      "TestLoss: 1.0357 MAE: 0.8111 RMSE: 1.0177\n",
      "ValLoss: 1.0988 MAE: 0.8434 RMSE: 1.0482\n",
      "Epoch 12: TrainLoss 0.9914 RecLoss: 0.0000 (left: 0:06:47)\n",
      "TestLoss: 1.0318 MAE: 0.8046 RMSE: 1.0158\n",
      "ValLoss: 1.0964 MAE: 0.8388 RMSE: 1.0471\n",
      "Epoch 13: TrainLoss 0.9886 RecLoss: 0.0000 (left: 0:06:45)\n",
      "TestLoss: 1.0306 MAE: 0.8012 RMSE: 1.0152\n",
      "ValLoss: 1.0962 MAE: 0.8369 RMSE: 1.0470\n",
      "Epoch 14: TrainLoss 0.9853 RecLoss: 0.0000 (left: 0:06:40)\n",
      "TestLoss: 1.0290 MAE: 0.8078 RMSE: 1.0144\n",
      "ValLoss: 1.0917 MAE: 0.8403 RMSE: 1.0448\n",
      "Epoch 15: TrainLoss 0.9815 RecLoss: 0.0000 (left: 0:06:30)\n",
      "TestLoss: 1.0255 MAE: 0.8024 RMSE: 1.0127\n",
      "ValLoss: 1.0901 MAE: 0.8367 RMSE: 1.0441\n",
      "Epoch 16: TrainLoss 0.9793 RecLoss: 0.0000 (left: 0:06:20)\n",
      "TestLoss: 1.0240 MAE: 0.8038 RMSE: 1.0119\n",
      "ValLoss: 1.0871 MAE: 0.8370 RMSE: 1.0426\n",
      "Epoch 17: TrainLoss 0.9771 RecLoss: 0.0000 (left: 0:06:11)\n",
      "TestLoss: 1.0240 MAE: 0.7966 RMSE: 1.0119\n",
      "ValLoss: 1.0915 MAE: 0.8338 RMSE: 1.0448\n",
      "Epoch 18: TrainLoss 0.9743 RecLoss: 0.0000 (left: 0:06:04)\n",
      "TestLoss: 1.0209 MAE: 0.7991 RMSE: 1.0104\n",
      "ValLoss: 1.0858 MAE: 0.8338 RMSE: 1.0420\n",
      "Epoch 19: TrainLoss 0.9719 RecLoss: 0.0000 (left: 0:06:00)\n",
      "TestLoss: 1.0201 MAE: 0.8034 RMSE: 1.0100\n",
      "ValLoss: 1.0831 MAE: 0.8359 RMSE: 1.0407\n",
      "Epoch 20: TrainLoss 0.9699 RecLoss: 0.0000 (left: 0:05:55)\n",
      "TestLoss: 1.0182 MAE: 0.7973 RMSE: 1.0091\n",
      "ValLoss: 1.0831 MAE: 0.8323 RMSE: 1.0407\n",
      "Epoch 21: TrainLoss 0.9673 RecLoss: 0.0000 (left: 0:05:47)\n",
      "TestLoss: 1.0189 MAE: 0.8063 RMSE: 1.0094\n",
      "ValLoss: 1.0784 MAE: 0.8362 RMSE: 1.0385\n",
      "Epoch 22: TrainLoss 0.9663 RecLoss: 0.0000 (left: 0:05:39)\n",
      "TestLoss: 1.0148 MAE: 0.7969 RMSE: 1.0074\n",
      "ValLoss: 1.0796 MAE: 0.8314 RMSE: 1.0391\n",
      "Epoch 23: TrainLoss 0.9629 RecLoss: 0.0000 (left: 0:05:33)\n",
      "TestLoss: 1.0180 MAE: 0.8078 RMSE: 1.0089\n",
      "ValLoss: 1.0784 MAE: 0.8374 RMSE: 1.0384\n",
      "Epoch 24: TrainLoss 0.9636 RecLoss: 0.0000 (left: 0:05:29)\n",
      "TestLoss: 1.0126 MAE: 0.8001 RMSE: 1.0063\n",
      "ValLoss: 1.0743 MAE: 0.8320 RMSE: 1.0365\n",
      "Epoch 25: TrainLoss 0.9585 RecLoss: 0.0000 (left: 0:05:23)\n",
      "TestLoss: 1.0126 MAE: 0.8019 RMSE: 1.0063\n",
      "ValLoss: 1.0721 MAE: 0.8321 RMSE: 1.0354\n",
      "Epoch 26: TrainLoss 0.9573 RecLoss: 0.0000 (left: 0:05:18)\n",
      "TestLoss: 1.0113 MAE: 0.8012 RMSE: 1.0056\n",
      "ValLoss: 1.0727 MAE: 0.8324 RMSE: 1.0357\n",
      "Epoch 27: TrainLoss 0.9551 RecLoss: 0.0000 (left: 0:05:11)\n",
      "TestLoss: 1.0089 MAE: 0.7984 RMSE: 1.0044\n",
      "ValLoss: 1.0716 MAE: 0.8309 RMSE: 1.0352\n",
      "Epoch 28: TrainLoss 0.9540 RecLoss: 0.0000 (left: 0:05:08)\n",
      "TestLoss: 1.0089 MAE: 0.8004 RMSE: 1.0045\n",
      "ValLoss: 1.0695 MAE: 0.8312 RMSE: 1.0342\n",
      "Epoch 29: TrainLoss 0.9518 RecLoss: 0.0000 (left: 0:05:02)\n",
      "TestLoss: 1.0077 MAE: 0.7982 RMSE: 1.0039\n",
      "ValLoss: 1.0687 MAE: 0.8297 RMSE: 1.0338\n",
      "Epoch 30: TrainLoss 0.9502 RecLoss: 0.0000 (left: 0:04:56)\n",
      "TestLoss: 1.0063 MAE: 0.7909 RMSE: 1.0032\n",
      "ValLoss: 1.0726 MAE: 0.8269 RMSE: 1.0357\n",
      "Epoch 31: TrainLoss 0.9492 RecLoss: 0.0000 (left: 0:04:52)\n",
      "TestLoss: 1.0051 MAE: 0.7918 RMSE: 1.0026\n",
      "ValLoss: 1.0689 MAE: 0.8261 RMSE: 1.0339\n",
      "Epoch 32: TrainLoss 0.9465 RecLoss: 0.0000 (left: 0:04:46)\n",
      "TestLoss: 1.0037 MAE: 0.7945 RMSE: 1.0018\n",
      "ValLoss: 1.0668 MAE: 0.8275 RMSE: 1.0329\n",
      "Epoch 33: TrainLoss 0.9451 RecLoss: 0.0000 (left: 0:04:42)\n",
      "TestLoss: 1.0032 MAE: 0.7942 RMSE: 1.0016\n",
      "ValLoss: 1.0655 MAE: 0.8270 RMSE: 1.0322\n",
      "Epoch 34: TrainLoss 0.9443 RecLoss: 0.0000 (left: 0:04:36)\n",
      "TestLoss: 1.0022 MAE: 0.7919 RMSE: 1.0011\n",
      "ValLoss: 1.0653 MAE: 0.8254 RMSE: 1.0321\n",
      "Epoch 35: TrainLoss 0.9428 RecLoss: 0.0000 (left: 0:04:31)\n",
      "TestLoss: 1.0015 MAE: 0.7930 RMSE: 1.0007\n",
      "ValLoss: 1.0634 MAE: 0.8257 RMSE: 1.0312\n",
      "Epoch 36: TrainLoss 0.9411 RecLoss: 0.0000 (left: 0:04:25)\n",
      "TestLoss: 1.0018 MAE: 0.7973 RMSE: 1.0009\n",
      "ValLoss: 1.0618 MAE: 0.8280 RMSE: 1.0304\n",
      "Epoch 37: TrainLoss 0.9394 RecLoss: 0.0000 (left: 0:04:20)\n",
      "TestLoss: 1.0002 MAE: 0.7920 RMSE: 1.0001\n",
      "ValLoss: 1.0620 MAE: 0.8246 RMSE: 1.0305\n",
      "Epoch 38: TrainLoss 0.9380 RecLoss: 0.0000 (left: 0:04:15)\n",
      "TestLoss: 0.9994 MAE: 0.7949 RMSE: 0.9997\n",
      "ValLoss: 1.0606 MAE: 0.8266 RMSE: 1.0299\n",
      "Epoch 39: TrainLoss 0.9371 RecLoss: 0.0000 (left: 0:04:11)\n",
      "TestLoss: 0.9984 MAE: 0.7927 RMSE: 0.9992\n",
      "ValLoss: 1.0603 MAE: 0.8251 RMSE: 1.0297\n",
      "Epoch 40: TrainLoss 0.9357 RecLoss: 0.0000 (left: 0:04:06)\n",
      "TestLoss: 0.9978 MAE: 0.7908 RMSE: 0.9989\n",
      "ValLoss: 1.0607 MAE: 0.8241 RMSE: 1.0299\n",
      "Epoch 41: TrainLoss 0.9345 RecLoss: 0.0000 (left: 0:04:02)\n",
      "TestLoss: 0.9982 MAE: 0.7954 RMSE: 0.9991\n",
      "ValLoss: 1.0585 MAE: 0.8263 RMSE: 1.0288\n",
      "Epoch 42: TrainLoss 0.9337 RecLoss: 0.0000 (left: 0:03:57)\n",
      "TestLoss: 0.9966 MAE: 0.7924 RMSE: 0.9983\n",
      "ValLoss: 1.0579 MAE: 0.8245 RMSE: 1.0285\n",
      "Epoch 43: TrainLoss 0.9333 RecLoss: 0.0000 (left: 0:03:52)\n",
      "TestLoss: 0.9984 MAE: 0.7982 RMSE: 0.9992\n",
      "ValLoss: 1.0563 MAE: 0.8274 RMSE: 1.0278\n",
      "Epoch 44: TrainLoss 0.9326 RecLoss: 0.0000 (left: 0:03:48)\n",
      "TestLoss: 0.9974 MAE: 0.7968 RMSE: 0.9987\n",
      "ValLoss: 1.0564 MAE: 0.8264 RMSE: 1.0278\n",
      "Epoch 45: TrainLoss 0.9304 RecLoss: 0.0000 (left: 0:03:45)\n",
      "TestLoss: 0.9951 MAE: 0.7908 RMSE: 0.9975\n",
      "ValLoss: 1.0565 MAE: 0.8230 RMSE: 1.0279\n",
      "Epoch 46: TrainLoss 0.9292 RecLoss: 0.0000 (left: 0:03:41)\n",
      "TestLoss: 0.9950 MAE: 0.7938 RMSE: 0.9975\n",
      "ValLoss: 1.0546 MAE: 0.8246 RMSE: 1.0269\n",
      "Epoch 47: TrainLoss 0.9284 RecLoss: 0.0000 (left: 0:03:37)\n",
      "TestLoss: 0.9952 MAE: 0.7955 RMSE: 0.9976\n",
      "ValLoss: 1.0535 MAE: 0.8253 RMSE: 1.0264\n",
      "Epoch 48: TrainLoss 0.9298 RecLoss: 0.0000 (left: 0:03:33)\n",
      "TestLoss: 0.9941 MAE: 0.7932 RMSE: 0.9970\n",
      "ValLoss: 1.0538 MAE: 0.8241 RMSE: 1.0266\n",
      "Epoch 49: TrainLoss 0.9262 RecLoss: 0.0000 (left: 0:03:28)\n",
      "TestLoss: 0.9930 MAE: 0.7915 RMSE: 0.9965\n",
      "ValLoss: 1.0538 MAE: 0.8230 RMSE: 1.0266\n",
      "Epoch 50: TrainLoss 0.9252 RecLoss: 0.0000 (left: 0:03:23)\n",
      "TestLoss: 0.9927 MAE: 0.7908 RMSE: 0.9963\n",
      "ValLoss: 1.0531 MAE: 0.8222 RMSE: 1.0262\n",
      "Epoch 51: TrainLoss 0.9248 RecLoss: 0.0000 (left: 0:03:19)\n",
      "TestLoss: 0.9926 MAE: 0.7878 RMSE: 0.9963\n",
      "ValLoss: 1.0542 MAE: 0.8203 RMSE: 1.0268\n",
      "Epoch 52: TrainLoss 0.9237 RecLoss: 0.0000 (left: 0:03:16)\n",
      "TestLoss: 0.9918 MAE: 0.7897 RMSE: 0.9959\n",
      "ValLoss: 1.0529 MAE: 0.8216 RMSE: 1.0261\n",
      "Epoch 53: TrainLoss 0.9229 RecLoss: 0.0000 (left: 0:03:13)\n",
      "TestLoss: 0.9921 MAE: 0.7930 RMSE: 0.9960\n",
      "ValLoss: 1.0513 MAE: 0.8236 RMSE: 1.0253\n",
      "Epoch 54: TrainLoss 0.9219 RecLoss: 0.0000 (left: 0:03:08)\n",
      "TestLoss: 0.9909 MAE: 0.7893 RMSE: 0.9954\n",
      "ValLoss: 1.0515 MAE: 0.8208 RMSE: 1.0254\n",
      "Epoch 55: TrainLoss 0.9213 RecLoss: 0.0000 (left: 0:03:04)\n",
      "TestLoss: 0.9914 MAE: 0.7927 RMSE: 0.9957\n",
      "ValLoss: 1.0511 MAE: 0.8234 RMSE: 1.0252\n",
      "Epoch 56: TrainLoss 0.9206 RecLoss: 0.0000 (left: 0:03:00)\n",
      "TestLoss: 0.9932 MAE: 0.7966 RMSE: 0.9966\n",
      "ValLoss: 1.0508 MAE: 0.8258 RMSE: 1.0251\n",
      "Epoch 57: TrainLoss 0.9216 RecLoss: 0.0000 (left: 0:02:57)\n",
      "TestLoss: 0.9922 MAE: 0.7952 RMSE: 0.9961\n",
      "ValLoss: 1.0496 MAE: 0.8244 RMSE: 1.0245\n",
      "Epoch 58: TrainLoss 0.9202 RecLoss: 0.0000 (left: 0:02:53)\n",
      "TestLoss: 0.9899 MAE: 0.7876 RMSE: 0.9949\n",
      "ValLoss: 1.0503 MAE: 0.8193 RMSE: 1.0249\n",
      "Epoch 59: TrainLoss 0.9186 RecLoss: 0.0000 (left: 0:02:49)\n",
      "TestLoss: 0.9914 MAE: 0.7838 RMSE: 0.9957\n",
      "ValLoss: 1.0548 MAE: 0.8173 RMSE: 1.0270\n",
      "Epoch 60: TrainLoss 0.9180 RecLoss: 0.0000 (left: 0:02:44)\n",
      "TestLoss: 0.9893 MAE: 0.7886 RMSE: 0.9946\n",
      "ValLoss: 1.0487 MAE: 0.8197 RMSE: 1.0241\n",
      "Epoch 61: TrainLoss 0.9167 RecLoss: 0.0000 (left: 0:02:39)\n",
      "TestLoss: 0.9885 MAE: 0.7894 RMSE: 0.9942\n",
      "ValLoss: 1.0482 MAE: 0.8206 RMSE: 1.0238\n",
      "Epoch 62: TrainLoss 0.9163 RecLoss: 0.0000 (left: 0:02:35)\n",
      "TestLoss: 0.9891 MAE: 0.7920 RMSE: 0.9945\n",
      "ValLoss: 1.0475 MAE: 0.8222 RMSE: 1.0235\n",
      "Epoch 63: TrainLoss 0.9157 RecLoss: 0.0000 (left: 0:02:31)\n",
      "TestLoss: 0.9881 MAE: 0.7874 RMSE: 0.9940\n",
      "ValLoss: 1.0486 MAE: 0.8192 RMSE: 1.0240\n",
      "Epoch 64: TrainLoss 0.9149 RecLoss: 0.0000 (left: 0:02:27)\n",
      "TestLoss: 0.9879 MAE: 0.7891 RMSE: 0.9939\n",
      "ValLoss: 1.0480 MAE: 0.8203 RMSE: 1.0237\n",
      "Epoch 65: TrainLoss 0.9149 RecLoss: 0.0000 (left: 0:02:23)\n",
      "TestLoss: 0.9890 MAE: 0.7845 RMSE: 0.9945\n",
      "ValLoss: 1.0505 MAE: 0.8170 RMSE: 1.0249\n",
      "Epoch 66: TrainLoss 0.9142 RecLoss: 0.0000 (left: 0:02:19)\n",
      "TestLoss: 0.9871 MAE: 0.7882 RMSE: 0.9935\n",
      "ValLoss: 1.0470 MAE: 0.8195 RMSE: 1.0232\n",
      "Epoch 67: TrainLoss 0.9132 RecLoss: 0.0000 (left: 0:02:15)\n",
      "TestLoss: 0.9891 MAE: 0.7939 RMSE: 0.9946\n",
      "ValLoss: 1.0467 MAE: 0.8234 RMSE: 1.0231\n",
      "Epoch 68: TrainLoss 0.9135 RecLoss: 0.0000 (left: 0:02:11)\n",
      "TestLoss: 0.9890 MAE: 0.7938 RMSE: 0.9945\n",
      "ValLoss: 1.0460 MAE: 0.8230 RMSE: 1.0227\n",
      "Epoch 69: TrainLoss 0.9121 RecLoss: 0.0000 (left: 0:02:07)\n",
      "TestLoss: 0.9865 MAE: 0.7871 RMSE: 0.9932\n",
      "ValLoss: 1.0468 MAE: 0.8188 RMSE: 1.0231\n",
      "Epoch 70: TrainLoss 0.9119 RecLoss: 0.0000 (left: 0:02:03)\n",
      "TestLoss: 0.9870 MAE: 0.7849 RMSE: 0.9935\n",
      "ValLoss: 1.0479 MAE: 0.8169 RMSE: 1.0237\n",
      "Epoch 71: TrainLoss 0.9105 RecLoss: 0.0000 (left: 0:01:59)\n",
      "TestLoss: 0.9883 MAE: 0.7934 RMSE: 0.9942\n",
      "ValLoss: 1.0456 MAE: 0.8227 RMSE: 1.0225\n",
      "Epoch 72: TrainLoss 0.9111 RecLoss: 0.0000 (left: 0:01:55)\n",
      "TestLoss: 0.9864 MAE: 0.7853 RMSE: 0.9932\n",
      "ValLoss: 1.0472 MAE: 0.8172 RMSE: 1.0233\n",
      "Epoch 73: TrainLoss 0.9099 RecLoss: 0.0000 (left: 0:01:50)\n",
      "TestLoss: 0.9861 MAE: 0.7894 RMSE: 0.9930\n",
      "ValLoss: 1.0446 MAE: 0.8199 RMSE: 1.0221\n",
      "Epoch 74: TrainLoss 0.9105 RecLoss: 0.0000 (left: 0:01:46)\n",
      "TestLoss: 0.9857 MAE: 0.7874 RMSE: 0.9928\n",
      "ValLoss: 1.0453 MAE: 0.8185 RMSE: 1.0224\n",
      "Epoch 75: TrainLoss 0.9093 RecLoss: 0.0000 (left: 0:01:42)\n",
      "TestLoss: 0.9866 MAE: 0.7841 RMSE: 0.9933\n",
      "ValLoss: 1.0476 MAE: 0.8162 RMSE: 1.0235\n",
      "Epoch 76: TrainLoss 0.9085 RecLoss: 0.0000 (left: 0:01:38)\n",
      "TestLoss: 0.9856 MAE: 0.7879 RMSE: 0.9928\n",
      "ValLoss: 1.0447 MAE: 0.8188 RMSE: 1.0221\n",
      "Epoch 77: TrainLoss 0.9084 RecLoss: 0.0000 (left: 0:01:34)\n",
      "TestLoss: 0.9860 MAE: 0.7844 RMSE: 0.9930\n",
      "ValLoss: 1.0465 MAE: 0.8163 RMSE: 1.0230\n",
      "Epoch 78: TrainLoss 0.9079 RecLoss: 0.0000 (left: 0:01:30)\n",
      "TestLoss: 0.9851 MAE: 0.7876 RMSE: 0.9925\n",
      "ValLoss: 1.0441 MAE: 0.8186 RMSE: 1.0218\n",
      "Epoch 79: TrainLoss 0.9071 RecLoss: 0.0000 (left: 0:01:25)\n",
      "TestLoss: 0.9856 MAE: 0.7890 RMSE: 0.9928\n",
      "ValLoss: 1.0436 MAE: 0.8193 RMSE: 1.0216\n",
      "Epoch 80: TrainLoss 0.9069 RecLoss: 0.0000 (left: 0:01:21)\n",
      "TestLoss: 0.9858 MAE: 0.7836 RMSE: 0.9929\n",
      "ValLoss: 1.0470 MAE: 0.8160 RMSE: 1.0232\n",
      "Epoch 81: TrainLoss 0.9066 RecLoss: 0.0000 (left: 0:01:17)\n",
      "TestLoss: 0.9847 MAE: 0.7859 RMSE: 0.9923\n",
      "ValLoss: 1.0443 MAE: 0.8174 RMSE: 1.0219\n",
      "Epoch 82: TrainLoss 0.9075 RecLoss: 0.0000 (left: 0:01:13)\n",
      "TestLoss: 0.9847 MAE: 0.7883 RMSE: 0.9923\n",
      "ValLoss: 1.0433 MAE: 0.8189 RMSE: 1.0214\n",
      "Epoch 83: TrainLoss 0.9057 RecLoss: 0.0000 (left: 0:01:09)\n",
      "TestLoss: 0.9851 MAE: 0.7902 RMSE: 0.9925\n",
      "ValLoss: 1.0430 MAE: 0.8202 RMSE: 1.0213\n",
      "Epoch 84: TrainLoss 0.9055 RecLoss: 0.0000 (left: 0:01:05)\n",
      "TestLoss: 0.9844 MAE: 0.7876 RMSE: 0.9922\n",
      "ValLoss: 1.0433 MAE: 0.8186 RMSE: 1.0214\n",
      "Epoch 85: TrainLoss 0.9055 RecLoss: 0.0000 (left: 0:01:01)\n",
      "TestLoss: 0.9844 MAE: 0.7883 RMSE: 0.9921\n",
      "ValLoss: 1.0431 MAE: 0.8191 RMSE: 1.0213\n",
      "Epoch 86: TrainLoss 0.9051 RecLoss: 0.0000 (left: 0:00:57)\n",
      "TestLoss: 0.9843 MAE: 0.7852 RMSE: 0.9921\n",
      "ValLoss: 1.0438 MAE: 0.8165 RMSE: 1.0217\n",
      "Epoch 87: TrainLoss 0.9041 RecLoss: 0.0000 (left: 0:00:53)\n",
      "TestLoss: 0.9847 MAE: 0.7901 RMSE: 0.9923\n",
      "ValLoss: 1.0417 MAE: 0.8199 RMSE: 1.0206\n",
      "Epoch 88: TrainLoss 0.9043 RecLoss: 0.0000 (left: 0:00:49)\n",
      "TestLoss: 0.9840 MAE: 0.7846 RMSE: 0.9920\n",
      "ValLoss: 1.0439 MAE: 0.8162 RMSE: 1.0217\n",
      "Epoch 89: TrainLoss 0.9035 RecLoss: 0.0000 (left: 0:00:45)\n",
      "TestLoss: 0.9837 MAE: 0.7849 RMSE: 0.9918\n",
      "ValLoss: 1.0435 MAE: 0.8166 RMSE: 1.0215\n",
      "Epoch 90: TrainLoss 0.9034 RecLoss: 0.0000 (left: 0:00:40)\n",
      "TestLoss: 0.9837 MAE: 0.7843 RMSE: 0.9918\n",
      "ValLoss: 1.0443 MAE: 0.8163 RMSE: 1.0219\n",
      "Epoch 91: TrainLoss 0.9028 RecLoss: 0.0000 (left: 0:00:36)\n",
      "TestLoss: 0.9856 MAE: 0.7815 RMSE: 0.9928\n",
      "ValLoss: 1.0475 MAE: 0.8141 RMSE: 1.0235\n",
      "Epoch 92: TrainLoss 0.9038 RecLoss: 0.0000 (left: 0:00:32)\n",
      "TestLoss: 0.9844 MAE: 0.7831 RMSE: 0.9922\n",
      "ValLoss: 1.0449 MAE: 0.8151 RMSE: 1.0222\n",
      "Epoch 93: TrainLoss 0.9023 RecLoss: 0.0000 (left: 0:00:28)\n",
      "TestLoss: 0.9833 MAE: 0.7860 RMSE: 0.9916\n",
      "ValLoss: 1.0424 MAE: 0.8171 RMSE: 1.0210\n",
      "Epoch 94: TrainLoss 0.9020 RecLoss: 0.0000 (left: 0:00:24)\n",
      "TestLoss: 0.9833 MAE: 0.7858 RMSE: 0.9916\n",
      "ValLoss: 1.0421 MAE: 0.8168 RMSE: 1.0208\n",
      "Epoch 95: TrainLoss 0.9017 RecLoss: 0.0000 (left: 0:00:20)\n",
      "TestLoss: 0.9834 MAE: 0.7878 RMSE: 0.9916\n",
      "ValLoss: 1.0417 MAE: 0.8184 RMSE: 1.0206\n",
      "Epoch 96: TrainLoss 0.9014 RecLoss: 0.0000 (left: 0:00:16)\n",
      "TestLoss: 0.9832 MAE: 0.7852 RMSE: 0.9916\n",
      "ValLoss: 1.0423 MAE: 0.8165 RMSE: 1.0209\n",
      "Epoch 97: TrainLoss 0.9010 RecLoss: 0.0000 (left: 0:00:12)\n",
      "TestLoss: 0.9832 MAE: 0.7873 RMSE: 0.9916\n",
      "ValLoss: 1.0418 MAE: 0.8180 RMSE: 1.0207\n",
      "Epoch 98: TrainLoss 0.9008 RecLoss: 0.0000 (left: 0:00:08)\n",
      "TestLoss: 0.9831 MAE: 0.7852 RMSE: 0.9915\n",
      "ValLoss: 1.0424 MAE: 0.8164 RMSE: 1.0210\n",
      "Epoch 99: TrainLoss 0.9008 RecLoss: 0.0000 (left: 0:00:04)\n",
      "TestLoss: 0.9837 MAE: 0.7826 RMSE: 0.9918\n",
      "ValLoss: 1.0445 MAE: 0.8147 RMSE: 1.0220\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 838282/19100\n",
      "test set size: support/query 3138/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.6890 RMSE: 0.8774 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7878 RMSE: 0.9916 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7092 RMSE: 0.9020 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 80% optimal cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 921625/19100\n",
      "test set size: support/query 4184/809\n",
      "Epoch 0 Step 856: Train 1.4599 Reg: 0.6109\n",
      "Test: 0.9337 MAE: 0.7677 RMSE: 0.9663\n",
      "Val: 0.8592 MAE: 0.7334 RMSE: 0.9269\n",
      "Epoch 1 Step 1712: Train 0.8481 Reg: 0.4128\n",
      "Test: 0.9246 MAE: 0.7658 RMSE: 0.9616\n",
      "Val: 0.8518 MAE: 0.7314 RMSE: 0.9229\n",
      "Epoch 2 Step 2568: Train 0.8420 Reg: 0.3619\n",
      "Test: 0.9058 MAE: 0.7521 RMSE: 0.9518\n",
      "Val: 0.8438 MAE: 0.7250 RMSE: 0.9186\n",
      "Epoch 3 Step 3424: Train 0.8323 Reg: 0.3190\n",
      "Test: 0.9146 MAE: 0.7639 RMSE: 0.9563\n",
      "Val: 0.8333 MAE: 0.7239 RMSE: 0.9128\n",
      "Epoch 4 Step 4280: Train 0.8166 Reg: 0.2902\n",
      "Test: 0.8959 MAE: 0.7459 RMSE: 0.9465\n",
      "Val: 0.8166 MAE: 0.7125 RMSE: 0.9037\n",
      "Epoch 5 Step 5136: Train 0.8017 Reg: 0.2794\n",
      "Test: 0.8876 MAE: 0.7459 RMSE: 0.9421\n",
      "Val: 0.7994 MAE: 0.7052 RMSE: 0.8941\n",
      "Epoch 6 Step 5992: Train 0.7767 Reg: 0.3323\n",
      "Test: 0.8611 MAE: 0.7358 RMSE: 0.9279\n",
      "Val: 0.7786 MAE: 0.6978 RMSE: 0.8824\n",
      "Epoch 7 Step 6848: Train 0.7596 Reg: 0.3546\n",
      "Test: 0.8474 MAE: 0.7254 RMSE: 0.9205\n",
      "Val: 0.7606 MAE: 0.6857 RMSE: 0.8721\n",
      "Epoch 8 Step 7704: Train 0.7352 Reg: 0.4132\n",
      "Test: 0.8184 MAE: 0.7165 RMSE: 0.9046\n",
      "Val: 0.7458 MAE: 0.6801 RMSE: 0.8636\n",
      "Epoch 9 Step 8560: Train 0.7171 Reg: 0.4400\n",
      "Test: 0.8041 MAE: 0.7073 RMSE: 0.8967\n",
      "Val: 0.7395 MAE: 0.6717 RMSE: 0.8599\n",
      "Epoch 10 Step 9416: Train 0.7038 Reg: 0.4580\n",
      "Test: 0.7933 MAE: 0.7029 RMSE: 0.8907\n",
      "Val: 0.7283 MAE: 0.6697 RMSE: 0.8534\n",
      "Epoch 11 Step 10272: Train 0.6908 Reg: 0.4795\n",
      "Test: 0.7927 MAE: 0.7078 RMSE: 0.8903\n",
      "Val: 0.7283 MAE: 0.6740 RMSE: 0.8534\n",
      "Epoch 12 Step 11128: Train 0.6795 Reg: 0.4964\n",
      "Test: 0.7737 MAE: 0.6941 RMSE: 0.8796\n",
      "Val: 0.7157 MAE: 0.6631 RMSE: 0.8460\n",
      "Epoch 13 Step 11984: Train 0.6687 Reg: 0.5154\n",
      "Test: 0.7768 MAE: 0.6982 RMSE: 0.8813\n",
      "Val: 0.7131 MAE: 0.6625 RMSE: 0.8444\n",
      "Epoch 14 Step 12840: Train 0.6557 Reg: 0.5360\n",
      "Test: 0.7748 MAE: 0.6972 RMSE: 0.8802\n",
      "Val: 0.7094 MAE: 0.6611 RMSE: 0.8423\n",
      "Epoch 15 Step 13696: Train 0.6435 Reg: 0.5542\n",
      "Test: 0.7688 MAE: 0.6896 RMSE: 0.8768\n",
      "Val: 0.7059 MAE: 0.6566 RMSE: 0.8402\n",
      "Epoch 16 Step 14552: Train 0.6318 Reg: 0.5708\n",
      "Test: 0.7717 MAE: 0.6909 RMSE: 0.8785\n",
      "Val: 0.7093 MAE: 0.6576 RMSE: 0.8422\n",
      "Epoch 17 Step 15408: Train 0.6198 Reg: 0.5903\n",
      "Test: 0.7711 MAE: 0.6873 RMSE: 0.8781\n",
      "Val: 0.7115 MAE: 0.6572 RMSE: 0.8435\n",
      "Epoch 18 Step 16264: Train 0.6064 Reg: 0.6081\n",
      "Test: 0.7679 MAE: 0.6869 RMSE: 0.8763\n",
      "Val: 0.7155 MAE: 0.6613 RMSE: 0.8459\n",
      "Epoch 19 Step 17120: Train 0.5920 Reg: 0.6250\n",
      "Test: 0.7753 MAE: 0.6925 RMSE: 0.8805\n",
      "Val: 0.7203 MAE: 0.6616 RMSE: 0.8487\n",
      "Epoch 20 Step 17976: Train 0.5791 Reg: 0.6372\n",
      "Test: 0.7786 MAE: 0.6926 RMSE: 0.8824\n",
      "Val: 0.7227 MAE: 0.6625 RMSE: 0.8501\n",
      "Epoch 21 Step 18832: Train 0.5674 Reg: 0.6454\n",
      "Test: 0.7860 MAE: 0.6938 RMSE: 0.8866\n",
      "Val: 0.7291 MAE: 0.6642 RMSE: 0.8539\n",
      "Epoch 22 Step 19688: Train 0.5564 Reg: 0.6519\n",
      "Test: 0.7874 MAE: 0.6946 RMSE: 0.8873\n",
      "Val: 0.7350 MAE: 0.6677 RMSE: 0.8573\n",
      "Epoch 23 Step 20544: Train 0.5466 Reg: 0.6557\n",
      "Test: 0.7889 MAE: 0.6921 RMSE: 0.8882\n",
      "Val: 0.7413 MAE: 0.6693 RMSE: 0.8610\n",
      "Epoch 24 Step 21400: Train 0.5374 Reg: 0.6579\n",
      "Test: 0.7965 MAE: 0.6971 RMSE: 0.8925\n",
      "Val: 0.7479 MAE: 0.6721 RMSE: 0.8648\n",
      "Epoch 25 Step 22256: Train 0.5286 Reg: 0.6595\n",
      "Test: 0.8015 MAE: 0.6963 RMSE: 0.8953\n",
      "Val: 0.7523 MAE: 0.6727 RMSE: 0.8674\n",
      "Epoch 26 Step 23112: Train 0.5206 Reg: 0.6587\n",
      "Test: 0.8051 MAE: 0.7015 RMSE: 0.8973\n",
      "Val: 0.7607 MAE: 0.6774 RMSE: 0.8722\n",
      "Epoch 27 Step 23968: Train 0.5135 Reg: 0.6558\n",
      "Test: 0.8088 MAE: 0.6986 RMSE: 0.8993\n",
      "Val: 0.7639 MAE: 0.6778 RMSE: 0.8740\n",
      "Epoch 28 Step 24824: Train 0.5073 Reg: 0.6520\n",
      "Test: 0.8145 MAE: 0.7033 RMSE: 0.9025\n",
      "Val: 0.7701 MAE: 0.6805 RMSE: 0.8776\n",
      "Epoch 29 Step 25680: Train 0.5011 Reg: 0.6483\n",
      "Test: 0.8165 MAE: 0.7022 RMSE: 0.9036\n",
      "Val: 0.7755 MAE: 0.6817 RMSE: 0.8806\n",
      "Epoch 30 Step 26536: Train 0.4955 Reg: 0.6437\n",
      "Test: 0.8218 MAE: 0.7034 RMSE: 0.9065\n",
      "Val: 0.7804 MAE: 0.6836 RMSE: 0.8834\n",
      "Epoch 31 Step 27392: Train 0.4904 Reg: 0.6384\n",
      "Test: 0.8314 MAE: 0.7054 RMSE: 0.9118\n",
      "Val: 0.7855 MAE: 0.6858 RMSE: 0.8863\n",
      "Epoch 32 Step 28248: Train 0.4859 Reg: 0.6323\n",
      "Test: 0.8354 MAE: 0.7059 RMSE: 0.9140\n",
      "Val: 0.7901 MAE: 0.6860 RMSE: 0.8889\n",
      "Epoch 33 Step 29104: Train 0.4815 Reg: 0.6269\n",
      "Test: 0.8406 MAE: 0.7087 RMSE: 0.9169\n",
      "Val: 0.7936 MAE: 0.6877 RMSE: 0.8909\n",
      "Epoch 34 Step 29960: Train 0.4766 Reg: 0.6222\n",
      "Test: 0.8477 MAE: 0.7109 RMSE: 0.9207\n",
      "Val: 0.7985 MAE: 0.6895 RMSE: 0.8936\n",
      "Epoch 35 Step 30816: Train 0.4720 Reg: 0.6171\n",
      "Test: 0.8478 MAE: 0.7106 RMSE: 0.9208\n",
      "Val: 0.8016 MAE: 0.6902 RMSE: 0.8953\n",
      "Epoch 36 Step 31672: Train 0.4678 Reg: 0.6113\n",
      "Test: 0.8652 MAE: 0.7207 RMSE: 0.9302\n",
      "Val: 0.8106 MAE: 0.6952 RMSE: 0.9003\n",
      "Epoch 37 Step 32528: Train 0.4641 Reg: 0.6051\n",
      "Test: 0.8632 MAE: 0.7172 RMSE: 0.9291\n",
      "Val: 0.8131 MAE: 0.6953 RMSE: 0.9017\n",
      "Epoch 38 Step 33384: Train 0.4607 Reg: 0.5990\n",
      "Test: 0.8686 MAE: 0.7212 RMSE: 0.9320\n",
      "Val: 0.8197 MAE: 0.6993 RMSE: 0.9054\n",
      "Epoch 39 Step 34240: Train 0.4573 Reg: 0.5930\n",
      "Test: 0.8698 MAE: 0.7186 RMSE: 0.9327\n",
      "Val: 0.8223 MAE: 0.6984 RMSE: 0.9068\n",
      "Epoch 40 Step 35096: Train 0.4544 Reg: 0.5868\n",
      "Test: 0.8704 MAE: 0.7216 RMSE: 0.9330\n",
      "Val: 0.8254 MAE: 0.7008 RMSE: 0.9085\n",
      "Epoch 41 Step 35952: Train 0.4515 Reg: 0.5806\n",
      "Test: 0.8772 MAE: 0.7224 RMSE: 0.9366\n",
      "Val: 0.8296 MAE: 0.7012 RMSE: 0.9108\n",
      "Epoch 42 Step 36808: Train 0.4488 Reg: 0.5748\n",
      "Test: 0.8846 MAE: 0.7254 RMSE: 0.9405\n",
      "Val: 0.8334 MAE: 0.7030 RMSE: 0.9129\n",
      "Epoch 43 Step 37664: Train 0.4462 Reg: 0.5691\n",
      "Test: 0.8873 MAE: 0.7270 RMSE: 0.9420\n",
      "Val: 0.8377 MAE: 0.7049 RMSE: 0.9153\n",
      "Epoch 44 Step 38520: Train 0.4435 Reg: 0.5634\n",
      "Test: 0.8927 MAE: 0.7293 RMSE: 0.9448\n",
      "Val: 0.8419 MAE: 0.7065 RMSE: 0.9175\n",
      "Epoch 45 Step 39376: Train 0.4410 Reg: 0.5581\n",
      "Test: 0.8950 MAE: 0.7294 RMSE: 0.9460\n",
      "Val: 0.8447 MAE: 0.7078 RMSE: 0.9191\n",
      "Epoch 46 Step 40232: Train 0.4387 Reg: 0.5527\n",
      "Test: 0.8984 MAE: 0.7275 RMSE: 0.9478\n",
      "Val: 0.8462 MAE: 0.7065 RMSE: 0.9199\n",
      "Epoch 47 Step 41088: Train 0.4365 Reg: 0.5476\n",
      "Test: 0.9076 MAE: 0.7327 RMSE: 0.9527\n",
      "Val: 0.8509 MAE: 0.7092 RMSE: 0.9224\n",
      "Epoch 48 Step 41944: Train 0.4343 Reg: 0.5427\n",
      "Test: 0.9074 MAE: 0.7298 RMSE: 0.9526\n",
      "Val: 0.8532 MAE: 0.7086 RMSE: 0.9237\n",
      "Epoch 49 Step 42800: Train 0.4321 Reg: 0.5381\n",
      "Test: 0.9116 MAE: 0.7320 RMSE: 0.9548\n",
      "Val: 0.8554 MAE: 0.7099 RMSE: 0.9249\n",
      "Epoch 50 Step 43656: Train 0.4300 Reg: 0.5333\n",
      "Test: 0.9155 MAE: 0.7346 RMSE: 0.9568\n",
      "Val: 0.8593 MAE: 0.7120 RMSE: 0.9270\n",
      "Epoch 51 Step 44512: Train 0.4281 Reg: 0.5288\n",
      "Test: 0.9203 MAE: 0.7357 RMSE: 0.9593\n",
      "Val: 0.8622 MAE: 0.7124 RMSE: 0.9286\n",
      "Epoch 52 Step 45368: Train 0.4263 Reg: 0.5245\n",
      "Test: 0.9255 MAE: 0.7392 RMSE: 0.9620\n",
      "Val: 0.8653 MAE: 0.7143 RMSE: 0.9302\n",
      "Epoch 53 Step 46224: Train 0.4244 Reg: 0.5202\n",
      "Test: 0.9265 MAE: 0.7385 RMSE: 0.9626\n",
      "Val: 0.8678 MAE: 0.7144 RMSE: 0.9316\n",
      "Epoch 54 Step 47080: Train 0.4227 Reg: 0.5164\n",
      "Test: 0.9319 MAE: 0.7419 RMSE: 0.9653\n",
      "Val: 0.8710 MAE: 0.7169 RMSE: 0.9333\n",
      "Epoch 55 Step 47936: Train 0.4210 Reg: 0.5125\n",
      "Test: 0.9337 MAE: 0.7400 RMSE: 0.9663\n",
      "Val: 0.8726 MAE: 0.7159 RMSE: 0.9342\n",
      "Epoch 56 Step 48792: Train 0.4193 Reg: 0.5087\n",
      "Test: 0.9369 MAE: 0.7419 RMSE: 0.9679\n",
      "Val: 0.8753 MAE: 0.7170 RMSE: 0.9356\n",
      "Epoch 57 Step 49648: Train 0.4178 Reg: 0.5051\n",
      "Test: 0.9412 MAE: 0.7430 RMSE: 0.9702\n",
      "Val: 0.8779 MAE: 0.7180 RMSE: 0.9370\n",
      "Epoch 58 Step 50504: Train 0.4162 Reg: 0.5017\n",
      "Test: 0.9430 MAE: 0.7437 RMSE: 0.9711\n",
      "Val: 0.8804 MAE: 0.7188 RMSE: 0.9383\n",
      "Epoch 59 Step 51360: Train 0.4148 Reg: 0.4985\n",
      "Test: 0.9474 MAE: 0.7459 RMSE: 0.9733\n",
      "Val: 0.8827 MAE: 0.7202 RMSE: 0.9395\n",
      "Epoch 60 Step 52216: Train 0.4133 Reg: 0.4952\n",
      "Test: 0.9503 MAE: 0.7476 RMSE: 0.9748\n",
      "Val: 0.8858 MAE: 0.7216 RMSE: 0.9412\n",
      "Epoch 61 Step 53072: Train 0.4120 Reg: 0.4922\n",
      "Test: 0.9517 MAE: 0.7462 RMSE: 0.9756\n",
      "Val: 0.8865 MAE: 0.7209 RMSE: 0.9415\n",
      "Epoch 62 Step 53928: Train 0.4107 Reg: 0.4894\n",
      "Test: 0.9552 MAE: 0.7481 RMSE: 0.9774\n",
      "Val: 0.8886 MAE: 0.7217 RMSE: 0.9426\n",
      "Epoch 63 Step 54784: Train 0.4094 Reg: 0.4866\n",
      "Test: 0.9594 MAE: 0.7512 RMSE: 0.9795\n",
      "Val: 0.8930 MAE: 0.7246 RMSE: 0.9450\n",
      "Epoch 64 Step 55640: Train 0.4082 Reg: 0.4840\n",
      "Test: 0.9604 MAE: 0.7496 RMSE: 0.9800\n",
      "Val: 0.8922 MAE: 0.7229 RMSE: 0.9446\n",
      "Epoch 65 Step 56496: Train 0.4071 Reg: 0.4814\n",
      "Test: 0.9633 MAE: 0.7511 RMSE: 0.9815\n",
      "Val: 0.8944 MAE: 0.7239 RMSE: 0.9457\n",
      "Epoch 66 Step 57352: Train 0.4059 Reg: 0.4791\n",
      "Test: 0.9651 MAE: 0.7518 RMSE: 0.9824\n",
      "Val: 0.8957 MAE: 0.7243 RMSE: 0.9464\n",
      "Epoch 67 Step 58208: Train 0.4049 Reg: 0.4767\n",
      "Test: 0.9676 MAE: 0.7505 RMSE: 0.9837\n",
      "Val: 0.8974 MAE: 0.7241 RMSE: 0.9473\n",
      "Epoch 68 Step 59064: Train 0.4039 Reg: 0.4746\n",
      "Test: 0.9695 MAE: 0.7526 RMSE: 0.9846\n",
      "Val: 0.8988 MAE: 0.7253 RMSE: 0.9481\n",
      "Epoch 69 Step 59920: Train 0.4029 Reg: 0.4724\n",
      "Test: 0.9729 MAE: 0.7540 RMSE: 0.9863\n",
      "Val: 0.9010 MAE: 0.7262 RMSE: 0.9492\n",
      "Epoch 70 Step 60776: Train 0.4019 Reg: 0.4704\n",
      "Test: 0.9751 MAE: 0.7544 RMSE: 0.9875\n",
      "Val: 0.9022 MAE: 0.7263 RMSE: 0.9498\n",
      "Epoch 71 Step 61632: Train 0.4010 Reg: 0.4684\n",
      "Test: 0.9774 MAE: 0.7552 RMSE: 0.9886\n",
      "Val: 0.9033 MAE: 0.7268 RMSE: 0.9504\n",
      "Epoch 72 Step 62488: Train 0.4001 Reg: 0.4666\n",
      "Test: 0.9785 MAE: 0.7558 RMSE: 0.9892\n",
      "Val: 0.9042 MAE: 0.7271 RMSE: 0.9509\n",
      "Epoch 73 Step 63344: Train 0.3993 Reg: 0.4649\n",
      "Test: 0.9806 MAE: 0.7573 RMSE: 0.9902\n",
      "Val: 0.9064 MAE: 0.7286 RMSE: 0.9521\n",
      "Epoch 74 Step 64200: Train 0.3985 Reg: 0.4632\n",
      "Test: 0.9828 MAE: 0.7574 RMSE: 0.9913\n",
      "Val: 0.9074 MAE: 0.7282 RMSE: 0.9526\n",
      "Epoch 75 Step 65056: Train 0.3977 Reg: 0.4616\n",
      "Test: 0.9833 MAE: 0.7573 RMSE: 0.9916\n",
      "Val: 0.9084 MAE: 0.7287 RMSE: 0.9531\n",
      "Epoch 76 Step 65912: Train 0.3970 Reg: 0.4601\n",
      "Test: 0.9856 MAE: 0.7583 RMSE: 0.9928\n",
      "Val: 0.9096 MAE: 0.7292 RMSE: 0.9537\n",
      "Epoch 77 Step 66768: Train 0.3963 Reg: 0.4586\n",
      "Test: 0.9865 MAE: 0.7583 RMSE: 0.9932\n",
      "Val: 0.9106 MAE: 0.7294 RMSE: 0.9543\n",
      "Epoch 78 Step 67624: Train 0.3956 Reg: 0.4572\n",
      "Test: 0.9903 MAE: 0.7611 RMSE: 0.9951\n",
      "Val: 0.9133 MAE: 0.7313 RMSE: 0.9557\n",
      "Epoch 79 Step 68480: Train 0.3950 Reg: 0.4559\n",
      "Test: 0.9895 MAE: 0.7592 RMSE: 0.9948\n",
      "Val: 0.9124 MAE: 0.7301 RMSE: 0.9552\n",
      "Epoch 80 Step 69336: Train 0.3943 Reg: 0.4547\n",
      "Test: 0.9916 MAE: 0.7604 RMSE: 0.9958\n",
      "Val: 0.9135 MAE: 0.7306 RMSE: 0.9558\n",
      "Epoch 81 Step 70192: Train 0.3937 Reg: 0.4535\n",
      "Test: 0.9921 MAE: 0.7600 RMSE: 0.9960\n",
      "Val: 0.9142 MAE: 0.7306 RMSE: 0.9561\n",
      "Epoch 82 Step 71048: Train 0.3932 Reg: 0.4523\n",
      "Test: 0.9932 MAE: 0.7606 RMSE: 0.9966\n",
      "Val: 0.9151 MAE: 0.7310 RMSE: 0.9566\n",
      "Epoch 83 Step 71904: Train 0.3926 Reg: 0.4512\n",
      "Test: 0.9947 MAE: 0.7611 RMSE: 0.9974\n",
      "Val: 0.9161 MAE: 0.7315 RMSE: 0.9571\n",
      "Epoch 84 Step 72760: Train 0.3921 Reg: 0.4502\n",
      "Test: 0.9961 MAE: 0.7619 RMSE: 0.9981\n",
      "Val: 0.9173 MAE: 0.7320 RMSE: 0.9577\n",
      "Epoch 85 Step 73616: Train 0.3916 Reg: 0.4492\n",
      "Test: 0.9966 MAE: 0.7611 RMSE: 0.9983\n",
      "Val: 0.9172 MAE: 0.7315 RMSE: 0.9577\n",
      "Epoch 86 Step 74472: Train 0.3911 Reg: 0.4483\n",
      "Test: 0.9975 MAE: 0.7616 RMSE: 0.9988\n",
      "Val: 0.9182 MAE: 0.7319 RMSE: 0.9582\n",
      "Epoch 87 Step 75328: Train 0.3907 Reg: 0.4474\n",
      "Test: 0.9992 MAE: 0.7625 RMSE: 0.9996\n",
      "Val: 0.9193 MAE: 0.7326 RMSE: 0.9588\n",
      "Epoch 88 Step 76184: Train 0.3902 Reg: 0.4465\n",
      "Test: 0.9999 MAE: 0.7622 RMSE: 1.0000\n",
      "Val: 0.9194 MAE: 0.7323 RMSE: 0.9589\n",
      "Epoch 89 Step 77040: Train 0.3898 Reg: 0.4457\n",
      "Test: 1.0004 MAE: 0.7624 RMSE: 1.0002\n",
      "Val: 0.9199 MAE: 0.7325 RMSE: 0.9591\n",
      "Epoch 90 Step 77896: Train 0.3894 Reg: 0.4449\n",
      "Test: 1.0017 MAE: 0.7631 RMSE: 1.0008\n",
      "Val: 0.9208 MAE: 0.7329 RMSE: 0.9596\n",
      "Epoch 91 Step 78752: Train 0.3890 Reg: 0.4442\n",
      "Test: 1.0021 MAE: 0.7630 RMSE: 1.0010\n",
      "Val: 0.9212 MAE: 0.7329 RMSE: 0.9598\n",
      "Epoch 92 Step 79608: Train 0.3887 Reg: 0.4435\n",
      "Test: 1.0035 MAE: 0.7641 RMSE: 1.0017\n",
      "Val: 0.9221 MAE: 0.7336 RMSE: 0.9603\n",
      "Epoch 93 Step 80464: Train 0.3884 Reg: 0.4428\n",
      "Test: 1.0039 MAE: 0.7639 RMSE: 1.0020\n",
      "Val: 0.9225 MAE: 0.7336 RMSE: 0.9605\n",
      "Epoch 94 Step 81320: Train 0.3880 Reg: 0.4422\n",
      "Test: 1.0054 MAE: 0.7651 RMSE: 1.0027\n",
      "Val: 0.9236 MAE: 0.7344 RMSE: 0.9610\n",
      "Epoch 95 Step 82176: Train 0.3877 Reg: 0.4416\n",
      "Test: 1.0050 MAE: 0.7642 RMSE: 1.0025\n",
      "Val: 0.9230 MAE: 0.7336 RMSE: 0.9607\n",
      "Epoch 96 Step 83032: Train 0.3874 Reg: 0.4410\n",
      "Test: 1.0059 MAE: 0.7646 RMSE: 1.0029\n",
      "Val: 0.9237 MAE: 0.7340 RMSE: 0.9611\n",
      "Epoch 97 Step 83888: Train 0.3871 Reg: 0.4405\n",
      "Test: 1.0058 MAE: 0.7636 RMSE: 1.0029\n",
      "Val: 0.9236 MAE: 0.7334 RMSE: 0.9610\n",
      "Epoch 98 Step 84744: Train 0.3868 Reg: 0.4399\n",
      "Test: 1.0071 MAE: 0.7650 RMSE: 1.0035\n",
      "Val: 0.9245 MAE: 0.7342 RMSE: 0.9615\n",
      "Epoch 99 Step 85600: Train 0.3866 Reg: 0.4394\n",
      "Test: 1.0075 MAE: 0.7649 RMSE: 1.0037\n",
      "Val: 0.9248 MAE: 0.7342 RMSE: 0.9617\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 921625/19100\n",
      "test set size: support/query 4184/809\n",
      "Epoch 0: TrainLoss 1.0422 RecLoss: 0.0000 (left: 0:07:16)\n",
      "TestLoss: 1.0709 MAE: 0.8219 RMSE: 1.0349\n",
      "ValLoss: 1.1268 MAE: 0.8546 RMSE: 1.0615\n",
      "Epoch 1: TrainLoss 1.0340 RecLoss: 0.0000 (left: 0:08:51)\n",
      "TestLoss: 1.0675 MAE: 0.8137 RMSE: 1.0332\n",
      "ValLoss: 1.1262 MAE: 0.8488 RMSE: 1.0612\n",
      "Epoch 2: TrainLoss 1.0290 RecLoss: 0.0000 (left: 0:09:00)\n",
      "TestLoss: 1.0660 MAE: 0.8222 RMSE: 1.0325\n",
      "ValLoss: 1.1211 MAE: 0.8529 RMSE: 1.0588\n",
      "Epoch 3: TrainLoss 1.0264 RecLoss: 0.0000 (left: 0:09:02)\n",
      "TestLoss: 1.0630 MAE: 0.8096 RMSE: 1.0310\n",
      "ValLoss: 1.1242 MAE: 0.8455 RMSE: 1.0603\n",
      "Epoch 4: TrainLoss 1.0220 RecLoss: 0.0000 (left: 0:08:55)\n",
      "TestLoss: 1.0593 MAE: 0.8211 RMSE: 1.0292\n",
      "ValLoss: 1.1170 MAE: 0.8522 RMSE: 1.0569\n",
      "Epoch 5: TrainLoss 1.0171 RecLoss: 0.0000 (left: 0:08:37)\n",
      "TestLoss: 1.0545 MAE: 0.8154 RMSE: 1.0269\n",
      "ValLoss: 1.1123 MAE: 0.8484 RMSE: 1.0547\n",
      "Epoch 6: TrainLoss 1.0118 RecLoss: 0.0000 (left: 0:08:33)\n",
      "TestLoss: 1.0540 MAE: 0.8070 RMSE: 1.0266\n",
      "ValLoss: 1.1136 MAE: 0.8425 RMSE: 1.0553\n",
      "Epoch 7: TrainLoss 1.0086 RecLoss: 0.0000 (left: 0:08:22)\n",
      "TestLoss: 1.0489 MAE: 0.8096 RMSE: 1.0242\n",
      "ValLoss: 1.1080 MAE: 0.8439 RMSE: 1.0526\n",
      "Epoch 8: TrainLoss 1.0062 RecLoss: 0.0000 (left: 0:08:16)\n",
      "TestLoss: 1.0468 MAE: 0.8111 RMSE: 1.0231\n",
      "ValLoss: 1.1051 MAE: 0.8443 RMSE: 1.0512\n",
      "Epoch 9: TrainLoss 1.0028 RecLoss: 0.0000 (left: 0:08:02)\n",
      "TestLoss: 1.0508 MAE: 0.8016 RMSE: 1.0251\n",
      "ValLoss: 1.1119 MAE: 0.8388 RMSE: 1.0545\n",
      "Epoch 10: TrainLoss 0.9979 RecLoss: 0.0000 (left: 0:07:46)\n",
      "TestLoss: 1.0413 MAE: 0.8049 RMSE: 1.0205\n",
      "ValLoss: 1.0998 MAE: 0.8393 RMSE: 1.0487\n",
      "Epoch 11: TrainLoss 0.9949 RecLoss: 0.0000 (left: 0:07:36)\n",
      "TestLoss: 1.0413 MAE: 0.8123 RMSE: 1.0204\n",
      "ValLoss: 1.0991 MAE: 0.8446 RMSE: 1.0484\n",
      "Epoch 12: TrainLoss 0.9918 RecLoss: 0.0000 (left: 0:07:26)\n",
      "TestLoss: 1.0375 MAE: 0.8050 RMSE: 1.0186\n",
      "ValLoss: 1.0959 MAE: 0.8391 RMSE: 1.0469\n",
      "Epoch 13: TrainLoss 0.9893 RecLoss: 0.0000 (left: 0:07:18)\n",
      "TestLoss: 1.0370 MAE: 0.8013 RMSE: 1.0183\n",
      "ValLoss: 1.0958 MAE: 0.8365 RMSE: 1.0468\n",
      "Epoch 14: TrainLoss 0.9863 RecLoss: 0.0000 (left: 0:07:06)\n",
      "TestLoss: 1.0340 MAE: 0.8077 RMSE: 1.0168\n",
      "ValLoss: 1.0915 MAE: 0.8406 RMSE: 1.0447\n",
      "Epoch 15: TrainLoss 0.9823 RecLoss: 0.0000 (left: 0:07:04)\n",
      "TestLoss: 1.0315 MAE: 0.8029 RMSE: 1.0156\n",
      "ValLoss: 1.0897 MAE: 0.8370 RMSE: 1.0439\n",
      "Epoch 16: TrainLoss 0.9802 RecLoss: 0.0000 (left: 0:06:59)\n",
      "TestLoss: 1.0301 MAE: 0.8040 RMSE: 1.0149\n",
      "ValLoss: 1.0870 MAE: 0.8373 RMSE: 1.0426\n",
      "Epoch 17: TrainLoss 0.9778 RecLoss: 0.0000 (left: 0:06:53)\n",
      "TestLoss: 1.0305 MAE: 0.7974 RMSE: 1.0151\n",
      "ValLoss: 1.0905 MAE: 0.8337 RMSE: 1.0443\n",
      "Epoch 18: TrainLoss 0.9755 RecLoss: 0.0000 (left: 0:06:45)\n",
      "TestLoss: 1.0268 MAE: 0.7992 RMSE: 1.0133\n",
      "ValLoss: 1.0849 MAE: 0.8338 RMSE: 1.0416\n",
      "Epoch 19: TrainLoss 0.9732 RecLoss: 0.0000 (left: 0:06:41)\n",
      "TestLoss: 1.0256 MAE: 0.8033 RMSE: 1.0127\n",
      "ValLoss: 1.0827 MAE: 0.8365 RMSE: 1.0405\n",
      "Epoch 20: TrainLoss 0.9706 RecLoss: 0.0000 (left: 0:06:35)\n",
      "TestLoss: 1.0240 MAE: 0.7979 RMSE: 1.0119\n",
      "ValLoss: 1.0826 MAE: 0.8329 RMSE: 1.0405\n",
      "Epoch 21: TrainLoss 0.9682 RecLoss: 0.0000 (left: 0:06:29)\n",
      "TestLoss: 1.0232 MAE: 0.8054 RMSE: 1.0115\n",
      "ValLoss: 1.0784 MAE: 0.8371 RMSE: 1.0384\n",
      "Epoch 22: TrainLoss 0.9670 RecLoss: 0.0000 (left: 0:06:22)\n",
      "TestLoss: 1.0218 MAE: 0.7966 RMSE: 1.0108\n",
      "ValLoss: 1.0796 MAE: 0.8314 RMSE: 1.0390\n",
      "Epoch 23: TrainLoss 0.9638 RecLoss: 0.0000 (left: 0:06:17)\n",
      "TestLoss: 1.0219 MAE: 0.8062 RMSE: 1.0109\n",
      "ValLoss: 1.0777 MAE: 0.8382 RMSE: 1.0381\n",
      "Epoch 24: TrainLoss 0.9640 RecLoss: 0.0000 (left: 0:06:14)\n",
      "TestLoss: 1.0184 MAE: 0.7990 RMSE: 1.0092\n",
      "ValLoss: 1.0743 MAE: 0.8325 RMSE: 1.0365\n",
      "Epoch 25: TrainLoss 0.9589 RecLoss: 0.0000 (left: 0:06:06)\n",
      "TestLoss: 1.0178 MAE: 0.8016 RMSE: 1.0089\n",
      "ValLoss: 1.0721 MAE: 0.8330 RMSE: 1.0354\n",
      "Epoch 26: TrainLoss 0.9580 RecLoss: 0.0000 (left: 0:05:58)\n",
      "TestLoss: 1.0166 MAE: 0.8015 RMSE: 1.0083\n",
      "ValLoss: 1.0723 MAE: 0.8340 RMSE: 1.0355\n",
      "Epoch 27: TrainLoss 0.9561 RecLoss: 0.0000 (left: 0:05:52)\n",
      "TestLoss: 1.0144 MAE: 0.7981 RMSE: 1.0072\n",
      "ValLoss: 1.0709 MAE: 0.8315 RMSE: 1.0349\n",
      "Epoch 28: TrainLoss 0.9540 RecLoss: 0.0000 (left: 0:05:45)\n",
      "TestLoss: 1.0142 MAE: 0.7995 RMSE: 1.0071\n",
      "ValLoss: 1.0695 MAE: 0.8319 RMSE: 1.0342\n",
      "Epoch 29: TrainLoss 0.9524 RecLoss: 0.0000 (left: 0:05:39)\n",
      "TestLoss: 1.0123 MAE: 0.7970 RMSE: 1.0061\n",
      "ValLoss: 1.0683 MAE: 0.8302 RMSE: 1.0336\n",
      "Epoch 30: TrainLoss 0.9512 RecLoss: 0.0000 (left: 0:05:33)\n",
      "TestLoss: 1.0126 MAE: 0.7914 RMSE: 1.0063\n",
      "ValLoss: 1.0715 MAE: 0.8271 RMSE: 1.0351\n",
      "Epoch 31: TrainLoss 0.9498 RecLoss: 0.0000 (left: 0:05:28)\n",
      "TestLoss: 1.0116 MAE: 0.7920 RMSE: 1.0058\n",
      "ValLoss: 1.0681 MAE: 0.8265 RMSE: 1.0335\n",
      "Epoch 32: TrainLoss 0.9474 RecLoss: 0.0000 (left: 0:05:22)\n",
      "TestLoss: 1.0099 MAE: 0.7946 RMSE: 1.0049\n",
      "ValLoss: 1.0659 MAE: 0.8282 RMSE: 1.0324\n",
      "Epoch 33: TrainLoss 0.9458 RecLoss: 0.0000 (left: 0:05:15)\n",
      "TestLoss: 1.0087 MAE: 0.7945 RMSE: 1.0044\n",
      "ValLoss: 1.0646 MAE: 0.8280 RMSE: 1.0318\n",
      "Epoch 34: TrainLoss 0.9454 RecLoss: 0.0000 (left: 0:05:09)\n",
      "TestLoss: 1.0086 MAE: 0.7914 RMSE: 1.0043\n",
      "ValLoss: 1.0651 MAE: 0.8257 RMSE: 1.0321\n",
      "Epoch 35: TrainLoss 0.9437 RecLoss: 0.0000 (left: 0:05:03)\n",
      "TestLoss: 1.0077 MAE: 0.7922 RMSE: 1.0038\n",
      "ValLoss: 1.0632 MAE: 0.8257 RMSE: 1.0311\n",
      "Epoch 36: TrainLoss 0.9415 RecLoss: 0.0000 (left: 0:04:57)\n",
      "TestLoss: 1.0069 MAE: 0.7960 RMSE: 1.0034\n",
      "ValLoss: 1.0616 MAE: 0.8285 RMSE: 1.0304\n",
      "Epoch 37: TrainLoss 0.9404 RecLoss: 0.0000 (left: 0:04:50)\n",
      "TestLoss: 1.0056 MAE: 0.7914 RMSE: 1.0028\n",
      "ValLoss: 1.0613 MAE: 0.8252 RMSE: 1.0302\n",
      "Epoch 38: TrainLoss 0.9395 RecLoss: 0.0000 (left: 0:04:45)\n",
      "TestLoss: 1.0047 MAE: 0.7942 RMSE: 1.0024\n",
      "ValLoss: 1.0601 MAE: 0.8275 RMSE: 1.0296\n",
      "Epoch 39: TrainLoss 0.9382 RecLoss: 0.0000 (left: 0:04:41)\n",
      "TestLoss: 1.0040 MAE: 0.7918 RMSE: 1.0020\n",
      "ValLoss: 1.0598 MAE: 0.8254 RMSE: 1.0294\n",
      "Epoch 40: TrainLoss 0.9365 RecLoss: 0.0000 (left: 0:04:35)\n",
      "TestLoss: 1.0040 MAE: 0.7908 RMSE: 1.0020\n",
      "ValLoss: 1.0597 MAE: 0.8245 RMSE: 1.0294\n",
      "Epoch 41: TrainLoss 0.9352 RecLoss: 0.0000 (left: 0:04:30)\n",
      "TestLoss: 1.0035 MAE: 0.7950 RMSE: 1.0017\n",
      "ValLoss: 1.0580 MAE: 0.8271 RMSE: 1.0286\n",
      "Epoch 42: TrainLoss 0.9347 RecLoss: 0.0000 (left: 0:04:26)\n",
      "TestLoss: 1.0022 MAE: 0.7924 RMSE: 1.0011\n",
      "ValLoss: 1.0575 MAE: 0.8254 RMSE: 1.0283\n",
      "Epoch 43: TrainLoss 0.9340 RecLoss: 0.0000 (left: 0:04:21)\n",
      "TestLoss: 1.0030 MAE: 0.7972 RMSE: 1.0015\n",
      "ValLoss: 1.0561 MAE: 0.8283 RMSE: 1.0277\n",
      "Epoch 44: TrainLoss 0.9335 RecLoss: 0.0000 (left: 0:04:18)\n",
      "TestLoss: 1.0027 MAE: 0.7962 RMSE: 1.0013\n",
      "ValLoss: 1.0562 MAE: 0.8277 RMSE: 1.0277\n",
      "Epoch 45: TrainLoss 0.9313 RecLoss: 0.0000 (left: 0:04:15)\n",
      "TestLoss: 1.0010 MAE: 0.7895 RMSE: 1.0005\n",
      "ValLoss: 1.0565 MAE: 0.8231 RMSE: 1.0278\n",
      "Epoch 46: TrainLoss 0.9296 RecLoss: 0.0000 (left: 0:04:09)\n",
      "TestLoss: 1.0003 MAE: 0.7926 RMSE: 1.0001\n",
      "ValLoss: 1.0541 MAE: 0.8247 RMSE: 1.0267\n",
      "Epoch 47: TrainLoss 0.9289 RecLoss: 0.0000 (left: 0:04:04)\n",
      "TestLoss: 1.0001 MAE: 0.7945 RMSE: 1.0000\n",
      "ValLoss: 1.0531 MAE: 0.8257 RMSE: 1.0262\n",
      "Epoch 48: TrainLoss 0.9305 RecLoss: 0.0000 (left: 0:03:59)\n",
      "TestLoss: 0.9988 MAE: 0.7923 RMSE: 0.9994\n",
      "ValLoss: 1.0534 MAE: 0.8245 RMSE: 1.0263\n",
      "Epoch 49: TrainLoss 0.9273 RecLoss: 0.0000 (left: 0:03:54)\n",
      "TestLoss: 0.9986 MAE: 0.7906 RMSE: 0.9993\n",
      "ValLoss: 1.0533 MAE: 0.8236 RMSE: 1.0263\n",
      "Epoch 50: TrainLoss 0.9262 RecLoss: 0.0000 (left: 0:03:49)\n",
      "TestLoss: 0.9983 MAE: 0.7901 RMSE: 0.9992\n",
      "ValLoss: 1.0527 MAE: 0.8229 RMSE: 1.0260\n",
      "Epoch 51: TrainLoss 0.9259 RecLoss: 0.0000 (left: 0:03:46)\n",
      "TestLoss: 0.9983 MAE: 0.7871 RMSE: 0.9991\n",
      "ValLoss: 1.0538 MAE: 0.8207 RMSE: 1.0265\n",
      "Epoch 52: TrainLoss 0.9244 RecLoss: 0.0000 (left: 0:03:41)\n",
      "TestLoss: 0.9973 MAE: 0.7889 RMSE: 0.9987\n",
      "ValLoss: 1.0524 MAE: 0.8220 RMSE: 1.0259\n",
      "Epoch 53: TrainLoss 0.9236 RecLoss: 0.0000 (left: 0:03:35)\n",
      "TestLoss: 0.9970 MAE: 0.7920 RMSE: 0.9985\n",
      "ValLoss: 1.0508 MAE: 0.8239 RMSE: 1.0251\n",
      "Epoch 54: TrainLoss 0.9229 RecLoss: 0.0000 (left: 0:03:30)\n",
      "TestLoss: 0.9961 MAE: 0.7883 RMSE: 0.9981\n",
      "ValLoss: 1.0507 MAE: 0.8211 RMSE: 1.0250\n",
      "Epoch 55: TrainLoss 0.9221 RecLoss: 0.0000 (left: 0:03:24)\n",
      "TestLoss: 0.9964 MAE: 0.7915 RMSE: 0.9982\n",
      "ValLoss: 1.0503 MAE: 0.8237 RMSE: 1.0249\n",
      "Epoch 56: TrainLoss 0.9217 RecLoss: 0.0000 (left: 0:03:20)\n",
      "TestLoss: 0.9979 MAE: 0.7958 RMSE: 0.9989\n",
      "ValLoss: 1.0505 MAE: 0.8264 RMSE: 1.0250\n",
      "Epoch 57: TrainLoss 0.9221 RecLoss: 0.0000 (left: 0:03:15)\n",
      "TestLoss: 0.9964 MAE: 0.7938 RMSE: 0.9982\n",
      "ValLoss: 1.0492 MAE: 0.8246 RMSE: 1.0243\n",
      "Epoch 58: TrainLoss 0.9214 RecLoss: 0.0000 (left: 0:03:10)\n",
      "TestLoss: 0.9954 MAE: 0.7865 RMSE: 0.9977\n",
      "ValLoss: 1.0499 MAE: 0.8193 RMSE: 1.0246\n",
      "Epoch 59: TrainLoss 0.9193 RecLoss: 0.0000 (left: 0:03:06)\n",
      "TestLoss: 0.9976 MAE: 0.7835 RMSE: 0.9988\n",
      "ValLoss: 1.0536 MAE: 0.8179 RMSE: 1.0264\n",
      "Epoch 60: TrainLoss 0.9189 RecLoss: 0.0000 (left: 0:03:01)\n",
      "TestLoss: 0.9947 MAE: 0.7874 RMSE: 0.9973\n",
      "ValLoss: 1.0485 MAE: 0.8196 RMSE: 1.0239\n",
      "Epoch 61: TrainLoss 0.9176 RecLoss: 0.0000 (left: 0:02:56)\n",
      "TestLoss: 0.9940 MAE: 0.7884 RMSE: 0.9970\n",
      "ValLoss: 1.0478 MAE: 0.8208 RMSE: 1.0236\n",
      "Epoch 62: TrainLoss 0.9171 RecLoss: 0.0000 (left: 0:02:51)\n",
      "TestLoss: 0.9940 MAE: 0.7904 RMSE: 0.9970\n",
      "ValLoss: 1.0473 MAE: 0.8222 RMSE: 1.0234\n",
      "Epoch 63: TrainLoss 0.9162 RecLoss: 0.0000 (left: 0:02:47)\n",
      "TestLoss: 0.9938 MAE: 0.7859 RMSE: 0.9969\n",
      "ValLoss: 1.0485 MAE: 0.8190 RMSE: 1.0240\n",
      "Epoch 64: TrainLoss 0.9159 RecLoss: 0.0000 (left: 0:02:42)\n",
      "TestLoss: 0.9932 MAE: 0.7874 RMSE: 0.9966\n",
      "ValLoss: 1.0480 MAE: 0.8204 RMSE: 1.0237\n",
      "Epoch 65: TrainLoss 0.9155 RecLoss: 0.0000 (left: 0:02:38)\n",
      "TestLoss: 0.9952 MAE: 0.7834 RMSE: 0.9976\n",
      "ValLoss: 1.0503 MAE: 0.8170 RMSE: 1.0248\n",
      "Epoch 66: TrainLoss 0.9151 RecLoss: 0.0000 (left: 0:02:34)\n",
      "TestLoss: 0.9924 MAE: 0.7868 RMSE: 0.9962\n",
      "ValLoss: 1.0462 MAE: 0.8192 RMSE: 1.0228\n",
      "Epoch 67: TrainLoss 0.9141 RecLoss: 0.0000 (left: 0:02:29)\n",
      "TestLoss: 0.9937 MAE: 0.7930 RMSE: 0.9968\n",
      "ValLoss: 1.0465 MAE: 0.8238 RMSE: 1.0230\n",
      "Epoch 68: TrainLoss 0.9139 RecLoss: 0.0000 (left: 0:02:25)\n",
      "TestLoss: 0.9937 MAE: 0.7929 RMSE: 0.9969\n",
      "ValLoss: 1.0457 MAE: 0.8231 RMSE: 1.0226\n",
      "Epoch 69: TrainLoss 0.9132 RecLoss: 0.0000 (left: 0:02:20)\n",
      "TestLoss: 0.9921 MAE: 0.7862 RMSE: 0.9960\n",
      "ValLoss: 1.0461 MAE: 0.8188 RMSE: 1.0228\n",
      "Epoch 70: TrainLoss 0.9130 RecLoss: 0.0000 (left: 0:02:15)\n",
      "TestLoss: 0.9929 MAE: 0.7840 RMSE: 0.9964\n",
      "ValLoss: 1.0472 MAE: 0.8170 RMSE: 1.0233\n",
      "Epoch 71: TrainLoss 0.9117 RecLoss: 0.0000 (left: 0:02:11)\n",
      "TestLoss: 0.9929 MAE: 0.7925 RMSE: 0.9964\n",
      "ValLoss: 1.0453 MAE: 0.8230 RMSE: 1.0224\n",
      "Epoch 72: TrainLoss 0.9118 RecLoss: 0.0000 (left: 0:02:06)\n",
      "TestLoss: 0.9920 MAE: 0.7841 RMSE: 0.9960\n",
      "ValLoss: 1.0466 MAE: 0.8171 RMSE: 1.0230\n",
      "Epoch 73: TrainLoss 0.9112 RecLoss: 0.0000 (left: 0:02:01)\n",
      "TestLoss: 0.9911 MAE: 0.7883 RMSE: 0.9955\n",
      "ValLoss: 1.0441 MAE: 0.8200 RMSE: 1.0218\n",
      "Epoch 74: TrainLoss 0.9114 RecLoss: 0.0000 (left: 0:01:56)\n",
      "TestLoss: 0.9907 MAE: 0.7865 RMSE: 0.9954\n",
      "ValLoss: 1.0444 MAE: 0.8185 RMSE: 1.0219\n",
      "Epoch 75: TrainLoss 0.9104 RecLoss: 0.0000 (left: 0:01:52)\n",
      "TestLoss: 0.9918 MAE: 0.7836 RMSE: 0.9959\n",
      "ValLoss: 1.0464 MAE: 0.8167 RMSE: 1.0230\n",
      "Epoch 76: TrainLoss 0.9094 RecLoss: 0.0000 (left: 0:01:48)\n",
      "TestLoss: 0.9906 MAE: 0.7867 RMSE: 0.9953\n",
      "ValLoss: 1.0445 MAE: 0.8191 RMSE: 1.0220\n",
      "Epoch 77: TrainLoss 0.9092 RecLoss: 0.0000 (left: 0:01:43)\n",
      "TestLoss: 0.9919 MAE: 0.7833 RMSE: 0.9959\n",
      "ValLoss: 1.0464 MAE: 0.8162 RMSE: 1.0230\n",
      "Epoch 78: TrainLoss 0.9089 RecLoss: 0.0000 (left: 0:01:39)\n",
      "TestLoss: 0.9903 MAE: 0.7863 RMSE: 0.9952\n",
      "ValLoss: 1.0439 MAE: 0.8185 RMSE: 1.0217\n",
      "Epoch 79: TrainLoss 0.9081 RecLoss: 0.0000 (left: 0:01:34)\n",
      "TestLoss: 0.9905 MAE: 0.7879 RMSE: 0.9952\n",
      "ValLoss: 1.0433 MAE: 0.8193 RMSE: 1.0214\n",
      "Epoch 80: TrainLoss 0.9074 RecLoss: 0.0000 (left: 0:01:30)\n",
      "TestLoss: 0.9918 MAE: 0.7827 RMSE: 0.9959\n",
      "ValLoss: 1.0466 MAE: 0.8159 RMSE: 1.0230\n",
      "Epoch 81: TrainLoss 0.9077 RecLoss: 0.0000 (left: 0:01:25)\n",
      "TestLoss: 0.9902 MAE: 0.7847 RMSE: 0.9951\n",
      "ValLoss: 1.0439 MAE: 0.8172 RMSE: 1.0217\n",
      "Epoch 82: TrainLoss 0.9085 RecLoss: 0.0000 (left: 0:01:21)\n",
      "TestLoss: 0.9896 MAE: 0.7868 RMSE: 0.9948\n",
      "ValLoss: 1.0430 MAE: 0.8188 RMSE: 1.0213\n",
      "Epoch 83: TrainLoss 0.9067 RecLoss: 0.0000 (left: 0:01:16)\n",
      "TestLoss: 0.9898 MAE: 0.7891 RMSE: 0.9949\n",
      "ValLoss: 1.0426 MAE: 0.8204 RMSE: 1.0211\n",
      "Epoch 84: TrainLoss 0.9066 RecLoss: 0.0000 (left: 0:01:11)\n",
      "TestLoss: 0.9896 MAE: 0.7871 RMSE: 0.9948\n",
      "ValLoss: 1.0428 MAE: 0.8190 RMSE: 1.0212\n",
      "Epoch 85: TrainLoss 0.9064 RecLoss: 0.0000 (left: 0:01:07)\n",
      "TestLoss: 0.9893 MAE: 0.7874 RMSE: 0.9946\n",
      "ValLoss: 1.0426 MAE: 0.8192 RMSE: 1.0211\n",
      "Epoch 86: TrainLoss 0.9061 RecLoss: 0.0000 (left: 0:01:02)\n",
      "TestLoss: 0.9897 MAE: 0.7844 RMSE: 0.9948\n",
      "ValLoss: 1.0434 MAE: 0.8167 RMSE: 1.0215\n",
      "Epoch 87: TrainLoss 0.9051 RecLoss: 0.0000 (left: 0:00:58)\n",
      "TestLoss: 0.9894 MAE: 0.7892 RMSE: 0.9947\n",
      "ValLoss: 1.0415 MAE: 0.8201 RMSE: 1.0206\n",
      "Epoch 88: TrainLoss 0.9051 RecLoss: 0.0000 (left: 0:00:53)\n",
      "TestLoss: 0.9896 MAE: 0.7837 RMSE: 0.9948\n",
      "ValLoss: 1.0434 MAE: 0.8162 RMSE: 1.0214\n",
      "Epoch 89: TrainLoss 0.9045 RecLoss: 0.0000 (left: 0:00:49)\n",
      "TestLoss: 0.9888 MAE: 0.7840 RMSE: 0.9944\n",
      "ValLoss: 1.0428 MAE: 0.8165 RMSE: 1.0212\n",
      "Epoch 90: TrainLoss 0.9043 RecLoss: 0.0000 (left: 0:00:44)\n",
      "TestLoss: 0.9890 MAE: 0.7834 RMSE: 0.9945\n",
      "ValLoss: 1.0435 MAE: 0.8162 RMSE: 1.0215\n",
      "Epoch 91: TrainLoss 0.9038 RecLoss: 0.0000 (left: 0:00:40)\n",
      "TestLoss: 0.9915 MAE: 0.7807 RMSE: 0.9957\n",
      "ValLoss: 1.0471 MAE: 0.8142 RMSE: 1.0233\n",
      "Epoch 92: TrainLoss 0.9048 RecLoss: 0.0000 (left: 0:00:35)\n",
      "TestLoss: 0.9903 MAE: 0.7821 RMSE: 0.9951\n",
      "ValLoss: 1.0447 MAE: 0.8151 RMSE: 1.0221\n",
      "Epoch 93: TrainLoss 0.9034 RecLoss: 0.0000 (left: 0:00:31)\n",
      "TestLoss: 0.9887 MAE: 0.7851 RMSE: 0.9943\n",
      "ValLoss: 1.0419 MAE: 0.8171 RMSE: 1.0208\n",
      "Epoch 94: TrainLoss 0.9030 RecLoss: 0.0000 (left: 0:00:26)\n",
      "TestLoss: 0.9885 MAE: 0.7851 RMSE: 0.9943\n",
      "ValLoss: 1.0417 MAE: 0.8167 RMSE: 1.0206\n",
      "Epoch 95: TrainLoss 0.9028 RecLoss: 0.0000 (left: 0:00:22)\n",
      "TestLoss: 0.9884 MAE: 0.7869 RMSE: 0.9942\n",
      "ValLoss: 1.0414 MAE: 0.8185 RMSE: 1.0205\n",
      "Epoch 96: TrainLoss 0.9024 RecLoss: 0.0000 (left: 0:00:17)\n",
      "TestLoss: 0.9883 MAE: 0.7842 RMSE: 0.9941\n",
      "ValLoss: 1.0419 MAE: 0.8164 RMSE: 1.0208\n",
      "Epoch 97: TrainLoss 0.9019 RecLoss: 0.0000 (left: 0:00:13)\n",
      "TestLoss: 0.9879 MAE: 0.7862 RMSE: 0.9939\n",
      "ValLoss: 1.0412 MAE: 0.8181 RMSE: 1.0204\n",
      "Epoch 98: TrainLoss 0.9015 RecLoss: 0.0000 (left: 0:00:08)\n",
      "TestLoss: 0.9881 MAE: 0.7847 RMSE: 0.9940\n",
      "ValLoss: 1.0415 MAE: 0.8167 RMSE: 1.0206\n",
      "Epoch 99: TrainLoss 0.9017 RecLoss: 0.0000 (left: 0:00:04)\n",
      "TestLoss: 0.9894 MAE: 0.7819 RMSE: 0.9947\n",
      "ValLoss: 1.0437 MAE: 0.8146 RMSE: 1.0216\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 921625/19100\n",
      "test set size: support/query 4184/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.6896 RMSE: 0.8768 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7862 RMSE: 0.9939 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7052 RMSE: 0.8968 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = [10, 20, 40, 60]\n",
    "y_axis = [1.0013,0.9986,0.9933, 0.9923]\n",
    "x1_axis = [10, 20, 40, 60]\n",
    "y1_axis = [0.9859, 0.9859, 0.9859, 0.9859]\n",
    "x2_axis = [10, 20, 40, 60]\n",
    "y2_axis = [0.9990, 0.9935, 0.9906, 0.9883]\n",
    "x4_axis = [10, 20, 40, 60]\n",
    "y4_axis = [0.9965, 0.9957, 0.9940, 0.9916]\n",
    "plt.plot(x1_axis, y1_axis, label=\"Base-Line 100% SUPPORT USERS ARE USED AS CORE USERS\")\n",
    "plt.plot(x_axis, y_axis, label=\"CORE USER CALCULATED USING COSINE SIMILARITY\")\n",
    "plt.plot(x2_axis, y2_axis, label=\"CORE USER CALCULATED USING CUR DECOMPOSITION\")\n",
    "plt.plot(x4_axis, y4_axis, label=\"CORE USER CALCULATED USING OPTIMAL CUR DECOMPOSITION\")\n",
    "\n",
    "plt.title('RMSE VS % of core user in support')\n",
    "plt.xlabel('% of core users in support')\n",
    "plt.ylabel('RMSE')\n",
    "plt.grid()\n",
    "plt.legend(fontsize=7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
