{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code to seperate out users with threshold > 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from scipy.sparse.linalg import svds\n",
    "import random \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as ss\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadData():\n",
    "    ml1m_dir = 'data/ratings.dat'\n",
    "    ml1m_rating = pd.read_csv(ml1m_dir, sep='::', header=None, names=['uid', 'mid', 'rating', 'timestamp'],  engine='python')\n",
    "    unique_uid = np.unique(np.array(ml1m_rating['uid'].tolist()))\n",
    "    unique_mid = np.unique(np.array(ml1m_rating['mid'].tolist()))\n",
    "    uid_dict = dict([(y,x) for x,y in enumerate(unique_uid)])\n",
    "    mid_dict = dict([(y,x) for x,y in enumerate(unique_mid)])\n",
    "    print('DICTIONARY PREPARED:')\n",
    "\n",
    "    # init user item dictionary:\n",
    "    \n",
    "    uid_list = ml1m_rating['uid'].tolist()\n",
    "    uid_list_len = len(uid_list)\n",
    "    mid_list = ml1m_rating['mid'].tolist()\n",
    "    mid_list_len = len(mid_list)\n",
    "    rating_list = ml1m_rating['rating'].tolist()\n",
    "    user_item_dict = {x:set() for x in range(len(unique_uid))}\n",
    "    item_user_dict = {x:set() for x in range(len(unique_mid))}\n",
    "    for i in range(uid_list_len):\n",
    "        uid_list[i] = uid_dict[uid_list[i]]\n",
    "        mid_list[i] = mid_dict[mid_list[i]]\n",
    "        # rating_list[i] = 1 # comment this line if you want to activate explicit ratings\n",
    "        user_item_dict[uid_list[i]].add(mid_list[i])\n",
    "        item_user_dict[mid_list[i]].add(uid_list[i])\n",
    "    tmp_df = pd.DataFrame({\"uid\":uid_list, \"mid\":mid_list, \"ratings\":rating_list})\n",
    "    v = tmp_df.uid.value_counts()\n",
    "    df = tmp_df[tmp_df.uid.isin(v.index[v.gt(30)])]\n",
    "### code to store less than 30 interactions:\n",
    "    df_less_30 = tmp_df[tmp_df.uid.isin(v.index[v.le(30)])]\n",
    "    return df, df_less_30, len(np.unique(mid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICTIONARY PREPARED:\n",
      "GREATER THAN 30:\n",
      "           uid   mid  ratings\n",
      "0           0  1104        5\n",
      "1           0   639        3\n",
      "2           0   853        3\n",
      "3           0  3177        4\n",
      "4           0  2162        5\n",
      "...       ...   ...      ...\n",
      "1000204  6039  1019        1\n",
      "1000205  6039  1022        5\n",
      "1000206  6039   548        5\n",
      "1000207  6039  1024        4\n",
      "1000208  6039  1025        4\n",
      "\n",
      "[980300 rows x 3 columns]\n",
      "LESS THAN 30: \n",
      "          uid   mid  ratings\n",
      "233        3  3235        5\n",
      "234        3  1120        3\n",
      "235        3  2743        4\n",
      "236        3  1124        4\n",
      "237        3   971        4\n",
      "...      ...   ...      ...\n",
      "999740  6037  1288        2\n",
      "999741  6037  2495        1\n",
      "999742  6037  2511        3\n",
      "999743  6037  3165        3\n",
      "999744  6037  1007        5\n",
      "\n",
      "[19909 rows x 3 columns]\n",
      "980300\n",
      "19909\n",
      "UNIQUE MIDS:  3706\n"
     ]
    }
   ],
   "source": [
    "df_gt_30, df_le_30, unique_mids = ReadData()\n",
    "print(\"GREATER THAN 30:\\n\", df_gt_30)\n",
    "print(\"LESS THAN 30: \\n\", df_le_30)\n",
    "print(len(df_gt_30))\n",
    "print(len(df_le_30))\n",
    "print(\"UNIQUE MIDS: \", unique_mids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_gt_30.groupby(\"uid\").tail(1)\n",
    "# print(len(df_gt_30))\n",
    "train_df = df_gt_30.drop(df_gt_30.groupby('uid').tail(1).index, inplace=False)\n",
    "assert(len(df_gt_30)== len(test_df) + len(train_df))\n",
    "# print(len(test_df))\n",
    "# print(len(train_df))\n",
    "dic_train_df_uid_mapping = dict([(y,x) for x,y in enumerate(np.unique(train_df['uid']))])\n",
    "dic_train_df_uid_rmapping = dict([(x,y) for x,y in enumerate(np.unique(train_df['uid']))])\n",
    "### no need for mid mapping\n",
    "\n",
    "uid_of_train_df = train_df['uid'].tolist()\n",
    "for i in range(len(uid_of_train_df)):\n",
    "    uid_of_train_df[i] = dic_train_df_uid_mapping[uid_of_train_df[i]]\n",
    "# for index, row in train_df.iterrows():\n",
    "#     train_df['uid'][index] = dic_train_df_uid_mapping[train_df['uid'][index]]\n",
    "core_user_ko_input_train_df = pd.DataFrame({'uid':uid_of_train_df, 'mid':train_df['mid'], 'ratings':train_df['ratings']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ui_dic = {}    \n",
    "for user in range(6040):\n",
    "    train_ui_dic[user] = []\n",
    "for index,row in train_df.iterrows():\n",
    "        train_ui_dic[row['uid']].append(row['mid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3699\n"
     ]
    }
   ],
   "source": [
    "print(len(np.unique(train_df['mid'])))\n",
    "# print(dic_train_df_uid_rmapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractCoreUsers(dataframe, unique_user_len, unique_item_len):\n",
    "    # print(\"# of rows in ml1m_ratings: \", len(dataframe))\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "    userItemMatrix = np.zeros(shape=(u_len, m_len))\n",
    "    # print(userItemMatrix)\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        userItemMatrix[row['uid']][row['mid']] = row['ratings']\n",
    "        # print(row['uid'], row['mid'])\n",
    "    print(\"USER ITEM MATRIX: \\n\", userItemMatrix)\n",
    "\n",
    "    df = pd.DataFrame(userItemMatrix)\n",
    "    cosineSimilarity = cosine_similarity(df)\n",
    "    print(\"SHAPE OF COSINE MATIX:\\n \", cosineSimilarity.shape)\n",
    "\n",
    "    listToStoreTopFiftyOfEveryUser = []\n",
    "    for i in range(0, cosineSimilarity.shape[0]):\n",
    "        idx = np.argpartition(cosineSimilarity[i], -50)[-50:]\n",
    "        listToStoreTopFiftyOfEveryUser.append(idx)\n",
    "    # print(\"Top fifty list: \\n\", listToStoreTopFiftyOfEveryUser)\n",
    "    # listToStoreTopFiftyOfEveryUser = np.array(listToStoreTopFiftyOfEveryUser)\n",
    "    flatten = np.concatenate(listToStoreTopFiftyOfEveryUser)\n",
    "    listToStoreTopFiftyOfEveryUser = flatten.ravel()\n",
    "\n",
    "    # print(\"List of top 50\", listToStoreTopFiftyOfEveryUser)\n",
    "    df = pd.DataFrame(listToStoreTopFiftyOfEveryUser)\n",
    "    allUserList = df.value_counts().index.tolist()\n",
    "    # print(\"ALL USERS LIST\", allUserList)\n",
    "    allUserList = list(sum(allUserList,()))\n",
    "    # print(\"ALL USERS LIST\", allUserList)\n",
    "    twentyPercentUserList = allUserList[:int(len(allUserList)*0.2)]\n",
    "    # print(\"TWENTY PERCENT USER:\", len(twentyPercentUserList))\n",
    "    # print(\"TWENTY PERCENT USER:\", (twentyPercentUserList))\n",
    "    coreusers = dataframe.iloc[np.where(dataframe.uid.isin(twentyPercentUserList))]\n",
    "    # coreusers.reset_index()\n",
    "    # print(\"CORE USERS:\\n\", coreusers)\n",
    "    return coreusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER LEN: 5231\n",
      "MOVIE LEN: 3706\n",
      "USER ITEM MATRIX: \n",
      " [[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 0.]]\n",
      "SHAPE OF COSINE MATIX:\n",
      "  (5231, 5231)\n",
      "CORE USERS:           uid   mid  ratings\n",
      "523         5   627        4\n",
      "524         5   805        4\n",
      "525         5  2708        5\n",
      "526         5  3341        3\n",
      "527         5  3550        3\n",
      "...       ...   ...      ...\n",
      "1000203  5230  1018        3\n",
      "1000204  5230  1019        1\n",
      "1000205  5230  1022        5\n",
      "1000206  5230   548        5\n",
      "1000207  5230  1024        4\n",
      "\n",
      "[366403 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "core_users = ExtractCoreUsers(core_user_ko_input_train_df, len(np.unique(uid_of_train_df)), unique_mids)\n",
    "support_user_list = np.unique(core_users['uid'])\n",
    "print(\"CORE USERS:\" ,core_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6038\n",
      "          uid   mid  ratings\n",
      "0           0  1104        5\n",
      "1           0   639        3\n",
      "2           0   853        3\n",
      "3           0  3177        4\n",
      "4           0  2162        5\n",
      "...       ...   ...      ...\n",
      "1000203  6039  1018        3\n",
      "1000204  6039  1019        1\n",
      "1000205  6039  1022        5\n",
      "1000206  6039   548        5\n",
      "1000207  6039  1024        4\n",
      "\n",
      "[975069 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_df['uid'][999866])\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON CORE USERS:          uid   mid  ratings\n",
      "0          0  1104        5\n",
      "1          0   639        3\n",
      "2          0   853        3\n",
      "3          0  3177        4\n",
      "4          0  2162        5\n",
      "...      ...   ...      ...\n",
      "999862  6038  1006        4\n",
      "999863  6038  1009        4\n",
      "999864  6038  1011        3\n",
      "999865  6038  1014        4\n",
      "999866  6038  1016        4\n",
      "\n",
      "[608666 rows x 3 columns]\n",
      "CORE USERS:           uid   mid  ratings\n",
      "523         5   627        4\n",
      "524         5   805        4\n",
      "525         5  2708        5\n",
      "526         5  3341        3\n",
      "527         5  3550        3\n",
      "...       ...   ...      ...\n",
      "1000203  5230  1018        3\n",
      "1000204  5230  1019        1\n",
      "1000205  5230  1022        5\n",
      "1000206  5230   548        5\n",
      "1000207  5230  1024        4\n",
      "\n",
      "[366403 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(\"CORE USERS:\" ,core_users)\n",
    "# print(\"UNIQUE USERS:\", len(np.unique(core_users['uid'])))\n",
    "core_users_index_list = core_users.index.to_list()\n",
    "non_core_user_index = (train_df.index.difference(core_users.index))\n",
    "non_core_user_index = non_core_user_index.tolist()\n",
    "\n",
    "core_users_df = train_df.loc[core_users_index_list]\n",
    "non_core_user_df = train_df.loc[non_core_user_index]\n",
    "print(\"NON CORE USERS:\" ,non_core_user_df)\n",
    "print(\"CORE USERS:\" ,core_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DF CONTAINS TEST FOR CORE AND NON CORE ENTITIES:\n",
      "           uid   mid  ratings\n",
      "52          0  1154        4\n",
      "181         1  1155        5\n",
      "232         2  1900        4\n",
      "451         4   683        4\n",
      "522         5    33        4\n",
      "...       ...   ...      ...\n",
      "998634   6034  1865        4\n",
      "999522   6035  1867        3\n",
      "999724   6036  1025        5\n",
      "999867   6038  1025        4\n",
      "1000208  6039  1025        4\n",
      "\n",
      "[5231 rows x 3 columns]\n",
      "1046\n",
      "SUPPORT TEST DF:           uid   mid  ratings\n",
      "553         6  3186        3\n",
      "798         8   414        3\n",
      "1199        9  1868        5\n",
      "1467       12  1865        4\n",
      "1693       14  1934        4\n",
      "...       ...   ...      ...\n",
      "997247   6020  1025        3\n",
      "997889   6025  1025        5\n",
      "998118   6029  1025        3\n",
      "999724   6036  1025        5\n",
      "1000208  6039  1025        4\n",
      "\n",
      "[1046 rows x 3 columns]\n",
      "QUERY TEST DF:\n",
      "          uid   mid  ratings\n",
      "52         0  1154        4\n",
      "181        1  1155        5\n",
      "232        2  1900        4\n",
      "451        4   683        4\n",
      "522        5    33        4\n",
      "...      ...   ...      ...\n",
      "998273  6031  1012        2\n",
      "998333  6032  1848        5\n",
      "998634  6034  1865        4\n",
      "999522  6035  1867        3\n",
      "999867  6038  1025        4\n",
      "\n",
      "[4185 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"TEST DF CONTAINS TEST FOR CORE AND NON CORE ENTITIES:\\n\" ,test_df)\n",
    "# print(core_users['uid'])\n",
    "unique_uids_in_support_trian = np.unique(np.array(core_users_df['uid']))\n",
    "unique_uids_in_query_trian = np.unique(non_core_user_df['uid'])\n",
    "print(len(unique_uids_in_support_trian))\n",
    "support_test_df = test_df.loc[test_df['uid'].isin(unique_uids_in_support_trian)]\n",
    "print(\"SUPPORT TEST DF:\" ,support_test_df)\n",
    "query_test_df = test_df.loc[test_df['uid'].isin(unique_uids_in_query_trian)]\n",
    "print(\"QUERY TEST DF:\\n\", query_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_train = []\n",
    "for index,row in core_users_df.iterrows():\n",
    "    support_train.append([row['uid'], row['mid'], row['ratings']])\n",
    "query_train = []\n",
    "for index, row in non_core_user_df.iterrows():\n",
    "    query_train.append([row['uid'], row['mid'], row['ratings']])\n",
    "support_test = []\n",
    "for index, row in support_test_df.iterrows():\n",
    "    support_test.append([row['uid'], row['mid'], row['ratings']])\n",
    "query_test = []\n",
    "for index, row in query_test_df.iterrows():\n",
    "    query_test.append([row['uid'], row['mid'], row['ratings']])\n",
    "user_his_dic = {}\n",
    "for u in train_ui_dic.keys():\n",
    "    user_his_dic[u] = train_ui_dic[u]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "193329ff9dce9d81919d1650a0fae85851d0854e3de134d2444776b3f06aa6e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
