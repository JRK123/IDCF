{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code to seperate out users with threshold > 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from scipy.sparse.linalg import svds\n",
    "import random \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as ss\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadData():\n",
    "    ml1m_dir = 'data/ratings.dat'\n",
    "    ml1m_rating = pd.read_csv(ml1m_dir, sep='::', header=None, names=['uid', 'mid', 'rating', 'timestamp'],  engine='python')\n",
    "    unique_uid = np.unique(np.array(ml1m_rating['uid'].tolist()))\n",
    "    unique_mid = np.unique(np.array(ml1m_rating['mid'].tolist()))\n",
    "    uid_dict = dict([(y,x) for x,y in enumerate(unique_uid)])\n",
    "    mid_dict = dict([(y,x) for x,y in enumerate(unique_mid)])\n",
    "    print('DICTIONARY PREPARED:')\n",
    "\n",
    "    # init user item dictionary:\n",
    "    \n",
    "    uid_list = ml1m_rating['uid'].tolist()\n",
    "    uid_list_len = len(uid_list)\n",
    "    mid_list = ml1m_rating['mid'].tolist()\n",
    "    mid_list_len = len(mid_list)\n",
    "    rating_list = ml1m_rating['rating'].tolist()\n",
    "    user_item_dict = {x:set() for x in range(len(unique_uid))}\n",
    "    item_user_dict = {x:set() for x in range(len(unique_mid))}\n",
    "    for i in range(uid_list_len):\n",
    "        uid_list[i] = uid_dict[uid_list[i]]\n",
    "        mid_list[i] = mid_dict[mid_list[i]]\n",
    "        # rating_list[i] = 1 # comment this line if you want to activate explicit ratings\n",
    "        user_item_dict[uid_list[i]].add(mid_list[i])\n",
    "        item_user_dict[mid_list[i]].add(uid_list[i])\n",
    "    tmp_df = pd.DataFrame({\"uid\":uid_list, \"mid\":mid_list, \"ratings\":rating_list})\n",
    "    v = tmp_df.uid.value_counts()\n",
    "    df = tmp_df[tmp_df.uid.isin(v.index[v.gt(30)])]\n",
    "### code to store less than 30 interactions:\n",
    "    df_less_30 = tmp_df[tmp_df.uid.isin(v.index[v.le(30)])]\n",
    "    return df, df_less_30, len(np.unique(mid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICTIONARY PREPARED:\n",
      "GREATER THAN 30:\n",
      "           uid   mid  ratings\n",
      "0           0  1104        5\n",
      "1           0   639        3\n",
      "2           0   853        3\n",
      "3           0  3177        4\n",
      "4           0  2162        5\n",
      "...       ...   ...      ...\n",
      "1000204  6039  1019        1\n",
      "1000205  6039  1022        5\n",
      "1000206  6039   548        5\n",
      "1000207  6039  1024        4\n",
      "1000208  6039  1025        4\n",
      "\n",
      "[980300 rows x 3 columns]\n",
      "LESS THAN 30: \n",
      "          uid   mid  ratings\n",
      "233        3  3235        5\n",
      "234        3  1120        3\n",
      "235        3  2743        4\n",
      "236        3  1124        4\n",
      "237        3   971        4\n",
      "...      ...   ...      ...\n",
      "999740  6037  1288        2\n",
      "999741  6037  2495        1\n",
      "999742  6037  2511        3\n",
      "999743  6037  3165        3\n",
      "999744  6037  1007        5\n",
      "\n",
      "[19909 rows x 3 columns]\n",
      "980300\n",
      "19909\n",
      "UNIQUE MIDS:  3706\n"
     ]
    }
   ],
   "source": [
    "df_gt_30, df_le_30, unique_mids = ReadData()\n",
    "print(\"GREATER THAN 30:\\n\", df_gt_30)\n",
    "print(\"LESS THAN 30: \\n\", df_le_30)\n",
    "print(len(df_gt_30))\n",
    "print(len(df_le_30))\n",
    "print(\"UNIQUE MIDS: \", unique_mids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_gt_30.groupby(\"uid\").tail(1)\n",
    "# print(len(df_gt_30))\n",
    "train_df = df_gt_30.drop(df_gt_30.groupby('uid').tail(1).index, inplace=False)\n",
    "assert(len(df_gt_30)== len(test_df) + len(train_df))\n",
    "# print(len(test_df))\n",
    "# print(len(train_df))\n",
    "dic_train_df_uid_mapping = dict([(y,x) for x,y in enumerate(np.unique(train_df['uid']))])\n",
    "dic_train_df_uid_rmapping = dict([(x,y) for x,y in enumerate(np.unique(train_df['uid']))])\n",
    "### no need for mid mapping\n",
    "\n",
    "uid_of_train_df = train_df['uid'].tolist()\n",
    "for i in range(len(uid_of_train_df)):\n",
    "    uid_of_train_df[i] = dic_train_df_uid_mapping[uid_of_train_df[i]]\n",
    "# for index, row in train_df.iterrows():\n",
    "#     train_df['uid'][index] = dic_train_df_uid_mapping[train_df['uid'][index]]\n",
    "core_user_ko_input_train_df = pd.DataFrame({'uid':uid_of_train_df, 'mid':train_df['mid'], 'ratings':train_df['ratings']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3699\n"
     ]
    }
   ],
   "source": [
    "print(len(np.unique(train_df['mid'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractCoreUsers(dataframe, unique_user_len, unique_item_len):\n",
    "    # print(\"# of rows in ml1m_ratings: \", len(dataframe))\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "    userItemMatrix = np.zeros(shape=(u_len, m_len))\n",
    "    # print(userItemMatrix)\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        userItemMatrix[row['uid']][row['mid']] = row['ratings']\n",
    "        # print(row['uid'], row['mid'])\n",
    "    print(\"USER ITEM MATRIX: \\n\", userItemMatrix)\n",
    "\n",
    "    df = pd.DataFrame(userItemMatrix)\n",
    "    cosineSimilarity = cosine_similarity(df)\n",
    "    print(\"SHAPE OF COSINE MATIX:\\n \", cosineSimilarity.shape)\n",
    "\n",
    "    listToStoreTopFiftyOfEveryUser = []\n",
    "    for i in range(0, cosineSimilarity.shape[0]):\n",
    "        idx = np.argpartition(cosineSimilarity[i], -50)[-50:]\n",
    "        listToStoreTopFiftyOfEveryUser.append(idx)\n",
    "    # print(\"Top fifty list: \\n\", listToStoreTopFiftyOfEveryUser)\n",
    "    # listToStoreTopFiftyOfEveryUser = np.array(listToStoreTopFiftyOfEveryUser)\n",
    "    flatten = np.concatenate(listToStoreTopFiftyOfEveryUser)\n",
    "    listToStoreTopFiftyOfEveryUser = flatten.ravel()\n",
    "\n",
    "    # print(\"List of top 50\", listToStoreTopFiftyOfEveryUser)\n",
    "    df = pd.DataFrame(listToStoreTopFiftyOfEveryUser)\n",
    "    allUserList = df.value_counts().index.tolist()\n",
    "    # print(\"ALL USERS LIST\", allUserList)\n",
    "    allUserList = list(sum(allUserList,()))\n",
    "    # print(\"ALL USERS LIST\", allUserList)\n",
    "    twentyPercentUserList = allUserList[:int(len(allUserList)*0.2)]\n",
    "    # print(\"TWENTY PERCENT USER:\", len(twentyPercentUserList))\n",
    "    # print(\"TWENTY PERCENT USER:\", (twentyPercentUserList))\n",
    "    coreusers = dataframe.iloc[np.where(dataframe.uid.isin(twentyPercentUserList))]\n",
    "    # coreusers.reset_index()\n",
    "    # print(\"CORE USERS:\\n\", coreusers)\n",
    "    return coreusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER LEN: 5231\n",
      "MOVIE LEN: 3706\n",
      "USER ITEM MATRIX: \n",
      " [[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 0.]]\n",
      "SHAPE OF COSINE MATIX:\n",
      "  (5231, 5231)\n",
      "[   5    7    8 ... 5222 5228 5230]\n"
     ]
    }
   ],
   "source": [
    "core_users = ExtractCoreUsers(core_user_ko_input_train_df, len(np.unique(uid_of_train_df)), unique_mids)\n",
    "support_user_list = np.unique(core_users['uid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6038\n"
     ]
    }
   ],
   "source": [
    "print(train_df['uid'][999866])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          uid   mid  ratings\n",
      "523         5   627        4\n",
      "524         5   805        4\n",
      "525         5  2708        5\n",
      "526         5  3341        3\n",
      "527         5  3550        3\n",
      "...       ...   ...      ...\n",
      "1000203  5230  1018        3\n",
      "1000204  5230  1019        1\n",
      "1000205  5230  1022        5\n",
      "1000206  5230   548        5\n",
      "1000207  5230  1024        4\n",
      "\n",
      "[366403 rows x 3 columns]\n",
      "1046\n",
      "NON CORE INDEX: Int64Index([     0,      1,      2,      3,      4,      5,      6,      7,\n",
      "                 8,      9,\n",
      "            ...\n",
      "            999857, 999858, 999859, 999860, 999861, 999862, 999863, 999864,\n",
      "            999865, 999866],\n",
      "           dtype='int64', length=608666)\n",
      "975069\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 975569 is out of bounds for axis 0 with size 975069",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/raid/home/jayantkalani/IDCF/code/ml-1m/IDCF-NN/runsv2.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.61/raid/home/jayantkalani/IDCF/code/ml-1m/IDCF-NN/runsv2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(train_df))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.61/raid/home/jayantkalani/IDCF/code/ml-1m/IDCF-NN/runsv2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39massert\u001b[39;00m(\u001b[39mlen\u001b[39m(core_users) \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(non_core_user_index)\u001b[39m==\u001b[39m\u001b[39mlen\u001b[39m(train_df))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.61/raid/home/jayantkalani/IDCF/code/ml-1m/IDCF-NN/runsv2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m non_core_user_df \u001b[39m=\u001b[39m train_df\u001b[39m.\u001b[39mloc[train_df\u001b[39m.\u001b[39;49mindex[non_core_user_index]]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.61/raid/home/jayantkalani/IDCF/code/ml-1m/IDCF-NN/runsv2.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(non_core_user_df)\n",
      "File \u001b[0;32m~/miniconda3/envs/ncf2/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5048\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m   5049\u001b[0m     \u001b[39m# if we have list[bools, length=1e5] then doing this check+convert\u001b[39;00m\n\u001b[1;32m   5050\u001b[0m     \u001b[39m#  takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__\u001b[39;00m\n\u001b[1;32m   5051\u001b[0m     \u001b[39m#  time below from 3.8 ms to 496 µs\u001b[39;00m\n\u001b[1;32m   5052\u001b[0m     \u001b[39m# if we already have ndarray[bool], the overhead is 1.4 µs or .25%\u001b[39;00m\n\u001b[1;32m   5053\u001b[0m     key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[0;32m-> 5055\u001b[0m result \u001b[39m=\u001b[39m getitem(key)\n\u001b[1;32m   5056\u001b[0m \u001b[39m# Because we ruled out integer above, we always get an arraylike here\u001b[39;00m\n\u001b[1;32m   5057\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mIndexError\u001b[0m: index 975569 is out of bounds for axis 0 with size 975069"
     ]
    }
   ],
   "source": [
    "print(core_users)\n",
    "print(len(np.unique(core_users['uid'])))\n",
    "non_core_user_index = (train_df.index.difference(core_users.index))\n",
    "print(\"NON CORE INDEX:\", non_core_user_index)\n",
    "print(len(train_df))\n",
    "assert(len(core_users) + len(non_core_user_index)==len(train_df))\n",
    "non_core_user_df = train_df.loc[train_df.index[non_core_user_index]]\n",
    "print(non_core_user_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "193329ff9dce9d81919d1650a0fae85851d0854e3de134d2444776b3f06aa6e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
