{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from scipy.sparse.linalg import svds\n",
    "import random \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as ss\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadData():\n",
    "    ml1m_dir = 'data/ratings.dat'\n",
    "    ml1m_rating = pd.read_csv(ml1m_dir, sep='::', header=None, names=['uid', 'mid', 'rating', 'timestamp'],  engine='python')\n",
    "    unique_uid = np.unique(np.array(ml1m_rating['uid'].tolist()))\n",
    "    unique_mid = np.unique(np.array(ml1m_rating['mid'].tolist()))\n",
    "    uid_dict = dict([(y,x) for x,y in enumerate(unique_uid)])\n",
    "    mid_dict = dict([(y,x) for x,y in enumerate(unique_mid)])\n",
    "    print('DICTIONARY PREPARED:')\n",
    "\n",
    "    # init user item dictionary:\n",
    "    \n",
    "    uid_list = ml1m_rating['uid'].tolist()\n",
    "    uid_list_len = len(uid_list)\n",
    "    mid_list = ml1m_rating['mid'].tolist()\n",
    "    mid_list_len = len(mid_list)\n",
    "    rating_list = ml1m_rating['rating'].tolist()\n",
    "    user_item_dict = {x:set() for x in range(len(unique_uid))}\n",
    "    item_user_dict = {x:set() for x in range(len(unique_mid))}\n",
    "    for i in range(uid_list_len):\n",
    "        uid_list[i] = uid_dict[uid_list[i]]\n",
    "        mid_list[i] = mid_dict[mid_list[i]]\n",
    "        # rating_list[i] = 1 # comment this line if you want to activate explicit ratings\n",
    "        user_item_dict[uid_list[i]].add(mid_list[i])\n",
    "        item_user_dict[mid_list[i]].add(uid_list[i])\n",
    "    tmp_df = pd.DataFrame({\"uid\":uid_list, \"mid\":mid_list, \"ratings\":rating_list})\n",
    "    v = tmp_df.uid.value_counts()\n",
    "    df = tmp_df[tmp_df.uid.isin(v.index[v.gt(30)])]\n",
    "### code to store less than 30 interactions:\n",
    "    df_less_30 = tmp_df[tmp_df.uid.isin(v.index[v.le(30)])]\n",
    "    return df, df_less_30, len(np.unique(mid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICTIONARY PREPARED:\n",
      "GREATER THAN 30:\n",
      "           uid   mid  ratings\n",
      "0           0  1104        5\n",
      "1           0   639        3\n",
      "2           0   853        3\n",
      "3           0  3177        4\n",
      "4           0  2162        5\n",
      "...       ...   ...      ...\n",
      "1000204  6039  1019        1\n",
      "1000205  6039  1022        5\n",
      "1000206  6039   548        5\n",
      "1000207  6039  1024        4\n",
      "1000208  6039  1025        4\n",
      "\n",
      "[980300 rows x 3 columns]\n",
      "LESS THAN 30: \n",
      "          uid   mid  ratings\n",
      "233        3  3235        5\n",
      "234        3  1120        3\n",
      "235        3  2743        4\n",
      "236        3  1124        4\n",
      "237        3   971        4\n",
      "...      ...   ...      ...\n",
      "999740  6037  1288        2\n",
      "999741  6037  2495        1\n",
      "999742  6037  2511        3\n",
      "999743  6037  3165        3\n",
      "999744  6037  1007        5\n",
      "\n",
      "[19909 rows x 3 columns]\n",
      "980300\n",
      "19909\n",
      "UNIQUE MIDS:  3706\n"
     ]
    }
   ],
   "source": [
    "df_gt_30, df_le_30, unique_mids = ReadData()\n",
    "print(\"GREATER THAN 30:\\n\", df_gt_30)\n",
    "print(\"LESS THAN 30: \\n\", df_le_30)\n",
    "print(len(df_gt_30))\n",
    "print(len(df_le_30))\n",
    "print(\"UNIQUE MIDS: \", unique_mids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_gt_30.groupby(\"uid\").tail(1)\n",
    "# print(len(df_gt_30))\n",
    "train_df = df_gt_30.drop(df_gt_30.groupby('uid').tail(1).index, inplace=False)\n",
    "assert(len(df_gt_30)== len(test_df) + len(train_df))\n",
    "# print(len(test_df))\n",
    "# print(len(train_df))\n",
    "dic_train_df_uid_mapping = dict([(y,x) for x,y in enumerate(np.unique(train_df['uid']))])\n",
    "dic_train_df_uid_rmapping = dict([(x,y) for x,y in enumerate(np.unique(train_df['uid']))])\n",
    "### no need for mid mapping\n",
    "\n",
    "uid_of_train_df = train_df['uid'].tolist()\n",
    "for i in range(len(uid_of_train_df)):\n",
    "    uid_of_train_df[i] = dic_train_df_uid_mapping[uid_of_train_df[i]]\n",
    "# for index, row in train_df.iterrows():\n",
    "#     train_df['uid'][index] = dic_train_df_uid_mapping[train_df['uid'][index]]\n",
    "core_user_ko_input_train_df = pd.DataFrame({'uid':uid_of_train_df, 'mid':train_df['mid'], 'ratings':train_df['ratings']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ui_dic = {}    \n",
    "for user in range(6040):\n",
    "    train_ui_dic[user] = []\n",
    "for index,row in train_df.iterrows():\n",
    "        train_ui_dic[row['uid']].append(row['mid'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- utility functions for CUR coreusers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MID = 27277 + 1\n",
    "def select_cols(mat, k, dup=False):\n",
    "    # prob 1d array of probabilities of all columns\n",
    "    prob = mat.T.dot(mat)\n",
    "    prob = np.array(np.diagonal(prob))\n",
    "    denom = np.abs(prob).sum(axis = 0)\n",
    "    prob = prob/denom\n",
    "\n",
    "    C = np.zeros((mat.shape[0], k))\n",
    "    ind_cols = np.arange(0, prob.size)\n",
    "    c_ind = []\n",
    "    for i in range(k):\n",
    "        rand_sel = np.random.choice(ind_cols, 1, p=prob)\n",
    "        c_ind.append(rand_sel[0])\n",
    "        C[:, i] = mat[:, rand_sel[0]]\n",
    "        # C[:, i] = C[:, i]/np.sqrt(k*prob[rand_sel[0]])\n",
    "\n",
    "    return C, c_ind\n",
    "\n",
    "def select_rows(mat, k, dup=False):\n",
    "\n",
    "    prob = mat.dot(mat.T)\n",
    "    prob = np.array(np.diagonal(prob))\n",
    "    denom = np.abs(prob).sum(axis=0)\n",
    "    prob = prob/denom\n",
    "    print(prob)\n",
    "    r = np.zeros((k, mat.shape[1]))\n",
    "    ind_rows = np.arange(0, prob.size)\n",
    "    r_ind = []\n",
    "    for i in range(k):\n",
    "        # print(ind_rows)\n",
    "        rand_sel = np.random.choice(ind_rows, 1, p=prob)\n",
    "        r_ind.append(rand_sel[0])\n",
    "        r[i, :] = mat[rand_sel[0], :]\n",
    "        # r[i, :] = r[i, :]/np.sqrt(k*prob[rand_sel[0]])\n",
    "    r_ind = np.array(r_ind)\n",
    "    return r, r_ind\n",
    "\n",
    "def matIntersection(mat, c_ind, r_ind):\n",
    "    \n",
    "    W = np.zeros((len(r_ind), len(c_ind)))\n",
    "    for i in range(len(r_ind)):\n",
    "        W[i] = mat[r_ind[i], c_ind]\n",
    "    \n",
    "    return W\n",
    "\n",
    "def pseudoInverse(W):\n",
    "    # U = WP (W+)\n",
    "\n",
    "    # W = X.Z.YT\n",
    "    X, Z, YT = np.linalg.svd(W)\n",
    "    \n",
    "    # W+ = Y.Z+.XT\n",
    "    XT = X.T\n",
    "    Y = YT.T\n",
    "    # Z+ = reciprocal(Z)\n",
    "    ZP = np.reciprocal(Z)\n",
    "    ZP = sp.spdiags(ZP, 0, ZP.size, ZP.size)\n",
    "    ZP = ZP@ZP\n",
    "    \n",
    "    # W+ = Y.Z+.XT\n",
    "    WP = Y@ZP\n",
    "    WP = WP@XT\n",
    "\n",
    "    return WP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CUR_ExtractCoreUsers(dataframe, unique_user_len, unique_item_len):\n",
    "    # print(\"# of rows in ml1m_ratings: \", len(dataframe))\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "    userItemMatrix = np.zeros(shape=(u_len, m_len))\n",
    "    # print(userItemMatrix)\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        userItemMatrix[row['uid']][row['mid']] = row['ratings']\n",
    "        # print(row['uid'], row['mid'])\n",
    "    print(\"USER ITEM MATRIX: \\n\", userItemMatrix)\n",
    "\n",
    "    mat = userItemMatrix\n",
    "    print(\"MAT:\", mat)\n",
    "    C, c_ind = select_cols(mat, int(u_len * 0.20)) ## getting 20% core users\n",
    "    r, r_ind= select_rows(mat, int(u_len * 0.20))\n",
    "    print(\"r\", r)\n",
    "    print(\"r_ind\", r_ind)\n",
    "\n",
    "    cur_coreusers = dataframe.iloc[np.where(dataframe.uid.isin(r_ind))]\n",
    "    # coreusers.reset_index()\n",
    "    # print(\"CORE USERS:\\n\", coreusers)\n",
    "    return cur_coreusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER LEN: 5231\n",
      "MOVIE LEN: 3706\n",
      "USER ITEM MATRIX: \n",
      " [[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 0.]]\n",
      "MAT: [[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 0.]]\n",
      "[6.85044107e-05 1.37447016e-04 5.90832284e-05 ... 2.13400733e-04\n",
      " 1.38688567e-04 3.52162333e-04]\n",
      "r [[0. 0. 0. ... 0. 0. 4.]\n",
      " [3. 5. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 5.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "r_ind [2472  681 3036 ... 4219 4213 2983]\n",
      "CORE USERS:          uid   mid  ratings\n",
      "4263      27  1087        2\n",
      "4264      27  1157        2\n",
      "4265      27  3189        2\n",
      "4266      27  2354        4\n",
      "4267      27  2357        3\n",
      "...      ...   ...      ...\n",
      "996786  5208  1022        4\n",
      "996787  5208   548        4\n",
      "996788  5208  1024        4\n",
      "996789  5208  1025        3\n",
      "996790  5208  1862        2\n",
      "\n",
      "[291458 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "core_users = CUR_ExtractCoreUsers(core_user_ko_input_train_df, len(np.unique(uid_of_train_df)), unique_mids)\n",
    "support_user_list = np.unique(core_users['uid'])\n",
    "print(\"CORE USERS:\" ,core_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON CORE USERS:           uid   mid  ratings\n",
      "0           0  1104        5\n",
      "1           0   639        3\n",
      "2           0   853        3\n",
      "3           0  3177        4\n",
      "4           0  2162        5\n",
      "...       ...   ...      ...\n",
      "1000203  6039  1018        3\n",
      "1000204  6039  1019        1\n",
      "1000205  6039  1022        5\n",
      "1000206  6039   548        5\n",
      "1000207  6039  1024        4\n",
      "\n",
      "[683611 rows x 3 columns]\n",
      "CORE USERS:          uid   mid  ratings\n",
      "4263      27  1087        2\n",
      "4264      27  1157        2\n",
      "4265      27  3189        2\n",
      "4266      27  2354        4\n",
      "4267      27  2357        3\n",
      "...      ...   ...      ...\n",
      "996786  5208  1022        4\n",
      "996787  5208   548        4\n",
      "996788  5208  1024        4\n",
      "996789  5208  1025        3\n",
      "996790  5208  1862        2\n",
      "\n",
      "[291458 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "core_users_index_list = core_users.index.to_list()\n",
    "non_core_user_index = (train_df.index.difference(core_users.index))\n",
    "non_core_user_index = non_core_user_index.tolist()\n",
    "\n",
    "core_users_df = train_df.loc[core_users_index_list]\n",
    "non_core_user_df = train_df.loc[non_core_user_index]\n",
    "print(\"NON CORE USERS:\" ,non_core_user_df)\n",
    "print(\"CORE USERS:\" ,core_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DF CONTAINS TEST FOR CORE AND NON CORE ENTITIES:\n",
      "           uid   mid  ratings\n",
      "52          0  1154        4\n",
      "181         1  1155        5\n",
      "232         2  1900        4\n",
      "451         4   683        4\n",
      "522         5    33        4\n",
      "...       ...   ...      ...\n",
      "998634   6034  1865        4\n",
      "999522   6035  1867        3\n",
      "999724   6036  1025        5\n",
      "999867   6038  1025        4\n",
      "1000208  6039  1025        4\n",
      "\n",
      "[5231 rows x 3 columns]\n",
      "894\n",
      "SUPPORT TEST DF:          uid   mid  ratings\n",
      "4653      32  1155        3\n",
      "8908      58  1155        5\n",
      "9512      61  1155        4\n",
      "11015     80  1155        5\n",
      "11133     81  1020        5\n",
      "...      ...   ...      ...\n",
      "991314  5986   548        4\n",
      "994110  6001  1025        4\n",
      "995572  6010  1865        5\n",
      "995882  6014  1007        5\n",
      "996791  6015  3540        4\n",
      "\n",
      "[894 rows x 3 columns]\n",
      "QUERY TEST DF:\n",
      "           uid   mid  ratings\n",
      "52          0  1154        4\n",
      "181         1  1155        5\n",
      "232         2  1900        4\n",
      "451         4   683        4\n",
      "522         5    33        4\n",
      "...       ...   ...      ...\n",
      "998634   6034  1865        4\n",
      "999522   6035  1867        3\n",
      "999724   6036  1025        5\n",
      "999867   6038  1025        4\n",
      "1000208  6039  1025        4\n",
      "\n",
      "[4337 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"TEST DF CONTAINS TEST FOR CORE AND NON CORE ENTITIES:\\n\" ,test_df)\n",
    "# print(core_users['uid'])\n",
    "unique_uids_in_support_trian = np.unique(np.array(core_users_df['uid']))\n",
    "unique_uids_in_query_trian = np.unique(non_core_user_df['uid'])\n",
    "print(len(unique_uids_in_support_trian))\n",
    "support_test_df = test_df.loc[test_df['uid'].isin(unique_uids_in_support_trian)]\n",
    "print(\"SUPPORT TEST DF:\" ,support_test_df)\n",
    "query_test_df = test_df.loc[test_df['uid'].isin(unique_uids_in_query_trian)]\n",
    "print(\"QUERY TEST DF:\\n\", query_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_train = []\n",
    "for index,row in core_users_df.iterrows():\n",
    "    support_train.append([row['uid'], row['mid'], row['ratings']])\n",
    "query_train = []\n",
    "for index, row in non_core_user_df.iterrows():\n",
    "    query_train.append([row['uid'], row['mid'], row['ratings']])\n",
    "support_test = []\n",
    "for index, row in support_test_df.iterrows():\n",
    "    support_test.append([row['uid'], row['mid'], row['ratings']])\n",
    "query_test = []\n",
    "for index, row in query_test_df.iterrows():\n",
    "    query_test.append([row['uid'], row['mid'], row['ratings']])\n",
    "user_his_dic = {}\n",
    "for u in train_ui_dic.keys():\n",
    "    user_his_dic[u] = train_ui_dic[u]\n",
    "user_supp_list = np.unique(core_users_df['uid']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"cur_20_utils_output_file_core_users.pkl\", \"wb\") as f:\n",
    "    pickle.dump(support_train, f)\n",
    "    pickle.dump(query_train, f)\n",
    "    pickle.dump(support_test, f)\n",
    "    pickle.dump(query_test, f)\n",
    "    pickle.dump(user_supp_list, f)\n",
    "    pickle.dump(user_his_dic, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
