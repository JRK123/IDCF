{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from scipy.sparse.linalg import svds\n",
    "import random \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as ss\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadData():\n",
    "    ml1m_dir = 'data/ratings.dat'\n",
    "    ml1m_rating = pd.read_csv(ml1m_dir, sep='::', header=None, names=['uid', 'mid', 'rating', 'timestamp'],  engine='python')\n",
    "    unique_uid = np.unique(np.array(ml1m_rating['uid'].tolist()))\n",
    "    unique_mid = np.unique(np.array(ml1m_rating['mid'].tolist()))\n",
    "    uid_dict = dict([(y,x) for x,y in enumerate(unique_uid)])\n",
    "    mid_dict = dict([(y,x) for x,y in enumerate(unique_mid)])\n",
    "    print('DICTIONARY PREPARED:')\n",
    "\n",
    "    # init user item dictionary:\n",
    "    \n",
    "    uid_list = ml1m_rating['uid'].tolist()\n",
    "    uid_list_len = len(uid_list)\n",
    "    mid_list = ml1m_rating['mid'].tolist()\n",
    "    mid_list_len = len(mid_list)\n",
    "    rating_list = ml1m_rating['rating'].tolist()\n",
    "    user_item_dict = {x:set() for x in range(len(unique_uid))}\n",
    "    item_user_dict = {x:set() for x in range(len(unique_mid))}\n",
    "    for i in range(uid_list_len):\n",
    "        uid_list[i] = uid_dict[uid_list[i]]\n",
    "        mid_list[i] = mid_dict[mid_list[i]]\n",
    "        # rating_list[i] = 1 # comment this line if you want to activate explicit ratings\n",
    "        user_item_dict[uid_list[i]].add(mid_list[i])\n",
    "        item_user_dict[mid_list[i]].add(uid_list[i])\n",
    "    tmp_df = pd.DataFrame({\"uid\":uid_list, \"mid\":mid_list, \"ratings\":rating_list})\n",
    "    v = tmp_df.uid.value_counts()\n",
    "    df = tmp_df[tmp_df.uid.isin(v.index[v.gt(30)])]\n",
    "### code to store less than 30 interactions:\n",
    "    df_less_30 = tmp_df[tmp_df.uid.isin(v.index[v.le(30)])]\n",
    "    return df, df_less_30, len(np.unique(mid_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICTIONARY PREPARED:\n",
      "GREATER THAN 30:\n",
      "           uid   mid  ratings\n",
      "0           0  1104        5\n",
      "1           0   639        3\n",
      "2           0   853        3\n",
      "3           0  3177        4\n",
      "4           0  2162        5\n",
      "...       ...   ...      ...\n",
      "1000204  6039  1019        1\n",
      "1000205  6039  1022        5\n",
      "1000206  6039   548        5\n",
      "1000207  6039  1024        4\n",
      "1000208  6039  1025        4\n",
      "\n",
      "[980300 rows x 3 columns]\n",
      "LESS THAN 30: \n",
      "          uid   mid  ratings\n",
      "233        3  3235        5\n",
      "234        3  1120        3\n",
      "235        3  2743        4\n",
      "236        3  1124        4\n",
      "237        3   971        4\n",
      "...      ...   ...      ...\n",
      "999740  6037  1288        2\n",
      "999741  6037  2495        1\n",
      "999742  6037  2511        3\n",
      "999743  6037  3165        3\n",
      "999744  6037  1007        5\n",
      "\n",
      "[19909 rows x 3 columns]\n",
      "980300\n",
      "19909\n",
      "UNIQUE MIDS:  3706\n"
     ]
    }
   ],
   "source": [
    "df_gt_30, df_le_30, unique_mids = ReadData()\n",
    "print(\"GREATER THAN 30:\\n\", df_gt_30)\n",
    "print(\"LESS THAN 30: \\n\", df_le_30)\n",
    "print(len(df_gt_30))\n",
    "print(len(df_le_30))\n",
    "print(\"UNIQUE MIDS: \", unique_mids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_gt_30.groupby(\"uid\").tail(1)\n",
    "# print(len(df_gt_30))\n",
    "train_df = df_gt_30.drop(df_gt_30.groupby('uid').tail(1).index, inplace=False)\n",
    "assert(len(df_gt_30)== len(test_df) + len(train_df))\n",
    "# print(len(test_df))\n",
    "# print(len(train_df))\n",
    "dic_train_df_uid_mapping = dict([(y,x) for x,y in enumerate(np.unique(train_df['uid']))])\n",
    "dic_train_df_uid_rmapping = dict([(x,y) for x,y in enumerate(np.unique(train_df['uid']))])\n",
    "### no need for mid mapping\n",
    "\n",
    "uid_of_train_df = train_df['uid'].tolist()\n",
    "for i in range(len(uid_of_train_df)):\n",
    "    uid_of_train_df[i] = dic_train_df_uid_mapping[uid_of_train_df[i]]\n",
    "# for index, row in train_df.iterrows():\n",
    "#     train_df['uid'][index] = dic_train_df_uid_mapping[train_df['uid'][index]]\n",
    "core_user_ko_input_train_df = pd.DataFrame({'uid':uid_of_train_df, 'mid':train_df['mid'], 'ratings':train_df['ratings']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ui_dic = {}    \n",
    "for user in range(6040):\n",
    "    train_ui_dic[user] = []\n",
    "for index,row in train_df.iterrows():\n",
    "        train_ui_dic[row['uid']].append(row['mid'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- utility functions for CUR coreusers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MID = 27277 + 1\n",
    "def select_cols(mat, k, dup=False):\n",
    "    # prob 1d array of probabilities of all columns\n",
    "    prob = mat.T.dot(mat)\n",
    "    prob = np.array(np.diagonal(prob))\n",
    "    denom = np.abs(prob).sum(axis = 0)\n",
    "    prob = prob/denom\n",
    "\n",
    "    C = np.zeros((mat.shape[0], k))\n",
    "    ind_cols = np.arange(0, prob.size)\n",
    "    c_ind = []\n",
    "    for i in range(k):\n",
    "        rand_sel = np.random.choice(ind_cols, 1, p=prob)\n",
    "        c_ind.append(rand_sel[0])\n",
    "        C[:, i] = mat[:, rand_sel[0]]\n",
    "        # C[:, i] = C[:, i]/np.sqrt(k*prob[rand_sel[0]])\n",
    "\n",
    "    return C, c_ind\n",
    "\n",
    "def select_rows(mat, k, dup=False):\n",
    "\n",
    "    prob = mat.dot(mat.T)\n",
    "    prob = np.array(np.diagonal(prob))\n",
    "    denom = np.abs(prob).sum(axis=0)\n",
    "    prob = prob/denom\n",
    "    print(prob)\n",
    "    r = np.zeros((k, mat.shape[1]))\n",
    "    ind_rows = np.arange(0, prob.size)\n",
    "    r_ind = []\n",
    "    for i in range(k):\n",
    "        # print(ind_rows)\n",
    "        rand_sel = np.random.choice(ind_rows, 1, p=prob)\n",
    "        r_ind.append(rand_sel[0])\n",
    "        r[i, :] = mat[rand_sel[0], :]\n",
    "        # r[i, :] = r[i, :]/np.sqrt(k*prob[rand_sel[0]])\n",
    "    r_ind = np.array(r_ind)\n",
    "    return r, r_ind\n",
    "\n",
    "def matIntersection(mat, c_ind, r_ind):\n",
    "    \n",
    "    W = np.zeros((len(r_ind), len(c_ind)))\n",
    "    for i in range(len(r_ind)):\n",
    "        W[i] = mat[r_ind[i], c_ind]\n",
    "    \n",
    "    return W\n",
    "\n",
    "def pseudoInverse(W):\n",
    "    # U = WP (W+)\n",
    "\n",
    "    # W = X.Z.YT\n",
    "    X, Z, YT = np.linalg.svd(W)\n",
    "    \n",
    "    # W+ = Y.Z+.XT\n",
    "    XT = X.T\n",
    "    Y = YT.T\n",
    "    # Z+ = reciprocal(Z)\n",
    "    ZP = np.reciprocal(Z)\n",
    "    ZP = sp.spdiags(ZP, 0, ZP.size, ZP.size)\n",
    "    ZP = ZP@ZP\n",
    "    \n",
    "    # W+ = Y.Z+.XT\n",
    "    WP = Y@ZP\n",
    "    WP = WP@XT\n",
    "\n",
    "    return WP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CUR_ExtractCoreUsers(dataframe, unique_user_len, unique_item_len):\n",
    "    # print(\"# of rows in ml1m_ratings: \", len(dataframe))\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "    userItemMatrix = np.zeros(shape=(u_len, m_len))\n",
    "    # print(userItemMatrix)\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        userItemMatrix[row['uid']][row['mid']] = row['ratings']\n",
    "        # print(row['uid'], row['mid'])\n",
    "    print(\"USER ITEM MATRIX: \\n\", userItemMatrix)\n",
    "\n",
    "    mat = userItemMatrix\n",
    "    print(\"MAT:\", mat)\n",
    "    C, c_ind = select_cols(mat, int(u_len * 0.20)) ## getting 20% core users\n",
    "    r, r_ind= select_rows(mat, int(u_len * 0.20))\n",
    "    print(\"r\", r)\n",
    "    print(\"r_ind\", r_ind)\n",
    "\n",
    "    cur_coreusers = dataframe.iloc[np.where(dataframe.uid.isin(r_ind))]\n",
    "    # coreusers.reset_index()\n",
    "    # print(\"CORE USERS:\\n\", coreusers)\n",
    "    return cur_coreusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER LEN: 5231\n",
      "MOVIE LEN: 3706\n",
      "USER ITEM MATRIX: \n",
      " [[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 0.]]\n",
      "MAT: [[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 0.]]\n",
      "[6.85044107e-05 1.37447016e-04 5.90832284e-05 ... 2.13400733e-04\n",
      " 1.38688567e-04 3.52162333e-04]\n",
      "r [[0. 0. 0. ... 0. 0. 4.]\n",
      " [3. 5. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 5.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "r_ind [2472  681 3036 ... 4219 4213 2983]\n",
      "CORE USERS:          uid   mid  ratings\n",
      "4263      27  1087        2\n",
      "4264      27  1157        2\n",
      "4265      27  3189        2\n",
      "4266      27  2354        4\n",
      "4267      27  2357        3\n",
      "...      ...   ...      ...\n",
      "996786  5208  1022        4\n",
      "996787  5208   548        4\n",
      "996788  5208  1024        4\n",
      "996789  5208  1025        3\n",
      "996790  5208  1862        2\n",
      "\n",
      "[291458 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "core_users = CUR_ExtractCoreUsers(core_user_ko_input_train_df, len(np.unique(uid_of_train_df)), unique_mids)\n",
    "support_user_list = np.unique(core_users['uid'])\n",
    "print(\"CORE USERS:\" ,core_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON CORE USERS:           uid   mid  ratings\n",
      "0           0  1104        5\n",
      "1           0   639        3\n",
      "2           0   853        3\n",
      "3           0  3177        4\n",
      "4           0  2162        5\n",
      "...       ...   ...      ...\n",
      "1000203  6039  1018        3\n",
      "1000204  6039  1019        1\n",
      "1000205  6039  1022        5\n",
      "1000206  6039   548        5\n",
      "1000207  6039  1024        4\n",
      "\n",
      "[683611 rows x 3 columns]\n",
      "CORE USERS:          uid   mid  ratings\n",
      "4263      27  1087        2\n",
      "4264      27  1157        2\n",
      "4265      27  3189        2\n",
      "4266      27  2354        4\n",
      "4267      27  2357        3\n",
      "...      ...   ...      ...\n",
      "996786  5208  1022        4\n",
      "996787  5208   548        4\n",
      "996788  5208  1024        4\n",
      "996789  5208  1025        3\n",
      "996790  5208  1862        2\n",
      "\n",
      "[291458 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "core_users_index_list = core_users.index.to_list()\n",
    "non_core_user_index = (train_df.index.difference(core_users.index))\n",
    "non_core_user_index = non_core_user_index.tolist()\n",
    "\n",
    "core_users_df = train_df.loc[core_users_index_list]\n",
    "non_core_user_df = train_df.loc[non_core_user_index]\n",
    "print(\"NON CORE USERS:\" ,non_core_user_df)\n",
    "print(\"CORE USERS:\" ,core_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DF CONTAINS TEST FOR CORE AND NON CORE ENTITIES:\n",
      "           uid   mid  ratings\n",
      "52          0  1154        4\n",
      "181         1  1155        5\n",
      "232         2  1900        4\n",
      "451         4   683        4\n",
      "522         5    33        4\n",
      "...       ...   ...      ...\n",
      "998634   6034  1865        4\n",
      "999522   6035  1867        3\n",
      "999724   6036  1025        5\n",
      "999867   6038  1025        4\n",
      "1000208  6039  1025        4\n",
      "\n",
      "[5231 rows x 3 columns]\n",
      "894\n",
      "SUPPORT TEST DF:          uid   mid  ratings\n",
      "4653      32  1155        3\n",
      "8908      58  1155        5\n",
      "9512      61  1155        4\n",
      "11015     80  1155        5\n",
      "11133     81  1020        5\n",
      "...      ...   ...      ...\n",
      "991314  5986   548        4\n",
      "994110  6001  1025        4\n",
      "995572  6010  1865        5\n",
      "995882  6014  1007        5\n",
      "996791  6015  3540        4\n",
      "\n",
      "[894 rows x 3 columns]\n",
      "QUERY TEST DF:\n",
      "           uid   mid  ratings\n",
      "52          0  1154        4\n",
      "181         1  1155        5\n",
      "232         2  1900        4\n",
      "451         4   683        4\n",
      "522         5    33        4\n",
      "...       ...   ...      ...\n",
      "998634   6034  1865        4\n",
      "999522   6035  1867        3\n",
      "999724   6036  1025        5\n",
      "999867   6038  1025        4\n",
      "1000208  6039  1025        4\n",
      "\n",
      "[4337 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"TEST DF CONTAINS TEST FOR CORE AND NON CORE ENTITIES:\\n\" ,test_df)\n",
    "# print(core_users['uid'])\n",
    "unique_uids_in_support_trian = np.unique(np.array(core_users_df['uid']))\n",
    "unique_uids_in_query_trian = np.unique(non_core_user_df['uid'])\n",
    "print(len(unique_uids_in_support_trian))\n",
    "support_test_df = test_df.loc[test_df['uid'].isin(unique_uids_in_support_trian)]\n",
    "print(\"SUPPORT TEST DF:\" ,support_test_df)\n",
    "query_test_df = test_df.loc[test_df['uid'].isin(unique_uids_in_query_trian)]\n",
    "print(\"QUERY TEST DF:\\n\", query_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_train = []\n",
    "for index,row in core_users_df.iterrows():\n",
    "    support_train.append([row['uid'], row['mid'], row['ratings']])\n",
    "query_train = []\n",
    "for index, row in non_core_user_df.iterrows():\n",
    "    query_train.append([row['uid'], row['mid'], row['ratings']])\n",
    "support_test = []\n",
    "for index, row in support_test_df.iterrows():\n",
    "    support_test.append([row['uid'], row['mid'], row['ratings']])\n",
    "query_test = []\n",
    "for index, row in query_test_df.iterrows():\n",
    "    query_test.append([row['uid'], row['mid'], row['ratings']])\n",
    "user_his_dic = {}\n",
    "for u in train_ui_dic.keys():\n",
    "    user_his_dic[u] = train_ui_dic[u]\n",
    "user_supp_list = np.unique(core_users_df['uid']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"cur_20_support_as_core.pkl\", \"wb\") as f:\n",
    "    pickle.dump(support_train, f)\n",
    "    pickle.dump(query_train, f)\n",
    "    pickle.dump(support_test, f)\n",
    "    pickle.dump(query_test, f)\n",
    "    pickle.dump(user_supp_list, f)\n",
    "    pickle.dump(user_his_dic, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20% cur coreusers into IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 291458/683611\n",
      "test set size: support/query 894/4337\n",
      "Epoch 0 Step 271: Train 2.6694 Reg: 0.5657\n",
      "Test: 0.8934 MAE: 0.7671 RMSE: 0.9452\n",
      "Val: 0.8126 MAE: 0.7110 RMSE: 0.9015\n",
      "Epoch 1 Step 542: Train 0.8031 Reg: 0.4971\n",
      "Test: 0.8746 MAE: 0.7540 RMSE: 0.9352\n",
      "Val: 0.8017 MAE: 0.7072 RMSE: 0.8954\n",
      "Epoch 2 Step 813: Train 0.7963 Reg: 0.4269\n",
      "Test: 0.8596 MAE: 0.7478 RMSE: 0.9272\n",
      "Val: 0.8049 MAE: 0.7073 RMSE: 0.8972\n",
      "Epoch 3 Step 1084: Train 0.7943 Reg: 0.3723\n",
      "Test: 0.8621 MAE: 0.7481 RMSE: 0.9285\n",
      "Val: 0.8012 MAE: 0.7062 RMSE: 0.8951\n",
      "Epoch 4 Step 1355: Train 0.7916 Reg: 0.3328\n",
      "Test: 0.8694 MAE: 0.7483 RMSE: 0.9324\n",
      "Val: 0.7938 MAE: 0.7020 RMSE: 0.8910\n",
      "Epoch 5 Step 1626: Train 0.7896 Reg: 0.3046\n",
      "Test: 0.8575 MAE: 0.7467 RMSE: 0.9260\n",
      "Val: 0.7939 MAE: 0.7039 RMSE: 0.8910\n",
      "Epoch 6 Step 1897: Train 0.7869 Reg: 0.2843\n",
      "Test: 0.8519 MAE: 0.7474 RMSE: 0.9230\n",
      "Val: 0.7944 MAE: 0.7043 RMSE: 0.8913\n",
      "Epoch 7 Step 2168: Train 0.7843 Reg: 0.2682\n",
      "Test: 0.8417 MAE: 0.7402 RMSE: 0.9175\n",
      "Val: 0.7939 MAE: 0.7033 RMSE: 0.8910\n",
      "Epoch 8 Step 2439: Train 0.7808 Reg: 0.2573\n",
      "Test: 0.8360 MAE: 0.7387 RMSE: 0.9144\n",
      "Val: 0.7889 MAE: 0.7019 RMSE: 0.8882\n",
      "Epoch 9 Step 2710: Train 0.7765 Reg: 0.2502\n",
      "Test: 0.8400 MAE: 0.7351 RMSE: 0.9165\n",
      "Val: 0.7842 MAE: 0.6976 RMSE: 0.8856\n",
      "Epoch 10 Step 2981: Train 0.7702 Reg: 0.2468\n",
      "Test: 0.8413 MAE: 0.7365 RMSE: 0.9172\n",
      "Val: 0.7783 MAE: 0.6945 RMSE: 0.8822\n",
      "Epoch 11 Step 3252: Train 0.7623 Reg: 0.2464\n",
      "Test: 0.8410 MAE: 0.7415 RMSE: 0.9171\n",
      "Val: 0.7718 MAE: 0.6908 RMSE: 0.8785\n",
      "Epoch 12 Step 3523: Train 0.7540 Reg: 0.2452\n",
      "Test: 0.8301 MAE: 0.7304 RMSE: 0.9111\n",
      "Val: 0.7667 MAE: 0.6881 RMSE: 0.8756\n",
      "Epoch 13 Step 3794: Train 0.7459 Reg: 0.2435\n",
      "Test: 0.8281 MAE: 0.7342 RMSE: 0.9100\n",
      "Val: 0.7624 MAE: 0.6871 RMSE: 0.8732\n",
      "Epoch 14 Step 4065: Train 0.7382 Reg: 0.2425\n",
      "Test: 0.8105 MAE: 0.7251 RMSE: 0.9003\n",
      "Val: 0.7574 MAE: 0.6843 RMSE: 0.8703\n",
      "Epoch 15 Step 4336: Train 0.7300 Reg: 0.2434\n",
      "Test: 0.8121 MAE: 0.7252 RMSE: 0.9012\n",
      "Val: 0.7523 MAE: 0.6796 RMSE: 0.8674\n",
      "Epoch 16 Step 4607: Train 0.7189 Reg: 0.2500\n",
      "Test: 0.8038 MAE: 0.7232 RMSE: 0.8966\n",
      "Val: 0.7436 MAE: 0.6759 RMSE: 0.8623\n",
      "Epoch 17 Step 4878: Train 0.7076 Reg: 0.2600\n",
      "Test: 0.8055 MAE: 0.7234 RMSE: 0.8975\n",
      "Val: 0.7395 MAE: 0.6733 RMSE: 0.8599\n",
      "Epoch 18 Step 5149: Train 0.6971 Reg: 0.2674\n",
      "Test: 0.7968 MAE: 0.7173 RMSE: 0.8926\n",
      "Val: 0.7382 MAE: 0.6719 RMSE: 0.8592\n",
      "Epoch 19 Step 5420: Train 0.6861 Reg: 0.2755\n",
      "Test: 0.8013 MAE: 0.7199 RMSE: 0.8951\n",
      "Val: 0.7370 MAE: 0.6717 RMSE: 0.8585\n",
      "Epoch 20 Step 5691: Train 0.6734 Reg: 0.2868\n",
      "Test: 0.7966 MAE: 0.7160 RMSE: 0.8925\n",
      "Val: 0.7314 MAE: 0.6675 RMSE: 0.8552\n",
      "Epoch 21 Step 5962: Train 0.6561 Reg: 0.3023\n",
      "Test: 0.7952 MAE: 0.7141 RMSE: 0.8918\n",
      "Val: 0.7278 MAE: 0.6666 RMSE: 0.8531\n",
      "Epoch 22 Step 6233: Train 0.6352 Reg: 0.3207\n",
      "Test: 0.7891 MAE: 0.7121 RMSE: 0.8883\n",
      "Val: 0.7235 MAE: 0.6639 RMSE: 0.8506\n",
      "Epoch 23 Step 6504: Train 0.6117 Reg: 0.3388\n",
      "Test: 0.7810 MAE: 0.7070 RMSE: 0.8837\n",
      "Val: 0.7229 MAE: 0.6628 RMSE: 0.8503\n",
      "Epoch 24 Step 6775: Train 0.5873 Reg: 0.3574\n",
      "Test: 0.7784 MAE: 0.7053 RMSE: 0.8822\n",
      "Val: 0.7262 MAE: 0.6655 RMSE: 0.8522\n",
      "Epoch 25 Step 7046: Train 0.5637 Reg: 0.3740\n",
      "Test: 0.7713 MAE: 0.6965 RMSE: 0.8782\n",
      "Val: 0.7333 MAE: 0.6662 RMSE: 0.8564\n",
      "Epoch 26 Step 7317: Train 0.5415 Reg: 0.3906\n",
      "Test: 0.7748 MAE: 0.6993 RMSE: 0.8802\n",
      "Val: 0.7409 MAE: 0.6704 RMSE: 0.8608\n",
      "Epoch 27 Step 7588: Train 0.5181 Reg: 0.4064\n",
      "Test: 0.7792 MAE: 0.6996 RMSE: 0.8827\n",
      "Val: 0.7524 MAE: 0.6744 RMSE: 0.8674\n",
      "Epoch 28 Step 7859: Train 0.4936 Reg: 0.4227\n",
      "Test: 0.7800 MAE: 0.6958 RMSE: 0.8832\n",
      "Val: 0.7657 MAE: 0.6782 RMSE: 0.8750\n",
      "Epoch 29 Step 8130: Train 0.4703 Reg: 0.4359\n",
      "Test: 0.7921 MAE: 0.7025 RMSE: 0.8900\n",
      "Val: 0.7819 MAE: 0.6853 RMSE: 0.8843\n",
      "Epoch 30 Step 8401: Train 0.4500 Reg: 0.4466\n",
      "Test: 0.8007 MAE: 0.7022 RMSE: 0.8948\n",
      "Val: 0.7985 MAE: 0.6909 RMSE: 0.8936\n",
      "Epoch 31 Step 8672: Train 0.4323 Reg: 0.4544\n",
      "Test: 0.8145 MAE: 0.7089 RMSE: 0.9025\n",
      "Val: 0.8136 MAE: 0.6977 RMSE: 0.9020\n",
      "Epoch 32 Step 8943: Train 0.4179 Reg: 0.4597\n",
      "Test: 0.8266 MAE: 0.7131 RMSE: 0.9092\n",
      "Val: 0.8297 MAE: 0.7055 RMSE: 0.9109\n",
      "Epoch 33 Step 9214: Train 0.4063 Reg: 0.4629\n",
      "Test: 0.8349 MAE: 0.7121 RMSE: 0.9137\n",
      "Val: 0.8418 MAE: 0.7079 RMSE: 0.9175\n",
      "Epoch 34 Step 9485: Train 0.3969 Reg: 0.4649\n",
      "Test: 0.8519 MAE: 0.7199 RMSE: 0.9230\n",
      "Val: 0.8527 MAE: 0.7129 RMSE: 0.9234\n",
      "Epoch 35 Step 9756: Train 0.3884 Reg: 0.4659\n",
      "Test: 0.8532 MAE: 0.7188 RMSE: 0.9237\n",
      "Val: 0.8651 MAE: 0.7170 RMSE: 0.9301\n",
      "Epoch 36 Step 10027: Train 0.3811 Reg: 0.4665\n",
      "Test: 0.8706 MAE: 0.7311 RMSE: 0.9331\n",
      "Val: 0.8769 MAE: 0.7232 RMSE: 0.9364\n",
      "Epoch 37 Step 10298: Train 0.3747 Reg: 0.4666\n",
      "Test: 0.8730 MAE: 0.7285 RMSE: 0.9343\n",
      "Val: 0.8845 MAE: 0.7249 RMSE: 0.9405\n",
      "Epoch 38 Step 10569: Train 0.3689 Reg: 0.4663\n",
      "Test: 0.8797 MAE: 0.7320 RMSE: 0.9379\n",
      "Val: 0.8943 MAE: 0.7288 RMSE: 0.9457\n",
      "Epoch 39 Step 10840: Train 0.3640 Reg: 0.4656\n",
      "Test: 0.8853 MAE: 0.7333 RMSE: 0.9409\n",
      "Val: 0.9018 MAE: 0.7314 RMSE: 0.9496\n",
      "Epoch 40 Step 11111: Train 0.3597 Reg: 0.4645\n",
      "Test: 0.8882 MAE: 0.7341 RMSE: 0.9424\n",
      "Val: 0.9078 MAE: 0.7331 RMSE: 0.9528\n",
      "Epoch 41 Step 11382: Train 0.3558 Reg: 0.4633\n",
      "Test: 0.8954 MAE: 0.7361 RMSE: 0.9463\n",
      "Val: 0.9170 MAE: 0.7364 RMSE: 0.9576\n",
      "Epoch 42 Step 11653: Train 0.3524 Reg: 0.4620\n",
      "Test: 0.9009 MAE: 0.7387 RMSE: 0.9492\n",
      "Val: 0.9237 MAE: 0.7395 RMSE: 0.9611\n",
      "Epoch 43 Step 11924: Train 0.3492 Reg: 0.4606\n",
      "Test: 0.9081 MAE: 0.7422 RMSE: 0.9529\n",
      "Val: 0.9312 MAE: 0.7423 RMSE: 0.9650\n",
      "Epoch 44 Step 12195: Train 0.3463 Reg: 0.4591\n",
      "Test: 0.9138 MAE: 0.7434 RMSE: 0.9559\n",
      "Val: 0.9370 MAE: 0.7439 RMSE: 0.9680\n",
      "Epoch 45 Step 12466: Train 0.3438 Reg: 0.4576\n",
      "Test: 0.9189 MAE: 0.7443 RMSE: 0.9586\n",
      "Val: 0.9415 MAE: 0.7452 RMSE: 0.9703\n",
      "Epoch 46 Step 12737: Train 0.3413 Reg: 0.4562\n",
      "Test: 0.9193 MAE: 0.7447 RMSE: 0.9588\n",
      "Val: 0.9464 MAE: 0.7472 RMSE: 0.9728\n",
      "Epoch 47 Step 13008: Train 0.3390 Reg: 0.4548\n",
      "Test: 0.9238 MAE: 0.7463 RMSE: 0.9611\n",
      "Val: 0.9504 MAE: 0.7484 RMSE: 0.9749\n",
      "Epoch 48 Step 13279: Train 0.3368 Reg: 0.4533\n",
      "Test: 0.9260 MAE: 0.7454 RMSE: 0.9623\n",
      "Val: 0.9549 MAE: 0.7495 RMSE: 0.9772\n",
      "Epoch 49 Step 13550: Train 0.3348 Reg: 0.4521\n",
      "Test: 0.9255 MAE: 0.7443 RMSE: 0.9620\n",
      "Val: 0.9584 MAE: 0.7505 RMSE: 0.9790\n",
      "Epoch 50 Step 13821: Train 0.3329 Reg: 0.4507\n",
      "Test: 0.9322 MAE: 0.7468 RMSE: 0.9655\n",
      "Val: 0.9628 MAE: 0.7520 RMSE: 0.9812\n",
      "Epoch 51 Step 14092: Train 0.3310 Reg: 0.4495\n",
      "Test: 0.9334 MAE: 0.7465 RMSE: 0.9661\n",
      "Val: 0.9672 MAE: 0.7535 RMSE: 0.9834\n",
      "Epoch 52 Step 14363: Train 0.3293 Reg: 0.4484\n",
      "Test: 0.9365 MAE: 0.7475 RMSE: 0.9678\n",
      "Val: 0.9703 MAE: 0.7544 RMSE: 0.9850\n",
      "Epoch 53 Step 14634: Train 0.3275 Reg: 0.4472\n",
      "Test: 0.9426 MAE: 0.7504 RMSE: 0.9709\n",
      "Val: 0.9741 MAE: 0.7563 RMSE: 0.9869\n",
      "Epoch 54 Step 14905: Train 0.3258 Reg: 0.4462\n",
      "Test: 0.9443 MAE: 0.7507 RMSE: 0.9717\n",
      "Val: 0.9778 MAE: 0.7572 RMSE: 0.9888\n",
      "Epoch 55 Step 15176: Train 0.3242 Reg: 0.4452\n",
      "Test: 0.9486 MAE: 0.7520 RMSE: 0.9739\n",
      "Val: 0.9814 MAE: 0.7586 RMSE: 0.9907\n",
      "Epoch 56 Step 15447: Train 0.3227 Reg: 0.4443\n",
      "Test: 0.9495 MAE: 0.7520 RMSE: 0.9744\n",
      "Val: 0.9841 MAE: 0.7594 RMSE: 0.9920\n",
      "Epoch 57 Step 15718: Train 0.3212 Reg: 0.4434\n",
      "Test: 0.9521 MAE: 0.7531 RMSE: 0.9757\n",
      "Val: 0.9871 MAE: 0.7604 RMSE: 0.9935\n",
      "Epoch 58 Step 15989: Train 0.3198 Reg: 0.4424\n",
      "Test: 0.9542 MAE: 0.7536 RMSE: 0.9768\n",
      "Val: 0.9897 MAE: 0.7611 RMSE: 0.9948\n",
      "Epoch 59 Step 16260: Train 0.3186 Reg: 0.4415\n",
      "Test: 0.9556 MAE: 0.7534 RMSE: 0.9776\n",
      "Val: 0.9927 MAE: 0.7620 RMSE: 0.9963\n",
      "Epoch 60 Step 16531: Train 0.3174 Reg: 0.4407\n",
      "Test: 0.9600 MAE: 0.7554 RMSE: 0.9798\n",
      "Val: 0.9955 MAE: 0.7636 RMSE: 0.9978\n",
      "Epoch 61 Step 16802: Train 0.3162 Reg: 0.4398\n",
      "Test: 0.9602 MAE: 0.7544 RMSE: 0.9799\n",
      "Val: 0.9974 MAE: 0.7637 RMSE: 0.9987\n",
      "Epoch 62 Step 17073: Train 0.3152 Reg: 0.4389\n",
      "Test: 0.9630 MAE: 0.7562 RMSE: 0.9813\n",
      "Val: 1.0008 MAE: 0.7653 RMSE: 1.0004\n",
      "Epoch 63 Step 17344: Train 0.3142 Reg: 0.4381\n",
      "Test: 0.9642 MAE: 0.7561 RMSE: 0.9819\n",
      "Val: 1.0025 MAE: 0.7655 RMSE: 1.0013\n",
      "Epoch 64 Step 17615: Train 0.3133 Reg: 0.4373\n",
      "Test: 0.9671 MAE: 0.7572 RMSE: 0.9834\n",
      "Val: 1.0040 MAE: 0.7661 RMSE: 1.0020\n",
      "Epoch 65 Step 17886: Train 0.3124 Reg: 0.4366\n",
      "Test: 0.9661 MAE: 0.7564 RMSE: 0.9829\n",
      "Val: 1.0057 MAE: 0.7664 RMSE: 1.0028\n",
      "Epoch 66 Step 18157: Train 0.3116 Reg: 0.4358\n",
      "Test: 0.9694 MAE: 0.7581 RMSE: 0.9846\n",
      "Val: 1.0085 MAE: 0.7677 RMSE: 1.0043\n",
      "Epoch 67 Step 18428: Train 0.3109 Reg: 0.4351\n",
      "Test: 0.9692 MAE: 0.7576 RMSE: 0.9845\n",
      "Val: 1.0094 MAE: 0.7678 RMSE: 1.0047\n",
      "Epoch 68 Step 18699: Train 0.3101 Reg: 0.4344\n",
      "Test: 0.9706 MAE: 0.7579 RMSE: 0.9852\n",
      "Val: 1.0112 MAE: 0.7683 RMSE: 1.0056\n",
      "Epoch 69 Step 18970: Train 0.3094 Reg: 0.4337\n",
      "Test: 0.9729 MAE: 0.7590 RMSE: 0.9864\n",
      "Val: 1.0131 MAE: 0.7692 RMSE: 1.0065\n",
      "Epoch 70 Step 19241: Train 0.3088 Reg: 0.4331\n",
      "Test: 0.9757 MAE: 0.7604 RMSE: 0.9878\n",
      "Val: 1.0151 MAE: 0.7701 RMSE: 1.0075\n",
      "Epoch 71 Step 19512: Train 0.3082 Reg: 0.4325\n",
      "Test: 0.9737 MAE: 0.7590 RMSE: 0.9867\n",
      "Val: 1.0157 MAE: 0.7699 RMSE: 1.0078\n",
      "Epoch 72 Step 19783: Train 0.3076 Reg: 0.4319\n",
      "Test: 0.9762 MAE: 0.7600 RMSE: 0.9880\n",
      "Val: 1.0176 MAE: 0.7707 RMSE: 1.0088\n",
      "Epoch 73 Step 20054: Train 0.3071 Reg: 0.4313\n",
      "Test: 0.9766 MAE: 0.7601 RMSE: 0.9882\n",
      "Val: 1.0185 MAE: 0.7709 RMSE: 1.0092\n",
      "Epoch 74 Step 20325: Train 0.3065 Reg: 0.4307\n",
      "Test: 0.9773 MAE: 0.7604 RMSE: 0.9886\n",
      "Val: 1.0198 MAE: 0.7715 RMSE: 1.0099\n",
      "Epoch 75 Step 20596: Train 0.3061 Reg: 0.4302\n",
      "Test: 0.9785 MAE: 0.7607 RMSE: 0.9892\n",
      "Val: 1.0211 MAE: 0.7718 RMSE: 1.0105\n",
      "Epoch 76 Step 20867: Train 0.3056 Reg: 0.4297\n",
      "Test: 0.9796 MAE: 0.7611 RMSE: 0.9898\n",
      "Val: 1.0221 MAE: 0.7722 RMSE: 1.0110\n",
      "Epoch 77 Step 21138: Train 0.3052 Reg: 0.4293\n",
      "Test: 0.9790 MAE: 0.7605 RMSE: 0.9895\n",
      "Val: 1.0227 MAE: 0.7723 RMSE: 1.0113\n",
      "Epoch 78 Step 21409: Train 0.3048 Reg: 0.4288\n",
      "Test: 0.9787 MAE: 0.7603 RMSE: 0.9893\n",
      "Val: 1.0238 MAE: 0.7726 RMSE: 1.0118\n",
      "Epoch 79 Step 21680: Train 0.3044 Reg: 0.4284\n",
      "Test: 0.9805 MAE: 0.7611 RMSE: 0.9902\n",
      "Val: 1.0248 MAE: 0.7730 RMSE: 1.0123\n",
      "Epoch 80 Step 21951: Train 0.3040 Reg: 0.4279\n",
      "Test: 0.9811 MAE: 0.7614 RMSE: 0.9905\n",
      "Val: 1.0256 MAE: 0.7732 RMSE: 1.0127\n",
      "Epoch 81 Step 22222: Train 0.3036 Reg: 0.4276\n",
      "Test: 0.9828 MAE: 0.7623 RMSE: 0.9914\n",
      "Val: 1.0268 MAE: 0.7738 RMSE: 1.0133\n",
      "Epoch 82 Step 22493: Train 0.3033 Reg: 0.4272\n",
      "Test: 0.9835 MAE: 0.7625 RMSE: 0.9917\n",
      "Val: 1.0275 MAE: 0.7740 RMSE: 1.0137\n",
      "Epoch 83 Step 22764: Train 0.3030 Reg: 0.4268\n",
      "Test: 0.9835 MAE: 0.7624 RMSE: 0.9917\n",
      "Val: 1.0280 MAE: 0.7741 RMSE: 1.0139\n",
      "Epoch 84 Step 23035: Train 0.3027 Reg: 0.4265\n",
      "Test: 0.9854 MAE: 0.7633 RMSE: 0.9927\n",
      "Val: 1.0294 MAE: 0.7748 RMSE: 1.0146\n",
      "Epoch 85 Step 23306: Train 0.3024 Reg: 0.4261\n",
      "Test: 0.9861 MAE: 0.7636 RMSE: 0.9930\n",
      "Val: 1.0301 MAE: 0.7750 RMSE: 1.0149\n",
      "Epoch 86 Step 23577: Train 0.3022 Reg: 0.4258\n",
      "Test: 0.9853 MAE: 0.7631 RMSE: 0.9926\n",
      "Val: 1.0302 MAE: 0.7748 RMSE: 1.0150\n",
      "Epoch 87 Step 23848: Train 0.3019 Reg: 0.4255\n",
      "Test: 0.9855 MAE: 0.7631 RMSE: 0.9927\n",
      "Val: 1.0308 MAE: 0.7750 RMSE: 1.0153\n",
      "Epoch 88 Step 24119: Train 0.3017 Reg: 0.4252\n",
      "Test: 0.9873 MAE: 0.7640 RMSE: 0.9936\n",
      "Val: 1.0319 MAE: 0.7756 RMSE: 1.0158\n",
      "Epoch 89 Step 24390: Train 0.3014 Reg: 0.4250\n",
      "Test: 0.9862 MAE: 0.7633 RMSE: 0.9931\n",
      "Val: 1.0319 MAE: 0.7754 RMSE: 1.0158\n",
      "Epoch 90 Step 24661: Train 0.3012 Reg: 0.4247\n",
      "Test: 0.9886 MAE: 0.7647 RMSE: 0.9943\n",
      "Val: 1.0332 MAE: 0.7761 RMSE: 1.0164\n",
      "Epoch 91 Step 24932: Train 0.3010 Reg: 0.4244\n",
      "Test: 0.9875 MAE: 0.7639 RMSE: 0.9938\n",
      "Val: 1.0330 MAE: 0.7758 RMSE: 1.0164\n",
      "Epoch 92 Step 25203: Train 0.3008 Reg: 0.4242\n",
      "Test: 0.9879 MAE: 0.7640 RMSE: 0.9939\n",
      "Val: 1.0336 MAE: 0.7760 RMSE: 1.0166\n",
      "Epoch 93 Step 25474: Train 0.3006 Reg: 0.4240\n",
      "Test: 0.9884 MAE: 0.7643 RMSE: 0.9942\n",
      "Val: 1.0341 MAE: 0.7762 RMSE: 1.0169\n",
      "Epoch 94 Step 25745: Train 0.3005 Reg: 0.4238\n",
      "Test: 0.9889 MAE: 0.7645 RMSE: 0.9944\n",
      "Val: 1.0345 MAE: 0.7764 RMSE: 1.0171\n",
      "Epoch 95 Step 26016: Train 0.3003 Reg: 0.4236\n",
      "Test: 0.9890 MAE: 0.7645 RMSE: 0.9945\n",
      "Val: 1.0349 MAE: 0.7765 RMSE: 1.0173\n",
      "Epoch 96 Step 26287: Train 0.3001 Reg: 0.4234\n",
      "Test: 0.9897 MAE: 0.7649 RMSE: 0.9948\n",
      "Val: 1.0355 MAE: 0.7767 RMSE: 1.0176\n",
      "Epoch 97 Step 26558: Train 0.3000 Reg: 0.4232\n",
      "Test: 0.9897 MAE: 0.7648 RMSE: 0.9948\n",
      "Val: 1.0357 MAE: 0.7768 RMSE: 1.0177\n",
      "Epoch 98 Step 26829: Train 0.2998 Reg: 0.4230\n",
      "Test: 0.9906 MAE: 0.7652 RMSE: 0.9953\n",
      "Val: 1.0363 MAE: 0.7770 RMSE: 1.0180\n",
      "Epoch 99 Step 27100: Train 0.2997 Reg: 0.4229\n",
      "Test: 0.9898 MAE: 0.7648 RMSE: 0.9949\n",
      "Val: 1.0363 MAE: 0.7769 RMSE: 1.0180\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 291458/683611\n",
      "test set size: support/query 894/4337\n",
      "Epoch 0: TrainLoss 0.8684 RecLoss: 0.0000 (left: 5:43:24)\n",
      "TestLoss: 0.8874 MAE: 0.7495 RMSE: 0.9420\n",
      "ValLoss: 0.8411 MAE: 0.7305 RMSE: 0.9171\n",
      "Epoch 1: TrainLoss 0.8279 RecLoss: 0.0000 (left: 5:48:15)\n",
      "TestLoss: 0.8761 MAE: 0.7400 RMSE: 0.9360\n",
      "ValLoss: 0.8319 MAE: 0.7228 RMSE: 0.9121\n",
      "Epoch 2: TrainLoss 0.8246 RecLoss: 0.0000 (left: 5:45:16)\n",
      "TestLoss: 0.8788 MAE: 0.7315 RMSE: 0.9374\n",
      "ValLoss: 0.8334 MAE: 0.7166 RMSE: 0.9129\n",
      "Epoch 3: TrainLoss 0.8237 RecLoss: 0.0000 (left: 5:41:02)\n",
      "TestLoss: 0.8820 MAE: 0.7472 RMSE: 0.9392\n",
      "ValLoss: 0.8348 MAE: 0.7276 RMSE: 0.9137\n",
      "Epoch 4: TrainLoss 0.8213 RecLoss: 0.0000 (left: 5:35:30)\n",
      "TestLoss: 0.8758 MAE: 0.7401 RMSE: 0.9359\n",
      "ValLoss: 0.8267 MAE: 0.7212 RMSE: 0.9092\n",
      "Epoch 5: TrainLoss 0.8208 RecLoss: 0.0000 (left: 5:32:05)\n",
      "TestLoss: 0.8768 MAE: 0.7289 RMSE: 0.9364\n",
      "ValLoss: 0.8308 MAE: 0.7136 RMSE: 0.9115\n",
      "Epoch 6: TrainLoss 0.8202 RecLoss: 0.0000 (left: 5:28:25)\n",
      "TestLoss: 0.8597 MAE: 0.7297 RMSE: 0.9272\n",
      "ValLoss: 0.8241 MAE: 0.7152 RMSE: 0.9078\n",
      "Epoch 7: TrainLoss 0.8184 RecLoss: 0.0000 (left: 5:26:41)\n",
      "TestLoss: 0.8699 MAE: 0.7375 RMSE: 0.9327\n",
      "ValLoss: 0.8240 MAE: 0.7201 RMSE: 0.9077\n",
      "Epoch 8: TrainLoss 0.8176 RecLoss: 0.0000 (left: 5:23:09)\n",
      "TestLoss: 0.8738 MAE: 0.7384 RMSE: 0.9348\n",
      "ValLoss: 0.8258 MAE: 0.7200 RMSE: 0.9087\n",
      "Epoch 9: TrainLoss 0.8170 RecLoss: 0.0000 (left: 5:20:20)\n",
      "TestLoss: 0.8756 MAE: 0.7284 RMSE: 0.9357\n",
      "ValLoss: 0.8287 MAE: 0.7131 RMSE: 0.9103\n",
      "Epoch 10: TrainLoss 0.8161 RecLoss: 0.0000 (left: 5:16:30)\n",
      "TestLoss: 0.8642 MAE: 0.7279 RMSE: 0.9296\n",
      "ValLoss: 0.8217 MAE: 0.7134 RMSE: 0.9065\n",
      "Epoch 11: TrainLoss 0.8158 RecLoss: 0.0000 (left: 5:12:11)\n",
      "TestLoss: 0.8633 MAE: 0.7263 RMSE: 0.9292\n",
      "ValLoss: 0.8208 MAE: 0.7122 RMSE: 0.9060\n",
      "Epoch 12: TrainLoss 0.8153 RecLoss: 0.0000 (left: 5:08:21)\n",
      "TestLoss: 0.8705 MAE: 0.7380 RMSE: 0.9330\n",
      "ValLoss: 0.8225 MAE: 0.7191 RMSE: 0.9069\n",
      "Epoch 13: TrainLoss 0.8157 RecLoss: 0.0000 (left: 5:04:27)\n",
      "TestLoss: 0.8757 MAE: 0.7428 RMSE: 0.9358\n",
      "ValLoss: 0.8290 MAE: 0.7251 RMSE: 0.9105\n",
      "Epoch 14: TrainLoss 0.8145 RecLoss: 0.0000 (left: 5:01:06)\n",
      "TestLoss: 0.8755 MAE: 0.7405 RMSE: 0.9357\n",
      "ValLoss: 0.8246 MAE: 0.7196 RMSE: 0.9081\n",
      "Epoch 15: TrainLoss 0.8148 RecLoss: 0.0000 (left: 4:57:47)\n",
      "TestLoss: 0.8637 MAE: 0.7338 RMSE: 0.9293\n",
      "ValLoss: 0.8200 MAE: 0.7155 RMSE: 0.9055\n",
      "Epoch 16: TrainLoss 0.8139 RecLoss: 0.0000 (left: 4:53:35)\n",
      "TestLoss: 0.8664 MAE: 0.7285 RMSE: 0.9308\n",
      "ValLoss: 0.8203 MAE: 0.7115 RMSE: 0.9057\n",
      "Epoch 17: TrainLoss 0.8140 RecLoss: 0.0000 (left: 4:49:35)\n",
      "TestLoss: 0.8816 MAE: 0.7401 RMSE: 0.9389\n",
      "ValLoss: 0.8260 MAE: 0.7178 RMSE: 0.9088\n",
      "Epoch 18: TrainLoss 0.8138 RecLoss: 0.0000 (left: 4:46:12)\n",
      "TestLoss: 0.8675 MAE: 0.7276 RMSE: 0.9314\n",
      "ValLoss: 0.8226 MAE: 0.7122 RMSE: 0.9070\n",
      "Epoch 19: TrainLoss 0.8135 RecLoss: 0.0000 (left: 4:43:26)\n",
      "TestLoss: 0.8667 MAE: 0.7287 RMSE: 0.9310\n",
      "ValLoss: 0.8207 MAE: 0.7126 RMSE: 0.9059\n",
      "Epoch 20: TrainLoss 0.8133 RecLoss: 0.0000 (left: 4:40:23)\n",
      "TestLoss: 0.8634 MAE: 0.7308 RMSE: 0.9292\n",
      "ValLoss: 0.8227 MAE: 0.7141 RMSE: 0.9070\n",
      "Epoch 21: TrainLoss 0.8123 RecLoss: 0.0000 (left: 4:36:40)\n",
      "TestLoss: 0.8674 MAE: 0.7378 RMSE: 0.9313\n",
      "ValLoss: 0.8210 MAE: 0.7181 RMSE: 0.9061\n",
      "Epoch 22: TrainLoss 0.8120 RecLoss: 0.0000 (left: 4:33:20)\n",
      "TestLoss: 0.8641 MAE: 0.7300 RMSE: 0.9296\n",
      "ValLoss: 0.8227 MAE: 0.7156 RMSE: 0.9070\n",
      "Epoch 23: TrainLoss 0.8119 RecLoss: 0.0000 (left: 4:30:07)\n",
      "TestLoss: 0.8647 MAE: 0.7302 RMSE: 0.9299\n",
      "ValLoss: 0.8206 MAE: 0.7128 RMSE: 0.9059\n",
      "Epoch 24: TrainLoss 0.8116 RecLoss: 0.0000 (left: 4:26:53)\n",
      "TestLoss: 0.8722 MAE: 0.7388 RMSE: 0.9339\n",
      "ValLoss: 0.8284 MAE: 0.7209 RMSE: 0.9102\n",
      "Epoch 25: TrainLoss 0.8112 RecLoss: 0.0000 (left: 4:23:33)\n",
      "TestLoss: 0.8754 MAE: 0.7422 RMSE: 0.9356\n",
      "ValLoss: 0.8230 MAE: 0.7202 RMSE: 0.9072\n",
      "Epoch 26: TrainLoss 0.8107 RecLoss: 0.0000 (left: 4:20:33)\n",
      "TestLoss: 0.8645 MAE: 0.7345 RMSE: 0.9298\n",
      "ValLoss: 0.8180 MAE: 0.7147 RMSE: 0.9045\n",
      "Epoch 27: TrainLoss 0.8103 RecLoss: 0.0000 (left: 4:17:42)\n",
      "TestLoss: 0.8624 MAE: 0.7331 RMSE: 0.9287\n",
      "ValLoss: 0.8170 MAE: 0.7135 RMSE: 0.9039\n",
      "Epoch 28: TrainLoss 0.8103 RecLoss: 0.0000 (left: 4:14:27)\n",
      "TestLoss: 0.8656 MAE: 0.7278 RMSE: 0.9304\n",
      "ValLoss: 0.8248 MAE: 0.7122 RMSE: 0.9082\n",
      "Epoch 29: TrainLoss 0.8104 RecLoss: 0.0000 (left: 4:11:13)\n",
      "TestLoss: 0.8652 MAE: 0.7362 RMSE: 0.9302\n",
      "ValLoss: 0.8181 MAE: 0.7169 RMSE: 0.9045\n",
      "Epoch 30: TrainLoss 0.8100 RecLoss: 0.0000 (left: 4:07:50)\n",
      "TestLoss: 0.8610 MAE: 0.7295 RMSE: 0.9279\n",
      "ValLoss: 0.8170 MAE: 0.7120 RMSE: 0.9039\n",
      "Epoch 31: TrainLoss 0.8098 RecLoss: 0.0000 (left: 4:04:09)\n",
      "TestLoss: 0.8593 MAE: 0.7304 RMSE: 0.9270\n",
      "ValLoss: 0.8180 MAE: 0.7125 RMSE: 0.9044\n",
      "Epoch 32: TrainLoss 0.8095 RecLoss: 0.0000 (left: 4:00:13)\n",
      "TestLoss: 0.8590 MAE: 0.7284 RMSE: 0.9268\n",
      "ValLoss: 0.8166 MAE: 0.7120 RMSE: 0.9037\n",
      "Epoch 33: TrainLoss 0.8093 RecLoss: 0.0000 (left: 3:56:36)\n",
      "TestLoss: 0.8630 MAE: 0.7261 RMSE: 0.9290\n",
      "ValLoss: 0.8198 MAE: 0.7107 RMSE: 0.9054\n",
      "Epoch 34: TrainLoss 0.8091 RecLoss: 0.0000 (left: 3:52:59)\n",
      "TestLoss: 0.8657 MAE: 0.7370 RMSE: 0.9304\n",
      "ValLoss: 0.8178 MAE: 0.7167 RMSE: 0.9043\n",
      "Epoch 35: TrainLoss 0.8088 RecLoss: 0.0000 (left: 3:49:28)\n",
      "TestLoss: 0.8651 MAE: 0.7376 RMSE: 0.9301\n",
      "ValLoss: 0.8189 MAE: 0.7186 RMSE: 0.9050\n",
      "Epoch 36: TrainLoss 0.8086 RecLoss: 0.0000 (left: 3:45:51)\n",
      "TestLoss: 0.8585 MAE: 0.7273 RMSE: 0.9265\n",
      "ValLoss: 0.8194 MAE: 0.7120 RMSE: 0.9052\n",
      "Epoch 37: TrainLoss 0.8088 RecLoss: 0.0000 (left: 3:42:19)\n",
      "TestLoss: 0.8626 MAE: 0.7325 RMSE: 0.9287\n",
      "ValLoss: 0.8168 MAE: 0.7128 RMSE: 0.9038\n",
      "Epoch 38: TrainLoss 0.8080 RecLoss: 0.0000 (left: 3:38:50)\n",
      "TestLoss: 0.8631 MAE: 0.7312 RMSE: 0.9290\n",
      "ValLoss: 0.8181 MAE: 0.7128 RMSE: 0.9045\n",
      "Epoch 39: TrainLoss 0.8080 RecLoss: 0.0000 (left: 3:35:01)\n",
      "TestLoss: 0.8585 MAE: 0.7288 RMSE: 0.9265\n",
      "ValLoss: 0.8160 MAE: 0.7116 RMSE: 0.9033\n",
      "Epoch 40: TrainLoss 0.8082 RecLoss: 0.0000 (left: 3:31:05)\n",
      "TestLoss: 0.8673 MAE: 0.7398 RMSE: 0.9313\n",
      "ValLoss: 0.8196 MAE: 0.7183 RMSE: 0.9053\n",
      "Epoch 41: TrainLoss 0.8082 RecLoss: 0.0000 (left: 3:27:23)\n",
      "TestLoss: 0.8624 MAE: 0.7285 RMSE: 0.9287\n",
      "ValLoss: 0.8170 MAE: 0.7118 RMSE: 0.9039\n",
      "Epoch 42: TrainLoss 0.8078 RecLoss: 0.0000 (left: 3:23:40)\n",
      "TestLoss: 0.8642 MAE: 0.7360 RMSE: 0.9296\n",
      "ValLoss: 0.8206 MAE: 0.7172 RMSE: 0.9059\n",
      "Epoch 43: TrainLoss 0.8068 RecLoss: 0.0000 (left: 3:19:57)\n",
      "TestLoss: 0.8633 MAE: 0.7269 RMSE: 0.9292\n",
      "ValLoss: 0.8197 MAE: 0.7106 RMSE: 0.9054\n",
      "Epoch 44: TrainLoss 0.8076 RecLoss: 0.0000 (left: 3:16:08)\n",
      "TestLoss: 0.8636 MAE: 0.7348 RMSE: 0.9293\n",
      "ValLoss: 0.8167 MAE: 0.7152 RMSE: 0.9037\n",
      "Epoch 45: TrainLoss 0.8070 RecLoss: 0.0000 (left: 3:12:15)\n",
      "TestLoss: 0.8620 MAE: 0.7257 RMSE: 0.9284\n",
      "ValLoss: 0.8191 MAE: 0.7100 RMSE: 0.9050\n",
      "Epoch 46: TrainLoss 0.8067 RecLoss: 0.0000 (left: 3:08:29)\n",
      "TestLoss: 0.8614 MAE: 0.7337 RMSE: 0.9281\n",
      "ValLoss: 0.8182 MAE: 0.7154 RMSE: 0.9046\n",
      "Epoch 47: TrainLoss 0.8070 RecLoss: 0.0000 (left: 3:04:52)\n",
      "TestLoss: 0.8536 MAE: 0.7259 RMSE: 0.9239\n",
      "ValLoss: 0.8167 MAE: 0.7108 RMSE: 0.9037\n",
      "Epoch 48: TrainLoss 0.8071 RecLoss: 0.0000 (left: 3:01:16)\n",
      "TestLoss: 0.8605 MAE: 0.7275 RMSE: 0.9276\n",
      "ValLoss: 0.8163 MAE: 0.7104 RMSE: 0.9035\n",
      "Epoch 49: TrainLoss 0.8062 RecLoss: 0.0000 (left: 2:57:40)\n",
      "TestLoss: 0.8614 MAE: 0.7301 RMSE: 0.9281\n",
      "ValLoss: 0.8141 MAE: 0.7112 RMSE: 0.9023\n",
      "Epoch 50: TrainLoss 0.8059 RecLoss: 0.0000 (left: 2:53:53)\n",
      "TestLoss: 0.8608 MAE: 0.7326 RMSE: 0.9278\n",
      "ValLoss: 0.8159 MAE: 0.7146 RMSE: 0.9033\n",
      "Epoch 51: TrainLoss 0.8063 RecLoss: 0.0000 (left: 2:50:09)\n",
      "TestLoss: 0.8635 MAE: 0.7328 RMSE: 0.9292\n",
      "ValLoss: 0.8166 MAE: 0.7144 RMSE: 0.9036\n",
      "Epoch 52: TrainLoss 0.8054 RecLoss: 0.0000 (left: 2:46:33)\n",
      "TestLoss: 0.8585 MAE: 0.7282 RMSE: 0.9266\n",
      "ValLoss: 0.8167 MAE: 0.7110 RMSE: 0.9037\n",
      "Epoch 53: TrainLoss 0.8056 RecLoss: 0.0000 (left: 2:42:52)\n",
      "TestLoss: 0.8607 MAE: 0.7285 RMSE: 0.9277\n",
      "ValLoss: 0.8164 MAE: 0.7113 RMSE: 0.9035\n",
      "Epoch 54: TrainLoss 0.8052 RecLoss: 0.0000 (left: 2:39:18)\n",
      "TestLoss: 0.8616 MAE: 0.7247 RMSE: 0.9282\n",
      "ValLoss: 0.8181 MAE: 0.7094 RMSE: 0.9045\n",
      "Epoch 55: TrainLoss 0.8051 RecLoss: 0.0000 (left: 2:35:37)\n",
      "TestLoss: 0.8638 MAE: 0.7337 RMSE: 0.9294\n",
      "ValLoss: 0.8151 MAE: 0.7135 RMSE: 0.9028\n",
      "Epoch 56: TrainLoss 0.8052 RecLoss: 0.0000 (left: 2:32:05)\n",
      "TestLoss: 0.8608 MAE: 0.7301 RMSE: 0.9278\n",
      "ValLoss: 0.8149 MAE: 0.7115 RMSE: 0.9027\n",
      "Epoch 57: TrainLoss 0.8050 RecLoss: 0.0000 (left: 2:28:30)\n",
      "TestLoss: 0.8633 MAE: 0.7269 RMSE: 0.9292\n",
      "ValLoss: 0.8188 MAE: 0.7096 RMSE: 0.9049\n",
      "Epoch 58: TrainLoss 0.8048 RecLoss: 0.0000 (left: 2:24:54)\n",
      "TestLoss: 0.8581 MAE: 0.7314 RMSE: 0.9263\n",
      "ValLoss: 0.8146 MAE: 0.7134 RMSE: 0.9026\n",
      "Epoch 59: TrainLoss 0.8047 RecLoss: 0.0000 (left: 2:21:20)\n",
      "TestLoss: 0.8618 MAE: 0.7327 RMSE: 0.9283\n",
      "ValLoss: 0.8157 MAE: 0.7141 RMSE: 0.9031\n",
      "Epoch 60: TrainLoss 0.8040 RecLoss: 0.0000 (left: 2:17:49)\n",
      "TestLoss: 0.8592 MAE: 0.7310 RMSE: 0.9269\n",
      "ValLoss: 0.8156 MAE: 0.7138 RMSE: 0.9031\n",
      "Epoch 61: TrainLoss 0.8046 RecLoss: 0.0000 (left: 2:14:18)\n",
      "TestLoss: 0.8555 MAE: 0.7268 RMSE: 0.9249\n",
      "ValLoss: 0.8161 MAE: 0.7104 RMSE: 0.9034\n",
      "Epoch 62: TrainLoss 0.8044 RecLoss: 0.0000 (left: 2:10:44)\n",
      "TestLoss: 0.8571 MAE: 0.7260 RMSE: 0.9258\n",
      "ValLoss: 0.8152 MAE: 0.7097 RMSE: 0.9029\n",
      "Epoch 63: TrainLoss 0.8036 RecLoss: 0.0000 (left: 2:07:10)\n",
      "TestLoss: 0.8579 MAE: 0.7246 RMSE: 0.9262\n",
      "ValLoss: 0.8184 MAE: 0.7086 RMSE: 0.9047\n",
      "Epoch 64: TrainLoss 0.8037 RecLoss: 0.0000 (left: 2:03:43)\n",
      "TestLoss: 0.8582 MAE: 0.7297 RMSE: 0.9264\n",
      "ValLoss: 0.8141 MAE: 0.7114 RMSE: 0.9023\n",
      "Epoch 65: TrainLoss 0.8038 RecLoss: 0.0000 (left: 2:00:16)\n",
      "TestLoss: 0.8570 MAE: 0.7286 RMSE: 0.9257\n",
      "ValLoss: 0.8140 MAE: 0.7119 RMSE: 0.9022\n",
      "Epoch 66: TrainLoss 0.8037 RecLoss: 0.0000 (left: 1:56:48)\n",
      "TestLoss: 0.8602 MAE: 0.7315 RMSE: 0.9275\n",
      "ValLoss: 0.8154 MAE: 0.7134 RMSE: 0.9030\n",
      "Epoch 67: TrainLoss 0.8036 RecLoss: 0.0000 (left: 1:53:20)\n",
      "TestLoss: 0.8621 MAE: 0.7314 RMSE: 0.9285\n",
      "ValLoss: 0.8141 MAE: 0.7122 RMSE: 0.9023\n",
      "Epoch 68: TrainLoss 0.8032 RecLoss: 0.0000 (left: 1:49:49)\n",
      "TestLoss: 0.8570 MAE: 0.7262 RMSE: 0.9257\n",
      "ValLoss: 0.8164 MAE: 0.7097 RMSE: 0.9035\n",
      "Epoch 69: TrainLoss 0.8030 RecLoss: 0.0000 (left: 1:46:27)\n",
      "TestLoss: 0.8567 MAE: 0.7272 RMSE: 0.9256\n",
      "ValLoss: 0.8149 MAE: 0.7115 RMSE: 0.9027\n",
      "Epoch 70: TrainLoss 0.8030 RecLoss: 0.0000 (left: 1:43:09)\n",
      "TestLoss: 0.8570 MAE: 0.7284 RMSE: 0.9257\n",
      "ValLoss: 0.8140 MAE: 0.7111 RMSE: 0.9022\n",
      "Epoch 71: TrainLoss 0.8030 RecLoss: 0.0000 (left: 1:39:52)\n",
      "TestLoss: 0.8596 MAE: 0.7252 RMSE: 0.9271\n",
      "ValLoss: 0.8182 MAE: 0.7094 RMSE: 0.9045\n",
      "Epoch 72: TrainLoss 0.8026 RecLoss: 0.0000 (left: 1:36:33)\n",
      "TestLoss: 0.8550 MAE: 0.7264 RMSE: 0.9247\n",
      "ValLoss: 0.8136 MAE: 0.7101 RMSE: 0.9020\n",
      "Epoch 73: TrainLoss 0.8024 RecLoss: 0.0000 (left: 1:33:16)\n",
      "TestLoss: 0.8588 MAE: 0.7317 RMSE: 0.9267\n",
      "ValLoss: 0.8139 MAE: 0.7135 RMSE: 0.9022\n",
      "Epoch 74: TrainLoss 0.8023 RecLoss: 0.0000 (left: 1:29:59)\n",
      "TestLoss: 0.8567 MAE: 0.7302 RMSE: 0.9256\n",
      "ValLoss: 0.8143 MAE: 0.7122 RMSE: 0.9024\n",
      "Epoch 75: TrainLoss 0.8027 RecLoss: 0.0000 (left: 1:26:37)\n",
      "TestLoss: 0.8578 MAE: 0.7268 RMSE: 0.9262\n",
      "ValLoss: 0.8149 MAE: 0.7091 RMSE: 0.9027\n",
      "Epoch 76: TrainLoss 0.8023 RecLoss: 0.0000 (left: 1:23:16)\n",
      "TestLoss: 0.8571 MAE: 0.7280 RMSE: 0.9258\n",
      "ValLoss: 0.8125 MAE: 0.7097 RMSE: 0.9014\n",
      "Epoch 77: TrainLoss 0.8019 RecLoss: 0.0000 (left: 1:19:55)\n",
      "TestLoss: 0.8577 MAE: 0.7325 RMSE: 0.9261\n",
      "ValLoss: 0.8143 MAE: 0.7147 RMSE: 0.9024\n",
      "Epoch 78: TrainLoss 0.8018 RecLoss: 0.0000 (left: 1:16:33)\n",
      "TestLoss: 0.8599 MAE: 0.7305 RMSE: 0.9273\n",
      "ValLoss: 0.8146 MAE: 0.7120 RMSE: 0.9025\n",
      "Epoch 79: TrainLoss 0.8013 RecLoss: 0.0000 (left: 1:13:09)\n",
      "TestLoss: 0.8553 MAE: 0.7291 RMSE: 0.9248\n",
      "ValLoss: 0.8139 MAE: 0.7116 RMSE: 0.9021\n",
      "Epoch 80: TrainLoss 0.8014 RecLoss: 0.0000 (left: 1:09:47)\n",
      "TestLoss: 0.8606 MAE: 0.7255 RMSE: 0.9277\n",
      "ValLoss: 0.8184 MAE: 0.7085 RMSE: 0.9047\n",
      "Epoch 81: TrainLoss 0.8014 RecLoss: 0.0000 (left: 1:06:24)\n",
      "TestLoss: 0.8535 MAE: 0.7255 RMSE: 0.9238\n",
      "ValLoss: 0.8154 MAE: 0.7095 RMSE: 0.9030\n",
      "Epoch 82: TrainLoss 0.8015 RecLoss: 0.0000 (left: 1:03:01)\n",
      "TestLoss: 0.8553 MAE: 0.7274 RMSE: 0.9248\n",
      "ValLoss: 0.8119 MAE: 0.7100 RMSE: 0.9010\n",
      "Epoch 83: TrainLoss 0.8008 RecLoss: 0.0000 (left: 0:59:35)\n",
      "TestLoss: 0.8592 MAE: 0.7264 RMSE: 0.9269\n",
      "ValLoss: 0.8159 MAE: 0.7092 RMSE: 0.9033\n",
      "Epoch 84: TrainLoss 0.8012 RecLoss: 0.0000 (left: 0:56:11)\n",
      "TestLoss: 0.8612 MAE: 0.7238 RMSE: 0.9280\n",
      "ValLoss: 0.8214 MAE: 0.7091 RMSE: 0.9063\n",
      "Epoch 85: TrainLoss 0.8006 RecLoss: 0.0000 (left: 0:52:44)\n",
      "TestLoss: 0.8578 MAE: 0.7311 RMSE: 0.9262\n",
      "ValLoss: 0.8157 MAE: 0.7149 RMSE: 0.9032\n",
      "Epoch 86: TrainLoss 0.8005 RecLoss: 0.0000 (left: 0:49:16)\n",
      "TestLoss: 0.8553 MAE: 0.7247 RMSE: 0.9248\n",
      "ValLoss: 0.8145 MAE: 0.7090 RMSE: 0.9025\n",
      "Epoch 87: TrainLoss 0.8006 RecLoss: 0.0000 (left: 0:45:49)\n",
      "TestLoss: 0.8588 MAE: 0.7312 RMSE: 0.9267\n",
      "ValLoss: 0.8135 MAE: 0.7125 RMSE: 0.9019\n",
      "Epoch 88: TrainLoss 0.8007 RecLoss: 0.0000 (left: 0:42:20)\n",
      "TestLoss: 0.8581 MAE: 0.7291 RMSE: 0.9264\n",
      "ValLoss: 0.8137 MAE: 0.7112 RMSE: 0.9021\n",
      "Epoch 89: TrainLoss 0.8003 RecLoss: 0.0000 (left: 0:38:52)\n",
      "TestLoss: 0.8543 MAE: 0.7301 RMSE: 0.9243\n",
      "ValLoss: 0.8135 MAE: 0.7127 RMSE: 0.9019\n",
      "Epoch 90: TrainLoss 0.8004 RecLoss: 0.0000 (left: 0:35:23)\n",
      "TestLoss: 0.8600 MAE: 0.7281 RMSE: 0.9274\n",
      "ValLoss: 0.8141 MAE: 0.7094 RMSE: 0.9023\n",
      "Epoch 91: TrainLoss 0.8002 RecLoss: 0.0000 (left: 0:31:52)\n",
      "TestLoss: 0.8585 MAE: 0.7333 RMSE: 0.9266\n",
      "ValLoss: 0.8132 MAE: 0.7132 RMSE: 0.9018\n",
      "Epoch 92: TrainLoss 0.7999 RecLoss: 0.0000 (left: 0:28:22)\n",
      "TestLoss: 0.8652 MAE: 0.7343 RMSE: 0.9301\n",
      "ValLoss: 0.8145 MAE: 0.7129 RMSE: 0.9025\n",
      "Epoch 93: TrainLoss 0.7999 RecLoss: 0.0000 (left: 0:24:50)\n",
      "TestLoss: 0.8585 MAE: 0.7301 RMSE: 0.9265\n",
      "ValLoss: 0.8132 MAE: 0.7124 RMSE: 0.9018\n",
      "Epoch 94: TrainLoss 0.7998 RecLoss: 0.0000 (left: 0:21:19)\n",
      "TestLoss: 0.8563 MAE: 0.7303 RMSE: 0.9253\n",
      "ValLoss: 0.8132 MAE: 0.7126 RMSE: 0.9018\n",
      "Epoch 95: TrainLoss 0.7993 RecLoss: 0.0000 (left: 0:17:46)\n",
      "TestLoss: 0.8571 MAE: 0.7275 RMSE: 0.9258\n",
      "ValLoss: 0.8130 MAE: 0.7089 RMSE: 0.9017\n",
      "Epoch 96: TrainLoss 0.7996 RecLoss: 0.0000 (left: 0:14:14)\n",
      "TestLoss: 0.8543 MAE: 0.7289 RMSE: 0.9243\n",
      "ValLoss: 0.8128 MAE: 0.7116 RMSE: 0.9015\n",
      "Epoch 97: TrainLoss 0.7994 RecLoss: 0.0000 (left: 0:10:41)\n",
      "TestLoss: 0.8583 MAE: 0.7251 RMSE: 0.9265\n",
      "ValLoss: 0.8161 MAE: 0.7089 RMSE: 0.9034\n",
      "Epoch 98: TrainLoss 0.7989 RecLoss: 0.0000 (left: 0:07:07)\n",
      "TestLoss: 0.8567 MAE: 0.7344 RMSE: 0.9256\n",
      "ValLoss: 0.8143 MAE: 0.7152 RMSE: 0.9024\n",
      "Epoch 99: TrainLoss 0.7992 RecLoss: 0.0000 (left: 0:03:34)\n",
      "TestLoss: 0.8549 MAE: 0.7258 RMSE: 0.9246\n",
      "ValLoss: 0.8124 MAE: 0.7092 RMSE: 0.9014\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 291458/683611\n",
      "test set size: support/query 894/4337\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.7070 RMSE: 0.8837 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7278 RMSE: 0.9243 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7242 RMSE: 0.9175 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
