{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the work to generate core users and feeding it to IDCF codebase Movielens-1m dataset.\n",
    "- greater than 30 interactions are taken into.\n",
    "- Less than 30 interations are taken into test set\n",
    "- some x% of coreusers are choosen as training set\n",
    "- coreusers are calculated using CUR decomposition and R matrix is taken as coreuser.\n",
    "- always the results are tested on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from scipy.sparse.linalg import svds\n",
    "import random \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as ss\n",
    "import pickle\n",
    "from sklearn.utils.extmath import randomized_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadData():\n",
    "    ml1m_dir = 'data/ratings.dat'\n",
    "    ml1m_rating = pd.read_csv(ml1m_dir, sep='::', header=None, names=['uid', 'mid', 'rating', 'timestamp'],  engine='python')\n",
    "    unique_uid = np.unique(np.array(ml1m_rating['uid'].tolist()))\n",
    "    unique_mid = np.unique(np.array(ml1m_rating['mid'].tolist()))\n",
    "    uid_dict = dict([(y,x) for x,y in enumerate(unique_uid)])\n",
    "    mid_dict = dict([(y,x) for x,y in enumerate(unique_mid)])\n",
    "    print('DICTIONARY PREPARED:')\n",
    "\n",
    "    # init user item dictionary:\n",
    "    \n",
    "    uid_list = ml1m_rating['uid'].tolist()\n",
    "    uid_list_len = len(uid_list)\n",
    "    mid_list = ml1m_rating['mid'].tolist()\n",
    "    mid_list_len = len(mid_list)\n",
    "    rating_list = ml1m_rating['rating'].tolist()\n",
    "    user_item_dict = {x:set() for x in range(len(unique_uid))}\n",
    "    item_user_dict = {x:set() for x in range(len(unique_mid))}\n",
    "    for i in range(uid_list_len):\n",
    "        uid_list[i] = uid_dict[uid_list[i]]\n",
    "        mid_list[i] = mid_dict[mid_list[i]]\n",
    "        # rating_list[i] = 1 # comment this line if you want to activate explicit ratings\n",
    "        user_item_dict[uid_list[i]].add(mid_list[i])\n",
    "        item_user_dict[mid_list[i]].add(uid_list[i])\n",
    "    tmp_df = pd.DataFrame({\"uid\":uid_list, \"mid\":mid_list, \"ratings\":rating_list})\n",
    "    v = tmp_df.uid.value_counts()\n",
    "    df = tmp_df[tmp_df.uid.isin(v.index[v.gt(30)])]\n",
    "### code to store less than 30 interactions:\n",
    "    df_less_30 = tmp_df[tmp_df.uid.isin(v.index[v.le(30)])]\n",
    "    return df, df_less_30, len(np.unique(mid_list)), len(unique_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICTIONARY PREPARED:\n",
      "GREATER THAN 30:\n",
      "           uid   mid  ratings\n",
      "0           0  1104        5\n",
      "1           0   639        3\n",
      "2           0   853        3\n",
      "3           0  3177        4\n",
      "4           0  2162        5\n",
      "...       ...   ...      ...\n",
      "1000204  6039  1019        1\n",
      "1000205  6039  1022        5\n",
      "1000206  6039   548        5\n",
      "1000207  6039  1024        4\n",
      "1000208  6039  1025        4\n",
      "\n",
      "[980300 rows x 3 columns]\n",
      "LESS THAN 30: \n",
      "          uid   mid  ratings\n",
      "233        3  3235        5\n",
      "234        3  1120        3\n",
      "235        3  2743        4\n",
      "236        3  1124        4\n",
      "237        3   971        4\n",
      "...      ...   ...      ...\n",
      "999740  6037  1288        2\n",
      "999741  6037  2495        1\n",
      "999742  6037  2511        3\n",
      "999743  6037  3165        3\n",
      "999744  6037  1007        5\n",
      "\n",
      "[19909 rows x 3 columns]\n",
      "980300\n",
      "19909\n",
      "UNIQUE MIDS:  3706\n",
      "UNIQUE UIDS:  6040\n"
     ]
    }
   ],
   "source": [
    "threshold = 30 #split the users into test and train by threshold number of interactions. if greater than threshold then all interactions of that user goes into train set.\n",
    "df_gt_30, df_le_30, unique_mids, unique_uids = ReadData()\n",
    "print(\"GREATER THAN 30:\\n\", df_gt_30)\n",
    "print(\"LESS THAN 30: \\n\", df_le_30)\n",
    "print(len(df_gt_30))\n",
    "print(len(df_le_30))\n",
    "print(\"UNIQUE MIDS: \", unique_mids)\n",
    "print(\"UNIQUE UIDS: \", unique_uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_test_df = df_gt_30.groupby(\"uid\").tail(1)\n",
    "# print(len(df_gt_30))\n",
    "support_train_df = df_gt_30.drop(df_gt_30.groupby('uid').tail(1).index, inplace=False)\n",
    "# print(\"#TEST INSTANCES: \" ,len(support_test_df))\n",
    "# print(\"#TRAIN INSTANCES: \" ,len(support_train_df))\n",
    "assert(len(df_gt_30)== len(support_test_df) + len(support_train_df))\n",
    "# print(len(test_df))\n",
    "# print(len(train_df))\n",
    "query_test_df = df_le_30.groupby(\"uid\").tail(1)\n",
    "query_train_df = df_le_30.drop(df_le_30.groupby('uid').tail(1).index, inplace=False)\n",
    "assert(len(df_le_30)== len(query_test_df) + len(query_train_df))\n",
    "dic_support_train_df_uid_mapping = dict([(y,x) for x,y in enumerate(np.unique(support_train_df['uid']))])\n",
    "dic_support_train_df_uid_rmapping = dict([(x,y) for x,y in enumerate(np.unique(support_train_df['uid']))])\n",
    "### no need for mid mapping\n",
    "\n",
    "uid_of_train_df = support_train_df['uid'].tolist()\n",
    "for i in range(len(uid_of_train_df)):\n",
    "    uid_of_train_df[i] = dic_support_train_df_uid_mapping[uid_of_train_df[i]]\n",
    "# for index, row in train_df.iterrows():\n",
    "#     train_df['uid'][index] = dic_train_df_uid_mapping[train_df['uid'][index]]\n",
    "core_user_ko_input_train_df = pd.DataFrame({'uid':uid_of_train_df, 'mid':support_train_df['mid'], 'ratings':support_train_df['ratings']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ui_dic = {}    \n",
    "for user in range(unique_uids):\n",
    "    train_ui_dic[user] = []\n",
    "for index,row in support_train_df.iterrows():\n",
    "        train_ui_dic[row['uid']].append(row['mid'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- utility functions for CUR coreusers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MID = 27277 + 1\n",
    "def select_cols(mat, k, dup=False):\n",
    "    # prob 1d array of probabilities of all columns\n",
    "    prob = mat.T.dot(mat)\n",
    "    prob = np.array(np.diagonal(prob))\n",
    "    denom = np.abs(prob).sum(axis = 0)\n",
    "    prob = prob/denom\n",
    "\n",
    "    C = np.zeros((mat.shape[0], k))\n",
    "    ind_cols = np.arange(0, prob.size)\n",
    "    c_ind = []\n",
    "    i = 0\n",
    "    while(i < k):\n",
    "        rand_sel = np.random.choice(ind_cols, 1, p=prob)\n",
    "        if rand_sel in c_ind:\n",
    "            continue\n",
    "        c_ind.append(rand_sel[0])\n",
    "        C[:, i] = mat[:, rand_sel[0]]\n",
    "        i += 1\n",
    "        # C[:, i] = C[:, i]/np.sqrt(k*prob[rand_sel[0]])\n",
    "\n",
    "    return C, c_ind\n",
    "\n",
    "def select_rows(mat, k, dup=False):\n",
    "\n",
    "    prob = mat.dot(mat.T)\n",
    "    prob = np.array(np.diagonal(prob))\n",
    "    denom = np.abs(prob).sum(axis=0)\n",
    "    prob = prob/denom\n",
    "    print(prob)\n",
    "    r = np.zeros((k, mat.shape[1]))\n",
    "    ind_rows = np.arange(0, prob.size)\n",
    "    r_ind = []\n",
    "    i = 0\n",
    "    while(i < k):\n",
    "        # print(ind_rows)\n",
    "        rand_sel = np.random.choice(ind_rows, 1, p=prob)\n",
    "        if rand_sel in r_ind:\n",
    "            continue\n",
    "        r_ind.append(rand_sel[0])\n",
    "        r[i, :] = mat[rand_sel[0], :]\n",
    "        i += 1\n",
    "        # r[i, :] = r[i, :]/np.sqrt(k*prob[rand_sel[0]])\n",
    "    r_ind = np.array(r_ind)\n",
    "    return r, r_ind\n",
    "\n",
    "# def matIntersection(mat, c_ind, r_ind):\n",
    "    \n",
    "#     W = np.zeros((len(r_ind), len(c_ind)))\n",
    "#     for i in range(len(r_ind)):\n",
    "#         W[i] = mat[r_ind[i], c_ind]\n",
    "    \n",
    "#     return W\n",
    "\n",
    "# def pseudoInverse(W):\n",
    "#     # U = WP (W+)\n",
    "\n",
    "#     # W = X.Z.YT\n",
    "#     X, Z, YT = np.linalg.svd(W)\n",
    "    \n",
    "#     # W+ = Y.Z+.XT\n",
    "#     XT = X.T\n",
    "#     Y = YT.T\n",
    "#     # Z+ = reciprocal(Z)\n",
    "#     ZP = np.reciprocal(Z)\n",
    "#     ZP = sp.spdiags(ZP, 0, ZP.size, ZP.size)\n",
    "#     ZP = ZP@ZP\n",
    "    \n",
    "#     # W+ = Y.Z+.XT\n",
    "#     WP = Y@ZP\n",
    "#     WP = WP@XT\n",
    "\n",
    "#     return WP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CUR_ExtractCoreUsers(dataframe, unique_user_len, unique_item_len):\n",
    "    # print(\"# of rows in ml1m_ratings: \", len(dataframe))\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "    userItemMatrix = np.zeros(shape=(u_len, m_len))\n",
    "    # print(userItemMatrix)\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        userItemMatrix[row['uid']][row['mid']] = row['ratings']\n",
    "        # print(row['uid'], row['mid'])\n",
    "    print(\"USER ITEM MATRIX: \\n\", userItemMatrix)\n",
    "\n",
    "    mat = userItemMatrix\n",
    "    print(\"MAT:\", mat)\n",
    "    print(mat.shape)\n",
    "    C, c_ind = select_cols(mat, int(u_len * 0.10)) ## getting 20% core users\n",
    "    r, r_ind= select_rows(mat, int(u_len * 0.10))\n",
    "    print(\"r\", r)\n",
    "    print(\"r_ind len\", len(r_ind))\n",
    "\n",
    "    cur_coreusers = dataframe.iloc[np.where(dataframe.uid.isin(r_ind))]\n",
    "    # coreusers.reset_index()\n",
    "    # print(\"CORE USERS:\\n\", coreusers)\n",
    "    return cur_coreusers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cur decomposition from paper (https://www.pnas.org/doi/10.1073/pnas.0803205106)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUR():\n",
    "    def __init__(self, k, eps, it=None, truncated=False):\n",
    "        self.k = k\n",
    "        print(\"K IS :\", self.k)\n",
    "        self.eps = eps\n",
    "        self.trunc = truncated \n",
    "        self.c = k * np.log(k) / eps**2 #expectation number of sampled columns\n",
    "        self.C, self.U, self.R = None, None, None #matrices of decomposition\n",
    "        self.pi_col, self.pi_row = None, None #leverage scores of corresponding columns/rows\n",
    "        self.col_indices = None\n",
    "        self.row_indices = None\n",
    "    \n",
    "    def column_select(self, A):\n",
    "        n = A.shape[1]\n",
    "        A = np.array(A.copy())\n",
    "        if self.trunc:\n",
    "            _, _, v_k = randomized_svd(A, self.k) #for very big matrices\n",
    "        else:\n",
    "            _, _, vh = np.linalg.svd(A, full_matrices=False)\n",
    "            v_k = vh[0:self.k, :]\n",
    "        \n",
    "        pi = 1 / self.k * np.sum(v_k**2, axis=0)\n",
    "        c_index = [np.random.choice(2, \n",
    "                        p=[1 - min(1, self.c * pi[i]), min(1, self.c * pi[i])]) for i in range(n)\n",
    "                  ]\n",
    "        c_index = np.nonzero(c_index)[0]\n",
    "        print(len(c_index))\n",
    "        C = A[:, c_index]\n",
    "        return C, c_index, pi\n",
    "\n",
    "    def run_CUR(self, A):\n",
    "        A = np.array(A.copy())\n",
    "        # self.C, self.col_indices, self.pi_col = self.column_select(A)\n",
    "        self.R, self.row_indices, self.pi_row = self.column_select(A.T)\n",
    "        # self.U = np.linalg.pinv(self.C) @ A @ np.linalg.pinv(self.R.T)\n",
    "        return self.row_indices\n",
    "def OPTIMAL_CUR_ExtractCoreUsers(dataframe, unique_user_len, unique_item_len):\n",
    "    # print(\"# of rows in ml1m_ratings: \", len(dataframe))\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "    userItemMatrix = np.zeros(shape=(u_len, m_len))\n",
    "    # print(userItemMatrix)\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        userItemMatrix[row['uid']][row['mid']] = row['ratings']\n",
    "        # print(row['uid'], row['mid'])\n",
    "    print(\"USER ITEM MATRIX: \\n\", userItemMatrix)\n",
    "\n",
    "    mat = userItemMatrix\n",
    "    print(\"MAT:\", mat)\n",
    "    print(mat.shape)\n",
    "    cur = CUR(k=int(u_len * 0.10), eps=0.5,)\n",
    "    # ids = np.argsort(cur.pi_col)[::-1][:5]\n",
    "    cur.run_CUR(mat)\n",
    "    cur_coreusers_idx = np.argsort(cur.pi_row)[::-1][:int(u_len * 0.10)]\n",
    "    cur_coreusers = dataframe.iloc[np.where(dataframe.uid.isin(cur_coreusers_idx))]\n",
    "    # print(len(cur_coreusers))\n",
    "    return cur_coreusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER LEN: 5231\n",
      "MOVIE LEN: 3706\n",
      "USER ITEM MATRIX: \n",
      " [[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 0.]]\n",
      "MAT: [[5. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [3. 0. 0. ... 0. 0. 0.]]\n",
      "(5231, 3706)\n",
      "K IS : 523\n",
      "4858\n"
     ]
    }
   ],
   "source": [
    "core_users = OPTIMAL_CUR_ExtractCoreUsers(core_user_ko_input_train_df, len(np.unique(uid_of_train_df)), unique_mids)\n",
    "support_user_list = np.unique(core_users['uid'])\n",
    "# print(\"CORE USERS:\" ,core_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523\n"
     ]
    }
   ],
   "source": [
    "print((len(support_user_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5231"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(support_user_list))\n",
    "len(np.unique(uid_of_train_df))\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORE USERS:            uid   mid  ratings\n",
      "0            0     1        1\n",
      "19          16   470        1\n",
      "21          18   506        1\n",
      "46          41   996        1\n",
      "50          45  1079        1\n",
      "...        ...   ...      ...\n",
      "1500194  48452  3490        1\n",
      "1500195  48452  6131        1\n",
      "1500196  48452  4637        1\n",
      "1500197  48452  3771        1\n",
      "1500198  48452  6172        1\n",
      "\n",
      "[140528 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "core_users_index_list = core_users.index.to_list()\n",
    "# non_core_user_index = (train_df.index.difference(core_users.index))\n",
    "# non_core_user_index = non_core_user_index.tolist()\n",
    "\n",
    "core_users_df = support_train_df.loc[core_users_index_list]\n",
    "# non_core_user_df = train_df.loc[non_core_user_index]\n",
    "# print(\"NON CORE USERS:\" ,non_core_user_df)\n",
    "print(\"CORE USERS:\" ,core_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4847\n",
      "SUPPORT TEST DF:            uid   mid  ratings\n",
      "55210        0    12        1\n",
      "55686       19   478        1\n",
      "55734       21   413        1\n",
      "56328       46  1006        1\n",
      "56445       50  1097        1\n",
      "...        ...   ...      ...\n",
      "1498974  55115  6585        1\n",
      "1499087  55120  1817        1\n",
      "1499448  55136  7316        1\n",
      "1499646  55143   633        1\n",
      "1500199  55163  2131        1\n",
      "\n",
      "[4847 rows x 3 columns]\n",
      "QUERY TEST DF:\n",
      "            uid   mid  ratings\n",
      "55229        1    34        1\n",
      "55416        9   219        1\n",
      "55435       10   237        1\n",
      "55903       29   682        1\n",
      "55970       32   740        1\n",
      "...        ...   ...      ...\n",
      "1499328  55131   856        1\n",
      "1499623  55142  5358        1\n",
      "1500406  55170  2066        1\n",
      "1500502  55174  4130        1\n",
      "1500727  55183  4905        1\n",
      "\n",
      "[6714 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(\"TEST DF CONTAINS TEST FOR CORE AND NON CORE ENTITIES:\\n\" ,test_df)\n",
    "# print(core_users['uid'])\n",
    "unique_uids_in_support_trian = np.unique(np.array(core_users_df['uid']))\n",
    "unique_uids_in_query_trian = np.unique(query_train_df['uid'])\n",
    "print(len(unique_uids_in_support_trian))\n",
    "support_test_df = support_test_df.loc[support_test_df['uid'].isin(unique_uids_in_support_trian)]\n",
    "print(\"SUPPORT TEST DF:\" ,support_test_df)\n",
    "query_test_df = query_test_df\n",
    "print(\"QUERY TEST DF:\\n\", query_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_train = []\n",
    "for index,row in core_users_df.iterrows():\n",
    "    support_train.append([row['uid'], row['mid'], row['ratings']])\n",
    "query_train = []\n",
    "for index, row in query_train_df.iterrows():\n",
    "    query_train.append([row['uid'], row['mid'], row['ratings']])\n",
    "support_test = []\n",
    "for index, row in support_test_df.iterrows():\n",
    "    support_test.append([row['uid'], row['mid'], row['ratings']])\n",
    "query_test = []\n",
    "for index, row in query_test_df.iterrows():\n",
    "    query_test.append([row['uid'], row['mid'], row['ratings']])\n",
    "user_his_dic = {}\n",
    "for u in train_ui_dic.keys():\n",
    "    user_his_dic[u] = train_ui_dic[u]\n",
    "user_supp_list = np.unique(core_users_df['uid']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"cur_20_support_as_core.pkl\", \"wb\") as f:\n",
    "    pickle.dump(support_train, f)\n",
    "    pickle.dump(query_train, f)\n",
    "    pickle.dump(support_test, f)\n",
    "    pickle.dump(query_test, f)\n",
    "    pickle.dump(user_supp_list, f)\n",
    "    pickle.dump(user_his_dic, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20% cur coreusers into IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 350454/19100\n",
      "test set size: support/query 1046/809\n",
      "Epoch 0 Step 326: Train 2.3744 Reg: 0.5801\n",
      "Test: 0.8841 MAE: 0.7485 RMSE: 0.9403\n",
      "Val: 0.8295 MAE: 0.7204 RMSE: 0.9108\n",
      "Epoch 1 Step 652: Train 0.8227 Reg: 0.4742\n",
      "Test: 0.8720 MAE: 0.7455 RMSE: 0.9338\n",
      "Val: 0.8162 MAE: 0.7159 RMSE: 0.9034\n",
      "Epoch 2 Step 978: Train 0.8162 Reg: 0.3923\n",
      "Test: 0.8831 MAE: 0.7473 RMSE: 0.9397\n",
      "Val: 0.8117 MAE: 0.7120 RMSE: 0.9010\n",
      "Epoch 3 Step 1304: Train 0.8133 Reg: 0.3389\n",
      "Test: 0.8575 MAE: 0.7363 RMSE: 0.9260\n",
      "Val: 0.8067 MAE: 0.7109 RMSE: 0.8982\n",
      "Epoch 4 Step 1630: Train 0.8103 Reg: 0.3066\n",
      "Test: 0.8620 MAE: 0.7369 RMSE: 0.9284\n",
      "Val: 0.8071 MAE: 0.7100 RMSE: 0.8984\n",
      "Epoch 5 Step 1956: Train 0.8064 Reg: 0.2876\n",
      "Test: 0.8742 MAE: 0.7433 RMSE: 0.9350\n",
      "Val: 0.8034 MAE: 0.7067 RMSE: 0.8963\n",
      "Epoch 6 Step 2282: Train 0.8025 Reg: 0.2758\n",
      "Test: 0.8604 MAE: 0.7388 RMSE: 0.9276\n",
      "Val: 0.7992 MAE: 0.7075 RMSE: 0.8940\n",
      "Epoch 7 Step 2608: Train 0.7960 Reg: 0.2701\n",
      "Test: 0.8504 MAE: 0.7321 RMSE: 0.9222\n",
      "Val: 0.7935 MAE: 0.7035 RMSE: 0.8908\n",
      "Epoch 8 Step 2934: Train 0.7887 Reg: 0.2694\n",
      "Test: 0.8536 MAE: 0.7333 RMSE: 0.9239\n",
      "Val: 0.7844 MAE: 0.6988 RMSE: 0.8857\n",
      "Epoch 9 Step 3260: Train 0.7804 Reg: 0.2688\n",
      "Test: 0.8416 MAE: 0.7262 RMSE: 0.9174\n",
      "Val: 0.7808 MAE: 0.6977 RMSE: 0.8836\n",
      "Epoch 10 Step 3586: Train 0.7705 Reg: 0.2698\n",
      "Test: 0.8435 MAE: 0.7275 RMSE: 0.9184\n",
      "Val: 0.7731 MAE: 0.6923 RMSE: 0.8793\n",
      "Epoch 11 Step 3912: Train 0.7574 Reg: 0.2722\n",
      "Test: 0.8416 MAE: 0.7282 RMSE: 0.9174\n",
      "Val: 0.7623 MAE: 0.6857 RMSE: 0.8731\n",
      "Epoch 12 Step 4238: Train 0.7446 Reg: 0.2769\n",
      "Test: 0.8260 MAE: 0.7220 RMSE: 0.9088\n",
      "Val: 0.7515 MAE: 0.6807 RMSE: 0.8669\n",
      "Epoch 13 Step 4564: Train 0.7314 Reg: 0.2833\n",
      "Test: 0.8114 MAE: 0.7144 RMSE: 0.9008\n",
      "Val: 0.7433 MAE: 0.6780 RMSE: 0.8622\n",
      "Epoch 14 Step 4890: Train 0.7170 Reg: 0.2922\n",
      "Test: 0.7973 MAE: 0.7149 RMSE: 0.8929\n",
      "Val: 0.7357 MAE: 0.6753 RMSE: 0.8578\n",
      "Epoch 15 Step 5216: Train 0.7029 Reg: 0.3004\n",
      "Test: 0.7947 MAE: 0.7039 RMSE: 0.8914\n",
      "Val: 0.7335 MAE: 0.6688 RMSE: 0.8564\n",
      "Epoch 16 Step 5542: Train 0.6891 Reg: 0.3113\n",
      "Test: 0.7869 MAE: 0.7028 RMSE: 0.8871\n",
      "Val: 0.7278 MAE: 0.6672 RMSE: 0.8531\n",
      "Epoch 17 Step 5868: Train 0.6758 Reg: 0.3213\n",
      "Test: 0.7811 MAE: 0.7044 RMSE: 0.8838\n",
      "Val: 0.7227 MAE: 0.6667 RMSE: 0.8501\n",
      "Epoch 18 Step 6194: Train 0.6618 Reg: 0.3310\n",
      "Test: 0.7718 MAE: 0.6975 RMSE: 0.8785\n",
      "Val: 0.7196 MAE: 0.6643 RMSE: 0.8483\n",
      "Epoch 19 Step 6520: Train 0.6465 Reg: 0.3420\n",
      "Test: 0.7642 MAE: 0.6919 RMSE: 0.8742\n",
      "Val: 0.7179 MAE: 0.6625 RMSE: 0.8473\n",
      "Epoch 20 Step 6846: Train 0.6270 Reg: 0.3596\n",
      "Test: 0.7540 MAE: 0.6888 RMSE: 0.8683\n",
      "Val: 0.7174 MAE: 0.6617 RMSE: 0.8470\n",
      "Epoch 21 Step 7172: Train 0.6049 Reg: 0.3805\n",
      "Test: 0.7477 MAE: 0.6871 RMSE: 0.8647\n",
      "Val: 0.7237 MAE: 0.6659 RMSE: 0.8507\n",
      "Epoch 22 Step 7498: Train 0.5803 Reg: 0.4034\n",
      "Test: 0.7497 MAE: 0.6807 RMSE: 0.8658\n",
      "Val: 0.7308 MAE: 0.6642 RMSE: 0.8549\n",
      "Epoch 23 Step 7824: Train 0.5511 Reg: 0.4307\n",
      "Test: 0.7560 MAE: 0.6876 RMSE: 0.8695\n",
      "Val: 0.7420 MAE: 0.6695 RMSE: 0.8614\n",
      "Epoch 24 Step 8150: Train 0.5205 Reg: 0.4550\n",
      "Test: 0.7651 MAE: 0.6881 RMSE: 0.8747\n",
      "Val: 0.7574 MAE: 0.6753 RMSE: 0.8703\n",
      "Epoch 25 Step 8476: Train 0.4935 Reg: 0.4738\n",
      "Test: 0.7752 MAE: 0.6942 RMSE: 0.8805\n",
      "Val: 0.7749 MAE: 0.6825 RMSE: 0.8803\n",
      "Epoch 26 Step 8802: Train 0.4714 Reg: 0.4871\n",
      "Test: 0.7911 MAE: 0.6970 RMSE: 0.8894\n",
      "Val: 0.7898 MAE: 0.6867 RMSE: 0.8887\n",
      "Epoch 27 Step 9128: Train 0.4539 Reg: 0.4954\n",
      "Test: 0.8018 MAE: 0.7003 RMSE: 0.8954\n",
      "Val: 0.8066 MAE: 0.6940 RMSE: 0.8981\n",
      "Epoch 28 Step 9454: Train 0.4402 Reg: 0.5004\n",
      "Test: 0.8183 MAE: 0.7058 RMSE: 0.9046\n",
      "Val: 0.8182 MAE: 0.6981 RMSE: 0.9045\n",
      "Epoch 29 Step 9780: Train 0.4297 Reg: 0.5029\n",
      "Test: 0.8298 MAE: 0.7103 RMSE: 0.9110\n",
      "Val: 0.8320 MAE: 0.7036 RMSE: 0.9121\n",
      "Epoch 30 Step 10106: Train 0.4209 Reg: 0.5042\n",
      "Test: 0.8400 MAE: 0.7114 RMSE: 0.9165\n",
      "Val: 0.8428 MAE: 0.7067 RMSE: 0.9180\n",
      "Epoch 31 Step 10432: Train 0.4132 Reg: 0.5048\n",
      "Test: 0.8538 MAE: 0.7171 RMSE: 0.9240\n",
      "Val: 0.8518 MAE: 0.7100 RMSE: 0.9229\n",
      "Epoch 32 Step 10758: Train 0.4065 Reg: 0.5044\n",
      "Test: 0.8666 MAE: 0.7201 RMSE: 0.9309\n",
      "Val: 0.8623 MAE: 0.7140 RMSE: 0.9286\n",
      "Epoch 33 Step 11084: Train 0.4006 Reg: 0.5038\n",
      "Test: 0.8802 MAE: 0.7256 RMSE: 0.9382\n",
      "Val: 0.8706 MAE: 0.7169 RMSE: 0.9331\n",
      "Epoch 34 Step 11410: Train 0.3954 Reg: 0.5026\n",
      "Test: 0.8889 MAE: 0.7286 RMSE: 0.9428\n",
      "Val: 0.8777 MAE: 0.7196 RMSE: 0.9369\n",
      "Epoch 35 Step 11736: Train 0.3902 Reg: 0.5014\n",
      "Test: 0.9010 MAE: 0.7345 RMSE: 0.9492\n",
      "Val: 0.8868 MAE: 0.7238 RMSE: 0.9417\n",
      "Epoch 36 Step 12062: Train 0.3857 Reg: 0.4999\n",
      "Test: 0.9089 MAE: 0.7353 RMSE: 0.9534\n",
      "Val: 0.8924 MAE: 0.7246 RMSE: 0.9447\n",
      "Epoch 37 Step 12388: Train 0.3816 Reg: 0.4981\n",
      "Test: 0.9223 MAE: 0.7411 RMSE: 0.9604\n",
      "Val: 0.9001 MAE: 0.7276 RMSE: 0.9488\n",
      "Epoch 38 Step 12714: Train 0.3779 Reg: 0.4963\n",
      "Test: 0.9327 MAE: 0.7441 RMSE: 0.9658\n",
      "Val: 0.9053 MAE: 0.7289 RMSE: 0.9515\n",
      "Epoch 39 Step 13040: Train 0.3744 Reg: 0.4943\n",
      "Test: 0.9411 MAE: 0.7488 RMSE: 0.9701\n",
      "Val: 0.9142 MAE: 0.7334 RMSE: 0.9561\n",
      "Epoch 40 Step 13366: Train 0.3714 Reg: 0.4921\n",
      "Test: 0.9489 MAE: 0.7497 RMSE: 0.9741\n",
      "Val: 0.9192 MAE: 0.7342 RMSE: 0.9587\n",
      "Epoch 41 Step 13692: Train 0.3685 Reg: 0.4901\n",
      "Test: 0.9566 MAE: 0.7527 RMSE: 0.9781\n",
      "Val: 0.9229 MAE: 0.7357 RMSE: 0.9607\n",
      "Epoch 42 Step 14018: Train 0.3659 Reg: 0.4878\n",
      "Test: 0.9640 MAE: 0.7540 RMSE: 0.9818\n",
      "Val: 0.9287 MAE: 0.7369 RMSE: 0.9637\n",
      "Epoch 43 Step 14344: Train 0.3634 Reg: 0.4858\n",
      "Test: 0.9727 MAE: 0.7579 RMSE: 0.9863\n",
      "Val: 0.9329 MAE: 0.7393 RMSE: 0.9658\n",
      "Epoch 44 Step 14670: Train 0.3612 Reg: 0.4837\n",
      "Test: 0.9773 MAE: 0.7589 RMSE: 0.9886\n",
      "Val: 0.9382 MAE: 0.7406 RMSE: 0.9686\n",
      "Epoch 45 Step 14996: Train 0.3591 Reg: 0.4816\n",
      "Test: 0.9873 MAE: 0.7622 RMSE: 0.9936\n",
      "Val: 0.9431 MAE: 0.7424 RMSE: 0.9711\n",
      "Epoch 46 Step 15322: Train 0.3570 Reg: 0.4795\n",
      "Test: 0.9928 MAE: 0.7640 RMSE: 0.9964\n",
      "Val: 0.9452 MAE: 0.7429 RMSE: 0.9722\n",
      "Epoch 47 Step 15648: Train 0.3552 Reg: 0.4774\n",
      "Test: 0.9969 MAE: 0.7647 RMSE: 0.9985\n",
      "Val: 0.9493 MAE: 0.7439 RMSE: 0.9743\n",
      "Epoch 48 Step 15974: Train 0.3534 Reg: 0.4756\n",
      "Test: 1.0039 MAE: 0.7678 RMSE: 1.0019\n",
      "Val: 0.9540 MAE: 0.7459 RMSE: 0.9768\n",
      "Epoch 49 Step 16300: Train 0.3517 Reg: 0.4736\n",
      "Test: 1.0082 MAE: 0.7684 RMSE: 1.0041\n",
      "Val: 0.9577 MAE: 0.7470 RMSE: 0.9786\n",
      "Epoch 50 Step 16626: Train 0.3501 Reg: 0.4718\n",
      "Test: 1.0122 MAE: 0.7693 RMSE: 1.0061\n",
      "Val: 0.9596 MAE: 0.7474 RMSE: 0.9796\n",
      "Epoch 51 Step 16952: Train 0.3486 Reg: 0.4699\n",
      "Test: 1.0168 MAE: 0.7703 RMSE: 1.0084\n",
      "Val: 0.9633 MAE: 0.7486 RMSE: 0.9815\n",
      "Epoch 52 Step 17278: Train 0.3472 Reg: 0.4682\n",
      "Test: 1.0217 MAE: 0.7719 RMSE: 1.0108\n",
      "Val: 0.9667 MAE: 0.7498 RMSE: 0.9832\n",
      "Epoch 53 Step 17604: Train 0.3459 Reg: 0.4666\n",
      "Test: 1.0263 MAE: 0.7731 RMSE: 1.0130\n",
      "Val: 0.9696 MAE: 0.7505 RMSE: 0.9847\n",
      "Epoch 54 Step 17930: Train 0.3446 Reg: 0.4650\n",
      "Test: 1.0303 MAE: 0.7735 RMSE: 1.0150\n",
      "Val: 0.9719 MAE: 0.7510 RMSE: 0.9859\n",
      "Epoch 55 Step 18256: Train 0.3434 Reg: 0.4635\n",
      "Test: 1.0333 MAE: 0.7748 RMSE: 1.0165\n",
      "Val: 0.9749 MAE: 0.7523 RMSE: 0.9873\n",
      "Epoch 56 Step 18582: Train 0.3423 Reg: 0.4619\n",
      "Test: 1.0359 MAE: 0.7758 RMSE: 1.0178\n",
      "Val: 0.9764 MAE: 0.7528 RMSE: 0.9881\n",
      "Epoch 57 Step 18908: Train 0.3412 Reg: 0.4605\n",
      "Test: 1.0407 MAE: 0.7761 RMSE: 1.0202\n",
      "Val: 0.9801 MAE: 0.7536 RMSE: 0.9900\n",
      "Epoch 58 Step 19234: Train 0.3401 Reg: 0.4591\n",
      "Test: 1.0448 MAE: 0.7779 RMSE: 1.0221\n",
      "Val: 0.9823 MAE: 0.7545 RMSE: 0.9911\n",
      "Epoch 59 Step 19560: Train 0.3392 Reg: 0.4578\n",
      "Test: 1.0458 MAE: 0.7784 RMSE: 1.0226\n",
      "Val: 0.9842 MAE: 0.7554 RMSE: 0.9921\n",
      "Epoch 60 Step 19886: Train 0.3383 Reg: 0.4565\n",
      "Test: 1.0482 MAE: 0.7787 RMSE: 1.0238\n",
      "Val: 0.9856 MAE: 0.7554 RMSE: 0.9928\n",
      "Epoch 61 Step 20212: Train 0.3374 Reg: 0.4553\n",
      "Test: 1.0515 MAE: 0.7801 RMSE: 1.0254\n",
      "Val: 0.9879 MAE: 0.7563 RMSE: 0.9939\n",
      "Epoch 62 Step 20538: Train 0.3365 Reg: 0.4540\n",
      "Test: 1.0552 MAE: 0.7809 RMSE: 1.0272\n",
      "Val: 0.9895 MAE: 0.7568 RMSE: 0.9948\n",
      "Epoch 63 Step 20864: Train 0.3358 Reg: 0.4529\n",
      "Test: 1.0570 MAE: 0.7816 RMSE: 1.0281\n",
      "Val: 0.9915 MAE: 0.7575 RMSE: 0.9957\n",
      "Epoch 64 Step 21190: Train 0.3350 Reg: 0.4519\n",
      "Test: 1.0592 MAE: 0.7823 RMSE: 1.0292\n",
      "Val: 0.9931 MAE: 0.7581 RMSE: 0.9966\n",
      "Epoch 65 Step 21516: Train 0.3343 Reg: 0.4508\n",
      "Test: 1.0618 MAE: 0.7832 RMSE: 1.0304\n",
      "Val: 0.9943 MAE: 0.7585 RMSE: 0.9971\n",
      "Epoch 66 Step 21842: Train 0.3336 Reg: 0.4498\n",
      "Test: 1.0636 MAE: 0.7845 RMSE: 1.0313\n",
      "Val: 0.9966 MAE: 0.7596 RMSE: 0.9983\n",
      "Epoch 67 Step 22168: Train 0.3330 Reg: 0.4489\n",
      "Test: 1.0658 MAE: 0.7839 RMSE: 1.0324\n",
      "Val: 0.9973 MAE: 0.7592 RMSE: 0.9986\n",
      "Epoch 68 Step 22494: Train 0.3324 Reg: 0.4480\n",
      "Test: 1.0666 MAE: 0.7843 RMSE: 1.0327\n",
      "Val: 0.9989 MAE: 0.7600 RMSE: 0.9994\n",
      "Epoch 69 Step 22820: Train 0.3318 Reg: 0.4471\n",
      "Test: 1.0697 MAE: 0.7861 RMSE: 1.0343\n",
      "Val: 1.0005 MAE: 0.7609 RMSE: 1.0003\n",
      "Epoch 70 Step 23146: Train 0.3312 Reg: 0.4463\n",
      "Test: 1.0699 MAE: 0.7852 RMSE: 1.0344\n",
      "Val: 1.0009 MAE: 0.7604 RMSE: 1.0004\n",
      "Epoch 71 Step 23472: Train 0.3307 Reg: 0.4455\n",
      "Test: 1.0724 MAE: 0.7859 RMSE: 1.0356\n",
      "Val: 1.0025 MAE: 0.7610 RMSE: 1.0012\n",
      "Epoch 72 Step 23798: Train 0.3302 Reg: 0.4447\n",
      "Test: 1.0742 MAE: 0.7865 RMSE: 1.0364\n",
      "Val: 1.0036 MAE: 0.7614 RMSE: 1.0018\n",
      "Epoch 73 Step 24124: Train 0.3298 Reg: 0.4440\n",
      "Test: 1.0752 MAE: 0.7868 RMSE: 1.0369\n",
      "Val: 1.0047 MAE: 0.7616 RMSE: 1.0024\n",
      "Epoch 74 Step 24450: Train 0.3293 Reg: 0.4433\n",
      "Test: 1.0761 MAE: 0.7867 RMSE: 1.0373\n",
      "Val: 1.0057 MAE: 0.7619 RMSE: 1.0028\n",
      "Epoch 75 Step 24776: Train 0.3289 Reg: 0.4427\n",
      "Test: 1.0780 MAE: 0.7880 RMSE: 1.0383\n",
      "Val: 1.0067 MAE: 0.7625 RMSE: 1.0034\n",
      "Epoch 76 Step 25102: Train 0.3285 Reg: 0.4421\n",
      "Test: 1.0793 MAE: 0.7876 RMSE: 1.0389\n",
      "Val: 1.0072 MAE: 0.7622 RMSE: 1.0036\n",
      "Epoch 77 Step 25428: Train 0.3281 Reg: 0.4414\n",
      "Test: 1.0806 MAE: 0.7890 RMSE: 1.0395\n",
      "Val: 1.0087 MAE: 0.7633 RMSE: 1.0044\n",
      "Epoch 78 Step 25754: Train 0.3277 Reg: 0.4409\n",
      "Test: 1.0818 MAE: 0.7886 RMSE: 1.0401\n",
      "Val: 1.0093 MAE: 0.7630 RMSE: 1.0047\n",
      "Epoch 79 Step 26080: Train 0.3274 Reg: 0.4403\n",
      "Test: 1.0825 MAE: 0.7888 RMSE: 1.0404\n",
      "Val: 1.0101 MAE: 0.7633 RMSE: 1.0050\n",
      "Epoch 80 Step 26406: Train 0.3270 Reg: 0.4398\n",
      "Test: 1.0835 MAE: 0.7892 RMSE: 1.0409\n",
      "Val: 1.0106 MAE: 0.7635 RMSE: 1.0053\n",
      "Epoch 81 Step 26732: Train 0.3267 Reg: 0.4393\n",
      "Test: 1.0849 MAE: 0.7897 RMSE: 1.0416\n",
      "Val: 1.0114 MAE: 0.7638 RMSE: 1.0057\n",
      "Epoch 82 Step 27058: Train 0.3264 Reg: 0.4389\n",
      "Test: 1.0858 MAE: 0.7903 RMSE: 1.0420\n",
      "Val: 1.0120 MAE: 0.7642 RMSE: 1.0060\n",
      "Epoch 83 Step 27384: Train 0.3261 Reg: 0.4384\n",
      "Test: 1.0865 MAE: 0.7906 RMSE: 1.0424\n",
      "Val: 1.0129 MAE: 0.7645 RMSE: 1.0064\n",
      "Epoch 84 Step 27710: Train 0.3259 Reg: 0.4380\n",
      "Test: 1.0874 MAE: 0.7907 RMSE: 1.0428\n",
      "Val: 1.0134 MAE: 0.7647 RMSE: 1.0067\n",
      "Epoch 85 Step 28036: Train 0.3256 Reg: 0.4376\n",
      "Test: 1.0878 MAE: 0.7905 RMSE: 1.0430\n",
      "Val: 1.0137 MAE: 0.7646 RMSE: 1.0068\n",
      "Epoch 86 Step 28362: Train 0.3253 Reg: 0.4372\n",
      "Test: 1.0886 MAE: 0.7909 RMSE: 1.0434\n",
      "Val: 1.0145 MAE: 0.7649 RMSE: 1.0072\n",
      "Epoch 87 Step 28688: Train 0.3251 Reg: 0.4368\n",
      "Test: 1.0891 MAE: 0.7911 RMSE: 1.0436\n",
      "Val: 1.0149 MAE: 0.7650 RMSE: 1.0074\n",
      "Epoch 88 Step 29014: Train 0.3249 Reg: 0.4365\n",
      "Test: 1.0899 MAE: 0.7914 RMSE: 1.0440\n",
      "Val: 1.0154 MAE: 0.7652 RMSE: 1.0076\n",
      "Epoch 89 Step 29340: Train 0.3247 Reg: 0.4361\n",
      "Test: 1.0908 MAE: 0.7918 RMSE: 1.0444\n",
      "Val: 1.0161 MAE: 0.7656 RMSE: 1.0080\n",
      "Epoch 90 Step 29666: Train 0.3245 Reg: 0.4358\n",
      "Test: 1.0914 MAE: 0.7918 RMSE: 1.0447\n",
      "Val: 1.0164 MAE: 0.7656 RMSE: 1.0081\n",
      "Epoch 91 Step 29992: Train 0.3243 Reg: 0.4355\n",
      "Test: 1.0917 MAE: 0.7917 RMSE: 1.0448\n",
      "Val: 1.0167 MAE: 0.7656 RMSE: 1.0083\n",
      "Epoch 92 Step 30318: Train 0.3241 Reg: 0.4352\n",
      "Test: 1.0922 MAE: 0.7917 RMSE: 1.0451\n",
      "Val: 1.0171 MAE: 0.7656 RMSE: 1.0085\n",
      "Epoch 93 Step 30644: Train 0.3239 Reg: 0.4349\n",
      "Test: 1.0928 MAE: 0.7920 RMSE: 1.0454\n",
      "Val: 1.0174 MAE: 0.7658 RMSE: 1.0087\n",
      "Epoch 94 Step 30970: Train 0.3238 Reg: 0.4347\n",
      "Test: 1.0935 MAE: 0.7923 RMSE: 1.0457\n",
      "Val: 1.0179 MAE: 0.7660 RMSE: 1.0089\n",
      "Epoch 95 Step 31296: Train 0.3236 Reg: 0.4344\n",
      "Test: 1.0938 MAE: 0.7921 RMSE: 1.0459\n",
      "Val: 1.0181 MAE: 0.7659 RMSE: 1.0090\n",
      "Epoch 96 Step 31622: Train 0.3235 Reg: 0.4342\n",
      "Test: 1.0941 MAE: 0.7921 RMSE: 1.0460\n",
      "Val: 1.0184 MAE: 0.7659 RMSE: 1.0091\n",
      "Epoch 97 Step 31948: Train 0.3234 Reg: 0.4340\n",
      "Test: 1.0946 MAE: 0.7925 RMSE: 1.0462\n",
      "Val: 1.0188 MAE: 0.7662 RMSE: 1.0093\n",
      "Epoch 98 Step 32274: Train 0.3232 Reg: 0.4338\n",
      "Test: 1.0949 MAE: 0.7926 RMSE: 1.0464\n",
      "Val: 1.0191 MAE: 0.7664 RMSE: 1.0095\n",
      "Epoch 99 Step 32600: Train 0.3231 Reg: 0.4336\n",
      "Test: 1.0954 MAE: 0.7929 RMSE: 1.0466\n",
      "Val: 1.0195 MAE: 0.7666 RMSE: 1.0097\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 350454/19100\n",
      "test set size: support/query 1046/809\n",
      "Epoch 0: TrainLoss 1.1397 RecLoss: 0.0000 (left: 0:08:35)\n",
      "TestLoss: 1.0780 MAE: 0.8056 RMSE: 1.0383\n",
      "ValLoss: 1.1385 MAE: 0.8391 RMSE: 1.0670\n",
      "Epoch 1: TrainLoss 1.0048 RecLoss: 0.0000 (left: 0:08:15)\n",
      "TestLoss: 1.0285 MAE: 0.8056 RMSE: 1.0141\n",
      "ValLoss: 1.0701 MAE: 0.8327 RMSE: 1.0344\n",
      "Epoch 2: TrainLoss 0.9693 RecLoss: 0.0000 (left: 0:08:23)\n",
      "TestLoss: 1.0158 MAE: 0.8051 RMSE: 1.0079\n",
      "ValLoss: 1.0528 MAE: 0.8283 RMSE: 1.0261\n",
      "Epoch 3: TrainLoss 0.9541 RecLoss: 0.0000 (left: 0:08:48)\n",
      "TestLoss: 1.0216 MAE: 0.8156 RMSE: 1.0108\n",
      "ValLoss: 1.0534 MAE: 0.8346 RMSE: 1.0264\n",
      "Epoch 4: TrainLoss 0.9341 RecLoss: 0.0000 (left: 0:08:55)\n",
      "TestLoss: 0.9953 MAE: 0.7925 RMSE: 0.9976\n",
      "ValLoss: 1.0336 MAE: 0.8167 RMSE: 1.0167\n",
      "Epoch 5: TrainLoss 0.9220 RecLoss: 0.0000 (left: 0:08:44)\n",
      "TestLoss: 0.9949 MAE: 0.7872 RMSE: 0.9975\n",
      "ValLoss: 1.0341 MAE: 0.8113 RMSE: 1.0169\n",
      "Epoch 6: TrainLoss 0.9141 RecLoss: 0.0000 (left: 0:08:41)\n",
      "TestLoss: 0.9935 MAE: 0.7860 RMSE: 0.9967\n",
      "ValLoss: 1.0338 MAE: 0.8124 RMSE: 1.0167\n",
      "Epoch 7: TrainLoss 0.9099 RecLoss: 0.0000 (left: 0:08:33)\n",
      "TestLoss: 0.9869 MAE: 0.7875 RMSE: 0.9935\n",
      "ValLoss: 1.0262 MAE: 0.8115 RMSE: 1.0130\n",
      "Epoch 8: TrainLoss 0.9068 RecLoss: 0.0000 (left: 0:08:35)\n",
      "TestLoss: 0.9974 MAE: 0.7992 RMSE: 0.9987\n",
      "ValLoss: 1.0289 MAE: 0.8182 RMSE: 1.0144\n",
      "Epoch 9: TrainLoss 0.9046 RecLoss: 0.0000 (left: 0:08:33)\n",
      "TestLoss: 0.9878 MAE: 0.7862 RMSE: 0.9939\n",
      "ValLoss: 1.0269 MAE: 0.8091 RMSE: 1.0134\n",
      "Epoch 10: TrainLoss 0.8978 RecLoss: 0.0000 (left: 0:08:30)\n",
      "TestLoss: 0.9909 MAE: 0.7890 RMSE: 0.9955\n",
      "ValLoss: 1.0326 MAE: 0.8153 RMSE: 1.0162\n",
      "Epoch 11: TrainLoss 0.8952 RecLoss: 0.0000 (left: 0:08:30)\n",
      "TestLoss: 0.9875 MAE: 0.7827 RMSE: 0.9937\n",
      "ValLoss: 1.0293 MAE: 0.8082 RMSE: 1.0145\n",
      "Epoch 12: TrainLoss 0.8952 RecLoss: 0.0000 (left: 0:08:23)\n",
      "TestLoss: 0.9941 MAE: 0.7828 RMSE: 0.9971\n",
      "ValLoss: 1.0394 MAE: 0.8098 RMSE: 1.0195\n",
      "Epoch 13: TrainLoss 0.8936 RecLoss: 0.0000 (left: 0:08:14)\n",
      "TestLoss: 0.9908 MAE: 0.7893 RMSE: 0.9954\n",
      "ValLoss: 1.0315 MAE: 0.8132 RMSE: 1.0156\n",
      "Epoch 14: TrainLoss 0.8954 RecLoss: 0.0000 (left: 0:08:05)\n",
      "TestLoss: 1.0091 MAE: 0.8083 RMSE: 1.0046\n",
      "ValLoss: 1.0418 MAE: 0.8264 RMSE: 1.0207\n",
      "Epoch 15: TrainLoss 0.8957 RecLoss: 0.0000 (left: 0:08:01)\n",
      "TestLoss: 0.9923 MAE: 0.7836 RMSE: 0.9962\n",
      "ValLoss: 1.0398 MAE: 0.8106 RMSE: 1.0197\n",
      "Epoch 16: TrainLoss 0.8915 RecLoss: 0.0000 (left: 0:07:57)\n",
      "TestLoss: 0.9933 MAE: 0.7909 RMSE: 0.9967\n",
      "ValLoss: 1.0355 MAE: 0.8156 RMSE: 1.0176\n",
      "Epoch 17: TrainLoss 0.8916 RecLoss: 0.0000 (left: 0:07:55)\n",
      "TestLoss: 0.9944 MAE: 0.7819 RMSE: 0.9972\n",
      "ValLoss: 1.0452 MAE: 0.8102 RMSE: 1.0223\n",
      "Epoch 18: TrainLoss 0.8923 RecLoss: 0.0000 (left: 0:07:50)\n",
      "TestLoss: 1.0032 MAE: 0.8021 RMSE: 1.0016\n",
      "ValLoss: 1.0449 MAE: 0.8245 RMSE: 1.0222\n",
      "Epoch 19: TrainLoss 0.8958 RecLoss: 0.0000 (left: 0:07:42)\n",
      "TestLoss: 0.9928 MAE: 0.7846 RMSE: 0.9964\n",
      "ValLoss: 1.0386 MAE: 0.8109 RMSE: 1.0191\n",
      "Epoch 20: TrainLoss 0.8909 RecLoss: 0.0000 (left: 0:07:37)\n",
      "TestLoss: 0.9919 MAE: 0.7875 RMSE: 0.9959\n",
      "ValLoss: 1.0403 MAE: 0.8144 RMSE: 1.0200\n",
      "Epoch 21: TrainLoss 0.8910 RecLoss: 0.0000 (left: 0:07:30)\n",
      "TestLoss: 0.9979 MAE: 0.7801 RMSE: 0.9989\n",
      "ValLoss: 1.0497 MAE: 0.8086 RMSE: 1.0246\n",
      "Epoch 22: TrainLoss 0.8921 RecLoss: 0.0000 (left: 0:07:22)\n",
      "TestLoss: 0.9954 MAE: 0.7914 RMSE: 0.9977\n",
      "ValLoss: 1.0393 MAE: 0.8151 RMSE: 1.0195\n",
      "Epoch 23: TrainLoss 0.8914 RecLoss: 0.0000 (left: 0:07:16)\n",
      "TestLoss: 1.0156 MAE: 0.8099 RMSE: 1.0078\n",
      "ValLoss: 1.0564 MAE: 0.8309 RMSE: 1.0278\n",
      "Epoch 24: TrainLoss 0.8983 RecLoss: 0.0000 (left: 0:07:10)\n",
      "TestLoss: 0.9934 MAE: 0.7893 RMSE: 0.9967\n",
      "ValLoss: 1.0420 MAE: 0.8153 RMSE: 1.0208\n",
      "Epoch 25: TrainLoss 0.8892 RecLoss: 0.0000 (left: 0:07:02)\n",
      "TestLoss: 0.9927 MAE: 0.7838 RMSE: 0.9964\n",
      "ValLoss: 1.0436 MAE: 0.8112 RMSE: 1.0216\n",
      "Epoch 26: TrainLoss 0.8893 RecLoss: 0.0000 (left: 0:06:53)\n",
      "TestLoss: 1.0025 MAE: 0.7794 RMSE: 1.0012\n",
      "ValLoss: 1.0550 MAE: 0.8090 RMSE: 1.0271\n",
      "Epoch 27: TrainLoss 0.8921 RecLoss: 0.0000 (left: 0:06:46)\n",
      "TestLoss: 0.9935 MAE: 0.7849 RMSE: 0.9967\n",
      "ValLoss: 1.0476 MAE: 0.8134 RMSE: 1.0235\n",
      "Epoch 28: TrainLoss 0.8904 RecLoss: 0.0000 (left: 0:06:39)\n",
      "TestLoss: 0.9985 MAE: 0.7936 RMSE: 0.9993\n",
      "ValLoss: 1.0465 MAE: 0.8189 RMSE: 1.0230\n",
      "Epoch 29: TrainLoss 0.8914 RecLoss: 0.0000 (left: 0:06:31)\n",
      "TestLoss: 0.9939 MAE: 0.7860 RMSE: 0.9969\n",
      "ValLoss: 1.0464 MAE: 0.8137 RMSE: 1.0229\n",
      "Epoch 30: TrainLoss 0.8903 RecLoss: 0.0000 (left: 0:06:21)\n",
      "TestLoss: 1.0085 MAE: 0.7780 RMSE: 1.0043\n",
      "ValLoss: 1.0698 MAE: 0.8101 RMSE: 1.0343\n",
      "Epoch 31: TrainLoss 0.8938 RecLoss: 0.0000 (left: 0:06:15)\n",
      "TestLoss: 0.9952 MAE: 0.7844 RMSE: 0.9976\n",
      "ValLoss: 1.0492 MAE: 0.8126 RMSE: 1.0243\n",
      "Epoch 32: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:06:11)\n",
      "TestLoss: 0.9942 MAE: 0.7843 RMSE: 0.9971\n",
      "ValLoss: 1.0476 MAE: 0.8121 RMSE: 1.0235\n",
      "Epoch 33: TrainLoss 0.8899 RecLoss: 0.0000 (left: 0:06:05)\n",
      "TestLoss: 0.9949 MAE: 0.7861 RMSE: 0.9975\n",
      "ValLoss: 1.0482 MAE: 0.8140 RMSE: 1.0238\n",
      "Epoch 34: TrainLoss 0.8882 RecLoss: 0.0000 (left: 0:06:02)\n",
      "TestLoss: 1.0019 MAE: 0.7787 RMSE: 1.0009\n",
      "ValLoss: 1.0601 MAE: 0.8099 RMSE: 1.0296\n",
      "Epoch 35: TrainLoss 0.8911 RecLoss: 0.0000 (left: 0:05:57)\n",
      "TestLoss: 1.0006 MAE: 0.7967 RMSE: 1.0003\n",
      "ValLoss: 1.0490 MAE: 0.8212 RMSE: 1.0242\n",
      "Epoch 36: TrainLoss 0.8893 RecLoss: 0.0000 (left: 0:05:53)\n",
      "TestLoss: 0.9955 MAE: 0.7869 RMSE: 0.9977\n",
      "ValLoss: 1.0465 MAE: 0.8132 RMSE: 1.0230\n",
      "Epoch 37: TrainLoss 0.8886 RecLoss: 0.0000 (left: 0:05:49)\n",
      "TestLoss: 0.9963 MAE: 0.7908 RMSE: 0.9981\n",
      "ValLoss: 1.0487 MAE: 0.8179 RMSE: 1.0241\n",
      "Epoch 38: TrainLoss 0.8895 RecLoss: 0.0000 (left: 0:05:43)\n",
      "TestLoss: 0.9975 MAE: 0.7914 RMSE: 0.9988\n",
      "ValLoss: 1.0483 MAE: 0.8179 RMSE: 1.0238\n",
      "Epoch 39: TrainLoss 0.8897 RecLoss: 0.0000 (left: 0:05:37)\n",
      "TestLoss: 0.9996 MAE: 0.7801 RMSE: 0.9998\n",
      "ValLoss: 1.0604 MAE: 0.8112 RMSE: 1.0298\n",
      "Epoch 40: TrainLoss 0.8913 RecLoss: 0.0000 (left: 0:05:30)\n",
      "TestLoss: 1.0039 MAE: 0.7803 RMSE: 1.0019\n",
      "ValLoss: 1.0643 MAE: 0.8115 RMSE: 1.0316\n",
      "Epoch 41: TrainLoss 0.8900 RecLoss: 0.0000 (left: 0:05:25)\n",
      "TestLoss: 0.9946 MAE: 0.7870 RMSE: 0.9973\n",
      "ValLoss: 1.0485 MAE: 0.8139 RMSE: 1.0240\n",
      "Epoch 42: TrainLoss 0.8900 RecLoss: 0.0000 (left: 0:05:20)\n",
      "TestLoss: 0.9994 MAE: 0.7931 RMSE: 0.9997\n",
      "ValLoss: 1.0490 MAE: 0.8186 RMSE: 1.0242\n",
      "Epoch 43: TrainLoss 0.8900 RecLoss: 0.0000 (left: 0:05:15)\n",
      "TestLoss: 0.9954 MAE: 0.7834 RMSE: 0.9977\n",
      "ValLoss: 1.0511 MAE: 0.8119 RMSE: 1.0252\n",
      "Epoch 44: TrainLoss 0.8876 RecLoss: 0.0000 (left: 0:05:10)\n",
      "TestLoss: 0.9948 MAE: 0.7860 RMSE: 0.9974\n",
      "ValLoss: 1.0517 MAE: 0.8150 RMSE: 1.0255\n",
      "Epoch 45: TrainLoss 0.8872 RecLoss: 0.0000 (left: 0:05:05)\n",
      "TestLoss: 0.9948 MAE: 0.7864 RMSE: 0.9974\n",
      "ValLoss: 1.0496 MAE: 0.8140 RMSE: 1.0245\n",
      "Epoch 46: TrainLoss 0.8867 RecLoss: 0.0000 (left: 0:04:59)\n",
      "TestLoss: 0.9956 MAE: 0.7849 RMSE: 0.9978\n",
      "ValLoss: 1.0505 MAE: 0.8125 RMSE: 1.0250\n",
      "Epoch 47: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:04:55)\n",
      "TestLoss: 0.9968 MAE: 0.7823 RMSE: 0.9984\n",
      "ValLoss: 1.0534 MAE: 0.8115 RMSE: 1.0264\n",
      "Epoch 48: TrainLoss 0.8892 RecLoss: 0.0000 (left: 0:04:49)\n",
      "TestLoss: 0.9969 MAE: 0.7818 RMSE: 0.9984\n",
      "ValLoss: 1.0565 MAE: 0.8124 RMSE: 1.0279\n",
      "Epoch 49: TrainLoss 0.8887 RecLoss: 0.0000 (left: 0:04:44)\n",
      "TestLoss: 0.9971 MAE: 0.7826 RMSE: 0.9985\n",
      "ValLoss: 1.0534 MAE: 0.8115 RMSE: 1.0264\n",
      "Epoch 50: TrainLoss 0.8885 RecLoss: 0.0000 (left: 0:04:37)\n",
      "TestLoss: 0.9978 MAE: 0.7827 RMSE: 0.9989\n",
      "ValLoss: 1.0558 MAE: 0.8123 RMSE: 1.0275\n",
      "Epoch 51: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:04:31)\n",
      "TestLoss: 0.9957 MAE: 0.7879 RMSE: 0.9979\n",
      "ValLoss: 1.0510 MAE: 0.8161 RMSE: 1.0252\n",
      "Epoch 52: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:04:25)\n",
      "TestLoss: 0.9972 MAE: 0.7910 RMSE: 0.9986\n",
      "ValLoss: 1.0512 MAE: 0.8179 RMSE: 1.0253\n",
      "Epoch 53: TrainLoss 0.8901 RecLoss: 0.0000 (left: 0:04:19)\n",
      "TestLoss: 0.9971 MAE: 0.7894 RMSE: 0.9985\n",
      "ValLoss: 1.0496 MAE: 0.8162 RMSE: 1.0245\n",
      "Epoch 54: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:04:13)\n",
      "TestLoss: 0.9961 MAE: 0.7835 RMSE: 0.9981\n",
      "ValLoss: 1.0535 MAE: 0.8122 RMSE: 1.0264\n",
      "Epoch 55: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:04:07)\n",
      "TestLoss: 0.9962 MAE: 0.7873 RMSE: 0.9981\n",
      "ValLoss: 1.0500 MAE: 0.8153 RMSE: 1.0247\n",
      "Epoch 56: TrainLoss 0.8871 RecLoss: 0.0000 (left: 0:04:02)\n",
      "TestLoss: 0.9949 MAE: 0.7870 RMSE: 0.9975\n",
      "ValLoss: 1.0518 MAE: 0.8152 RMSE: 1.0256\n",
      "Epoch 57: TrainLoss 0.8885 RecLoss: 0.0000 (left: 0:03:57)\n",
      "TestLoss: 0.9995 MAE: 0.7807 RMSE: 0.9998\n",
      "ValLoss: 1.0573 MAE: 0.8108 RMSE: 1.0283\n",
      "Epoch 58: TrainLoss 0.8872 RecLoss: 0.0000 (left: 0:03:52)\n",
      "TestLoss: 0.9956 MAE: 0.7868 RMSE: 0.9978\n",
      "ValLoss: 1.0503 MAE: 0.8139 RMSE: 1.0248\n",
      "Epoch 59: TrainLoss 0.8865 RecLoss: 0.0000 (left: 0:03:47)\n",
      "TestLoss: 0.9949 MAE: 0.7861 RMSE: 0.9975\n",
      "ValLoss: 1.0507 MAE: 0.8140 RMSE: 1.0251\n",
      "Epoch 60: TrainLoss 0.8870 RecLoss: 0.0000 (left: 0:03:41)\n",
      "TestLoss: 0.9961 MAE: 0.7823 RMSE: 0.9980\n",
      "ValLoss: 1.0535 MAE: 0.8110 RMSE: 1.0264\n",
      "Epoch 61: TrainLoss 0.8883 RecLoss: 0.0000 (left: 0:03:36)\n",
      "TestLoss: 0.9947 MAE: 0.7871 RMSE: 0.9973\n",
      "ValLoss: 1.0506 MAE: 0.8153 RMSE: 1.0250\n",
      "Epoch 62: TrainLoss 0.8867 RecLoss: 0.0000 (left: 0:03:30)\n",
      "TestLoss: 0.9993 MAE: 0.7935 RMSE: 0.9997\n",
      "ValLoss: 1.0506 MAE: 0.8196 RMSE: 1.0250\n",
      "Epoch 63: TrainLoss 0.8901 RecLoss: 0.0000 (left: 0:03:25)\n",
      "TestLoss: 1.0010 MAE: 0.7952 RMSE: 1.0005\n",
      "ValLoss: 1.0525 MAE: 0.8213 RMSE: 1.0259\n",
      "Epoch 64: TrainLoss 0.8887 RecLoss: 0.0000 (left: 0:03:19)\n",
      "TestLoss: 0.9959 MAE: 0.7851 RMSE: 0.9979\n",
      "ValLoss: 1.0532 MAE: 0.8136 RMSE: 1.0262\n",
      "Epoch 65: TrainLoss 0.8869 RecLoss: 0.0000 (left: 0:03:13)\n",
      "TestLoss: 0.9978 MAE: 0.7820 RMSE: 0.9989\n",
      "ValLoss: 1.0572 MAE: 0.8119 RMSE: 1.0282\n",
      "Epoch 66: TrainLoss 0.8871 RecLoss: 0.0000 (left: 0:03:08)\n",
      "TestLoss: 0.9940 MAE: 0.7842 RMSE: 0.9970\n",
      "ValLoss: 1.0509 MAE: 0.8128 RMSE: 1.0251\n",
      "Epoch 67: TrainLoss 0.8868 RecLoss: 0.0000 (left: 0:03:02)\n",
      "TestLoss: 0.9961 MAE: 0.7827 RMSE: 0.9980\n",
      "ValLoss: 1.0542 MAE: 0.8119 RMSE: 1.0267\n",
      "Epoch 68: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:02:57)\n",
      "TestLoss: 0.9949 MAE: 0.7831 RMSE: 0.9974\n",
      "ValLoss: 1.0514 MAE: 0.8115 RMSE: 1.0254\n",
      "Epoch 69: TrainLoss 0.8905 RecLoss: 0.0000 (left: 0:02:51)\n",
      "TestLoss: 1.0012 MAE: 0.7800 RMSE: 1.0006\n",
      "ValLoss: 1.0630 MAE: 0.8119 RMSE: 1.0310\n",
      "Epoch 70: TrainLoss 0.8933 RecLoss: 0.0000 (left: 0:02:46)\n",
      "TestLoss: 1.0152 MAE: 0.7787 RMSE: 1.0076\n",
      "ValLoss: 1.0804 MAE: 0.8123 RMSE: 1.0394\n",
      "Epoch 71: TrainLoss 0.8898 RecLoss: 0.0000 (left: 0:02:40)\n",
      "TestLoss: 0.9951 MAE: 0.7844 RMSE: 0.9975\n",
      "ValLoss: 1.0529 MAE: 0.8129 RMSE: 1.0261\n",
      "Epoch 72: TrainLoss 0.8871 RecLoss: 0.0000 (left: 0:02:34)\n",
      "TestLoss: 0.9983 MAE: 0.7814 RMSE: 0.9991\n",
      "ValLoss: 1.0586 MAE: 0.8119 RMSE: 1.0289\n",
      "Epoch 73: TrainLoss 0.8871 RecLoss: 0.0000 (left: 0:02:29)\n",
      "TestLoss: 0.9956 MAE: 0.7858 RMSE: 0.9978\n",
      "ValLoss: 1.0509 MAE: 0.8138 RMSE: 1.0252\n",
      "Epoch 74: TrainLoss 0.8876 RecLoss: 0.0000 (left: 0:02:23)\n",
      "TestLoss: 0.9947 MAE: 0.7846 RMSE: 0.9973\n",
      "ValLoss: 1.0526 MAE: 0.8132 RMSE: 1.0260\n",
      "Epoch 75: TrainLoss 0.8869 RecLoss: 0.0000 (left: 0:02:18)\n",
      "TestLoss: 1.0029 MAE: 0.7797 RMSE: 1.0015\n",
      "ValLoss: 1.0632 MAE: 0.8108 RMSE: 1.0311\n",
      "Epoch 76: TrainLoss 0.8891 RecLoss: 0.0000 (left: 0:02:12)\n",
      "TestLoss: 0.9971 MAE: 0.7820 RMSE: 0.9985\n",
      "ValLoss: 1.0569 MAE: 0.8123 RMSE: 1.0280\n",
      "Epoch 77: TrainLoss 0.8873 RecLoss: 0.0000 (left: 0:02:07)\n",
      "TestLoss: 0.9979 MAE: 0.7822 RMSE: 0.9990\n",
      "ValLoss: 1.0562 MAE: 0.8110 RMSE: 1.0277\n",
      "Epoch 78: TrainLoss 0.8887 RecLoss: 0.0000 (left: 0:02:01)\n",
      "TestLoss: 1.0034 MAE: 0.7792 RMSE: 1.0017\n",
      "ValLoss: 1.0677 MAE: 0.8122 RMSE: 1.0333\n",
      "Epoch 79: TrainLoss 0.8874 RecLoss: 0.0000 (left: 0:01:56)\n",
      "TestLoss: 0.9963 MAE: 0.7885 RMSE: 0.9981\n",
      "ValLoss: 1.0506 MAE: 0.8157 RMSE: 1.0250\n",
      "Epoch 80: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:01:50)\n",
      "TestLoss: 0.9966 MAE: 0.7903 RMSE: 0.9983\n",
      "ValLoss: 1.0509 MAE: 0.8173 RMSE: 1.0251\n",
      "Epoch 81: TrainLoss 0.8865 RecLoss: 0.0000 (left: 0:01:45)\n",
      "TestLoss: 0.9933 MAE: 0.7859 RMSE: 0.9967\n",
      "ValLoss: 1.0513 MAE: 0.8146 RMSE: 1.0253\n",
      "Epoch 82: TrainLoss 0.8898 RecLoss: 0.0000 (left: 0:01:39)\n",
      "TestLoss: 1.0021 MAE: 0.7798 RMSE: 1.0010\n",
      "ValLoss: 1.0646 MAE: 0.8116 RMSE: 1.0318\n",
      "Epoch 83: TrainLoss 0.8932 RecLoss: 0.0000 (left: 0:01:34)\n",
      "TestLoss: 0.9979 MAE: 0.7823 RMSE: 0.9990\n",
      "ValLoss: 1.0581 MAE: 0.8119 RMSE: 1.0287\n",
      "Epoch 84: TrainLoss 0.8860 RecLoss: 0.0000 (left: 0:01:28)\n",
      "TestLoss: 0.9967 MAE: 0.7892 RMSE: 0.9983\n",
      "ValLoss: 1.0516 MAE: 0.8167 RMSE: 1.0255\n",
      "Epoch 85: TrainLoss 0.8882 RecLoss: 0.0000 (left: 0:01:22)\n",
      "TestLoss: 0.9949 MAE: 0.7836 RMSE: 0.9974\n",
      "ValLoss: 1.0541 MAE: 0.8132 RMSE: 1.0267\n",
      "Epoch 86: TrainLoss 0.8882 RecLoss: 0.0000 (left: 0:01:17)\n",
      "TestLoss: 0.9991 MAE: 0.7815 RMSE: 0.9996\n",
      "ValLoss: 1.0594 MAE: 0.8117 RMSE: 1.0293\n",
      "Epoch 87: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:01:11)\n",
      "TestLoss: 0.9952 MAE: 0.7845 RMSE: 0.9976\n",
      "ValLoss: 1.0534 MAE: 0.8134 RMSE: 1.0263\n",
      "Epoch 88: TrainLoss 0.8893 RecLoss: 0.0000 (left: 0:01:06)\n",
      "TestLoss: 0.9983 MAE: 0.7822 RMSE: 0.9991\n",
      "ValLoss: 1.0571 MAE: 0.8117 RMSE: 1.0282\n",
      "Epoch 89: TrainLoss 0.8874 RecLoss: 0.0000 (left: 0:01:00)\n",
      "TestLoss: 0.9960 MAE: 0.7836 RMSE: 0.9980\n",
      "ValLoss: 1.0546 MAE: 0.8128 RMSE: 1.0270\n",
      "Epoch 90: TrainLoss 0.8863 RecLoss: 0.0000 (left: 0:00:55)\n",
      "TestLoss: 0.9959 MAE: 0.7886 RMSE: 0.9980\n",
      "ValLoss: 1.0522 MAE: 0.8165 RMSE: 1.0258\n",
      "Epoch 91: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:00:49)\n",
      "TestLoss: 0.9950 MAE: 0.7843 RMSE: 0.9975\n",
      "ValLoss: 1.0531 MAE: 0.8131 RMSE: 1.0262\n",
      "Epoch 92: TrainLoss 0.8865 RecLoss: 0.0000 (left: 0:00:44)\n",
      "TestLoss: 0.9954 MAE: 0.7854 RMSE: 0.9977\n",
      "ValLoss: 1.0518 MAE: 0.8137 RMSE: 1.0256\n",
      "Epoch 93: TrainLoss 0.8867 RecLoss: 0.0000 (left: 0:00:38)\n",
      "TestLoss: 0.9993 MAE: 0.7933 RMSE: 0.9997\n",
      "ValLoss: 1.0520 MAE: 0.8197 RMSE: 1.0257\n",
      "Epoch 94: TrainLoss 0.8908 RecLoss: 0.0000 (left: 0:00:33)\n",
      "TestLoss: 0.9950 MAE: 0.7835 RMSE: 0.9975\n",
      "ValLoss: 1.0537 MAE: 0.8124 RMSE: 1.0265\n",
      "Epoch 95: TrainLoss 0.8892 RecLoss: 0.0000 (left: 0:00:27)\n",
      "TestLoss: 0.9963 MAE: 0.7834 RMSE: 0.9982\n",
      "ValLoss: 1.0556 MAE: 0.8131 RMSE: 1.0274\n",
      "Epoch 96: TrainLoss 0.8871 RecLoss: 0.0000 (left: 0:00:21)\n",
      "TestLoss: 1.0014 MAE: 0.7800 RMSE: 1.0007\n",
      "ValLoss: 1.0627 MAE: 0.8110 RMSE: 1.0309\n",
      "Epoch 97: TrainLoss 0.8877 RecLoss: 0.0000 (left: 0:00:16)\n",
      "TestLoss: 0.9954 MAE: 0.7848 RMSE: 0.9977\n",
      "ValLoss: 1.0533 MAE: 0.8138 RMSE: 1.0263\n",
      "Epoch 98: TrainLoss 0.8860 RecLoss: 0.0000 (left: 0:00:10)\n",
      "TestLoss: 0.9950 MAE: 0.7863 RMSE: 0.9975\n",
      "ValLoss: 1.0514 MAE: 0.8145 RMSE: 1.0254\n",
      "Epoch 99: TrainLoss 0.8861 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 0.9966 MAE: 0.7906 RMSE: 0.9983\n",
      "ValLoss: 1.0511 MAE: 0.8179 RMSE: 1.0253\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 350454/19100\n",
      "test set size: support/query 1046/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.6888 RMSE: 0.8683 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7875 RMSE: 0.9935 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7318 RMSE: 0.9250 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10% CUR coueusers to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 181085/19100\n",
      "test set size: support/query 523/809\n",
      "Epoch 0 Step 168: Train 3.6543 Reg: 0.5106\n",
      "Test: 0.9035 MAE: 0.7842 RMSE: 0.9506\n",
      "Val: 0.8944 MAE: 0.7500 RMSE: 0.9457\n",
      "Epoch 1 Step 336: Train 0.8412 Reg: 0.4776\n",
      "Test: 0.8339 MAE: 0.7370 RMSE: 0.9132\n",
      "Val: 0.8397 MAE: 0.7243 RMSE: 0.9164\n",
      "Epoch 2 Step 504: Train 0.8179 Reg: 0.4384\n",
      "Test: 0.8199 MAE: 0.7289 RMSE: 0.9055\n",
      "Val: 0.8333 MAE: 0.7230 RMSE: 0.9129\n",
      "Epoch 3 Step 672: Train 0.8120 Reg: 0.4062\n",
      "Test: 0.8104 MAE: 0.7268 RMSE: 0.9002\n",
      "Val: 0.8261 MAE: 0.7184 RMSE: 0.9089\n",
      "Epoch 4 Step 840: Train 0.8091 Reg: 0.3781\n",
      "Test: 0.8072 MAE: 0.7271 RMSE: 0.8984\n",
      "Val: 0.8276 MAE: 0.7198 RMSE: 0.9097\n",
      "Epoch 5 Step 1008: Train 0.8074 Reg: 0.3540\n",
      "Test: 0.8100 MAE: 0.7274 RMSE: 0.9000\n",
      "Val: 0.8269 MAE: 0.7192 RMSE: 0.9093\n",
      "Epoch 6 Step 1176: Train 0.8061 Reg: 0.3343\n",
      "Test: 0.8202 MAE: 0.7295 RMSE: 0.9056\n",
      "Val: 0.8256 MAE: 0.7187 RMSE: 0.9086\n",
      "Epoch 7 Step 1344: Train 0.8031 Reg: 0.3189\n",
      "Test: 0.8000 MAE: 0.7192 RMSE: 0.8944\n",
      "Val: 0.8210 MAE: 0.7166 RMSE: 0.9061\n",
      "Epoch 8 Step 1512: Train 0.8013 Reg: 0.3045\n",
      "Test: 0.7944 MAE: 0.7219 RMSE: 0.8913\n",
      "Val: 0.8188 MAE: 0.7171 RMSE: 0.9049\n",
      "Epoch 9 Step 1680: Train 0.7987 Reg: 0.2928\n",
      "Test: 0.7965 MAE: 0.7161 RMSE: 0.8925\n",
      "Val: 0.8161 MAE: 0.7141 RMSE: 0.9034\n",
      "Epoch 10 Step 1848: Train 0.7956 Reg: 0.2837\n",
      "Test: 0.7936 MAE: 0.7153 RMSE: 0.8909\n",
      "Val: 0.8121 MAE: 0.7118 RMSE: 0.9012\n",
      "Epoch 11 Step 2016: Train 0.7923 Reg: 0.2751\n",
      "Test: 0.7988 MAE: 0.7208 RMSE: 0.8938\n",
      "Val: 0.8092 MAE: 0.7124 RMSE: 0.8996\n",
      "Epoch 12 Step 2184: Train 0.7878 Reg: 0.2696\n",
      "Test: 0.7967 MAE: 0.7133 RMSE: 0.8926\n",
      "Val: 0.8086 MAE: 0.7098 RMSE: 0.8992\n",
      "Epoch 13 Step 2352: Train 0.7824 Reg: 0.2650\n",
      "Test: 0.7837 MAE: 0.7096 RMSE: 0.8853\n",
      "Val: 0.8020 MAE: 0.7076 RMSE: 0.8955\n",
      "Epoch 14 Step 2520: Train 0.7762 Reg: 0.2621\n",
      "Test: 0.7859 MAE: 0.7085 RMSE: 0.8865\n",
      "Val: 0.7978 MAE: 0.7060 RMSE: 0.8932\n",
      "Epoch 15 Step 2688: Train 0.7700 Reg: 0.2591\n",
      "Test: 0.7764 MAE: 0.7054 RMSE: 0.8811\n",
      "Val: 0.7943 MAE: 0.7035 RMSE: 0.8912\n",
      "Epoch 16 Step 2856: Train 0.7642 Reg: 0.2569\n",
      "Test: 0.7814 MAE: 0.7070 RMSE: 0.8840\n",
      "Val: 0.7933 MAE: 0.7031 RMSE: 0.8907\n",
      "Epoch 17 Step 3024: Train 0.7589 Reg: 0.2543\n",
      "Test: 0.7700 MAE: 0.7043 RMSE: 0.8775\n",
      "Val: 0.7904 MAE: 0.7028 RMSE: 0.8891\n",
      "Epoch 18 Step 3192: Train 0.7551 Reg: 0.2510\n",
      "Test: 0.7682 MAE: 0.7009 RMSE: 0.8765\n",
      "Val: 0.7889 MAE: 0.7018 RMSE: 0.8882\n",
      "Epoch 19 Step 3360: Train 0.7514 Reg: 0.2478\n",
      "Test: 0.7714 MAE: 0.6991 RMSE: 0.8783\n",
      "Val: 0.7880 MAE: 0.7008 RMSE: 0.8877\n",
      "Epoch 20 Step 3528: Train 0.7478 Reg: 0.2446\n",
      "Test: 0.7700 MAE: 0.7008 RMSE: 0.8775\n",
      "Val: 0.7889 MAE: 0.7018 RMSE: 0.8882\n",
      "Epoch 21 Step 3696: Train 0.7447 Reg: 0.2417\n",
      "Test: 0.7550 MAE: 0.6931 RMSE: 0.8689\n",
      "Val: 0.7857 MAE: 0.6990 RMSE: 0.8864\n",
      "Epoch 22 Step 3864: Train 0.7416 Reg: 0.2388\n",
      "Test: 0.7602 MAE: 0.6940 RMSE: 0.8719\n",
      "Val: 0.7860 MAE: 0.6999 RMSE: 0.8865\n",
      "Epoch 23 Step 4032: Train 0.7393 Reg: 0.2363\n",
      "Test: 0.7651 MAE: 0.6969 RMSE: 0.8747\n",
      "Val: 0.7860 MAE: 0.7001 RMSE: 0.8866\n",
      "Epoch 24 Step 4200: Train 0.7362 Reg: 0.2339\n",
      "Test: 0.7611 MAE: 0.6965 RMSE: 0.8724\n",
      "Val: 0.7857 MAE: 0.6987 RMSE: 0.8864\n",
      "Epoch 25 Step 4368: Train 0.7330 Reg: 0.2322\n",
      "Test: 0.7573 MAE: 0.6929 RMSE: 0.8702\n",
      "Val: 0.7834 MAE: 0.6974 RMSE: 0.8851\n",
      "Epoch 26 Step 4536: Train 0.7302 Reg: 0.2303\n",
      "Test: 0.7564 MAE: 0.6932 RMSE: 0.8697\n",
      "Val: 0.7826 MAE: 0.6975 RMSE: 0.8847\n",
      "Epoch 27 Step 4704: Train 0.7271 Reg: 0.2290\n",
      "Test: 0.7609 MAE: 0.6936 RMSE: 0.8723\n",
      "Val: 0.7806 MAE: 0.6971 RMSE: 0.8835\n",
      "Epoch 28 Step 4872: Train 0.7240 Reg: 0.2281\n",
      "Test: 0.7591 MAE: 0.6932 RMSE: 0.8713\n",
      "Val: 0.7803 MAE: 0.6972 RMSE: 0.8833\n",
      "Epoch 29 Step 5040: Train 0.7207 Reg: 0.2277\n",
      "Test: 0.7583 MAE: 0.6918 RMSE: 0.8708\n",
      "Val: 0.7800 MAE: 0.6949 RMSE: 0.8832\n",
      "Epoch 30 Step 5208: Train 0.7173 Reg: 0.2275\n",
      "Test: 0.7582 MAE: 0.6917 RMSE: 0.8707\n",
      "Val: 0.7781 MAE: 0.6952 RMSE: 0.8821\n",
      "Epoch 31 Step 5376: Train 0.7135 Reg: 0.2279\n",
      "Test: 0.7560 MAE: 0.6891 RMSE: 0.8695\n",
      "Val: 0.7774 MAE: 0.6936 RMSE: 0.8817\n",
      "Epoch 32 Step 5544: Train 0.7094 Reg: 0.2287\n",
      "Test: 0.7504 MAE: 0.6873 RMSE: 0.8662\n",
      "Val: 0.7756 MAE: 0.6930 RMSE: 0.8807\n",
      "Epoch 33 Step 5712: Train 0.7046 Reg: 0.2305\n",
      "Test: 0.7484 MAE: 0.6861 RMSE: 0.8651\n",
      "Val: 0.7755 MAE: 0.6927 RMSE: 0.8806\n",
      "Epoch 34 Step 5880: Train 0.6992 Reg: 0.2327\n",
      "Test: 0.7460 MAE: 0.6849 RMSE: 0.8637\n",
      "Val: 0.7725 MAE: 0.6910 RMSE: 0.8789\n",
      "Epoch 35 Step 6048: Train 0.6933 Reg: 0.2357\n",
      "Test: 0.7481 MAE: 0.6873 RMSE: 0.8649\n",
      "Val: 0.7711 MAE: 0.6908 RMSE: 0.8781\n",
      "Epoch 36 Step 6216: Train 0.6863 Reg: 0.2392\n",
      "Test: 0.7442 MAE: 0.6841 RMSE: 0.8627\n",
      "Val: 0.7692 MAE: 0.6895 RMSE: 0.8771\n",
      "Epoch 37 Step 6384: Train 0.6789 Reg: 0.2432\n",
      "Test: 0.7405 MAE: 0.6827 RMSE: 0.8605\n",
      "Val: 0.7667 MAE: 0.6885 RMSE: 0.8756\n",
      "Epoch 38 Step 6552: Train 0.6713 Reg: 0.2473\n",
      "Test: 0.7399 MAE: 0.6835 RMSE: 0.8602\n",
      "Val: 0.7644 MAE: 0.6886 RMSE: 0.8743\n",
      "Epoch 39 Step 6720: Train 0.6634 Reg: 0.2515\n",
      "Test: 0.7389 MAE: 0.6820 RMSE: 0.8596\n",
      "Val: 0.7633 MAE: 0.6876 RMSE: 0.8736\n",
      "Epoch 40 Step 6888: Train 0.6558 Reg: 0.2554\n",
      "Test: 0.7352 MAE: 0.6787 RMSE: 0.8574\n",
      "Val: 0.7628 MAE: 0.6867 RMSE: 0.8734\n",
      "Epoch 41 Step 7056: Train 0.6482 Reg: 0.2593\n",
      "Test: 0.7331 MAE: 0.6763 RMSE: 0.8562\n",
      "Val: 0.7617 MAE: 0.6867 RMSE: 0.8727\n",
      "Epoch 42 Step 7224: Train 0.6405 Reg: 0.2630\n",
      "Test: 0.7327 MAE: 0.6769 RMSE: 0.8560\n",
      "Val: 0.7623 MAE: 0.6868 RMSE: 0.8731\n",
      "Epoch 43 Step 7392: Train 0.6330 Reg: 0.2667\n",
      "Test: 0.7336 MAE: 0.6791 RMSE: 0.8565\n",
      "Val: 0.7620 MAE: 0.6870 RMSE: 0.8729\n",
      "Epoch 44 Step 7560: Train 0.6255 Reg: 0.2703\n",
      "Test: 0.7318 MAE: 0.6775 RMSE: 0.8555\n",
      "Val: 0.7630 MAE: 0.6873 RMSE: 0.8735\n",
      "Epoch 45 Step 7728: Train 0.6178 Reg: 0.2740\n",
      "Test: 0.7334 MAE: 0.6789 RMSE: 0.8564\n",
      "Val: 0.7637 MAE: 0.6880 RMSE: 0.8739\n",
      "Epoch 46 Step 7896: Train 0.6100 Reg: 0.2776\n",
      "Test: 0.7362 MAE: 0.6802 RMSE: 0.8580\n",
      "Val: 0.7643 MAE: 0.6888 RMSE: 0.8743\n",
      "Epoch 47 Step 8064: Train 0.6021 Reg: 0.2811\n",
      "Test: 0.7335 MAE: 0.6767 RMSE: 0.8564\n",
      "Val: 0.7659 MAE: 0.6885 RMSE: 0.8751\n",
      "Epoch 48 Step 8232: Train 0.5941 Reg: 0.2849\n",
      "Test: 0.7354 MAE: 0.6780 RMSE: 0.8575\n",
      "Val: 0.7677 MAE: 0.6893 RMSE: 0.8762\n",
      "Epoch 49 Step 8400: Train 0.5859 Reg: 0.2885\n",
      "Test: 0.7365 MAE: 0.6782 RMSE: 0.8582\n",
      "Val: 0.7696 MAE: 0.6901 RMSE: 0.8773\n",
      "Epoch 50 Step 8568: Train 0.5778 Reg: 0.2921\n",
      "Test: 0.7372 MAE: 0.6797 RMSE: 0.8586\n",
      "Val: 0.7717 MAE: 0.6914 RMSE: 0.8784\n",
      "Epoch 51 Step 8736: Train 0.5696 Reg: 0.2957\n",
      "Test: 0.7382 MAE: 0.6786 RMSE: 0.8592\n",
      "Val: 0.7744 MAE: 0.6921 RMSE: 0.8800\n",
      "Epoch 52 Step 8904: Train 0.5617 Reg: 0.2991\n",
      "Test: 0.7383 MAE: 0.6772 RMSE: 0.8592\n",
      "Val: 0.7768 MAE: 0.6926 RMSE: 0.8814\n",
      "Epoch 53 Step 9072: Train 0.5537 Reg: 0.3025\n",
      "Test: 0.7398 MAE: 0.6782 RMSE: 0.8601\n",
      "Val: 0.7799 MAE: 0.6936 RMSE: 0.8831\n",
      "Epoch 54 Step 9240: Train 0.5461 Reg: 0.3056\n",
      "Test: 0.7413 MAE: 0.6795 RMSE: 0.8610\n",
      "Val: 0.7827 MAE: 0.6950 RMSE: 0.8847\n",
      "Epoch 55 Step 9408: Train 0.5387 Reg: 0.3087\n",
      "Test: 0.7423 MAE: 0.6794 RMSE: 0.8616\n",
      "Val: 0.7856 MAE: 0.6961 RMSE: 0.8864\n",
      "Epoch 56 Step 9576: Train 0.5315 Reg: 0.3115\n",
      "Test: 0.7457 MAE: 0.6819 RMSE: 0.8636\n",
      "Val: 0.7887 MAE: 0.6976 RMSE: 0.8881\n",
      "Epoch 57 Step 9744: Train 0.5246 Reg: 0.3142\n",
      "Test: 0.7456 MAE: 0.6807 RMSE: 0.8635\n",
      "Val: 0.7916 MAE: 0.6985 RMSE: 0.8897\n",
      "Epoch 58 Step 9912: Train 0.5179 Reg: 0.3167\n",
      "Test: 0.7478 MAE: 0.6829 RMSE: 0.8648\n",
      "Val: 0.7944 MAE: 0.7002 RMSE: 0.8913\n",
      "Epoch 59 Step 10080: Train 0.5116 Reg: 0.3190\n",
      "Test: 0.7497 MAE: 0.6826 RMSE: 0.8658\n",
      "Val: 0.7981 MAE: 0.7011 RMSE: 0.8934\n",
      "Epoch 60 Step 10248: Train 0.5056 Reg: 0.3212\n",
      "Test: 0.7502 MAE: 0.6831 RMSE: 0.8661\n",
      "Val: 0.8009 MAE: 0.7023 RMSE: 0.8949\n",
      "Epoch 61 Step 10416: Train 0.4999 Reg: 0.3232\n",
      "Test: 0.7524 MAE: 0.6842 RMSE: 0.8674\n",
      "Val: 0.8036 MAE: 0.7034 RMSE: 0.8964\n",
      "Epoch 62 Step 10584: Train 0.4945 Reg: 0.3251\n",
      "Test: 0.7544 MAE: 0.6851 RMSE: 0.8685\n",
      "Val: 0.8068 MAE: 0.7046 RMSE: 0.8982\n",
      "Epoch 63 Step 10752: Train 0.4894 Reg: 0.3268\n",
      "Test: 0.7556 MAE: 0.6850 RMSE: 0.8692\n",
      "Val: 0.8092 MAE: 0.7053 RMSE: 0.8996\n",
      "Epoch 64 Step 10920: Train 0.4845 Reg: 0.3284\n",
      "Test: 0.7577 MAE: 0.6861 RMSE: 0.8705\n",
      "Val: 0.8121 MAE: 0.7066 RMSE: 0.9012\n",
      "Epoch 65 Step 11088: Train 0.4799 Reg: 0.3299\n",
      "Test: 0.7595 MAE: 0.6859 RMSE: 0.8715\n",
      "Val: 0.8144 MAE: 0.7073 RMSE: 0.9024\n",
      "Epoch 66 Step 11256: Train 0.4756 Reg: 0.3313\n",
      "Test: 0.7613 MAE: 0.6866 RMSE: 0.8725\n",
      "Val: 0.8170 MAE: 0.7082 RMSE: 0.9039\n",
      "Epoch 67 Step 11424: Train 0.4715 Reg: 0.3325\n",
      "Test: 0.7625 MAE: 0.6873 RMSE: 0.8732\n",
      "Val: 0.8195 MAE: 0.7093 RMSE: 0.9053\n",
      "Epoch 68 Step 11592: Train 0.4676 Reg: 0.3337\n",
      "Test: 0.7648 MAE: 0.6892 RMSE: 0.8745\n",
      "Val: 0.8215 MAE: 0.7105 RMSE: 0.9064\n",
      "Epoch 69 Step 11760: Train 0.4640 Reg: 0.3348\n",
      "Test: 0.7660 MAE: 0.6883 RMSE: 0.8752\n",
      "Val: 0.8237 MAE: 0.7108 RMSE: 0.9076\n",
      "Epoch 70 Step 11928: Train 0.4605 Reg: 0.3358\n",
      "Test: 0.7678 MAE: 0.6886 RMSE: 0.8762\n",
      "Val: 0.8257 MAE: 0.7115 RMSE: 0.9087\n",
      "Epoch 71 Step 12096: Train 0.4572 Reg: 0.3368\n",
      "Test: 0.7694 MAE: 0.6886 RMSE: 0.8772\n",
      "Val: 0.8279 MAE: 0.7121 RMSE: 0.9099\n",
      "Epoch 72 Step 12264: Train 0.4542 Reg: 0.3377\n",
      "Test: 0.7705 MAE: 0.6891 RMSE: 0.8778\n",
      "Val: 0.8297 MAE: 0.7130 RMSE: 0.9109\n",
      "Epoch 73 Step 12432: Train 0.4513 Reg: 0.3385\n",
      "Test: 0.7719 MAE: 0.6897 RMSE: 0.8786\n",
      "Val: 0.8315 MAE: 0.7138 RMSE: 0.9119\n",
      "Epoch 74 Step 12600: Train 0.4485 Reg: 0.3392\n",
      "Test: 0.7733 MAE: 0.6901 RMSE: 0.8794\n",
      "Val: 0.8332 MAE: 0.7145 RMSE: 0.9128\n",
      "Epoch 75 Step 12768: Train 0.4459 Reg: 0.3399\n",
      "Test: 0.7749 MAE: 0.6905 RMSE: 0.8803\n",
      "Val: 0.8351 MAE: 0.7151 RMSE: 0.9138\n",
      "Epoch 76 Step 12936: Train 0.4435 Reg: 0.3406\n",
      "Test: 0.7758 MAE: 0.6903 RMSE: 0.8808\n",
      "Val: 0.8366 MAE: 0.7156 RMSE: 0.9147\n",
      "Epoch 77 Step 13104: Train 0.4411 Reg: 0.3412\n",
      "Test: 0.7770 MAE: 0.6910 RMSE: 0.8815\n",
      "Val: 0.8381 MAE: 0.7163 RMSE: 0.9155\n",
      "Epoch 78 Step 13272: Train 0.4389 Reg: 0.3418\n",
      "Test: 0.7783 MAE: 0.6920 RMSE: 0.8822\n",
      "Val: 0.8395 MAE: 0.7170 RMSE: 0.9162\n",
      "Epoch 79 Step 13440: Train 0.4369 Reg: 0.3423\n",
      "Test: 0.7791 MAE: 0.6922 RMSE: 0.8827\n",
      "Val: 0.8408 MAE: 0.7176 RMSE: 0.9169\n",
      "Epoch 80 Step 13608: Train 0.4349 Reg: 0.3428\n",
      "Test: 0.7803 MAE: 0.6926 RMSE: 0.8834\n",
      "Val: 0.8420 MAE: 0.7181 RMSE: 0.9176\n",
      "Epoch 81 Step 13776: Train 0.4330 Reg: 0.3432\n",
      "Test: 0.7817 MAE: 0.6925 RMSE: 0.8841\n",
      "Val: 0.8433 MAE: 0.7184 RMSE: 0.9183\n",
      "Epoch 82 Step 13944: Train 0.4313 Reg: 0.3437\n",
      "Test: 0.7823 MAE: 0.6928 RMSE: 0.8845\n",
      "Val: 0.8444 MAE: 0.7189 RMSE: 0.9189\n",
      "Epoch 83 Step 14112: Train 0.4296 Reg: 0.3441\n",
      "Test: 0.7831 MAE: 0.6935 RMSE: 0.8849\n",
      "Val: 0.8455 MAE: 0.7195 RMSE: 0.9195\n",
      "Epoch 84 Step 14280: Train 0.4281 Reg: 0.3445\n",
      "Test: 0.7843 MAE: 0.6935 RMSE: 0.8856\n",
      "Val: 0.8467 MAE: 0.7198 RMSE: 0.9201\n",
      "Epoch 85 Step 14448: Train 0.4266 Reg: 0.3448\n",
      "Test: 0.7851 MAE: 0.6938 RMSE: 0.8860\n",
      "Val: 0.8477 MAE: 0.7203 RMSE: 0.9207\n",
      "Epoch 86 Step 14616: Train 0.4252 Reg: 0.3451\n",
      "Test: 0.7860 MAE: 0.6936 RMSE: 0.8866\n",
      "Val: 0.8487 MAE: 0.7206 RMSE: 0.9213\n",
      "Epoch 87 Step 14784: Train 0.4239 Reg: 0.3454\n",
      "Test: 0.7867 MAE: 0.6943 RMSE: 0.8870\n",
      "Val: 0.8496 MAE: 0.7210 RMSE: 0.9217\n",
      "Epoch 88 Step 14952: Train 0.4226 Reg: 0.3457\n",
      "Test: 0.7872 MAE: 0.6941 RMSE: 0.8872\n",
      "Val: 0.8505 MAE: 0.7213 RMSE: 0.9222\n",
      "Epoch 89 Step 15120: Train 0.4214 Reg: 0.3460\n",
      "Test: 0.7881 MAE: 0.6947 RMSE: 0.8877\n",
      "Val: 0.8513 MAE: 0.7217 RMSE: 0.9227\n",
      "Epoch 90 Step 15288: Train 0.4203 Reg: 0.3463\n",
      "Test: 0.7888 MAE: 0.6951 RMSE: 0.8881\n",
      "Val: 0.8520 MAE: 0.7221 RMSE: 0.9231\n",
      "Epoch 91 Step 15456: Train 0.4192 Reg: 0.3465\n",
      "Test: 0.7896 MAE: 0.6951 RMSE: 0.8886\n",
      "Val: 0.8528 MAE: 0.7223 RMSE: 0.9235\n",
      "Epoch 92 Step 15624: Train 0.4182 Reg: 0.3467\n",
      "Test: 0.7901 MAE: 0.6951 RMSE: 0.8889\n",
      "Val: 0.8536 MAE: 0.7225 RMSE: 0.9239\n",
      "Epoch 93 Step 15792: Train 0.4173 Reg: 0.3469\n",
      "Test: 0.7908 MAE: 0.6950 RMSE: 0.8893\n",
      "Val: 0.8543 MAE: 0.7227 RMSE: 0.9243\n",
      "Epoch 94 Step 15960: Train 0.4163 Reg: 0.3471\n",
      "Test: 0.7915 MAE: 0.6950 RMSE: 0.8897\n",
      "Val: 0.8550 MAE: 0.7229 RMSE: 0.9247\n",
      "Epoch 95 Step 16128: Train 0.4155 Reg: 0.3473\n",
      "Test: 0.7920 MAE: 0.6955 RMSE: 0.8899\n",
      "Val: 0.8556 MAE: 0.7233 RMSE: 0.9250\n",
      "Epoch 96 Step 16296: Train 0.4147 Reg: 0.3475\n",
      "Test: 0.7924 MAE: 0.6961 RMSE: 0.8902\n",
      "Val: 0.8562 MAE: 0.7237 RMSE: 0.9253\n",
      "Epoch 97 Step 16464: Train 0.4139 Reg: 0.3477\n",
      "Test: 0.7929 MAE: 0.6959 RMSE: 0.8905\n",
      "Val: 0.8568 MAE: 0.7238 RMSE: 0.9256\n",
      "Epoch 98 Step 16632: Train 0.4132 Reg: 0.3478\n",
      "Test: 0.7934 MAE: 0.6960 RMSE: 0.8907\n",
      "Val: 0.8573 MAE: 0.7240 RMSE: 0.9259\n",
      "Epoch 99 Step 16800: Train 0.4125 Reg: 0.3480\n",
      "Test: 0.7940 MAE: 0.6962 RMSE: 0.8911\n",
      "Val: 0.8578 MAE: 0.7242 RMSE: 0.9262\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 181085/19100\n",
      "test set size: support/query 523/809\n",
      "Epoch 0: TrainLoss 1.1273 RecLoss: 0.0000 (left: 0:09:13)\n",
      "TestLoss: 1.0638 MAE: 0.8091 RMSE: 1.0314\n",
      "ValLoss: 1.1340 MAE: 0.8431 RMSE: 1.0649\n",
      "Epoch 1: TrainLoss 1.0037 RecLoss: 0.0000 (left: 0:08:51)\n",
      "TestLoss: 1.0320 MAE: 0.8053 RMSE: 1.0159\n",
      "ValLoss: 1.0861 MAE: 0.8292 RMSE: 1.0422\n",
      "Epoch 2: TrainLoss 0.9710 RecLoss: 0.0000 (left: 0:08:46)\n",
      "TestLoss: 1.0200 MAE: 0.8107 RMSE: 1.0099\n",
      "ValLoss: 1.0623 MAE: 0.8277 RMSE: 1.0307\n",
      "Epoch 3: TrainLoss 0.9551 RecLoss: 0.0000 (left: 0:08:43)\n",
      "TestLoss: 1.0275 MAE: 0.8230 RMSE: 1.0137\n",
      "ValLoss: 1.0612 MAE: 0.8348 RMSE: 1.0301\n",
      "Epoch 4: TrainLoss 0.9358 RecLoss: 0.0000 (left: 0:08:22)\n",
      "TestLoss: 1.0030 MAE: 0.7998 RMSE: 1.0015\n",
      "ValLoss: 1.0447 MAE: 0.8185 RMSE: 1.0221\n",
      "Epoch 5: TrainLoss 0.9240 RecLoss: 0.0000 (left: 0:08:07)\n",
      "TestLoss: 0.9994 MAE: 0.7950 RMSE: 0.9997\n",
      "ValLoss: 1.0496 MAE: 0.8155 RMSE: 1.0245\n",
      "Epoch 6: TrainLoss 0.9161 RecLoss: 0.0000 (left: 0:07:48)\n",
      "TestLoss: 0.9978 MAE: 0.7923 RMSE: 0.9989\n",
      "ValLoss: 1.0435 MAE: 0.8128 RMSE: 1.0215\n",
      "Epoch 7: TrainLoss 0.9108 RecLoss: 0.0000 (left: 0:07:45)\n",
      "TestLoss: 0.9947 MAE: 0.7928 RMSE: 0.9973\n",
      "ValLoss: 1.0405 MAE: 0.8138 RMSE: 1.0200\n",
      "Epoch 8: TrainLoss 0.9090 RecLoss: 0.0000 (left: 0:07:35)\n",
      "TestLoss: 1.0003 MAE: 0.8018 RMSE: 1.0002\n",
      "ValLoss: 1.0397 MAE: 0.8179 RMSE: 1.0197\n",
      "Epoch 9: TrainLoss 0.9055 RecLoss: 0.0000 (left: 0:07:31)\n",
      "TestLoss: 0.9993 MAE: 0.7977 RMSE: 0.9996\n",
      "ValLoss: 1.0399 MAE: 0.8155 RMSE: 1.0198\n",
      "Epoch 10: TrainLoss 0.8998 RecLoss: 0.0000 (left: 0:07:16)\n",
      "TestLoss: 0.9979 MAE: 0.7979 RMSE: 0.9990\n",
      "ValLoss: 1.0390 MAE: 0.8162 RMSE: 1.0193\n",
      "Epoch 11: TrainLoss 0.8972 RecLoss: 0.0000 (left: 0:07:14)\n",
      "TestLoss: 0.9966 MAE: 0.7895 RMSE: 0.9983\n",
      "ValLoss: 1.0440 MAE: 0.8101 RMSE: 1.0218\n",
      "Epoch 12: TrainLoss 0.8969 RecLoss: 0.0000 (left: 0:07:08)\n",
      "TestLoss: 0.9988 MAE: 0.7896 RMSE: 0.9994\n",
      "ValLoss: 1.0501 MAE: 0.8119 RMSE: 1.0248\n",
      "Epoch 13: TrainLoss 0.8958 RecLoss: 0.0000 (left: 0:06:56)\n",
      "TestLoss: 0.9994 MAE: 0.7929 RMSE: 0.9997\n",
      "ValLoss: 1.0436 MAE: 0.8120 RMSE: 1.0216\n",
      "Epoch 14: TrainLoss 0.8977 RecLoss: 0.0000 (left: 0:06:43)\n",
      "TestLoss: 1.0266 MAE: 0.8220 RMSE: 1.0132\n",
      "ValLoss: 1.0578 MAE: 0.8343 RMSE: 1.0285\n",
      "Epoch 15: TrainLoss 0.8994 RecLoss: 0.0000 (left: 0:06:31)\n",
      "TestLoss: 1.0005 MAE: 0.7959 RMSE: 1.0003\n",
      "ValLoss: 1.0480 MAE: 0.8158 RMSE: 1.0237\n",
      "Epoch 16: TrainLoss 0.8929 RecLoss: 0.0000 (left: 0:06:23)\n",
      "TestLoss: 1.0015 MAE: 0.7965 RMSE: 1.0007\n",
      "ValLoss: 1.0474 MAE: 0.8165 RMSE: 1.0234\n",
      "Epoch 17: TrainLoss 0.8936 RecLoss: 0.0000 (left: 0:06:15)\n",
      "TestLoss: 1.0018 MAE: 0.7899 RMSE: 1.0009\n",
      "ValLoss: 1.0575 MAE: 0.8135 RMSE: 1.0283\n",
      "Epoch 18: TrainLoss 0.8948 RecLoss: 0.0000 (left: 0:06:07)\n",
      "TestLoss: 1.0072 MAE: 0.8039 RMSE: 1.0036\n",
      "ValLoss: 1.0531 MAE: 0.8235 RMSE: 1.0262\n",
      "Epoch 19: TrainLoss 0.8963 RecLoss: 0.0000 (left: 0:05:59)\n",
      "TestLoss: 1.0030 MAE: 0.7948 RMSE: 1.0015\n",
      "ValLoss: 1.0493 MAE: 0.8145 RMSE: 1.0244\n",
      "Epoch 20: TrainLoss 0.8936 RecLoss: 0.0000 (left: 0:05:57)\n",
      "TestLoss: 1.0042 MAE: 0.7993 RMSE: 1.0021\n",
      "ValLoss: 1.0503 MAE: 0.8193 RMSE: 1.0248\n",
      "Epoch 21: TrainLoss 0.8935 RecLoss: 0.0000 (left: 0:05:53)\n",
      "TestLoss: 1.0053 MAE: 0.7867 RMSE: 1.0026\n",
      "ValLoss: 1.0636 MAE: 0.8104 RMSE: 1.0313\n",
      "Epoch 22: TrainLoss 0.8939 RecLoss: 0.0000 (left: 0:05:50)\n",
      "TestLoss: 1.0048 MAE: 0.7977 RMSE: 1.0024\n",
      "ValLoss: 1.0518 MAE: 0.8164 RMSE: 1.0256\n",
      "Epoch 23: TrainLoss 0.8934 RecLoss: 0.0000 (left: 0:05:47)\n",
      "TestLoss: 1.0258 MAE: 0.8181 RMSE: 1.0128\n",
      "ValLoss: 1.0643 MAE: 0.8338 RMSE: 1.0316\n",
      "Epoch 24: TrainLoss 0.8991 RecLoss: 0.0000 (left: 0:05:46)\n",
      "TestLoss: 1.0086 MAE: 0.8030 RMSE: 1.0043\n",
      "ValLoss: 1.0540 MAE: 0.8216 RMSE: 1.0267\n",
      "Epoch 25: TrainLoss 0.8910 RecLoss: 0.0000 (left: 0:05:45)\n",
      "TestLoss: 1.0020 MAE: 0.7932 RMSE: 1.0010\n",
      "ValLoss: 1.0542 MAE: 0.8150 RMSE: 1.0267\n",
      "Epoch 26: TrainLoss 0.8913 RecLoss: 0.0000 (left: 0:05:39)\n",
      "TestLoss: 1.0081 MAE: 0.7858 RMSE: 1.0041\n",
      "ValLoss: 1.0692 MAE: 0.8100 RMSE: 1.0340\n",
      "Epoch 27: TrainLoss 0.8941 RecLoss: 0.0000 (left: 0:05:34)\n",
      "TestLoss: 1.0040 MAE: 0.7918 RMSE: 1.0020\n",
      "ValLoss: 1.0610 MAE: 0.8153 RMSE: 1.0300\n",
      "Epoch 28: TrainLoss 0.8922 RecLoss: 0.0000 (left: 0:05:29)\n",
      "TestLoss: 1.0082 MAE: 0.8006 RMSE: 1.0041\n",
      "ValLoss: 1.0562 MAE: 0.8201 RMSE: 1.0277\n",
      "Epoch 29: TrainLoss 0.8931 RecLoss: 0.0000 (left: 0:05:25)\n",
      "TestLoss: 1.0031 MAE: 0.7934 RMSE: 1.0016\n",
      "ValLoss: 1.0589 MAE: 0.8159 RMSE: 1.0290\n",
      "Epoch 30: TrainLoss 0.8920 RecLoss: 0.0000 (left: 0:05:21)\n",
      "TestLoss: 1.0135 MAE: 0.7837 RMSE: 1.0067\n",
      "ValLoss: 1.0804 MAE: 0.8113 RMSE: 1.0394\n",
      "Epoch 31: TrainLoss 0.8955 RecLoss: 0.0000 (left: 0:05:17)\n",
      "TestLoss: 1.0032 MAE: 0.7903 RMSE: 1.0016\n",
      "ValLoss: 1.0614 MAE: 0.8141 RMSE: 1.0303\n",
      "Epoch 32: TrainLoss 0.8897 RecLoss: 0.0000 (left: 0:05:12)\n",
      "TestLoss: 1.0036 MAE: 0.7922 RMSE: 1.0018\n",
      "ValLoss: 1.0588 MAE: 0.8141 RMSE: 1.0290\n",
      "Epoch 33: TrainLoss 0.8915 RecLoss: 0.0000 (left: 0:05:08)\n",
      "TestLoss: 1.0042 MAE: 0.7949 RMSE: 1.0021\n",
      "ValLoss: 1.0581 MAE: 0.8164 RMSE: 1.0287\n",
      "Epoch 34: TrainLoss 0.8903 RecLoss: 0.0000 (left: 0:05:02)\n",
      "TestLoss: 1.0071 MAE: 0.7864 RMSE: 1.0035\n",
      "ValLoss: 1.0693 MAE: 0.8113 RMSE: 1.0341\n",
      "Epoch 35: TrainLoss 0.8926 RecLoss: 0.0000 (left: 0:04:57)\n",
      "TestLoss: 1.0146 MAE: 0.8074 RMSE: 1.0073\n",
      "ValLoss: 1.0613 MAE: 0.8257 RMSE: 1.0302\n",
      "Epoch 36: TrainLoss 0.8919 RecLoss: 0.0000 (left: 0:04:52)\n",
      "TestLoss: 1.0044 MAE: 0.7933 RMSE: 1.0022\n",
      "ValLoss: 1.0569 MAE: 0.8141 RMSE: 1.0280\n",
      "Epoch 37: TrainLoss 0.8901 RecLoss: 0.0000 (left: 0:04:47)\n",
      "TestLoss: 1.0057 MAE: 0.7979 RMSE: 1.0028\n",
      "ValLoss: 1.0599 MAE: 0.8187 RMSE: 1.0295\n",
      "Epoch 38: TrainLoss 0.8913 RecLoss: 0.0000 (left: 0:04:45)\n",
      "TestLoss: 1.0070 MAE: 0.7986 RMSE: 1.0035\n",
      "ValLoss: 1.0587 MAE: 0.8188 RMSE: 1.0289\n",
      "Epoch 39: TrainLoss 0.8914 RecLoss: 0.0000 (left: 0:04:41)\n",
      "TestLoss: 1.0099 MAE: 0.7851 RMSE: 1.0049\n",
      "ValLoss: 1.0764 MAE: 0.8128 RMSE: 1.0375\n",
      "Epoch 40: TrainLoss 0.8948 RecLoss: 0.0000 (left: 0:04:35)\n",
      "TestLoss: 1.0095 MAE: 0.7870 RMSE: 1.0047\n",
      "ValLoss: 1.0743 MAE: 0.8129 RMSE: 1.0365\n",
      "Epoch 41: TrainLoss 0.8919 RecLoss: 0.0000 (left: 0:04:30)\n",
      "TestLoss: 1.0067 MAE: 0.7978 RMSE: 1.0033\n",
      "ValLoss: 1.0589 MAE: 0.8175 RMSE: 1.0290\n",
      "Epoch 42: TrainLoss 0.8928 RecLoss: 0.0000 (left: 0:04:25)\n",
      "TestLoss: 1.0093 MAE: 0.8023 RMSE: 1.0046\n",
      "ValLoss: 1.0596 MAE: 0.8217 RMSE: 1.0294\n",
      "Epoch 43: TrainLoss 0.8919 RecLoss: 0.0000 (left: 0:04:20)\n",
      "TestLoss: 1.0041 MAE: 0.7908 RMSE: 1.0020\n",
      "ValLoss: 1.0632 MAE: 0.8131 RMSE: 1.0311\n",
      "Epoch 44: TrainLoss 0.8893 RecLoss: 0.0000 (left: 0:04:17)\n",
      "TestLoss: 1.0046 MAE: 0.7955 RMSE: 1.0023\n",
      "ValLoss: 1.0603 MAE: 0.8176 RMSE: 1.0297\n",
      "Epoch 45: TrainLoss 0.8897 RecLoss: 0.0000 (left: 0:04:13)\n",
      "TestLoss: 1.0059 MAE: 0.7959 RMSE: 1.0030\n",
      "ValLoss: 1.0606 MAE: 0.8165 RMSE: 1.0298\n",
      "Epoch 46: TrainLoss 0.8892 RecLoss: 0.0000 (left: 0:04:10)\n",
      "TestLoss: 1.0053 MAE: 0.7931 RMSE: 1.0026\n",
      "ValLoss: 1.0617 MAE: 0.8151 RMSE: 1.0304\n",
      "Epoch 47: TrainLoss 0.8902 RecLoss: 0.0000 (left: 0:04:06)\n",
      "TestLoss: 1.0031 MAE: 0.7907 RMSE: 1.0015\n",
      "ValLoss: 1.0616 MAE: 0.8131 RMSE: 1.0303\n",
      "Epoch 48: TrainLoss 0.8911 RecLoss: 0.0000 (left: 0:04:03)\n",
      "TestLoss: 1.0048 MAE: 0.7908 RMSE: 1.0024\n",
      "ValLoss: 1.0629 MAE: 0.8135 RMSE: 1.0310\n",
      "Epoch 49: TrainLoss 0.8903 RecLoss: 0.0000 (left: 0:03:58)\n",
      "TestLoss: 1.0045 MAE: 0.7904 RMSE: 1.0023\n",
      "ValLoss: 1.0648 MAE: 0.8135 RMSE: 1.0319\n",
      "Epoch 50: TrainLoss 0.8906 RecLoss: 0.0000 (left: 0:03:54)\n",
      "TestLoss: 1.0049 MAE: 0.7897 RMSE: 1.0024\n",
      "ValLoss: 1.0663 MAE: 0.8136 RMSE: 1.0326\n",
      "Epoch 51: TrainLoss 0.8903 RecLoss: 0.0000 (left: 0:03:50)\n",
      "TestLoss: 1.0065 MAE: 0.7976 RMSE: 1.0032\n",
      "ValLoss: 1.0603 MAE: 0.8182 RMSE: 1.0297\n",
      "Epoch 52: TrainLoss 0.8902 RecLoss: 0.0000 (left: 0:03:45)\n",
      "TestLoss: 1.0102 MAE: 0.8027 RMSE: 1.0051\n",
      "ValLoss: 1.0617 MAE: 0.8219 RMSE: 1.0304\n",
      "Epoch 53: TrainLoss 0.8928 RecLoss: 0.0000 (left: 0:03:41)\n",
      "TestLoss: 1.0081 MAE: 0.7996 RMSE: 1.0041\n",
      "ValLoss: 1.0574 MAE: 0.8187 RMSE: 1.0283\n",
      "Epoch 54: TrainLoss 0.8902 RecLoss: 0.0000 (left: 0:03:36)\n",
      "TestLoss: 1.0048 MAE: 0.7921 RMSE: 1.0024\n",
      "ValLoss: 1.0628 MAE: 0.8140 RMSE: 1.0309\n",
      "Epoch 55: TrainLoss 0.8903 RecLoss: 0.0000 (left: 0:03:32)\n",
      "TestLoss: 1.0054 MAE: 0.7956 RMSE: 1.0027\n",
      "ValLoss: 1.0601 MAE: 0.8168 RMSE: 1.0296\n",
      "Epoch 56: TrainLoss 0.8898 RecLoss: 0.0000 (left: 0:03:28)\n",
      "TestLoss: 1.0045 MAE: 0.7935 RMSE: 1.0023\n",
      "ValLoss: 1.0622 MAE: 0.8161 RMSE: 1.0306\n",
      "Epoch 57: TrainLoss 0.8915 RecLoss: 0.0000 (left: 0:03:24)\n",
      "TestLoss: 1.0068 MAE: 0.7868 RMSE: 1.0034\n",
      "ValLoss: 1.0695 MAE: 0.8118 RMSE: 1.0341\n",
      "Epoch 58: TrainLoss 0.8891 RecLoss: 0.0000 (left: 0:03:20)\n",
      "TestLoss: 1.0046 MAE: 0.7940 RMSE: 1.0023\n",
      "ValLoss: 1.0613 MAE: 0.8154 RMSE: 1.0302\n",
      "Epoch 59: TrainLoss 0.8890 RecLoss: 0.0000 (left: 0:03:15)\n",
      "TestLoss: 1.0045 MAE: 0.7945 RMSE: 1.0023\n",
      "ValLoss: 1.0601 MAE: 0.8160 RMSE: 1.0296\n",
      "Epoch 60: TrainLoss 0.8889 RecLoss: 0.0000 (left: 0:03:10)\n",
      "TestLoss: 1.0047 MAE: 0.7916 RMSE: 1.0023\n",
      "ValLoss: 1.0617 MAE: 0.8133 RMSE: 1.0304\n",
      "Epoch 61: TrainLoss 0.8895 RecLoss: 0.0000 (left: 0:03:05)\n",
      "TestLoss: 1.0054 MAE: 0.7963 RMSE: 1.0027\n",
      "ValLoss: 1.0596 MAE: 0.8172 RMSE: 1.0294\n",
      "Epoch 62: TrainLoss 0.8892 RecLoss: 0.0000 (left: 0:03:00)\n",
      "TestLoss: 1.0132 MAE: 0.8057 RMSE: 1.0066\n",
      "ValLoss: 1.0601 MAE: 0.8236 RMSE: 1.0296\n",
      "Epoch 63: TrainLoss 0.8931 RecLoss: 0.0000 (left: 0:02:55)\n",
      "TestLoss: 1.0121 MAE: 0.8035 RMSE: 1.0060\n",
      "ValLoss: 1.0611 MAE: 0.8223 RMSE: 1.0301\n",
      "Epoch 64: TrainLoss 0.8908 RecLoss: 0.0000 (left: 0:02:50)\n",
      "TestLoss: 1.0042 MAE: 0.7922 RMSE: 1.0021\n",
      "ValLoss: 1.0631 MAE: 0.8150 RMSE: 1.0311\n",
      "Epoch 65: TrainLoss 0.8891 RecLoss: 0.0000 (left: 0:02:45)\n",
      "TestLoss: 1.0066 MAE: 0.7885 RMSE: 1.0033\n",
      "ValLoss: 1.0697 MAE: 0.8129 RMSE: 1.0343\n",
      "Epoch 66: TrainLoss 0.8891 RecLoss: 0.0000 (left: 0:02:41)\n",
      "TestLoss: 1.0037 MAE: 0.7905 RMSE: 1.0019\n",
      "ValLoss: 1.0615 MAE: 0.8129 RMSE: 1.0303\n",
      "Epoch 67: TrainLoss 0.8891 RecLoss: 0.0000 (left: 0:02:36)\n",
      "TestLoss: 1.0037 MAE: 0.7911 RMSE: 1.0018\n",
      "ValLoss: 1.0642 MAE: 0.8140 RMSE: 1.0316\n",
      "Epoch 68: TrainLoss 0.8902 RecLoss: 0.0000 (left: 0:02:31)\n",
      "TestLoss: 1.0046 MAE: 0.7888 RMSE: 1.0023\n",
      "ValLoss: 1.0632 MAE: 0.8117 RMSE: 1.0311\n",
      "Epoch 69: TrainLoss 0.8934 RecLoss: 0.0000 (left: 0:02:27)\n",
      "TestLoss: 1.0093 MAE: 0.7855 RMSE: 1.0046\n",
      "ValLoss: 1.0757 MAE: 0.8121 RMSE: 1.0371\n",
      "Epoch 70: TrainLoss 0.8966 RecLoss: 0.0000 (left: 0:02:23)\n",
      "TestLoss: 1.0215 MAE: 0.7838 RMSE: 1.0107\n",
      "ValLoss: 1.0957 MAE: 0.8145 RMSE: 1.0468\n",
      "Epoch 71: TrainLoss 0.8927 RecLoss: 0.0000 (left: 0:02:18)\n",
      "TestLoss: 1.0041 MAE: 0.7909 RMSE: 1.0020\n",
      "ValLoss: 1.0632 MAE: 0.8135 RMSE: 1.0311\n",
      "Epoch 72: TrainLoss 0.8897 RecLoss: 0.0000 (left: 0:02:13)\n",
      "TestLoss: 1.0054 MAE: 0.7890 RMSE: 1.0027\n",
      "ValLoss: 1.0676 MAE: 0.8132 RMSE: 1.0333\n",
      "Epoch 73: TrainLoss 0.8887 RecLoss: 0.0000 (left: 0:02:08)\n",
      "TestLoss: 1.0053 MAE: 0.7954 RMSE: 1.0026\n",
      "ValLoss: 1.0602 MAE: 0.8163 RMSE: 1.0297\n",
      "Epoch 74: TrainLoss 0.8890 RecLoss: 0.0000 (left: 0:02:04)\n",
      "TestLoss: 1.0042 MAE: 0.7933 RMSE: 1.0021\n",
      "ValLoss: 1.0618 MAE: 0.8155 RMSE: 1.0304\n",
      "Epoch 75: TrainLoss 0.8889 RecLoss: 0.0000 (left: 0:01:59)\n",
      "TestLoss: 1.0086 MAE: 0.7852 RMSE: 1.0043\n",
      "ValLoss: 1.0740 MAE: 0.8106 RMSE: 1.0363\n",
      "Epoch 76: TrainLoss 0.8913 RecLoss: 0.0000 (left: 0:01:54)\n",
      "TestLoss: 1.0044 MAE: 0.7897 RMSE: 1.0022\n",
      "ValLoss: 1.0662 MAE: 0.8139 RMSE: 1.0326\n",
      "Epoch 77: TrainLoss 0.8894 RecLoss: 0.0000 (left: 0:01:49)\n",
      "TestLoss: 1.0062 MAE: 0.7885 RMSE: 1.0031\n",
      "ValLoss: 1.0680 MAE: 0.8115 RMSE: 1.0334\n",
      "Epoch 78: TrainLoss 0.8905 RecLoss: 0.0000 (left: 0:01:44)\n",
      "TestLoss: 1.0095 MAE: 0.7855 RMSE: 1.0047\n",
      "ValLoss: 1.0773 MAE: 0.8123 RMSE: 1.0379\n",
      "Epoch 79: TrainLoss 0.8894 RecLoss: 0.0000 (left: 0:01:40)\n",
      "TestLoss: 1.0054 MAE: 0.7964 RMSE: 1.0027\n",
      "ValLoss: 1.0593 MAE: 0.8168 RMSE: 1.0292\n",
      "Epoch 80: TrainLoss 0.8897 RecLoss: 0.0000 (left: 0:01:35)\n",
      "TestLoss: 1.0060 MAE: 0.7981 RMSE: 1.0030\n",
      "ValLoss: 1.0606 MAE: 0.8180 RMSE: 1.0299\n",
      "Epoch 81: TrainLoss 0.8884 RecLoss: 0.0000 (left: 0:01:31)\n",
      "TestLoss: 1.0035 MAE: 0.7941 RMSE: 1.0017\n",
      "ValLoss: 1.0605 MAE: 0.8161 RMSE: 1.0298\n",
      "Epoch 82: TrainLoss 0.8918 RecLoss: 0.0000 (left: 0:01:26)\n",
      "TestLoss: 1.0066 MAE: 0.7867 RMSE: 1.0033\n",
      "ValLoss: 1.0711 MAE: 0.8118 RMSE: 1.0349\n",
      "Epoch 83: TrainLoss 0.8954 RecLoss: 0.0000 (left: 0:01:21)\n",
      "TestLoss: 1.0054 MAE: 0.7897 RMSE: 1.0027\n",
      "ValLoss: 1.0676 MAE: 0.8137 RMSE: 1.0333\n",
      "Epoch 84: TrainLoss 0.8884 RecLoss: 0.0000 (left: 0:01:16)\n",
      "TestLoss: 1.0069 MAE: 0.7982 RMSE: 1.0034\n",
      "ValLoss: 1.0599 MAE: 0.8180 RMSE: 1.0295\n",
      "Epoch 85: TrainLoss 0.8910 RecLoss: 0.0000 (left: 0:01:12)\n",
      "TestLoss: 1.0036 MAE: 0.7926 RMSE: 1.0018\n",
      "ValLoss: 1.0625 MAE: 0.8153 RMSE: 1.0308\n",
      "Epoch 86: TrainLoss 0.8907 RecLoss: 0.0000 (left: 0:01:07)\n",
      "TestLoss: 1.0060 MAE: 0.7885 RMSE: 1.0030\n",
      "ValLoss: 1.0698 MAE: 0.8136 RMSE: 1.0343\n",
      "Epoch 87: TrainLoss 0.8903 RecLoss: 0.0000 (left: 0:01:02)\n",
      "TestLoss: 1.0045 MAE: 0.7898 RMSE: 1.0023\n",
      "ValLoss: 1.0649 MAE: 0.8129 RMSE: 1.0320\n",
      "Epoch 88: TrainLoss 0.8915 RecLoss: 0.0000 (left: 0:00:57)\n",
      "TestLoss: 1.0057 MAE: 0.7900 RMSE: 1.0029\n",
      "ValLoss: 1.0671 MAE: 0.8132 RMSE: 1.0330\n",
      "Epoch 89: TrainLoss 0.8897 RecLoss: 0.0000 (left: 0:00:52)\n",
      "TestLoss: 1.0044 MAE: 0.7903 RMSE: 1.0022\n",
      "ValLoss: 1.0642 MAE: 0.8131 RMSE: 1.0316\n",
      "Epoch 90: TrainLoss 0.8894 RecLoss: 0.0000 (left: 0:00:47)\n",
      "TestLoss: 1.0046 MAE: 0.7952 RMSE: 1.0023\n",
      "ValLoss: 1.0622 MAE: 0.8167 RMSE: 1.0306\n",
      "Epoch 91: TrainLoss 0.8914 RecLoss: 0.0000 (left: 0:00:43)\n",
      "TestLoss: 1.0042 MAE: 0.7942 RMSE: 1.0021\n",
      "ValLoss: 1.0607 MAE: 0.8156 RMSE: 1.0299\n",
      "Epoch 92: TrainLoss 0.8884 RecLoss: 0.0000 (left: 0:00:38)\n",
      "TestLoss: 1.0039 MAE: 0.7934 RMSE: 1.0019\n",
      "ValLoss: 1.0607 MAE: 0.8149 RMSE: 1.0299\n",
      "Epoch 93: TrainLoss 0.8886 RecLoss: 0.0000 (left: 0:00:33)\n",
      "TestLoss: 1.0105 MAE: 0.8032 RMSE: 1.0052\n",
      "ValLoss: 1.0612 MAE: 0.8219 RMSE: 1.0302\n",
      "Epoch 94: TrainLoss 0.8929 RecLoss: 0.0000 (left: 0:00:28)\n",
      "TestLoss: 1.0034 MAE: 0.7917 RMSE: 1.0017\n",
      "ValLoss: 1.0626 MAE: 0.8139 RMSE: 1.0308\n",
      "Epoch 95: TrainLoss 0.8916 RecLoss: 0.0000 (left: 0:00:23)\n",
      "TestLoss: 1.0042 MAE: 0.7899 RMSE: 1.0021\n",
      "ValLoss: 1.0660 MAE: 0.8138 RMSE: 1.0325\n",
      "Epoch 96: TrainLoss 0.8892 RecLoss: 0.0000 (left: 0:00:19)\n",
      "TestLoss: 1.0085 MAE: 0.7864 RMSE: 1.0042\n",
      "ValLoss: 1.0727 MAE: 0.8110 RMSE: 1.0357\n",
      "Epoch 97: TrainLoss 0.8899 RecLoss: 0.0000 (left: 0:00:14)\n",
      "TestLoss: 1.0039 MAE: 0.7924 RMSE: 1.0019\n",
      "ValLoss: 1.0635 MAE: 0.8149 RMSE: 1.0313\n",
      "Epoch 98: TrainLoss 0.8878 RecLoss: 0.0000 (left: 0:00:09)\n",
      "TestLoss: 1.0042 MAE: 0.7946 RMSE: 1.0021\n",
      "ValLoss: 1.0594 MAE: 0.8155 RMSE: 1.0293\n",
      "Epoch 99: TrainLoss 0.8882 RecLoss: 0.0000 (left: 0:00:04)\n",
      "TestLoss: 1.0073 MAE: 0.7997 RMSE: 1.0036\n",
      "ValLoss: 1.0602 MAE: 0.8191 RMSE: 1.0297\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 181085/19100\n",
      "test set size: support/query 523/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.6763 RMSE: 0.8562 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7979 RMSE: 0.9990 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7502 RMSE: 0.9455 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 60% CUR core user as input to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 789731/19100\n",
      "test set size: support/query 3138/809\n",
      "Epoch 0 Step 733: Train 1.5780 Reg: 0.6163\n",
      "Test: 0.8974 MAE: 0.7530 RMSE: 0.9473\n",
      "Val: 0.8343 MAE: 0.7252 RMSE: 0.9134\n",
      "Epoch 1 Step 1466: Train 0.8332 Reg: 0.3995\n",
      "Test: 0.8914 MAE: 0.7469 RMSE: 0.9441\n",
      "Val: 0.8254 MAE: 0.7209 RMSE: 0.9085\n",
      "Epoch 2 Step 2199: Train 0.8279 Reg: 0.3445\n",
      "Test: 0.8778 MAE: 0.7447 RMSE: 0.9369\n",
      "Val: 0.8206 MAE: 0.7181 RMSE: 0.9059\n",
      "Epoch 3 Step 2932: Train 0.8215 Reg: 0.3114\n",
      "Test: 0.8715 MAE: 0.7424 RMSE: 0.9335\n",
      "Val: 0.8159 MAE: 0.7185 RMSE: 0.9033\n",
      "Epoch 4 Step 3665: Train 0.8108 Reg: 0.2929\n",
      "Test: 0.8789 MAE: 0.7421 RMSE: 0.9375\n",
      "Val: 0.8003 MAE: 0.7090 RMSE: 0.8946\n",
      "Epoch 5 Step 4398: Train 0.7949 Reg: 0.2933\n",
      "Test: 0.8668 MAE: 0.7350 RMSE: 0.9310\n",
      "Val: 0.7843 MAE: 0.6988 RMSE: 0.8856\n",
      "Epoch 6 Step 5131: Train 0.7749 Reg: 0.3176\n",
      "Test: 0.8413 MAE: 0.7182 RMSE: 0.9172\n",
      "Val: 0.7647 MAE: 0.6878 RMSE: 0.8745\n",
      "Epoch 7 Step 5864: Train 0.7495 Reg: 0.3756\n",
      "Test: 0.8167 MAE: 0.7118 RMSE: 0.9037\n",
      "Val: 0.7417 MAE: 0.6789 RMSE: 0.8612\n",
      "Epoch 8 Step 6597: Train 0.7273 Reg: 0.3985\n",
      "Test: 0.8128 MAE: 0.7154 RMSE: 0.9015\n",
      "Val: 0.7308 MAE: 0.6761 RMSE: 0.8549\n",
      "Epoch 9 Step 7330: Train 0.7095 Reg: 0.4230\n",
      "Test: 0.7916 MAE: 0.7043 RMSE: 0.8897\n",
      "Val: 0.7164 MAE: 0.6684 RMSE: 0.8464\n",
      "Epoch 10 Step 8063: Train 0.6886 Reg: 0.4599\n",
      "Test: 0.7692 MAE: 0.6854 RMSE: 0.8771\n",
      "Val: 0.7037 MAE: 0.6569 RMSE: 0.8388\n",
      "Epoch 11 Step 8796: Train 0.6688 Reg: 0.4880\n",
      "Test: 0.7651 MAE: 0.6906 RMSE: 0.8747\n",
      "Val: 0.6950 MAE: 0.6554 RMSE: 0.8337\n",
      "Epoch 12 Step 9529: Train 0.6524 Reg: 0.5143\n",
      "Test: 0.7631 MAE: 0.6862 RMSE: 0.8735\n",
      "Val: 0.6940 MAE: 0.6536 RMSE: 0.8330\n",
      "Epoch 13 Step 10262: Train 0.6372 Reg: 0.5348\n",
      "Test: 0.7552 MAE: 0.6854 RMSE: 0.8690\n",
      "Val: 0.6916 MAE: 0.6506 RMSE: 0.8316\n",
      "Epoch 14 Step 10995: Train 0.6230 Reg: 0.5510\n",
      "Test: 0.7569 MAE: 0.6843 RMSE: 0.8700\n",
      "Val: 0.6926 MAE: 0.6516 RMSE: 0.8323\n",
      "Epoch 15 Step 11728: Train 0.6099 Reg: 0.5629\n",
      "Test: 0.7563 MAE: 0.6821 RMSE: 0.8697\n",
      "Val: 0.6945 MAE: 0.6517 RMSE: 0.8334\n",
      "Epoch 16 Step 12461: Train 0.5988 Reg: 0.5710\n",
      "Test: 0.7612 MAE: 0.6856 RMSE: 0.8725\n",
      "Val: 0.6965 MAE: 0.6533 RMSE: 0.8346\n",
      "Epoch 17 Step 13194: Train 0.5894 Reg: 0.5761\n",
      "Test: 0.7614 MAE: 0.6876 RMSE: 0.8726\n",
      "Val: 0.7010 MAE: 0.6550 RMSE: 0.8373\n",
      "Epoch 18 Step 13927: Train 0.5800 Reg: 0.5836\n",
      "Test: 0.7656 MAE: 0.6854 RMSE: 0.8750\n",
      "Val: 0.7043 MAE: 0.6552 RMSE: 0.8392\n",
      "Epoch 19 Step 14660: Train 0.5698 Reg: 0.5904\n",
      "Test: 0.7713 MAE: 0.6856 RMSE: 0.8782\n",
      "Val: 0.7055 MAE: 0.6546 RMSE: 0.8400\n",
      "Epoch 20 Step 15393: Train 0.5595 Reg: 0.5978\n",
      "Test: 0.7794 MAE: 0.6909 RMSE: 0.8828\n",
      "Val: 0.7125 MAE: 0.6576 RMSE: 0.8441\n",
      "Epoch 21 Step 16126: Train 0.5488 Reg: 0.6045\n",
      "Test: 0.7864 MAE: 0.6906 RMSE: 0.8868\n",
      "Val: 0.7185 MAE: 0.6590 RMSE: 0.8476\n",
      "Epoch 22 Step 16859: Train 0.5384 Reg: 0.6089\n",
      "Test: 0.7896 MAE: 0.6941 RMSE: 0.8886\n",
      "Val: 0.7255 MAE: 0.6634 RMSE: 0.8517\n",
      "Epoch 23 Step 17592: Train 0.5299 Reg: 0.6095\n",
      "Test: 0.7961 MAE: 0.6974 RMSE: 0.8923\n",
      "Val: 0.7292 MAE: 0.6645 RMSE: 0.8539\n",
      "Epoch 24 Step 18325: Train 0.5231 Reg: 0.6063\n",
      "Test: 0.8089 MAE: 0.7025 RMSE: 0.8994\n",
      "Val: 0.7367 MAE: 0.6681 RMSE: 0.8583\n",
      "Epoch 25 Step 19058: Train 0.5172 Reg: 0.6028\n",
      "Test: 0.8130 MAE: 0.7023 RMSE: 0.9016\n",
      "Val: 0.7398 MAE: 0.6674 RMSE: 0.8601\n",
      "Epoch 26 Step 19791: Train 0.5124 Reg: 0.5986\n",
      "Test: 0.8192 MAE: 0.7076 RMSE: 0.9051\n",
      "Val: 0.7454 MAE: 0.6708 RMSE: 0.8634\n",
      "Epoch 27 Step 20524: Train 0.5067 Reg: 0.5959\n",
      "Test: 0.8243 MAE: 0.7091 RMSE: 0.9079\n",
      "Val: 0.7507 MAE: 0.6732 RMSE: 0.8664\n",
      "Epoch 28 Step 21257: Train 0.5003 Reg: 0.5942\n",
      "Test: 0.8273 MAE: 0.7068 RMSE: 0.9095\n",
      "Val: 0.7538 MAE: 0.6724 RMSE: 0.8682\n",
      "Epoch 29 Step 21990: Train 0.4944 Reg: 0.5912\n",
      "Test: 0.8352 MAE: 0.7088 RMSE: 0.9139\n",
      "Val: 0.7593 MAE: 0.6743 RMSE: 0.8714\n",
      "Epoch 30 Step 22723: Train 0.4895 Reg: 0.5867\n",
      "Test: 0.8388 MAE: 0.7147 RMSE: 0.9159\n",
      "Val: 0.7678 MAE: 0.6798 RMSE: 0.8763\n",
      "Epoch 31 Step 23456: Train 0.4851 Reg: 0.5819\n",
      "Test: 0.8490 MAE: 0.7168 RMSE: 0.9214\n",
      "Val: 0.7703 MAE: 0.6782 RMSE: 0.8777\n",
      "Epoch 32 Step 24189: Train 0.4807 Reg: 0.5788\n",
      "Test: 0.8481 MAE: 0.7128 RMSE: 0.9209\n",
      "Val: 0.7752 MAE: 0.6794 RMSE: 0.8805\n",
      "Epoch 33 Step 24922: Train 0.4751 Reg: 0.5762\n",
      "Test: 0.8593 MAE: 0.7221 RMSE: 0.9270\n",
      "Val: 0.7832 MAE: 0.6847 RMSE: 0.8850\n",
      "Epoch 34 Step 25655: Train 0.4696 Reg: 0.5734\n",
      "Test: 0.8605 MAE: 0.7199 RMSE: 0.9276\n",
      "Val: 0.7872 MAE: 0.6846 RMSE: 0.8872\n",
      "Epoch 35 Step 26388: Train 0.4652 Reg: 0.5692\n",
      "Test: 0.8625 MAE: 0.7217 RMSE: 0.9287\n",
      "Val: 0.7926 MAE: 0.6871 RMSE: 0.8903\n",
      "Epoch 36 Step 27121: Train 0.4612 Reg: 0.5649\n",
      "Test: 0.8714 MAE: 0.7263 RMSE: 0.9335\n",
      "Val: 0.7976 MAE: 0.6898 RMSE: 0.8931\n",
      "Epoch 37 Step 27854: Train 0.4577 Reg: 0.5598\n",
      "Test: 0.8759 MAE: 0.7269 RMSE: 0.9359\n",
      "Val: 0.7999 MAE: 0.6894 RMSE: 0.8944\n",
      "Epoch 38 Step 28587: Train 0.4546 Reg: 0.5546\n",
      "Test: 0.8777 MAE: 0.7273 RMSE: 0.9369\n",
      "Val: 0.8029 MAE: 0.6908 RMSE: 0.8961\n",
      "Epoch 39 Step 29320: Train 0.4517 Reg: 0.5495\n",
      "Test: 0.8823 MAE: 0.7295 RMSE: 0.9393\n",
      "Val: 0.8089 MAE: 0.6926 RMSE: 0.8994\n",
      "Epoch 40 Step 30053: Train 0.4489 Reg: 0.5446\n",
      "Test: 0.8838 MAE: 0.7291 RMSE: 0.9401\n",
      "Val: 0.8107 MAE: 0.6928 RMSE: 0.9004\n",
      "Epoch 41 Step 30786: Train 0.4464 Reg: 0.5395\n",
      "Test: 0.8906 MAE: 0.7302 RMSE: 0.9437\n",
      "Val: 0.8154 MAE: 0.6935 RMSE: 0.9030\n",
      "Epoch 42 Step 31519: Train 0.4439 Reg: 0.5346\n",
      "Test: 0.8937 MAE: 0.7318 RMSE: 0.9453\n",
      "Val: 0.8193 MAE: 0.6964 RMSE: 0.9051\n",
      "Epoch 43 Step 32252: Train 0.4415 Reg: 0.5299\n",
      "Test: 0.8966 MAE: 0.7332 RMSE: 0.9469\n",
      "Val: 0.8239 MAE: 0.6981 RMSE: 0.9077\n",
      "Epoch 44 Step 32985: Train 0.4392 Reg: 0.5254\n",
      "Test: 0.9021 MAE: 0.7352 RMSE: 0.9498\n",
      "Val: 0.8258 MAE: 0.6981 RMSE: 0.9088\n",
      "Epoch 45 Step 33718: Train 0.4371 Reg: 0.5209\n",
      "Test: 0.9059 MAE: 0.7361 RMSE: 0.9518\n",
      "Val: 0.8283 MAE: 0.6984 RMSE: 0.9101\n",
      "Epoch 46 Step 34451: Train 0.4349 Reg: 0.5167\n",
      "Test: 0.9111 MAE: 0.7375 RMSE: 0.9545\n",
      "Val: 0.8325 MAE: 0.6996 RMSE: 0.9124\n",
      "Epoch 47 Step 35184: Train 0.4329 Reg: 0.5125\n",
      "Test: 0.9119 MAE: 0.7386 RMSE: 0.9549\n",
      "Val: 0.8348 MAE: 0.7008 RMSE: 0.9137\n",
      "Epoch 48 Step 35917: Train 0.4310 Reg: 0.5086\n",
      "Test: 0.9166 MAE: 0.7407 RMSE: 0.9574\n",
      "Val: 0.8385 MAE: 0.7021 RMSE: 0.9157\n",
      "Epoch 49 Step 36650: Train 0.4290 Reg: 0.5047\n",
      "Test: 0.9214 MAE: 0.7432 RMSE: 0.9599\n",
      "Val: 0.8413 MAE: 0.7035 RMSE: 0.9172\n",
      "Epoch 50 Step 37383: Train 0.4271 Reg: 0.5011\n",
      "Test: 0.9216 MAE: 0.7436 RMSE: 0.9600\n",
      "Val: 0.8439 MAE: 0.7043 RMSE: 0.9187\n",
      "Epoch 51 Step 38116: Train 0.4254 Reg: 0.4975\n",
      "Test: 0.9259 MAE: 0.7449 RMSE: 0.9622\n",
      "Val: 0.8463 MAE: 0.7052 RMSE: 0.9199\n",
      "Epoch 52 Step 38849: Train 0.4236 Reg: 0.4940\n",
      "Test: 0.9291 MAE: 0.7453 RMSE: 0.9639\n",
      "Val: 0.8485 MAE: 0.7058 RMSE: 0.9212\n",
      "Epoch 53 Step 39582: Train 0.4219 Reg: 0.4908\n",
      "Test: 0.9340 MAE: 0.7475 RMSE: 0.9664\n",
      "Val: 0.8511 MAE: 0.7068 RMSE: 0.9226\n",
      "Epoch 54 Step 40315: Train 0.4203 Reg: 0.4876\n",
      "Test: 0.9368 MAE: 0.7494 RMSE: 0.9679\n",
      "Val: 0.8548 MAE: 0.7085 RMSE: 0.9245\n",
      "Epoch 55 Step 41048: Train 0.4188 Reg: 0.4846\n",
      "Test: 0.9376 MAE: 0.7493 RMSE: 0.9683\n",
      "Val: 0.8558 MAE: 0.7085 RMSE: 0.9251\n",
      "Epoch 56 Step 41781: Train 0.4173 Reg: 0.4817\n",
      "Test: 0.9424 MAE: 0.7511 RMSE: 0.9707\n",
      "Val: 0.8595 MAE: 0.7101 RMSE: 0.9271\n",
      "Epoch 57 Step 42514: Train 0.4159 Reg: 0.4789\n",
      "Test: 0.9444 MAE: 0.7522 RMSE: 0.9718\n",
      "Val: 0.8609 MAE: 0.7105 RMSE: 0.9278\n",
      "Epoch 58 Step 43247: Train 0.4145 Reg: 0.4761\n",
      "Test: 0.9453 MAE: 0.7510 RMSE: 0.9723\n",
      "Val: 0.8628 MAE: 0.7106 RMSE: 0.9288\n",
      "Epoch 59 Step 43980: Train 0.4132 Reg: 0.4737\n",
      "Test: 0.9475 MAE: 0.7513 RMSE: 0.9734\n",
      "Val: 0.8646 MAE: 0.7107 RMSE: 0.9299\n",
      "Epoch 60 Step 44713: Train 0.4119 Reg: 0.4712\n",
      "Test: 0.9512 MAE: 0.7545 RMSE: 0.9753\n",
      "Val: 0.8672 MAE: 0.7127 RMSE: 0.9312\n",
      "Epoch 61 Step 45446: Train 0.4107 Reg: 0.4688\n",
      "Test: 0.9523 MAE: 0.7536 RMSE: 0.9758\n",
      "Val: 0.8678 MAE: 0.7120 RMSE: 0.9316\n",
      "Epoch 62 Step 46179: Train 0.4095 Reg: 0.4665\n",
      "Test: 0.9551 MAE: 0.7557 RMSE: 0.9773\n",
      "Val: 0.8705 MAE: 0.7136 RMSE: 0.9330\n",
      "Epoch 63 Step 46912: Train 0.4084 Reg: 0.4644\n",
      "Test: 0.9579 MAE: 0.7569 RMSE: 0.9787\n",
      "Val: 0.8719 MAE: 0.7143 RMSE: 0.9338\n",
      "Epoch 64 Step 47645: Train 0.4074 Reg: 0.4623\n",
      "Test: 0.9591 MAE: 0.7566 RMSE: 0.9793\n",
      "Val: 0.8731 MAE: 0.7142 RMSE: 0.9344\n",
      "Epoch 65 Step 48378: Train 0.4063 Reg: 0.4604\n",
      "Test: 0.9610 MAE: 0.7578 RMSE: 0.9803\n",
      "Val: 0.8747 MAE: 0.7151 RMSE: 0.9352\n",
      "Epoch 66 Step 49111: Train 0.4054 Reg: 0.4584\n",
      "Test: 0.9614 MAE: 0.7567 RMSE: 0.9805\n",
      "Val: 0.8755 MAE: 0.7147 RMSE: 0.9357\n",
      "Epoch 67 Step 49844: Train 0.4044 Reg: 0.4566\n",
      "Test: 0.9632 MAE: 0.7577 RMSE: 0.9814\n",
      "Val: 0.8770 MAE: 0.7155 RMSE: 0.9365\n",
      "Epoch 68 Step 50577: Train 0.4035 Reg: 0.4549\n",
      "Test: 0.9656 MAE: 0.7595 RMSE: 0.9827\n",
      "Val: 0.8792 MAE: 0.7167 RMSE: 0.9376\n",
      "Epoch 69 Step 51310: Train 0.4026 Reg: 0.4533\n",
      "Test: 0.9675 MAE: 0.7594 RMSE: 0.9836\n",
      "Val: 0.8800 MAE: 0.7164 RMSE: 0.9381\n",
      "Epoch 70 Step 52043: Train 0.4017 Reg: 0.4517\n",
      "Test: 0.9683 MAE: 0.7596 RMSE: 0.9840\n",
      "Val: 0.8812 MAE: 0.7168 RMSE: 0.9387\n",
      "Epoch 71 Step 52776: Train 0.4010 Reg: 0.4501\n",
      "Test: 0.9714 MAE: 0.7616 RMSE: 0.9856\n",
      "Val: 0.8831 MAE: 0.7180 RMSE: 0.9397\n",
      "Epoch 72 Step 53509: Train 0.4002 Reg: 0.4487\n",
      "Test: 0.9730 MAE: 0.7624 RMSE: 0.9864\n",
      "Val: 0.8845 MAE: 0.7185 RMSE: 0.9405\n",
      "Epoch 73 Step 54242: Train 0.3995 Reg: 0.4473\n",
      "Test: 0.9726 MAE: 0.7618 RMSE: 0.9862\n",
      "Val: 0.8848 MAE: 0.7182 RMSE: 0.9407\n",
      "Epoch 74 Step 54975: Train 0.3988 Reg: 0.4460\n",
      "Test: 0.9746 MAE: 0.7625 RMSE: 0.9872\n",
      "Val: 0.8860 MAE: 0.7187 RMSE: 0.9413\n",
      "Epoch 75 Step 55708: Train 0.3981 Reg: 0.4448\n",
      "Test: 0.9764 MAE: 0.7630 RMSE: 0.9881\n",
      "Val: 0.8868 MAE: 0.7189 RMSE: 0.9417\n",
      "Epoch 76 Step 56441: Train 0.3975 Reg: 0.4436\n",
      "Test: 0.9786 MAE: 0.7644 RMSE: 0.9892\n",
      "Val: 0.8884 MAE: 0.7198 RMSE: 0.9425\n",
      "Epoch 77 Step 57174: Train 0.3968 Reg: 0.4424\n",
      "Test: 0.9795 MAE: 0.7648 RMSE: 0.9897\n",
      "Val: 0.8892 MAE: 0.7200 RMSE: 0.9430\n",
      "Epoch 78 Step 57907: Train 0.3963 Reg: 0.4414\n",
      "Test: 0.9808 MAE: 0.7649 RMSE: 0.9903\n",
      "Val: 0.8900 MAE: 0.7201 RMSE: 0.9434\n",
      "Epoch 79 Step 58640: Train 0.3957 Reg: 0.4403\n",
      "Test: 0.9808 MAE: 0.7641 RMSE: 0.9904\n",
      "Val: 0.8900 MAE: 0.7197 RMSE: 0.9434\n",
      "Epoch 80 Step 59373: Train 0.3952 Reg: 0.4393\n",
      "Test: 0.9812 MAE: 0.7643 RMSE: 0.9905\n",
      "Val: 0.8906 MAE: 0.7198 RMSE: 0.9437\n",
      "Epoch 81 Step 60106: Train 0.3947 Reg: 0.4384\n",
      "Test: 0.9839 MAE: 0.7664 RMSE: 0.9919\n",
      "Val: 0.8926 MAE: 0.7212 RMSE: 0.9448\n",
      "Epoch 82 Step 60839: Train 0.3942 Reg: 0.4375\n",
      "Test: 0.9840 MAE: 0.7657 RMSE: 0.9919\n",
      "Val: 0.8923 MAE: 0.7207 RMSE: 0.9446\n",
      "Epoch 83 Step 61572: Train 0.3937 Reg: 0.4366\n",
      "Test: 0.9846 MAE: 0.7658 RMSE: 0.9923\n",
      "Val: 0.8932 MAE: 0.7209 RMSE: 0.9451\n",
      "Epoch 84 Step 62305: Train 0.3933 Reg: 0.4358\n",
      "Test: 0.9857 MAE: 0.7663 RMSE: 0.9928\n",
      "Val: 0.8937 MAE: 0.7211 RMSE: 0.9453\n",
      "Epoch 85 Step 63038: Train 0.3929 Reg: 0.4351\n",
      "Test: 0.9866 MAE: 0.7667 RMSE: 0.9933\n",
      "Val: 0.8945 MAE: 0.7214 RMSE: 0.9458\n",
      "Epoch 86 Step 63771: Train 0.3925 Reg: 0.4343\n",
      "Test: 0.9863 MAE: 0.7661 RMSE: 0.9931\n",
      "Val: 0.8946 MAE: 0.7211 RMSE: 0.9459\n",
      "Epoch 87 Step 64504: Train 0.3921 Reg: 0.4336\n",
      "Test: 0.9876 MAE: 0.7668 RMSE: 0.9938\n",
      "Val: 0.8953 MAE: 0.7215 RMSE: 0.9462\n",
      "Epoch 88 Step 65237: Train 0.3917 Reg: 0.4329\n",
      "Test: 0.9878 MAE: 0.7665 RMSE: 0.9939\n",
      "Val: 0.8956 MAE: 0.7214 RMSE: 0.9464\n",
      "Epoch 89 Step 65970: Train 0.3914 Reg: 0.4323\n",
      "Test: 0.9886 MAE: 0.7670 RMSE: 0.9943\n",
      "Val: 0.8963 MAE: 0.7217 RMSE: 0.9467\n",
      "Epoch 90 Step 66703: Train 0.3910 Reg: 0.4317\n",
      "Test: 0.9894 MAE: 0.7674 RMSE: 0.9947\n",
      "Val: 0.8968 MAE: 0.7220 RMSE: 0.9470\n",
      "Epoch 91 Step 67436: Train 0.3907 Reg: 0.4311\n",
      "Test: 0.9905 MAE: 0.7681 RMSE: 0.9952\n",
      "Val: 0.8974 MAE: 0.7224 RMSE: 0.9473\n",
      "Epoch 92 Step 68169: Train 0.3904 Reg: 0.4306\n",
      "Test: 0.9911 MAE: 0.7684 RMSE: 0.9955\n",
      "Val: 0.8981 MAE: 0.7226 RMSE: 0.9477\n",
      "Epoch 93 Step 68902: Train 0.3901 Reg: 0.4300\n",
      "Test: 0.9911 MAE: 0.7681 RMSE: 0.9956\n",
      "Val: 0.8982 MAE: 0.7224 RMSE: 0.9477\n",
      "Epoch 94 Step 69635: Train 0.3898 Reg: 0.4295\n",
      "Test: 0.9919 MAE: 0.7685 RMSE: 0.9959\n",
      "Val: 0.8987 MAE: 0.7227 RMSE: 0.9480\n",
      "Epoch 95 Step 70368: Train 0.3896 Reg: 0.4291\n",
      "Test: 0.9930 MAE: 0.7694 RMSE: 0.9965\n",
      "Val: 0.8996 MAE: 0.7233 RMSE: 0.9485\n",
      "Epoch 96 Step 71101: Train 0.3893 Reg: 0.4286\n",
      "Test: 0.9922 MAE: 0.7681 RMSE: 0.9961\n",
      "Val: 0.8991 MAE: 0.7225 RMSE: 0.9482\n",
      "Epoch 97 Step 71834: Train 0.3891 Reg: 0.4282\n",
      "Test: 0.9928 MAE: 0.7684 RMSE: 0.9964\n",
      "Val: 0.8995 MAE: 0.7227 RMSE: 0.9484\n",
      "Epoch 98 Step 72567: Train 0.3888 Reg: 0.4278\n",
      "Test: 0.9930 MAE: 0.7685 RMSE: 0.9965\n",
      "Val: 0.8997 MAE: 0.7228 RMSE: 0.9485\n",
      "Epoch 99 Step 73300: Train 0.3886 Reg: 0.4274\n",
      "Test: 0.9934 MAE: 0.7685 RMSE: 0.9967\n",
      "Val: 0.9000 MAE: 0.7228 RMSE: 0.9487\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 789731/19100\n",
      "test set size: support/query 3138/809\n",
      "Epoch 0: TrainLoss 1.1618 RecLoss: 0.0000 (left: 0:09:44)\n",
      "TestLoss: 1.0781 MAE: 0.7962 RMSE: 1.0383\n",
      "ValLoss: 1.1548 MAE: 0.8413 RMSE: 1.0746\n",
      "Epoch 1: TrainLoss 1.0036 RecLoss: 0.0000 (left: 0:10:07)\n",
      "TestLoss: 1.0205 MAE: 0.8093 RMSE: 1.0102\n",
      "ValLoss: 1.0745 MAE: 0.8385 RMSE: 1.0366\n",
      "Epoch 2: TrainLoss 0.9626 RecLoss: 0.0000 (left: 0:09:51)\n",
      "TestLoss: 1.0005 MAE: 0.7981 RMSE: 1.0002\n",
      "ValLoss: 1.0571 MAE: 0.8282 RMSE: 1.0282\n",
      "Epoch 3: TrainLoss 0.9469 RecLoss: 0.0000 (left: 0:09:30)\n",
      "TestLoss: 0.9995 MAE: 0.8039 RMSE: 0.9998\n",
      "ValLoss: 1.0495 MAE: 0.8296 RMSE: 1.0245\n",
      "Epoch 4: TrainLoss 0.9262 RecLoss: 0.0000 (left: 0:09:26)\n",
      "TestLoss: 0.9824 MAE: 0.7849 RMSE: 0.9912\n",
      "ValLoss: 1.0384 MAE: 0.8159 RMSE: 1.0190\n",
      "Epoch 5: TrainLoss 0.9157 RecLoss: 0.0000 (left: 0:09:10)\n",
      "TestLoss: 0.9794 MAE: 0.7829 RMSE: 0.9897\n",
      "ValLoss: 1.0323 MAE: 0.8114 RMSE: 1.0160\n",
      "Epoch 6: TrainLoss 0.9074 RecLoss: 0.0000 (left: 0:09:06)\n",
      "TestLoss: 0.9776 MAE: 0.7808 RMSE: 0.9887\n",
      "ValLoss: 1.0359 MAE: 0.8134 RMSE: 1.0178\n",
      "Epoch 7: TrainLoss 0.9021 RecLoss: 0.0000 (left: 0:09:03)\n",
      "TestLoss: 0.9767 MAE: 0.7808 RMSE: 0.9883\n",
      "ValLoss: 1.0272 MAE: 0.8089 RMSE: 1.0135\n",
      "Epoch 8: TrainLoss 0.9008 RecLoss: 0.0000 (left: 0:08:56)\n",
      "TestLoss: 0.9789 MAE: 0.7891 RMSE: 0.9894\n",
      "ValLoss: 1.0299 MAE: 0.8146 RMSE: 1.0148\n",
      "Epoch 9: TrainLoss 0.8972 RecLoss: 0.0000 (left: 0:08:42)\n",
      "TestLoss: 0.9788 MAE: 0.7849 RMSE: 0.9893\n",
      "ValLoss: 1.0295 MAE: 0.8116 RMSE: 1.0147\n",
      "Epoch 10: TrainLoss 0.8921 RecLoss: 0.0000 (left: 0:08:38)\n",
      "TestLoss: 0.9765 MAE: 0.7858 RMSE: 0.9882\n",
      "ValLoss: 1.0309 MAE: 0.8128 RMSE: 1.0153\n",
      "Epoch 11: TrainLoss 0.8887 RecLoss: 0.0000 (left: 0:08:34)\n",
      "TestLoss: 0.9760 MAE: 0.7795 RMSE: 0.9879\n",
      "ValLoss: 1.0344 MAE: 0.8094 RMSE: 1.0171\n",
      "Epoch 12: TrainLoss 0.8881 RecLoss: 0.0000 (left: 0:08:32)\n",
      "TestLoss: 0.9799 MAE: 0.7764 RMSE: 0.9899\n",
      "ValLoss: 1.0382 MAE: 0.8082 RMSE: 1.0189\n",
      "Epoch 13: TrainLoss 0.8867 RecLoss: 0.0000 (left: 0:08:29)\n",
      "TestLoss: 0.9790 MAE: 0.7825 RMSE: 0.9895\n",
      "ValLoss: 1.0347 MAE: 0.8104 RMSE: 1.0172\n",
      "Epoch 14: TrainLoss 0.8876 RecLoss: 0.0000 (left: 0:08:22)\n",
      "TestLoss: 0.9975 MAE: 0.8041 RMSE: 0.9987\n",
      "ValLoss: 1.0445 MAE: 0.8255 RMSE: 1.0220\n",
      "Epoch 15: TrainLoss 0.8890 RecLoss: 0.0000 (left: 0:08:16)\n",
      "TestLoss: 0.9814 MAE: 0.7868 RMSE: 0.9907\n",
      "ValLoss: 1.0385 MAE: 0.8144 RMSE: 1.0191\n",
      "Epoch 16: TrainLoss 0.8841 RecLoss: 0.0000 (left: 0:08:09)\n",
      "TestLoss: 0.9818 MAE: 0.7864 RMSE: 0.9909\n",
      "ValLoss: 1.0372 MAE: 0.8144 RMSE: 1.0184\n",
      "Epoch 17: TrainLoss 0.8848 RecLoss: 0.0000 (left: 0:08:06)\n",
      "TestLoss: 0.9850 MAE: 0.7759 RMSE: 0.9924\n",
      "ValLoss: 1.0469 MAE: 0.8098 RMSE: 1.0232\n",
      "Epoch 18: TrainLoss 0.8844 RecLoss: 0.0000 (left: 0:07:57)\n",
      "TestLoss: 0.9851 MAE: 0.7908 RMSE: 0.9925\n",
      "ValLoss: 1.0408 MAE: 0.8163 RMSE: 1.0202\n",
      "Epoch 19: TrainLoss 0.8867 RecLoss: 0.0000 (left: 0:07:54)\n",
      "TestLoss: 0.9834 MAE: 0.7868 RMSE: 0.9917\n",
      "ValLoss: 1.0418 MAE: 0.8148 RMSE: 1.0207\n",
      "Epoch 20: TrainLoss 0.8857 RecLoss: 0.0000 (left: 0:07:51)\n",
      "TestLoss: 0.9873 MAE: 0.7918 RMSE: 0.9936\n",
      "ValLoss: 1.0414 MAE: 0.8174 RMSE: 1.0205\n",
      "Epoch 21: TrainLoss 0.8851 RecLoss: 0.0000 (left: 0:07:44)\n",
      "TestLoss: 0.9844 MAE: 0.7776 RMSE: 0.9922\n",
      "ValLoss: 1.0459 MAE: 0.8093 RMSE: 1.0227\n",
      "Epoch 22: TrainLoss 0.8845 RecLoss: 0.0000 (left: 0:07:37)\n",
      "TestLoss: 0.9845 MAE: 0.7824 RMSE: 0.9922\n",
      "ValLoss: 1.0430 MAE: 0.8117 RMSE: 1.0213\n",
      "Epoch 23: TrainLoss 0.8830 RecLoss: 0.0000 (left: 0:07:30)\n",
      "TestLoss: 0.9983 MAE: 0.8015 RMSE: 0.9992\n",
      "ValLoss: 1.0530 MAE: 0.8259 RMSE: 1.0261\n",
      "Epoch 24: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:07:22)\n",
      "TestLoss: 0.9937 MAE: 0.7970 RMSE: 0.9969\n",
      "ValLoss: 1.0462 MAE: 0.8204 RMSE: 1.0229\n",
      "Epoch 25: TrainLoss 0.8817 RecLoss: 0.0000 (left: 0:07:17)\n",
      "TestLoss: 0.9838 MAE: 0.7843 RMSE: 0.9919\n",
      "ValLoss: 1.0435 MAE: 0.8128 RMSE: 1.0215\n",
      "Epoch 26: TrainLoss 0.8820 RecLoss: 0.0000 (left: 0:07:10)\n",
      "TestLoss: 0.9884 MAE: 0.7757 RMSE: 0.9942\n",
      "ValLoss: 1.0561 MAE: 0.8110 RMSE: 1.0277\n",
      "Epoch 27: TrainLoss 0.8838 RecLoss: 0.0000 (left: 0:07:05)\n",
      "TestLoss: 0.9859 MAE: 0.7767 RMSE: 0.9929\n",
      "ValLoss: 1.0547 MAE: 0.8116 RMSE: 1.0270\n",
      "Epoch 28: TrainLoss 0.8815 RecLoss: 0.0000 (left: 0:07:00)\n",
      "TestLoss: 0.9869 MAE: 0.7869 RMSE: 0.9934\n",
      "ValLoss: 1.0480 MAE: 0.8153 RMSE: 1.0237\n",
      "Epoch 29: TrainLoss 0.8834 RecLoss: 0.0000 (left: 0:06:54)\n",
      "TestLoss: 0.9846 MAE: 0.7851 RMSE: 0.9923\n",
      "ValLoss: 1.0466 MAE: 0.8140 RMSE: 1.0230\n",
      "Epoch 30: TrainLoss 0.8823 RecLoss: 0.0000 (left: 0:06:49)\n",
      "TestLoss: 0.9920 MAE: 0.7744 RMSE: 0.9960\n",
      "ValLoss: 1.0632 MAE: 0.8120 RMSE: 1.0311\n",
      "Epoch 31: TrainLoss 0.8838 RecLoss: 0.0000 (left: 0:06:43)\n",
      "TestLoss: 0.9873 MAE: 0.7780 RMSE: 0.9936\n",
      "ValLoss: 1.0536 MAE: 0.8110 RMSE: 1.0265\n",
      "Epoch 32: TrainLoss 0.8804 RecLoss: 0.0000 (left: 0:06:37)\n",
      "TestLoss: 0.9848 MAE: 0.7811 RMSE: 0.9924\n",
      "ValLoss: 1.0517 MAE: 0.8130 RMSE: 1.0255\n",
      "Epoch 33: TrainLoss 0.8820 RecLoss: 0.0000 (left: 0:06:32)\n",
      "TestLoss: 0.9860 MAE: 0.7804 RMSE: 0.9930\n",
      "ValLoss: 1.0506 MAE: 0.8121 RMSE: 1.0250\n",
      "Epoch 34: TrainLoss 0.8803 RecLoss: 0.0000 (left: 0:06:25)\n",
      "TestLoss: 0.9946 MAE: 0.7740 RMSE: 0.9973\n",
      "ValLoss: 1.0644 MAE: 0.8111 RMSE: 1.0317\n",
      "Epoch 35: TrainLoss 0.8828 RecLoss: 0.0000 (left: 0:06:18)\n",
      "TestLoss: 0.9904 MAE: 0.7918 RMSE: 0.9952\n",
      "ValLoss: 1.0491 MAE: 0.8174 RMSE: 1.0243\n",
      "Epoch 36: TrainLoss 0.8812 RecLoss: 0.0000 (left: 0:06:12)\n",
      "TestLoss: 0.9867 MAE: 0.7814 RMSE: 0.9933\n",
      "ValLoss: 1.0513 MAE: 0.8123 RMSE: 1.0254\n",
      "Epoch 37: TrainLoss 0.8804 RecLoss: 0.0000 (left: 0:06:06)\n",
      "TestLoss: 0.9859 MAE: 0.7857 RMSE: 0.9929\n",
      "ValLoss: 1.0502 MAE: 0.8151 RMSE: 1.0248\n",
      "Epoch 38: TrainLoss 0.8819 RecLoss: 0.0000 (left: 0:06:01)\n",
      "TestLoss: 0.9903 MAE: 0.7917 RMSE: 0.9951\n",
      "ValLoss: 1.0528 MAE: 0.8198 RMSE: 1.0261\n",
      "Epoch 39: TrainLoss 0.8826 RecLoss: 0.0000 (left: 0:05:56)\n",
      "TestLoss: 0.9880 MAE: 0.7777 RMSE: 0.9940\n",
      "ValLoss: 1.0575 MAE: 0.8117 RMSE: 1.0283\n",
      "Epoch 40: TrainLoss 0.8820 RecLoss: 0.0000 (left: 0:05:49)\n",
      "TestLoss: 0.9935 MAE: 0.7756 RMSE: 0.9967\n",
      "ValLoss: 1.0663 MAE: 0.8129 RMSE: 1.0326\n",
      "Epoch 41: TrainLoss 0.8819 RecLoss: 0.0000 (left: 0:05:42)\n",
      "TestLoss: 0.9869 MAE: 0.7832 RMSE: 0.9934\n",
      "ValLoss: 1.0522 MAE: 0.8133 RMSE: 1.0258\n",
      "Epoch 42: TrainLoss 0.8820 RecLoss: 0.0000 (left: 0:05:36)\n",
      "TestLoss: 0.9893 MAE: 0.7886 RMSE: 0.9946\n",
      "ValLoss: 1.0506 MAE: 0.8162 RMSE: 1.0250\n",
      "Epoch 43: TrainLoss 0.8816 RecLoss: 0.0000 (left: 0:05:30)\n",
      "TestLoss: 0.9876 MAE: 0.7806 RMSE: 0.9938\n",
      "ValLoss: 1.0534 MAE: 0.8122 RMSE: 1.0264\n",
      "Epoch 44: TrainLoss 0.8797 RecLoss: 0.0000 (left: 0:05:23)\n",
      "TestLoss: 0.9862 MAE: 0.7826 RMSE: 0.9931\n",
      "ValLoss: 1.0536 MAE: 0.8144 RMSE: 1.0265\n",
      "Epoch 45: TrainLoss 0.8798 RecLoss: 0.0000 (left: 0:05:17)\n",
      "TestLoss: 0.9881 MAE: 0.7833 RMSE: 0.9940\n",
      "ValLoss: 1.0527 MAE: 0.8139 RMSE: 1.0260\n",
      "Epoch 46: TrainLoss 0.8794 RecLoss: 0.0000 (left: 0:05:10)\n",
      "TestLoss: 0.9881 MAE: 0.7798 RMSE: 0.9940\n",
      "ValLoss: 1.0554 MAE: 0.8123 RMSE: 1.0273\n",
      "Epoch 47: TrainLoss 0.8807 RecLoss: 0.0000 (left: 0:05:05)\n",
      "TestLoss: 0.9870 MAE: 0.7785 RMSE: 0.9935\n",
      "ValLoss: 1.0559 MAE: 0.8121 RMSE: 1.0276\n",
      "Epoch 48: TrainLoss 0.8811 RecLoss: 0.0000 (left: 0:05:00)\n",
      "TestLoss: 0.9924 MAE: 0.7759 RMSE: 0.9962\n",
      "ValLoss: 1.0653 MAE: 0.8124 RMSE: 1.0321\n",
      "Epoch 49: TrainLoss 0.8821 RecLoss: 0.0000 (left: 0:04:53)\n",
      "TestLoss: 0.9911 MAE: 0.7769 RMSE: 0.9955\n",
      "ValLoss: 1.0610 MAE: 0.8122 RMSE: 1.0301\n",
      "Epoch 50: TrainLoss 0.8830 RecLoss: 0.0000 (left: 0:04:48)\n",
      "TestLoss: 0.9908 MAE: 0.7792 RMSE: 0.9954\n",
      "ValLoss: 1.0585 MAE: 0.8127 RMSE: 1.0289\n",
      "Epoch 51: TrainLoss 0.8802 RecLoss: 0.0000 (left: 0:04:42)\n",
      "TestLoss: 0.9881 MAE: 0.7840 RMSE: 0.9940\n",
      "ValLoss: 1.0551 MAE: 0.8150 RMSE: 1.0272\n",
      "Epoch 52: TrainLoss 0.8794 RecLoss: 0.0000 (left: 0:04:37)\n",
      "TestLoss: 0.9878 MAE: 0.7863 RMSE: 0.9939\n",
      "ValLoss: 1.0542 MAE: 0.8162 RMSE: 1.0268\n",
      "Epoch 53: TrainLoss 0.8813 RecLoss: 0.0000 (left: 0:04:31)\n",
      "TestLoss: 0.9884 MAE: 0.7864 RMSE: 0.9942\n",
      "ValLoss: 1.0522 MAE: 0.8150 RMSE: 1.0258\n",
      "Epoch 54: TrainLoss 0.8797 RecLoss: 0.0000 (left: 0:04:26)\n",
      "TestLoss: 0.9863 MAE: 0.7815 RMSE: 0.9931\n",
      "ValLoss: 1.0540 MAE: 0.8133 RMSE: 1.0267\n",
      "Epoch 55: TrainLoss 0.8802 RecLoss: 0.0000 (left: 0:04:20)\n",
      "TestLoss: 0.9899 MAE: 0.7882 RMSE: 0.9949\n",
      "ValLoss: 1.0534 MAE: 0.8172 RMSE: 1.0264\n",
      "Epoch 56: TrainLoss 0.8803 RecLoss: 0.0000 (left: 0:04:14)\n",
      "TestLoss: 0.9882 MAE: 0.7871 RMSE: 0.9941\n",
      "ValLoss: 1.0540 MAE: 0.8168 RMSE: 1.0266\n",
      "Epoch 57: TrainLoss 0.8803 RecLoss: 0.0000 (left: 0:04:08)\n",
      "TestLoss: 0.9903 MAE: 0.7777 RMSE: 0.9951\n",
      "ValLoss: 1.0598 MAE: 0.8121 RMSE: 1.0295\n",
      "Epoch 58: TrainLoss 0.8794 RecLoss: 0.0000 (left: 0:04:02)\n",
      "TestLoss: 0.9878 MAE: 0.7842 RMSE: 0.9939\n",
      "ValLoss: 1.0541 MAE: 0.8147 RMSE: 1.0267\n",
      "Epoch 59: TrainLoss 0.8794 RecLoss: 0.0000 (left: 0:03:57)\n",
      "TestLoss: 0.9874 MAE: 0.7828 RMSE: 0.9937\n",
      "ValLoss: 1.0551 MAE: 0.8144 RMSE: 1.0272\n",
      "Epoch 60: TrainLoss 0.8795 RecLoss: 0.0000 (left: 0:03:51)\n",
      "TestLoss: 0.9884 MAE: 0.7794 RMSE: 0.9942\n",
      "ValLoss: 1.0551 MAE: 0.8116 RMSE: 1.0272\n",
      "Epoch 61: TrainLoss 0.8800 RecLoss: 0.0000 (left: 0:03:44)\n",
      "TestLoss: 0.9868 MAE: 0.7854 RMSE: 0.9934\n",
      "ValLoss: 1.0537 MAE: 0.8159 RMSE: 1.0265\n",
      "Epoch 62: TrainLoss 0.8799 RecLoss: 0.0000 (left: 0:03:39)\n",
      "TestLoss: 0.9921 MAE: 0.7928 RMSE: 0.9961\n",
      "ValLoss: 1.0550 MAE: 0.8200 RMSE: 1.0271\n",
      "Epoch 63: TrainLoss 0.8829 RecLoss: 0.0000 (left: 0:03:33)\n",
      "TestLoss: 0.9944 MAE: 0.7943 RMSE: 0.9972\n",
      "ValLoss: 1.0560 MAE: 0.8206 RMSE: 1.0276\n",
      "Epoch 64: TrainLoss 0.8814 RecLoss: 0.0000 (left: 0:03:26)\n",
      "TestLoss: 0.9873 MAE: 0.7828 RMSE: 0.9936\n",
      "ValLoss: 1.0556 MAE: 0.8148 RMSE: 1.0274\n",
      "Epoch 65: TrainLoss 0.8787 RecLoss: 0.0000 (left: 0:03:20)\n",
      "TestLoss: 0.9903 MAE: 0.7794 RMSE: 0.9952\n",
      "ValLoss: 1.0564 MAE: 0.8124 RMSE: 1.0278\n",
      "Epoch 66: TrainLoss 0.8794 RecLoss: 0.0000 (left: 0:03:14)\n",
      "TestLoss: 0.9857 MAE: 0.7809 RMSE: 0.9928\n",
      "ValLoss: 1.0549 MAE: 0.8133 RMSE: 1.0271\n",
      "Epoch 67: TrainLoss 0.8797 RecLoss: 0.0000 (left: 0:03:09)\n",
      "TestLoss: 0.9874 MAE: 0.7800 RMSE: 0.9937\n",
      "ValLoss: 1.0572 MAE: 0.8131 RMSE: 1.0282\n",
      "Epoch 68: TrainLoss 0.8806 RecLoss: 0.0000 (left: 0:03:03)\n",
      "TestLoss: 0.9880 MAE: 0.7809 RMSE: 0.9940\n",
      "ValLoss: 1.0539 MAE: 0.8125 RMSE: 1.0266\n",
      "Epoch 69: TrainLoss 0.8826 RecLoss: 0.0000 (left: 0:02:57)\n",
      "TestLoss: 0.9897 MAE: 0.7771 RMSE: 0.9948\n",
      "ValLoss: 1.0610 MAE: 0.8131 RMSE: 1.0300\n",
      "Epoch 70: TrainLoss 0.8839 RecLoss: 0.0000 (left: 0:02:51)\n",
      "TestLoss: 1.0033 MAE: 0.7744 RMSE: 1.0016\n",
      "ValLoss: 1.0796 MAE: 0.8142 RMSE: 1.0390\n",
      "Epoch 71: TrainLoss 0.8817 RecLoss: 0.0000 (left: 0:02:45)\n",
      "TestLoss: 0.9871 MAE: 0.7826 RMSE: 0.9935\n",
      "ValLoss: 1.0556 MAE: 0.8145 RMSE: 1.0274\n",
      "Epoch 72: TrainLoss 0.8794 RecLoss: 0.0000 (left: 0:02:39)\n",
      "TestLoss: 0.9894 MAE: 0.7785 RMSE: 0.9947\n",
      "ValLoss: 1.0607 MAE: 0.8131 RMSE: 1.0299\n",
      "Epoch 73: TrainLoss 0.8793 RecLoss: 0.0000 (left: 0:02:34)\n",
      "TestLoss: 0.9875 MAE: 0.7831 RMSE: 0.9937\n",
      "ValLoss: 1.0537 MAE: 0.8142 RMSE: 1.0265\n",
      "Epoch 74: TrainLoss 0.8798 RecLoss: 0.0000 (left: 0:02:28)\n",
      "TestLoss: 0.9878 MAE: 0.7812 RMSE: 0.9939\n",
      "ValLoss: 1.0562 MAE: 0.8136 RMSE: 1.0277\n",
      "Epoch 75: TrainLoss 0.8795 RecLoss: 0.0000 (left: 0:02:22)\n",
      "TestLoss: 0.9942 MAE: 0.7758 RMSE: 0.9971\n",
      "ValLoss: 1.0666 MAE: 0.8126 RMSE: 1.0327\n",
      "Epoch 76: TrainLoss 0.8804 RecLoss: 0.0000 (left: 0:02:17)\n",
      "TestLoss: 0.9888 MAE: 0.7793 RMSE: 0.9944\n",
      "ValLoss: 1.0577 MAE: 0.8129 RMSE: 1.0284\n",
      "Epoch 77: TrainLoss 0.8799 RecLoss: 0.0000 (left: 0:02:11)\n",
      "TestLoss: 0.9887 MAE: 0.7801 RMSE: 0.9943\n",
      "ValLoss: 1.0572 MAE: 0.8126 RMSE: 1.0282\n",
      "Epoch 78: TrainLoss 0.8798 RecLoss: 0.0000 (left: 0:02:05)\n",
      "TestLoss: 0.9931 MAE: 0.7759 RMSE: 0.9965\n",
      "ValLoss: 1.0669 MAE: 0.8132 RMSE: 1.0329\n",
      "Epoch 79: TrainLoss 0.8796 RecLoss: 0.0000 (left: 0:01:59)\n",
      "TestLoss: 0.9891 MAE: 0.7867 RMSE: 0.9946\n",
      "ValLoss: 1.0542 MAE: 0.8158 RMSE: 1.0267\n",
      "Epoch 80: TrainLoss 0.8799 RecLoss: 0.0000 (left: 0:01:53)\n",
      "TestLoss: 0.9885 MAE: 0.7868 RMSE: 0.9942\n",
      "ValLoss: 1.0539 MAE: 0.8164 RMSE: 1.0266\n",
      "Epoch 81: TrainLoss 0.8789 RecLoss: 0.0000 (left: 0:01:47)\n",
      "TestLoss: 0.9868 MAE: 0.7832 RMSE: 0.9934\n",
      "ValLoss: 1.0535 MAE: 0.8139 RMSE: 1.0264\n",
      "Epoch 82: TrainLoss 0.8824 RecLoss: 0.0000 (left: 0:01:42)\n",
      "TestLoss: 0.9958 MAE: 0.7754 RMSE: 0.9979\n",
      "ValLoss: 1.0701 MAE: 0.8136 RMSE: 1.0345\n",
      "Epoch 83: TrainLoss 0.8858 RecLoss: 0.0000 (left: 0:01:36)\n",
      "TestLoss: 0.9904 MAE: 0.7781 RMSE: 0.9952\n",
      "ValLoss: 1.0619 MAE: 0.8132 RMSE: 1.0305\n",
      "Epoch 84: TrainLoss 0.8783 RecLoss: 0.0000 (left: 0:01:30)\n",
      "TestLoss: 0.9892 MAE: 0.7863 RMSE: 0.9946\n",
      "ValLoss: 1.0547 MAE: 0.8160 RMSE: 1.0270\n",
      "Epoch 85: TrainLoss 0.8806 RecLoss: 0.0000 (left: 0:01:24)\n",
      "TestLoss: 0.9884 MAE: 0.7802 RMSE: 0.9942\n",
      "ValLoss: 1.0579 MAE: 0.8136 RMSE: 1.0286\n",
      "Epoch 86: TrainLoss 0.8805 RecLoss: 0.0000 (left: 0:01:19)\n",
      "TestLoss: 0.9918 MAE: 0.7774 RMSE: 0.9959\n",
      "ValLoss: 1.0636 MAE: 0.8131 RMSE: 1.0313\n",
      "Epoch 87: TrainLoss 0.8804 RecLoss: 0.0000 (left: 0:01:13)\n",
      "TestLoss: 0.9885 MAE: 0.7819 RMSE: 0.9942\n",
      "ValLoss: 1.0562 MAE: 0.8140 RMSE: 1.0277\n",
      "Epoch 88: TrainLoss 0.8823 RecLoss: 0.0000 (left: 0:01:07)\n",
      "TestLoss: 0.9896 MAE: 0.7795 RMSE: 0.9948\n",
      "ValLoss: 1.0591 MAE: 0.8131 RMSE: 1.0291\n",
      "Epoch 89: TrainLoss 0.8801 RecLoss: 0.0000 (left: 0:01:02)\n",
      "TestLoss: 0.9881 MAE: 0.7798 RMSE: 0.9940\n",
      "ValLoss: 1.0587 MAE: 0.8135 RMSE: 1.0289\n",
      "Epoch 90: TrainLoss 0.8791 RecLoss: 0.0000 (left: 0:00:56)\n",
      "TestLoss: 0.9879 MAE: 0.7856 RMSE: 0.9939\n",
      "ValLoss: 1.0567 MAE: 0.8166 RMSE: 1.0279\n",
      "Epoch 91: TrainLoss 0.8813 RecLoss: 0.0000 (left: 0:00:50)\n",
      "TestLoss: 0.9873 MAE: 0.7821 RMSE: 0.9937\n",
      "ValLoss: 1.0557 MAE: 0.8140 RMSE: 1.0275\n",
      "Epoch 92: TrainLoss 0.8786 RecLoss: 0.0000 (left: 0:00:45)\n",
      "TestLoss: 0.9884 MAE: 0.7831 RMSE: 0.9942\n",
      "ValLoss: 1.0542 MAE: 0.8139 RMSE: 1.0267\n",
      "Epoch 93: TrainLoss 0.8793 RecLoss: 0.0000 (left: 0:00:39)\n",
      "TestLoss: 0.9910 MAE: 0.7904 RMSE: 0.9955\n",
      "ValLoss: 1.0545 MAE: 0.8183 RMSE: 1.0269\n",
      "Epoch 94: TrainLoss 0.8829 RecLoss: 0.0000 (left: 0:00:33)\n",
      "TestLoss: 0.9890 MAE: 0.7791 RMSE: 0.9945\n",
      "ValLoss: 1.0587 MAE: 0.8129 RMSE: 1.0289\n",
      "Epoch 95: TrainLoss 0.8811 RecLoss: 0.0000 (left: 0:00:28)\n",
      "TestLoss: 0.9888 MAE: 0.7794 RMSE: 0.9944\n",
      "ValLoss: 1.0594 MAE: 0.8139 RMSE: 1.0293\n",
      "Epoch 96: TrainLoss 0.8795 RecLoss: 0.0000 (left: 0:00:22)\n",
      "TestLoss: 0.9944 MAE: 0.7759 RMSE: 0.9972\n",
      "ValLoss: 1.0663 MAE: 0.8123 RMSE: 1.0326\n",
      "Epoch 97: TrainLoss 0.8801 RecLoss: 0.0000 (left: 0:00:16)\n",
      "TestLoss: 0.9878 MAE: 0.7818 RMSE: 0.9939\n",
      "ValLoss: 1.0567 MAE: 0.8144 RMSE: 1.0279\n",
      "Epoch 98: TrainLoss 0.8786 RecLoss: 0.0000 (left: 0:00:11)\n",
      "TestLoss: 0.9879 MAE: 0.7847 RMSE: 0.9939\n",
      "ValLoss: 1.0545 MAE: 0.8147 RMSE: 1.0269\n",
      "Epoch 99: TrainLoss 0.8786 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 0.9886 MAE: 0.7876 RMSE: 0.9943\n",
      "ValLoss: 1.0539 MAE: 0.8163 RMSE: 1.0266\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 789731/19100\n",
      "test set size: support/query 3138/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.6854 RMSE: 0.8690 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7808 RMSE: 0.9883 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7050 RMSE: 0.8947 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 40% CUR coreusers input to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 601508/19100\n",
      "test set size: support/query 2092/809\n",
      "Epoch 0 Step 559: Train 1.7367 Reg: 0.6178\n",
      "Test: 0.8674 MAE: 0.7415 RMSE: 0.9313\n",
      "Val: 0.8281 MAE: 0.7198 RMSE: 0.9100\n",
      "Epoch 1 Step 1118: Train 0.8199 Reg: 0.4178\n",
      "Test: 0.8714 MAE: 0.7433 RMSE: 0.9335\n",
      "Val: 0.8177 MAE: 0.7142 RMSE: 0.9043\n",
      "Epoch 2 Step 1677: Train 0.8154 Reg: 0.3411\n",
      "Test: 0.8585 MAE: 0.7379 RMSE: 0.9265\n",
      "Val: 0.8177 MAE: 0.7152 RMSE: 0.9043\n",
      "Epoch 3 Step 2236: Train 0.8114 Reg: 0.3114\n",
      "Test: 0.8584 MAE: 0.7350 RMSE: 0.9265\n",
      "Val: 0.8129 MAE: 0.7140 RMSE: 0.9016\n",
      "Epoch 4 Step 2795: Train 0.8065 Reg: 0.2894\n",
      "Test: 0.8419 MAE: 0.7302 RMSE: 0.9176\n",
      "Val: 0.8071 MAE: 0.7106 RMSE: 0.8984\n",
      "Epoch 5 Step 3354: Train 0.8000 Reg: 0.2711\n",
      "Test: 0.8575 MAE: 0.7325 RMSE: 0.9260\n",
      "Val: 0.7999 MAE: 0.7054 RMSE: 0.8944\n",
      "Epoch 6 Step 3913: Train 0.7908 Reg: 0.2576\n",
      "Test: 0.8478 MAE: 0.7295 RMSE: 0.9207\n",
      "Val: 0.7921 MAE: 0.7005 RMSE: 0.8900\n",
      "Epoch 7 Step 4472: Train 0.7807 Reg: 0.2529\n",
      "Test: 0.8307 MAE: 0.7228 RMSE: 0.9114\n",
      "Val: 0.7817 MAE: 0.6970 RMSE: 0.8841\n",
      "Epoch 8 Step 5031: Train 0.7620 Reg: 0.2714\n",
      "Test: 0.8099 MAE: 0.7116 RMSE: 0.8999\n",
      "Val: 0.7626 MAE: 0.6867 RMSE: 0.8733\n",
      "Epoch 9 Step 5590: Train 0.7440 Reg: 0.2906\n",
      "Test: 0.8095 MAE: 0.7140 RMSE: 0.8997\n",
      "Val: 0.7558 MAE: 0.6813 RMSE: 0.8693\n",
      "Epoch 10 Step 6149: Train 0.7322 Reg: 0.3028\n",
      "Test: 0.7913 MAE: 0.7013 RMSE: 0.8896\n",
      "Val: 0.7441 MAE: 0.6776 RMSE: 0.8626\n",
      "Epoch 11 Step 6708: Train 0.7137 Reg: 0.3367\n",
      "Test: 0.7829 MAE: 0.7033 RMSE: 0.8848\n",
      "Val: 0.7284 MAE: 0.6672 RMSE: 0.8535\n",
      "Epoch 12 Step 7267: Train 0.6894 Reg: 0.3842\n",
      "Test: 0.7716 MAE: 0.6973 RMSE: 0.8784\n",
      "Val: 0.7159 MAE: 0.6635 RMSE: 0.8461\n",
      "Epoch 13 Step 7826: Train 0.6656 Reg: 0.4197\n",
      "Test: 0.7590 MAE: 0.6885 RMSE: 0.8712\n",
      "Val: 0.7057 MAE: 0.6567 RMSE: 0.8400\n",
      "Epoch 14 Step 8385: Train 0.6423 Reg: 0.4513\n",
      "Test: 0.7551 MAE: 0.6893 RMSE: 0.8690\n",
      "Val: 0.7011 MAE: 0.6557 RMSE: 0.8373\n",
      "Epoch 15 Step 8944: Train 0.6201 Reg: 0.4793\n",
      "Test: 0.7506 MAE: 0.6816 RMSE: 0.8664\n",
      "Val: 0.7037 MAE: 0.6546 RMSE: 0.8389\n",
      "Epoch 16 Step 9503: Train 0.5998 Reg: 0.5023\n",
      "Test: 0.7532 MAE: 0.6824 RMSE: 0.8679\n",
      "Val: 0.7081 MAE: 0.6558 RMSE: 0.8415\n",
      "Epoch 17 Step 10062: Train 0.5796 Reg: 0.5294\n",
      "Test: 0.7589 MAE: 0.6887 RMSE: 0.8711\n",
      "Val: 0.7147 MAE: 0.6604 RMSE: 0.8454\n",
      "Epoch 18 Step 10621: Train 0.5576 Reg: 0.5525\n",
      "Test: 0.7605 MAE: 0.6831 RMSE: 0.8721\n",
      "Val: 0.7197 MAE: 0.6595 RMSE: 0.8484\n",
      "Epoch 19 Step 11180: Train 0.5381 Reg: 0.5687\n",
      "Test: 0.7694 MAE: 0.6887 RMSE: 0.8771\n",
      "Val: 0.7290 MAE: 0.6634 RMSE: 0.8538\n",
      "Epoch 20 Step 11739: Train 0.5218 Reg: 0.5778\n",
      "Test: 0.7774 MAE: 0.6919 RMSE: 0.8817\n",
      "Val: 0.7381 MAE: 0.6688 RMSE: 0.8591\n",
      "Epoch 21 Step 12298: Train 0.5094 Reg: 0.5824\n",
      "Test: 0.7920 MAE: 0.6992 RMSE: 0.8899\n",
      "Val: 0.7465 MAE: 0.6721 RMSE: 0.8640\n",
      "Epoch 22 Step 12857: Train 0.4988 Reg: 0.5855\n",
      "Test: 0.7973 MAE: 0.6982 RMSE: 0.8929\n",
      "Val: 0.7570 MAE: 0.6747 RMSE: 0.8700\n",
      "Epoch 23 Step 13416: Train 0.4889 Reg: 0.5870\n",
      "Test: 0.8080 MAE: 0.7001 RMSE: 0.8989\n",
      "Val: 0.7640 MAE: 0.6757 RMSE: 0.8741\n",
      "Epoch 24 Step 13975: Train 0.4807 Reg: 0.5859\n",
      "Test: 0.8191 MAE: 0.7018 RMSE: 0.9050\n",
      "Val: 0.7717 MAE: 0.6780 RMSE: 0.8784\n",
      "Epoch 25 Step 14534: Train 0.4736 Reg: 0.5841\n",
      "Test: 0.8277 MAE: 0.7073 RMSE: 0.9098\n",
      "Val: 0.7783 MAE: 0.6815 RMSE: 0.8822\n",
      "Epoch 26 Step 15093: Train 0.4672 Reg: 0.5815\n",
      "Test: 0.8367 MAE: 0.7095 RMSE: 0.9147\n",
      "Val: 0.7861 MAE: 0.6839 RMSE: 0.8866\n",
      "Epoch 27 Step 15652: Train 0.4606 Reg: 0.5808\n",
      "Test: 0.8363 MAE: 0.7091 RMSE: 0.9145\n",
      "Val: 0.7922 MAE: 0.6854 RMSE: 0.8901\n",
      "Epoch 28 Step 16211: Train 0.4538 Reg: 0.5785\n",
      "Test: 0.8486 MAE: 0.7164 RMSE: 0.9212\n",
      "Val: 0.8023 MAE: 0.6900 RMSE: 0.8957\n",
      "Epoch 29 Step 16770: Train 0.4479 Reg: 0.5754\n",
      "Test: 0.8527 MAE: 0.7188 RMSE: 0.9234\n",
      "Val: 0.8063 MAE: 0.6911 RMSE: 0.8979\n",
      "Epoch 30 Step 17329: Train 0.4432 Reg: 0.5710\n",
      "Test: 0.8607 MAE: 0.7194 RMSE: 0.9277\n",
      "Val: 0.8149 MAE: 0.6937 RMSE: 0.9027\n",
      "Epoch 31 Step 17888: Train 0.4390 Reg: 0.5666\n",
      "Test: 0.8676 MAE: 0.7231 RMSE: 0.9314\n",
      "Val: 0.8193 MAE: 0.6957 RMSE: 0.9051\n",
      "Epoch 32 Step 18447: Train 0.4350 Reg: 0.5618\n",
      "Test: 0.8713 MAE: 0.7283 RMSE: 0.9334\n",
      "Val: 0.8256 MAE: 0.6987 RMSE: 0.9086\n",
      "Epoch 33 Step 19006: Train 0.4317 Reg: 0.5569\n",
      "Test: 0.8779 MAE: 0.7297 RMSE: 0.9369\n",
      "Val: 0.8310 MAE: 0.7010 RMSE: 0.9116\n",
      "Epoch 34 Step 19565: Train 0.4284 Reg: 0.5519\n",
      "Test: 0.8866 MAE: 0.7336 RMSE: 0.9416\n",
      "Val: 0.8369 MAE: 0.7036 RMSE: 0.9148\n",
      "Epoch 35 Step 20124: Train 0.4254 Reg: 0.5473\n",
      "Test: 0.8879 MAE: 0.7316 RMSE: 0.9423\n",
      "Val: 0.8402 MAE: 0.7028 RMSE: 0.9166\n",
      "Epoch 36 Step 20683: Train 0.4226 Reg: 0.5424\n",
      "Test: 0.8994 MAE: 0.7375 RMSE: 0.9483\n",
      "Val: 0.8456 MAE: 0.7055 RMSE: 0.9196\n",
      "Epoch 37 Step 21242: Train 0.4198 Reg: 0.5378\n",
      "Test: 0.9007 MAE: 0.7370 RMSE: 0.9491\n",
      "Val: 0.8500 MAE: 0.7070 RMSE: 0.9219\n",
      "Epoch 38 Step 21801: Train 0.4171 Reg: 0.5331\n",
      "Test: 0.9055 MAE: 0.7379 RMSE: 0.9516\n",
      "Val: 0.8531 MAE: 0.7067 RMSE: 0.9236\n",
      "Epoch 39 Step 22360: Train 0.4146 Reg: 0.5285\n",
      "Test: 0.9083 MAE: 0.7383 RMSE: 0.9531\n",
      "Val: 0.8570 MAE: 0.7082 RMSE: 0.9257\n",
      "Epoch 40 Step 22919: Train 0.4125 Reg: 0.5241\n",
      "Test: 0.9136 MAE: 0.7418 RMSE: 0.9558\n",
      "Val: 0.8620 MAE: 0.7106 RMSE: 0.9284\n",
      "Epoch 41 Step 23478: Train 0.4102 Reg: 0.5199\n",
      "Test: 0.9161 MAE: 0.7409 RMSE: 0.9571\n",
      "Val: 0.8645 MAE: 0.7110 RMSE: 0.9298\n",
      "Epoch 42 Step 24037: Train 0.4081 Reg: 0.5155\n",
      "Test: 0.9206 MAE: 0.7428 RMSE: 0.9595\n",
      "Val: 0.8687 MAE: 0.7122 RMSE: 0.9320\n",
      "Epoch 43 Step 24596: Train 0.4061 Reg: 0.5115\n",
      "Test: 0.9279 MAE: 0.7443 RMSE: 0.9633\n",
      "Val: 0.8731 MAE: 0.7132 RMSE: 0.9344\n",
      "Epoch 44 Step 25155: Train 0.4041 Reg: 0.5076\n",
      "Test: 0.9277 MAE: 0.7455 RMSE: 0.9632\n",
      "Val: 0.8745 MAE: 0.7149 RMSE: 0.9352\n",
      "Epoch 45 Step 25714: Train 0.4023 Reg: 0.5037\n",
      "Test: 0.9318 MAE: 0.7461 RMSE: 0.9653\n",
      "Val: 0.8779 MAE: 0.7155 RMSE: 0.9369\n",
      "Epoch 46 Step 26273: Train 0.4005 Reg: 0.5000\n",
      "Test: 0.9361 MAE: 0.7481 RMSE: 0.9675\n",
      "Val: 0.8828 MAE: 0.7171 RMSE: 0.9396\n",
      "Epoch 47 Step 26832: Train 0.3988 Reg: 0.4965\n",
      "Test: 0.9420 MAE: 0.7505 RMSE: 0.9706\n",
      "Val: 0.8853 MAE: 0.7182 RMSE: 0.9409\n",
      "Epoch 48 Step 27391: Train 0.3972 Reg: 0.4931\n",
      "Test: 0.9453 MAE: 0.7518 RMSE: 0.9723\n",
      "Val: 0.8873 MAE: 0.7190 RMSE: 0.9419\n",
      "Epoch 49 Step 27950: Train 0.3956 Reg: 0.4898\n",
      "Test: 0.9497 MAE: 0.7537 RMSE: 0.9745\n",
      "Val: 0.8918 MAE: 0.7207 RMSE: 0.9443\n",
      "Epoch 50 Step 28509: Train 0.3941 Reg: 0.4867\n",
      "Test: 0.9522 MAE: 0.7552 RMSE: 0.9758\n",
      "Val: 0.8957 MAE: 0.7227 RMSE: 0.9464\n",
      "Epoch 51 Step 29068: Train 0.3927 Reg: 0.4836\n",
      "Test: 0.9563 MAE: 0.7569 RMSE: 0.9779\n",
      "Val: 0.8970 MAE: 0.7230 RMSE: 0.9471\n",
      "Epoch 52 Step 29627: Train 0.3912 Reg: 0.4807\n",
      "Test: 0.9580 MAE: 0.7567 RMSE: 0.9788\n",
      "Val: 0.9000 MAE: 0.7236 RMSE: 0.9487\n",
      "Epoch 53 Step 30186: Train 0.3900 Reg: 0.4778\n",
      "Test: 0.9627 MAE: 0.7579 RMSE: 0.9812\n",
      "Val: 0.9015 MAE: 0.7238 RMSE: 0.9495\n",
      "Epoch 54 Step 30745: Train 0.3888 Reg: 0.4751\n",
      "Test: 0.9647 MAE: 0.7590 RMSE: 0.9822\n",
      "Val: 0.9044 MAE: 0.7252 RMSE: 0.9510\n",
      "Epoch 55 Step 31304: Train 0.3875 Reg: 0.4725\n",
      "Test: 0.9675 MAE: 0.7592 RMSE: 0.9836\n",
      "Val: 0.9054 MAE: 0.7251 RMSE: 0.9515\n",
      "Epoch 56 Step 31863: Train 0.3863 Reg: 0.4700\n",
      "Test: 0.9693 MAE: 0.7600 RMSE: 0.9845\n",
      "Val: 0.9078 MAE: 0.7258 RMSE: 0.9528\n",
      "Epoch 57 Step 32422: Train 0.3852 Reg: 0.4676\n",
      "Test: 0.9727 MAE: 0.7616 RMSE: 0.9862\n",
      "Val: 0.9109 MAE: 0.7270 RMSE: 0.9544\n",
      "Epoch 58 Step 32981: Train 0.3841 Reg: 0.4654\n",
      "Test: 0.9748 MAE: 0.7636 RMSE: 0.9873\n",
      "Val: 0.9131 MAE: 0.7285 RMSE: 0.9556\n",
      "Epoch 59 Step 33540: Train 0.3831 Reg: 0.4632\n",
      "Test: 0.9768 MAE: 0.7632 RMSE: 0.9883\n",
      "Val: 0.9144 MAE: 0.7285 RMSE: 0.9563\n",
      "Epoch 60 Step 34099: Train 0.3821 Reg: 0.4611\n",
      "Test: 0.9788 MAE: 0.7632 RMSE: 0.9894\n",
      "Val: 0.9165 MAE: 0.7285 RMSE: 0.9573\n",
      "Epoch 61 Step 34658: Train 0.3812 Reg: 0.4591\n",
      "Test: 0.9814 MAE: 0.7646 RMSE: 0.9907\n",
      "Val: 0.9186 MAE: 0.7295 RMSE: 0.9584\n",
      "Epoch 62 Step 35217: Train 0.3803 Reg: 0.4572\n",
      "Test: 0.9830 MAE: 0.7654 RMSE: 0.9915\n",
      "Val: 0.9193 MAE: 0.7298 RMSE: 0.9588\n",
      "Epoch 63 Step 35776: Train 0.3794 Reg: 0.4553\n",
      "Test: 0.9855 MAE: 0.7665 RMSE: 0.9927\n",
      "Val: 0.9211 MAE: 0.7306 RMSE: 0.9597\n",
      "Epoch 64 Step 36335: Train 0.3786 Reg: 0.4535\n",
      "Test: 0.9869 MAE: 0.7670 RMSE: 0.9934\n",
      "Val: 0.9232 MAE: 0.7314 RMSE: 0.9608\n",
      "Epoch 65 Step 36894: Train 0.3778 Reg: 0.4519\n",
      "Test: 0.9875 MAE: 0.7664 RMSE: 0.9937\n",
      "Val: 0.9238 MAE: 0.7310 RMSE: 0.9611\n",
      "Epoch 66 Step 37453: Train 0.3770 Reg: 0.4503\n",
      "Test: 0.9909 MAE: 0.7693 RMSE: 0.9954\n",
      "Val: 0.9268 MAE: 0.7332 RMSE: 0.9627\n",
      "Epoch 67 Step 38012: Train 0.3763 Reg: 0.4488\n",
      "Test: 0.9910 MAE: 0.7676 RMSE: 0.9955\n",
      "Val: 0.9264 MAE: 0.7322 RMSE: 0.9625\n",
      "Epoch 68 Step 38571: Train 0.3756 Reg: 0.4473\n",
      "Test: 0.9934 MAE: 0.7686 RMSE: 0.9967\n",
      "Val: 0.9276 MAE: 0.7325 RMSE: 0.9631\n",
      "Epoch 69 Step 39130: Train 0.3749 Reg: 0.4459\n",
      "Test: 0.9949 MAE: 0.7695 RMSE: 0.9974\n",
      "Val: 0.9290 MAE: 0.7331 RMSE: 0.9638\n",
      "Epoch 70 Step 39689: Train 0.3743 Reg: 0.4445\n",
      "Test: 0.9959 MAE: 0.7690 RMSE: 0.9979\n",
      "Val: 0.9298 MAE: 0.7331 RMSE: 0.9642\n",
      "Epoch 71 Step 40248: Train 0.3737 Reg: 0.4433\n",
      "Test: 0.9989 MAE: 0.7708 RMSE: 0.9995\n",
      "Val: 0.9314 MAE: 0.7340 RMSE: 0.9651\n",
      "Epoch 72 Step 40807: Train 0.3731 Reg: 0.4420\n",
      "Test: 1.0005 MAE: 0.7714 RMSE: 1.0002\n",
      "Val: 0.9331 MAE: 0.7349 RMSE: 0.9660\n",
      "Epoch 73 Step 41366: Train 0.3725 Reg: 0.4409\n",
      "Test: 1.0008 MAE: 0.7709 RMSE: 1.0004\n",
      "Val: 0.9334 MAE: 0.7344 RMSE: 0.9661\n",
      "Epoch 74 Step 41925: Train 0.3720 Reg: 0.4398\n",
      "Test: 1.0020 MAE: 0.7716 RMSE: 1.0010\n",
      "Val: 0.9343 MAE: 0.7349 RMSE: 0.9666\n",
      "Epoch 75 Step 42484: Train 0.3715 Reg: 0.4387\n",
      "Test: 1.0034 MAE: 0.7721 RMSE: 1.0017\n",
      "Val: 0.9350 MAE: 0.7350 RMSE: 0.9669\n",
      "Epoch 76 Step 43043: Train 0.3710 Reg: 0.4377\n",
      "Test: 1.0041 MAE: 0.7723 RMSE: 1.0021\n",
      "Val: 0.9359 MAE: 0.7353 RMSE: 0.9674\n",
      "Epoch 77 Step 43602: Train 0.3705 Reg: 0.4368\n",
      "Test: 1.0055 MAE: 0.7726 RMSE: 1.0027\n",
      "Val: 0.9368 MAE: 0.7355 RMSE: 0.9679\n",
      "Epoch 78 Step 44161: Train 0.3701 Reg: 0.4358\n",
      "Test: 1.0064 MAE: 0.7737 RMSE: 1.0032\n",
      "Val: 0.9379 MAE: 0.7364 RMSE: 0.9685\n",
      "Epoch 79 Step 44720: Train 0.3697 Reg: 0.4350\n",
      "Test: 1.0076 MAE: 0.7737 RMSE: 1.0038\n",
      "Val: 0.9383 MAE: 0.7362 RMSE: 0.9687\n",
      "Epoch 80 Step 45279: Train 0.3693 Reg: 0.4341\n",
      "Test: 1.0079 MAE: 0.7734 RMSE: 1.0040\n",
      "Val: 0.9390 MAE: 0.7363 RMSE: 0.9690\n",
      "Epoch 81 Step 45838: Train 0.3689 Reg: 0.4334\n",
      "Test: 1.0092 MAE: 0.7742 RMSE: 1.0046\n",
      "Val: 0.9396 MAE: 0.7367 RMSE: 0.9693\n",
      "Epoch 82 Step 46397: Train 0.3685 Reg: 0.4326\n",
      "Test: 1.0096 MAE: 0.7737 RMSE: 1.0048\n",
      "Val: 0.9399 MAE: 0.7365 RMSE: 0.9695\n",
      "Epoch 83 Step 46956: Train 0.3682 Reg: 0.4319\n",
      "Test: 1.0107 MAE: 0.7748 RMSE: 1.0053\n",
      "Val: 0.9410 MAE: 0.7373 RMSE: 0.9701\n",
      "Epoch 84 Step 47515: Train 0.3678 Reg: 0.4312\n",
      "Test: 1.0113 MAE: 0.7743 RMSE: 1.0056\n",
      "Val: 0.9412 MAE: 0.7370 RMSE: 0.9702\n",
      "Epoch 85 Step 48074: Train 0.3675 Reg: 0.4306\n",
      "Test: 1.0124 MAE: 0.7746 RMSE: 1.0062\n",
      "Val: 0.9419 MAE: 0.7371 RMSE: 0.9705\n",
      "Epoch 86 Step 48633: Train 0.3672 Reg: 0.4299\n",
      "Test: 1.0131 MAE: 0.7752 RMSE: 1.0065\n",
      "Val: 0.9425 MAE: 0.7376 RMSE: 0.9708\n",
      "Epoch 87 Step 49192: Train 0.3669 Reg: 0.4294\n",
      "Test: 1.0139 MAE: 0.7756 RMSE: 1.0069\n",
      "Val: 0.9433 MAE: 0.7380 RMSE: 0.9713\n",
      "Epoch 88 Step 49751: Train 0.3667 Reg: 0.4288\n",
      "Test: 1.0147 MAE: 0.7763 RMSE: 1.0073\n",
      "Val: 0.9440 MAE: 0.7383 RMSE: 0.9716\n",
      "Epoch 89 Step 50310: Train 0.3664 Reg: 0.4283\n",
      "Test: 1.0151 MAE: 0.7758 RMSE: 1.0075\n",
      "Val: 0.9441 MAE: 0.7381 RMSE: 0.9716\n",
      "Epoch 90 Step 50869: Train 0.3661 Reg: 0.4278\n",
      "Test: 1.0153 MAE: 0.7757 RMSE: 1.0076\n",
      "Val: 0.9445 MAE: 0.7381 RMSE: 0.9718\n",
      "Epoch 91 Step 51428: Train 0.3659 Reg: 0.4273\n",
      "Test: 1.0162 MAE: 0.7764 RMSE: 1.0081\n",
      "Val: 0.9450 MAE: 0.7385 RMSE: 0.9721\n",
      "Epoch 92 Step 51987: Train 0.3657 Reg: 0.4268\n",
      "Test: 1.0165 MAE: 0.7759 RMSE: 1.0082\n",
      "Val: 0.9450 MAE: 0.7382 RMSE: 0.9721\n",
      "Epoch 93 Step 52546: Train 0.3655 Reg: 0.4264\n",
      "Test: 1.0171 MAE: 0.7763 RMSE: 1.0085\n",
      "Val: 0.9455 MAE: 0.7384 RMSE: 0.9723\n",
      "Epoch 94 Step 53105: Train 0.3653 Reg: 0.4260\n",
      "Test: 1.0173 MAE: 0.7763 RMSE: 1.0086\n",
      "Val: 0.9457 MAE: 0.7385 RMSE: 0.9725\n",
      "Epoch 95 Step 53664: Train 0.3651 Reg: 0.4256\n",
      "Test: 1.0180 MAE: 0.7766 RMSE: 1.0089\n",
      "Val: 0.9461 MAE: 0.7386 RMSE: 0.9727\n",
      "Epoch 96 Step 54223: Train 0.3649 Reg: 0.4252\n",
      "Test: 1.0184 MAE: 0.7766 RMSE: 1.0092\n",
      "Val: 0.9463 MAE: 0.7386 RMSE: 0.9728\n",
      "Epoch 97 Step 54782: Train 0.3647 Reg: 0.4248\n",
      "Test: 1.0190 MAE: 0.7774 RMSE: 1.0095\n",
      "Val: 0.9471 MAE: 0.7392 RMSE: 0.9732\n",
      "Epoch 98 Step 55341: Train 0.3645 Reg: 0.4245\n",
      "Test: 1.0194 MAE: 0.7774 RMSE: 1.0096\n",
      "Val: 0.9473 MAE: 0.7392 RMSE: 0.9733\n",
      "Epoch 99 Step 55900: Train 0.3644 Reg: 0.4242\n",
      "Test: 1.0197 MAE: 0.7777 RMSE: 1.0098\n",
      "Val: 0.9476 MAE: 0.7393 RMSE: 0.9734\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 601508/19100\n",
      "test set size: support/query 2092/809\n",
      "Epoch 0: TrainLoss 1.1262 RecLoss: 0.0000 (left: 0:11:04)\n",
      "TestLoss: 1.0681 MAE: 0.7993 RMSE: 1.0335\n",
      "ValLoss: 1.1452 MAE: 0.8433 RMSE: 1.0702\n",
      "Epoch 1: TrainLoss 0.9995 RecLoss: 0.0000 (left: 0:10:05)\n",
      "TestLoss: 1.0147 MAE: 0.8000 RMSE: 1.0073\n",
      "ValLoss: 1.0703 MAE: 0.8359 RMSE: 1.0345\n",
      "Epoch 2: TrainLoss 0.9627 RecLoss: 0.0000 (left: 0:09:35)\n",
      "TestLoss: 1.0014 MAE: 0.7978 RMSE: 1.0007\n",
      "ValLoss: 1.0578 MAE: 0.8327 RMSE: 1.0285\n",
      "Epoch 3: TrainLoss 0.9483 RecLoss: 0.0000 (left: 0:09:15)\n",
      "TestLoss: 1.0093 MAE: 0.8113 RMSE: 1.0046\n",
      "ValLoss: 1.0562 MAE: 0.8384 RMSE: 1.0277\n",
      "Epoch 4: TrainLoss 0.9277 RecLoss: 0.0000 (left: 0:08:50)\n",
      "TestLoss: 0.9840 MAE: 0.7864 RMSE: 0.9920\n",
      "ValLoss: 1.0391 MAE: 0.8212 RMSE: 1.0193\n",
      "Epoch 5: TrainLoss 0.9158 RecLoss: 0.0000 (left: 0:08:50)\n",
      "TestLoss: 0.9809 MAE: 0.7822 RMSE: 0.9904\n",
      "ValLoss: 1.0341 MAE: 0.8160 RMSE: 1.0169\n",
      "Epoch 6: TrainLoss 0.9078 RecLoss: 0.0000 (left: 0:08:41)\n",
      "TestLoss: 0.9819 MAE: 0.7814 RMSE: 0.9909\n",
      "ValLoss: 1.0373 MAE: 0.8160 RMSE: 1.0185\n",
      "Epoch 7: TrainLoss 0.9032 RecLoss: 0.0000 (left: 0:08:18)\n",
      "TestLoss: 0.9775 MAE: 0.7810 RMSE: 0.9887\n",
      "ValLoss: 1.0306 MAE: 0.8139 RMSE: 1.0152\n",
      "Epoch 8: TrainLoss 0.9012 RecLoss: 0.0000 (left: 0:08:22)\n",
      "TestLoss: 0.9859 MAE: 0.7937 RMSE: 0.9929\n",
      "ValLoss: 1.0351 MAE: 0.8231 RMSE: 1.0174\n",
      "Epoch 9: TrainLoss 0.8983 RecLoss: 0.0000 (left: 0:08:12)\n",
      "TestLoss: 0.9814 MAE: 0.7844 RMSE: 0.9906\n",
      "ValLoss: 1.0305 MAE: 0.8153 RMSE: 1.0151\n",
      "Epoch 10: TrainLoss 0.8927 RecLoss: 0.0000 (left: 0:08:06)\n",
      "TestLoss: 0.9798 MAE: 0.7843 RMSE: 0.9899\n",
      "ValLoss: 1.0339 MAE: 0.8175 RMSE: 1.0168\n",
      "Epoch 11: TrainLoss 0.8900 RecLoss: 0.0000 (left: 0:08:03)\n",
      "TestLoss: 0.9804 MAE: 0.7800 RMSE: 0.9902\n",
      "ValLoss: 1.0362 MAE: 0.8139 RMSE: 1.0179\n",
      "Epoch 12: TrainLoss 0.8890 RecLoss: 0.0000 (left: 0:08:00)\n",
      "TestLoss: 0.9838 MAE: 0.7777 RMSE: 0.9919\n",
      "ValLoss: 1.0413 MAE: 0.8135 RMSE: 1.0204\n",
      "Epoch 13: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:07:55)\n",
      "TestLoss: 0.9839 MAE: 0.7846 RMSE: 0.9919\n",
      "ValLoss: 1.0371 MAE: 0.8170 RMSE: 1.0184\n",
      "Epoch 14: TrainLoss 0.8903 RecLoss: 0.0000 (left: 0:07:51)\n",
      "TestLoss: 1.0037 MAE: 0.8064 RMSE: 1.0019\n",
      "ValLoss: 1.0488 MAE: 0.8317 RMSE: 1.0241\n",
      "Epoch 15: TrainLoss 0.8906 RecLoss: 0.0000 (left: 0:07:49)\n",
      "TestLoss: 0.9836 MAE: 0.7836 RMSE: 0.9917\n",
      "ValLoss: 1.0400 MAE: 0.8166 RMSE: 1.0198\n",
      "Epoch 16: TrainLoss 0.8856 RecLoss: 0.0000 (left: 0:07:42)\n",
      "TestLoss: 0.9853 MAE: 0.7857 RMSE: 0.9926\n",
      "ValLoss: 1.0398 MAE: 0.8186 RMSE: 1.0197\n",
      "Epoch 17: TrainLoss 0.8857 RecLoss: 0.0000 (left: 0:07:36)\n",
      "TestLoss: 0.9875 MAE: 0.7780 RMSE: 0.9937\n",
      "ValLoss: 1.0501 MAE: 0.8152 RMSE: 1.0247\n",
      "Epoch 18: TrainLoss 0.8868 RecLoss: 0.0000 (left: 0:07:31)\n",
      "TestLoss: 0.9919 MAE: 0.7932 RMSE: 0.9959\n",
      "ValLoss: 1.0443 MAE: 0.8236 RMSE: 1.0219\n",
      "Epoch 19: TrainLoss 0.8896 RecLoss: 0.0000 (left: 0:07:26)\n",
      "TestLoss: 0.9870 MAE: 0.7866 RMSE: 0.9935\n",
      "ValLoss: 1.0431 MAE: 0.8194 RMSE: 1.0213\n",
      "Epoch 20: TrainLoss 0.8869 RecLoss: 0.0000 (left: 0:07:23)\n",
      "TestLoss: 0.9866 MAE: 0.7874 RMSE: 0.9933\n",
      "ValLoss: 1.0438 MAE: 0.8204 RMSE: 1.0217\n",
      "Epoch 21: TrainLoss 0.8860 RecLoss: 0.0000 (left: 0:07:20)\n",
      "TestLoss: 0.9893 MAE: 0.7779 RMSE: 0.9946\n",
      "ValLoss: 1.0520 MAE: 0.8147 RMSE: 1.0256\n",
      "Epoch 22: TrainLoss 0.8858 RecLoss: 0.0000 (left: 0:07:13)\n",
      "TestLoss: 0.9885 MAE: 0.7857 RMSE: 0.9942\n",
      "ValLoss: 1.0450 MAE: 0.8180 RMSE: 1.0223\n",
      "Epoch 23: TrainLoss 0.8853 RecLoss: 0.0000 (left: 0:07:06)\n",
      "TestLoss: 1.0081 MAE: 0.8068 RMSE: 1.0041\n",
      "ValLoss: 1.0587 MAE: 0.8335 RMSE: 1.0289\n",
      "Epoch 24: TrainLoss 0.8916 RecLoss: 0.0000 (left: 0:07:00)\n",
      "TestLoss: 0.9917 MAE: 0.7920 RMSE: 0.9958\n",
      "ValLoss: 1.0474 MAE: 0.8231 RMSE: 1.0234\n",
      "Epoch 25: TrainLoss 0.8833 RecLoss: 0.0000 (left: 0:06:55)\n",
      "TestLoss: 0.9863 MAE: 0.7817 RMSE: 0.9931\n",
      "ValLoss: 1.0486 MAE: 0.8172 RMSE: 1.0240\n",
      "Epoch 26: TrainLoss 0.8841 RecLoss: 0.0000 (left: 0:06:49)\n",
      "TestLoss: 0.9955 MAE: 0.7772 RMSE: 0.9977\n",
      "ValLoss: 1.0601 MAE: 0.8153 RMSE: 1.0296\n",
      "Epoch 27: TrainLoss 0.8859 RecLoss: 0.0000 (left: 0:06:44)\n",
      "TestLoss: 0.9889 MAE: 0.7794 RMSE: 0.9944\n",
      "ValLoss: 1.0560 MAE: 0.8173 RMSE: 1.0276\n",
      "Epoch 28: TrainLoss 0.8840 RecLoss: 0.0000 (left: 0:06:38)\n",
      "TestLoss: 0.9914 MAE: 0.7888 RMSE: 0.9957\n",
      "ValLoss: 1.0495 MAE: 0.8211 RMSE: 1.0245\n",
      "Epoch 29: TrainLoss 0.8856 RecLoss: 0.0000 (left: 0:06:29)\n",
      "TestLoss: 0.9881 MAE: 0.7835 RMSE: 0.9940\n",
      "ValLoss: 1.0502 MAE: 0.8185 RMSE: 1.0248\n",
      "Epoch 30: TrainLoss 0.8843 RecLoss: 0.0000 (left: 0:06:25)\n",
      "TestLoss: 1.0006 MAE: 0.7753 RMSE: 1.0003\n",
      "ValLoss: 1.0719 MAE: 0.8159 RMSE: 1.0353\n",
      "Epoch 31: TrainLoss 0.8879 RecLoss: 0.0000 (left: 0:06:22)\n",
      "TestLoss: 0.9909 MAE: 0.7799 RMSE: 0.9954\n",
      "ValLoss: 1.0555 MAE: 0.8168 RMSE: 1.0274\n",
      "Epoch 32: TrainLoss 0.8823 RecLoss: 0.0000 (left: 0:06:15)\n",
      "TestLoss: 0.9888 MAE: 0.7829 RMSE: 0.9944\n",
      "ValLoss: 1.0523 MAE: 0.8181 RMSE: 1.0258\n",
      "Epoch 33: TrainLoss 0.8834 RecLoss: 0.0000 (left: 0:06:10)\n",
      "TestLoss: 0.9890 MAE: 0.7823 RMSE: 0.9945\n",
      "ValLoss: 1.0540 MAE: 0.8182 RMSE: 1.0266\n",
      "Epoch 34: TrainLoss 0.8828 RecLoss: 0.0000 (left: 0:06:04)\n",
      "TestLoss: 0.9974 MAE: 0.7762 RMSE: 0.9987\n",
      "ValLoss: 1.0656 MAE: 0.8160 RMSE: 1.0323\n",
      "Epoch 35: TrainLoss 0.8856 RecLoss: 0.0000 (left: 0:05:59)\n",
      "TestLoss: 0.9972 MAE: 0.7968 RMSE: 0.9986\n",
      "ValLoss: 1.0543 MAE: 0.8260 RMSE: 1.0268\n",
      "Epoch 36: TrainLoss 0.8842 RecLoss: 0.0000 (left: 0:05:52)\n",
      "TestLoss: 0.9894 MAE: 0.7845 RMSE: 0.9947\n",
      "ValLoss: 1.0522 MAE: 0.8189 RMSE: 1.0258\n",
      "Epoch 37: TrainLoss 0.8828 RecLoss: 0.0000 (left: 0:05:47)\n",
      "TestLoss: 0.9902 MAE: 0.7875 RMSE: 0.9951\n",
      "ValLoss: 1.0520 MAE: 0.8212 RMSE: 1.0257\n",
      "Epoch 38: TrainLoss 0.8840 RecLoss: 0.0000 (left: 0:05:42)\n",
      "TestLoss: 0.9924 MAE: 0.7900 RMSE: 0.9962\n",
      "ValLoss: 1.0539 MAE: 0.8230 RMSE: 1.0266\n",
      "Epoch 39: TrainLoss 0.8845 RecLoss: 0.0000 (left: 0:05:34)\n",
      "TestLoss: 0.9941 MAE: 0.7777 RMSE: 0.9970\n",
      "ValLoss: 1.0632 MAE: 0.8162 RMSE: 1.0311\n",
      "Epoch 40: TrainLoss 0.8854 RecLoss: 0.0000 (left: 0:05:27)\n",
      "TestLoss: 0.9975 MAE: 0.7773 RMSE: 0.9987\n",
      "ValLoss: 1.0693 MAE: 0.8175 RMSE: 1.0341\n",
      "Epoch 41: TrainLoss 0.8844 RecLoss: 0.0000 (left: 0:05:22)\n",
      "TestLoss: 0.9903 MAE: 0.7852 RMSE: 0.9951\n",
      "ValLoss: 1.0535 MAE: 0.8194 RMSE: 1.0264\n",
      "Epoch 42: TrainLoss 0.8848 RecLoss: 0.0000 (left: 0:05:17)\n",
      "TestLoss: 0.9933 MAE: 0.7909 RMSE: 0.9966\n",
      "ValLoss: 1.0542 MAE: 0.8233 RMSE: 1.0268\n",
      "Epoch 43: TrainLoss 0.8842 RecLoss: 0.0000 (left: 0:05:12)\n",
      "TestLoss: 0.9899 MAE: 0.7819 RMSE: 0.9950\n",
      "ValLoss: 1.0555 MAE: 0.8178 RMSE: 1.0274\n",
      "Epoch 44: TrainLoss 0.8818 RecLoss: 0.0000 (left: 0:05:06)\n",
      "TestLoss: 0.9901 MAE: 0.7838 RMSE: 0.9950\n",
      "ValLoss: 1.0561 MAE: 0.8198 RMSE: 1.0277\n",
      "Epoch 45: TrainLoss 0.8818 RecLoss: 0.0000 (left: 0:04:59)\n",
      "TestLoss: 0.9914 MAE: 0.7851 RMSE: 0.9957\n",
      "ValLoss: 1.0544 MAE: 0.8194 RMSE: 1.0269\n",
      "Epoch 46: TrainLoss 0.8813 RecLoss: 0.0000 (left: 0:04:53)\n",
      "TestLoss: 0.9905 MAE: 0.7828 RMSE: 0.9952\n",
      "ValLoss: 1.0551 MAE: 0.8181 RMSE: 1.0272\n",
      "Epoch 47: TrainLoss 0.8826 RecLoss: 0.0000 (left: 0:04:47)\n",
      "TestLoss: 0.9903 MAE: 0.7803 RMSE: 0.9951\n",
      "ValLoss: 1.0578 MAE: 0.8173 RMSE: 1.0285\n",
      "Epoch 48: TrainLoss 0.8836 RecLoss: 0.0000 (left: 0:04:41)\n",
      "TestLoss: 0.9932 MAE: 0.7798 RMSE: 0.9966\n",
      "ValLoss: 1.0613 MAE: 0.8177 RMSE: 1.0302\n",
      "Epoch 49: TrainLoss 0.8833 RecLoss: 0.0000 (left: 0:04:34)\n",
      "TestLoss: 0.9927 MAE: 0.7801 RMSE: 0.9963\n",
      "ValLoss: 1.0601 MAE: 0.8177 RMSE: 1.0296\n",
      "Epoch 50: TrainLoss 0.8839 RecLoss: 0.0000 (left: 0:04:28)\n",
      "TestLoss: 0.9934 MAE: 0.7806 RMSE: 0.9967\n",
      "ValLoss: 1.0602 MAE: 0.8173 RMSE: 1.0296\n",
      "Epoch 51: TrainLoss 0.8829 RecLoss: 0.0000 (left: 0:04:21)\n",
      "TestLoss: 0.9912 MAE: 0.7858 RMSE: 0.9956\n",
      "ValLoss: 1.0560 MAE: 0.8207 RMSE: 1.0276\n",
      "Epoch 52: TrainLoss 0.8819 RecLoss: 0.0000 (left: 0:04:16)\n",
      "TestLoss: 0.9920 MAE: 0.7878 RMSE: 0.9960\n",
      "ValLoss: 1.0556 MAE: 0.8216 RMSE: 1.0274\n",
      "Epoch 53: TrainLoss 0.8841 RecLoss: 0.0000 (left: 0:04:10)\n",
      "TestLoss: 0.9913 MAE: 0.7876 RMSE: 0.9956\n",
      "ValLoss: 1.0541 MAE: 0.8210 RMSE: 1.0267\n",
      "Epoch 54: TrainLoss 0.8829 RecLoss: 0.0000 (left: 0:04:05)\n",
      "TestLoss: 0.9914 MAE: 0.7819 RMSE: 0.9957\n",
      "ValLoss: 1.0571 MAE: 0.8178 RMSE: 1.0282\n",
      "Epoch 55: TrainLoss 0.8828 RecLoss: 0.0000 (left: 0:03:58)\n",
      "TestLoss: 0.9918 MAE: 0.7865 RMSE: 0.9959\n",
      "ValLoss: 1.0549 MAE: 0.8210 RMSE: 1.0271\n",
      "Epoch 56: TrainLoss 0.8821 RecLoss: 0.0000 (left: 0:03:52)\n",
      "TestLoss: 0.9902 MAE: 0.7852 RMSE: 0.9951\n",
      "ValLoss: 1.0555 MAE: 0.8202 RMSE: 1.0274\n",
      "Epoch 57: TrainLoss 0.8832 RecLoss: 0.0000 (left: 0:03:45)\n",
      "TestLoss: 0.9950 MAE: 0.7782 RMSE: 0.9975\n",
      "ValLoss: 1.0635 MAE: 0.8169 RMSE: 1.0313\n",
      "Epoch 58: TrainLoss 0.8817 RecLoss: 0.0000 (left: 0:03:39)\n",
      "TestLoss: 0.9909 MAE: 0.7841 RMSE: 0.9954\n",
      "ValLoss: 1.0560 MAE: 0.8194 RMSE: 1.0276\n",
      "Epoch 59: TrainLoss 0.8812 RecLoss: 0.0000 (left: 0:03:33)\n",
      "TestLoss: 0.9902 MAE: 0.7847 RMSE: 0.9951\n",
      "ValLoss: 1.0548 MAE: 0.8193 RMSE: 1.0270\n",
      "Epoch 60: TrainLoss 0.8812 RecLoss: 0.0000 (left: 0:03:28)\n",
      "TestLoss: 0.9908 MAE: 0.7811 RMSE: 0.9954\n",
      "ValLoss: 1.0574 MAE: 0.8172 RMSE: 1.0283\n",
      "Epoch 61: TrainLoss 0.8822 RecLoss: 0.0000 (left: 0:03:22)\n",
      "TestLoss: 0.9906 MAE: 0.7862 RMSE: 0.9953\n",
      "ValLoss: 1.0547 MAE: 0.8210 RMSE: 1.0270\n",
      "Epoch 62: TrainLoss 0.8820 RecLoss: 0.0000 (left: 0:03:16)\n",
      "TestLoss: 0.9954 MAE: 0.7928 RMSE: 0.9977\n",
      "ValLoss: 1.0554 MAE: 0.8246 RMSE: 1.0273\n",
      "Epoch 63: TrainLoss 0.8848 RecLoss: 0.0000 (left: 0:03:11)\n",
      "TestLoss: 0.9966 MAE: 0.7933 RMSE: 0.9983\n",
      "ValLoss: 1.0563 MAE: 0.8249 RMSE: 1.0277\n",
      "Epoch 64: TrainLoss 0.8832 RecLoss: 0.0000 (left: 0:03:06)\n",
      "TestLoss: 0.9905 MAE: 0.7830 RMSE: 0.9953\n",
      "ValLoss: 1.0593 MAE: 0.8199 RMSE: 1.0292\n",
      "Epoch 65: TrainLoss 0.8816 RecLoss: 0.0000 (left: 0:03:00)\n",
      "TestLoss: 0.9914 MAE: 0.7807 RMSE: 0.9957\n",
      "ValLoss: 1.0595 MAE: 0.8177 RMSE: 1.0293\n",
      "Epoch 66: TrainLoss 0.8812 RecLoss: 0.0000 (left: 0:02:55)\n",
      "TestLoss: 0.9897 MAE: 0.7824 RMSE: 0.9948\n",
      "ValLoss: 1.0549 MAE: 0.8181 RMSE: 1.0271\n",
      "Epoch 67: TrainLoss 0.8812 RecLoss: 0.0000 (left: 0:02:50)\n",
      "TestLoss: 0.9922 MAE: 0.7813 RMSE: 0.9961\n",
      "ValLoss: 1.0594 MAE: 0.8180 RMSE: 1.0293\n",
      "Epoch 68: TrainLoss 0.8826 RecLoss: 0.0000 (left: 0:02:45)\n",
      "TestLoss: 0.9910 MAE: 0.7803 RMSE: 0.9955\n",
      "ValLoss: 1.0576 MAE: 0.8169 RMSE: 1.0284\n",
      "Epoch 69: TrainLoss 0.8860 RecLoss: 0.0000 (left: 0:02:40)\n",
      "TestLoss: 0.9965 MAE: 0.7779 RMSE: 0.9983\n",
      "ValLoss: 1.0669 MAE: 0.8174 RMSE: 1.0329\n",
      "Epoch 70: TrainLoss 0.8877 RecLoss: 0.0000 (left: 0:02:35)\n",
      "TestLoss: 1.0099 MAE: 0.7760 RMSE: 1.0049\n",
      "ValLoss: 1.0843 MAE: 0.8181 RMSE: 1.0413\n",
      "Epoch 71: TrainLoss 0.8850 RecLoss: 0.0000 (left: 0:02:30)\n",
      "TestLoss: 0.9913 MAE: 0.7821 RMSE: 0.9957\n",
      "ValLoss: 1.0586 MAE: 0.8188 RMSE: 1.0289\n",
      "Epoch 72: TrainLoss 0.8821 RecLoss: 0.0000 (left: 0:02:24)\n",
      "TestLoss: 0.9935 MAE: 0.7794 RMSE: 0.9968\n",
      "ValLoss: 1.0635 MAE: 0.8178 RMSE: 1.0313\n",
      "Epoch 73: TrainLoss 0.8818 RecLoss: 0.0000 (left: 0:02:19)\n",
      "TestLoss: 0.9903 MAE: 0.7842 RMSE: 0.9951\n",
      "ValLoss: 1.0560 MAE: 0.8197 RMSE: 1.0276\n",
      "Epoch 74: TrainLoss 0.8823 RecLoss: 0.0000 (left: 0:02:14)\n",
      "TestLoss: 0.9900 MAE: 0.7832 RMSE: 0.9950\n",
      "ValLoss: 1.0572 MAE: 0.8192 RMSE: 1.0282\n",
      "Epoch 75: TrainLoss 0.8813 RecLoss: 0.0000 (left: 0:02:09)\n",
      "TestLoss: 0.9987 MAE: 0.7775 RMSE: 0.9994\n",
      "ValLoss: 1.0696 MAE: 0.8172 RMSE: 1.0342\n",
      "Epoch 76: TrainLoss 0.8837 RecLoss: 0.0000 (left: 0:02:03)\n",
      "TestLoss: 0.9926 MAE: 0.7804 RMSE: 0.9963\n",
      "ValLoss: 1.0610 MAE: 0.8180 RMSE: 1.0300\n",
      "Epoch 77: TrainLoss 0.8824 RecLoss: 0.0000 (left: 0:01:58)\n",
      "TestLoss: 0.9925 MAE: 0.7810 RMSE: 0.9962\n",
      "ValLoss: 1.0602 MAE: 0.8179 RMSE: 1.0297\n",
      "Epoch 78: TrainLoss 0.8825 RecLoss: 0.0000 (left: 0:01:53)\n",
      "TestLoss: 0.9966 MAE: 0.7778 RMSE: 0.9983\n",
      "ValLoss: 1.0684 MAE: 0.8178 RMSE: 1.0336\n",
      "Epoch 79: TrainLoss 0.8820 RecLoss: 0.0000 (left: 0:01:48)\n",
      "TestLoss: 0.9914 MAE: 0.7868 RMSE: 0.9957\n",
      "ValLoss: 1.0554 MAE: 0.8209 RMSE: 1.0273\n",
      "Epoch 80: TrainLoss 0.8821 RecLoss: 0.0000 (left: 0:01:43)\n",
      "TestLoss: 0.9920 MAE: 0.7882 RMSE: 0.9960\n",
      "ValLoss: 1.0551 MAE: 0.8216 RMSE: 1.0272\n",
      "Epoch 81: TrainLoss 0.8808 RecLoss: 0.0000 (left: 0:01:38)\n",
      "TestLoss: 0.9895 MAE: 0.7846 RMSE: 0.9948\n",
      "ValLoss: 1.0557 MAE: 0.8199 RMSE: 1.0275\n",
      "Epoch 82: TrainLoss 0.8844 RecLoss: 0.0000 (left: 0:01:32)\n",
      "TestLoss: 0.9968 MAE: 0.7775 RMSE: 0.9984\n",
      "ValLoss: 1.0681 MAE: 0.8175 RMSE: 1.0335\n",
      "Epoch 83: TrainLoss 0.8878 RecLoss: 0.0000 (left: 0:01:27)\n",
      "TestLoss: 0.9933 MAE: 0.7803 RMSE: 0.9966\n",
      "ValLoss: 1.0618 MAE: 0.8178 RMSE: 1.0304\n",
      "Epoch 84: TrainLoss 0.8805 RecLoss: 0.0000 (left: 0:01:22)\n",
      "TestLoss: 0.9919 MAE: 0.7864 RMSE: 0.9959\n",
      "ValLoss: 1.0570 MAE: 0.8212 RMSE: 1.0281\n",
      "Epoch 85: TrainLoss 0.8824 RecLoss: 0.0000 (left: 0:01:17)\n",
      "TestLoss: 0.9917 MAE: 0.7823 RMSE: 0.9959\n",
      "ValLoss: 1.0587 MAE: 0.8188 RMSE: 1.0289\n",
      "Epoch 86: TrainLoss 0.8826 RecLoss: 0.0000 (left: 0:01:11)\n",
      "TestLoss: 0.9945 MAE: 0.7793 RMSE: 0.9972\n",
      "ValLoss: 1.0640 MAE: 0.8176 RMSE: 1.0315\n",
      "Epoch 87: TrainLoss 0.8824 RecLoss: 0.0000 (left: 0:01:06)\n",
      "TestLoss: 0.9914 MAE: 0.7826 RMSE: 0.9957\n",
      "ValLoss: 1.0584 MAE: 0.8190 RMSE: 1.0288\n",
      "Epoch 88: TrainLoss 0.8842 RecLoss: 0.0000 (left: 0:01:01)\n",
      "TestLoss: 0.9939 MAE: 0.7801 RMSE: 0.9969\n",
      "ValLoss: 1.0630 MAE: 0.8180 RMSE: 1.0310\n",
      "Epoch 89: TrainLoss 0.8828 RecLoss: 0.0000 (left: 0:00:56)\n",
      "TestLoss: 0.9909 MAE: 0.7812 RMSE: 0.9954\n",
      "ValLoss: 1.0592 MAE: 0.8179 RMSE: 1.0292\n",
      "Epoch 90: TrainLoss 0.8814 RecLoss: 0.0000 (left: 0:00:51)\n",
      "TestLoss: 0.9913 MAE: 0.7871 RMSE: 0.9957\n",
      "ValLoss: 1.0563 MAE: 0.8214 RMSE: 1.0278\n",
      "Epoch 91: TrainLoss 0.8831 RecLoss: 0.0000 (left: 0:00:46)\n",
      "TestLoss: 0.9903 MAE: 0.7833 RMSE: 0.9952\n",
      "ValLoss: 1.0571 MAE: 0.8192 RMSE: 1.0282\n",
      "Epoch 92: TrainLoss 0.8810 RecLoss: 0.0000 (left: 0:00:40)\n",
      "TestLoss: 0.9905 MAE: 0.7840 RMSE: 0.9952\n",
      "ValLoss: 1.0564 MAE: 0.8196 RMSE: 1.0278\n",
      "Epoch 93: TrainLoss 0.8810 RecLoss: 0.0000 (left: 0:00:35)\n",
      "TestLoss: 0.9933 MAE: 0.7902 RMSE: 0.9967\n",
      "ValLoss: 1.0560 MAE: 0.8232 RMSE: 1.0276\n",
      "Epoch 94: TrainLoss 0.8848 RecLoss: 0.0000 (left: 0:00:30)\n",
      "TestLoss: 0.9913 MAE: 0.7822 RMSE: 0.9956\n",
      "ValLoss: 1.0581 MAE: 0.8182 RMSE: 1.0286\n",
      "Epoch 95: TrainLoss 0.8837 RecLoss: 0.0000 (left: 0:00:25)\n",
      "TestLoss: 0.9919 MAE: 0.7815 RMSE: 0.9960\n",
      "ValLoss: 1.0597 MAE: 0.8187 RMSE: 1.0294\n",
      "Epoch 96: TrainLoss 0.8819 RecLoss: 0.0000 (left: 0:00:20)\n",
      "TestLoss: 0.9978 MAE: 0.7775 RMSE: 0.9989\n",
      "ValLoss: 1.0676 MAE: 0.8165 RMSE: 1.0333\n",
      "Epoch 97: TrainLoss 0.8824 RecLoss: 0.0000 (left: 0:00:15)\n",
      "TestLoss: 0.9909 MAE: 0.7836 RMSE: 0.9954\n",
      "ValLoss: 1.0572 MAE: 0.8194 RMSE: 1.0282\n",
      "Epoch 98: TrainLoss 0.8805 RecLoss: 0.0000 (left: 0:00:10)\n",
      "TestLoss: 0.9905 MAE: 0.7855 RMSE: 0.9952\n",
      "ValLoss: 1.0555 MAE: 0.8201 RMSE: 1.0274\n",
      "Epoch 99: TrainLoss 0.8805 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 0.9916 MAE: 0.7880 RMSE: 0.9958\n",
      "ValLoss: 1.0558 MAE: 0.8220 RMSE: 1.0275\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 601508/19100\n",
      "test set size: support/query 2092/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.6893 RMSE: 0.8690 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7844 RMSE: 0.9906 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7158 RMSE: 0.9046 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10% optimal cur to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 321973/19100\n",
      "test set size: support/query 523/809\n",
      "Epoch 0 Step 299: Train 2.4073 Reg: 0.5220\n",
      "Test: 0.7121 MAE: 0.6744 RMSE: 0.8439\n",
      "Val: 0.8141 MAE: 0.7106 RMSE: 0.9023\n",
      "Epoch 1 Step 598: Train 0.7942 Reg: 0.4424\n",
      "Test: 0.6925 MAE: 0.6669 RMSE: 0.8322\n",
      "Val: 0.8084 MAE: 0.7104 RMSE: 0.8991\n",
      "Epoch 2 Step 897: Train 0.7902 Reg: 0.3834\n",
      "Test: 0.6863 MAE: 0.6577 RMSE: 0.8284\n",
      "Val: 0.8066 MAE: 0.7080 RMSE: 0.8981\n",
      "Epoch 3 Step 1196: Train 0.7875 Reg: 0.3426\n",
      "Test: 0.6751 MAE: 0.6581 RMSE: 0.8216\n",
      "Val: 0.8069 MAE: 0.7094 RMSE: 0.8983\n",
      "Epoch 4 Step 1495: Train 0.7847 Reg: 0.3154\n",
      "Test: 0.6914 MAE: 0.6637 RMSE: 0.8315\n",
      "Val: 0.8040 MAE: 0.7060 RMSE: 0.8966\n",
      "Epoch 5 Step 1794: Train 0.7814 Reg: 0.2948\n",
      "Test: 0.6873 MAE: 0.6575 RMSE: 0.8290\n",
      "Val: 0.8003 MAE: 0.7055 RMSE: 0.8946\n",
      "Epoch 6 Step 2093: Train 0.7780 Reg: 0.2793\n",
      "Test: 0.6755 MAE: 0.6528 RMSE: 0.8219\n",
      "Val: 0.7938 MAE: 0.7017 RMSE: 0.8910\n",
      "Epoch 7 Step 2392: Train 0.7721 Reg: 0.2688\n",
      "Test: 0.6968 MAE: 0.6628 RMSE: 0.8347\n",
      "Val: 0.7909 MAE: 0.7011 RMSE: 0.8893\n",
      "Epoch 8 Step 2691: Train 0.7664 Reg: 0.2613\n",
      "Test: 0.6771 MAE: 0.6503 RMSE: 0.8229\n",
      "Val: 0.7833 MAE: 0.6947 RMSE: 0.8851\n",
      "Epoch 9 Step 2990: Train 0.7585 Reg: 0.2577\n",
      "Test: 0.6610 MAE: 0.6424 RMSE: 0.8130\n",
      "Val: 0.7769 MAE: 0.6908 RMSE: 0.8814\n",
      "Epoch 10 Step 3289: Train 0.7510 Reg: 0.2554\n",
      "Test: 0.6705 MAE: 0.6497 RMSE: 0.8188\n",
      "Val: 0.7691 MAE: 0.6877 RMSE: 0.8770\n",
      "Epoch 11 Step 3588: Train 0.7429 Reg: 0.2525\n",
      "Test: 0.6681 MAE: 0.6472 RMSE: 0.8174\n",
      "Val: 0.7650 MAE: 0.6832 RMSE: 0.8746\n",
      "Epoch 12 Step 3887: Train 0.7318 Reg: 0.2522\n",
      "Test: 0.6676 MAE: 0.6548 RMSE: 0.8170\n",
      "Val: 0.7515 MAE: 0.6798 RMSE: 0.8669\n",
      "Epoch 13 Step 4186: Train 0.7207 Reg: 0.2538\n",
      "Test: 0.6614 MAE: 0.6470 RMSE: 0.8133\n",
      "Val: 0.7468 MAE: 0.6736 RMSE: 0.8642\n",
      "Epoch 14 Step 4485: Train 0.7100 Reg: 0.2569\n",
      "Test: 0.6853 MAE: 0.6587 RMSE: 0.8278\n",
      "Val: 0.7411 MAE: 0.6734 RMSE: 0.8609\n",
      "Epoch 15 Step 4784: Train 0.6993 Reg: 0.2613\n",
      "Test: 0.6659 MAE: 0.6504 RMSE: 0.8160\n",
      "Val: 0.7377 MAE: 0.6686 RMSE: 0.8589\n",
      "Epoch 16 Step 5083: Train 0.6854 Reg: 0.2696\n",
      "Test: 0.6668 MAE: 0.6573 RMSE: 0.8166\n",
      "Val: 0.7306 MAE: 0.6680 RMSE: 0.8547\n",
      "Epoch 17 Step 5382: Train 0.6699 Reg: 0.2811\n",
      "Test: 0.6503 MAE: 0.6454 RMSE: 0.8064\n",
      "Val: 0.7289 MAE: 0.6655 RMSE: 0.8538\n",
      "Epoch 18 Step 5681: Train 0.6532 Reg: 0.2945\n",
      "Test: 0.6618 MAE: 0.6533 RMSE: 0.8135\n",
      "Val: 0.7277 MAE: 0.6655 RMSE: 0.8531\n",
      "Epoch 19 Step 5980: Train 0.6341 Reg: 0.3091\n",
      "Test: 0.6620 MAE: 0.6449 RMSE: 0.8136\n",
      "Val: 0.7275 MAE: 0.6639 RMSE: 0.8529\n",
      "Epoch 20 Step 6279: Train 0.6128 Reg: 0.3234\n",
      "Test: 0.6667 MAE: 0.6508 RMSE: 0.8165\n",
      "Val: 0.7271 MAE: 0.6637 RMSE: 0.8527\n",
      "Epoch 21 Step 6578: Train 0.5928 Reg: 0.3356\n",
      "Test: 0.6729 MAE: 0.6485 RMSE: 0.8203\n",
      "Val: 0.7310 MAE: 0.6634 RMSE: 0.8550\n",
      "Epoch 22 Step 6877: Train 0.5742 Reg: 0.3469\n",
      "Test: 0.6821 MAE: 0.6552 RMSE: 0.8259\n",
      "Val: 0.7333 MAE: 0.6666 RMSE: 0.8563\n",
      "Epoch 23 Step 7176: Train 0.5537 Reg: 0.3601\n",
      "Test: 0.6791 MAE: 0.6502 RMSE: 0.8241\n",
      "Val: 0.7390 MAE: 0.6671 RMSE: 0.8597\n",
      "Epoch 24 Step 7475: Train 0.5319 Reg: 0.3745\n",
      "Test: 0.6790 MAE: 0.6471 RMSE: 0.8240\n",
      "Val: 0.7482 MAE: 0.6692 RMSE: 0.8650\n",
      "Epoch 25 Step 7774: Train 0.5104 Reg: 0.3880\n",
      "Test: 0.6892 MAE: 0.6540 RMSE: 0.8302\n",
      "Val: 0.7564 MAE: 0.6724 RMSE: 0.8697\n",
      "Epoch 26 Step 8073: Train 0.4899 Reg: 0.3999\n",
      "Test: 0.7077 MAE: 0.6653 RMSE: 0.8413\n",
      "Val: 0.7674 MAE: 0.6780 RMSE: 0.8760\n",
      "Epoch 27 Step 8372: Train 0.4718 Reg: 0.4090\n",
      "Test: 0.7224 MAE: 0.6703 RMSE: 0.8500\n",
      "Val: 0.7798 MAE: 0.6838 RMSE: 0.8831\n",
      "Epoch 28 Step 8671: Train 0.4571 Reg: 0.4151\n",
      "Test: 0.7247 MAE: 0.6695 RMSE: 0.8513\n",
      "Val: 0.7909 MAE: 0.6866 RMSE: 0.8893\n",
      "Epoch 29 Step 8970: Train 0.4446 Reg: 0.4196\n",
      "Test: 0.7298 MAE: 0.6683 RMSE: 0.8543\n",
      "Val: 0.8015 MAE: 0.6907 RMSE: 0.8952\n",
      "Epoch 30 Step 9269: Train 0.4341 Reg: 0.4227\n",
      "Test: 0.7476 MAE: 0.6785 RMSE: 0.8646\n",
      "Val: 0.8116 MAE: 0.6955 RMSE: 0.9009\n",
      "Epoch 31 Step 9568: Train 0.4248 Reg: 0.4245\n",
      "Test: 0.7551 MAE: 0.6821 RMSE: 0.8690\n",
      "Val: 0.8208 MAE: 0.6993 RMSE: 0.9060\n",
      "Epoch 32 Step 9867: Train 0.4164 Reg: 0.4257\n",
      "Test: 0.7533 MAE: 0.6786 RMSE: 0.8679\n",
      "Val: 0.8286 MAE: 0.7011 RMSE: 0.9103\n",
      "Epoch 33 Step 10166: Train 0.4098 Reg: 0.4256\n",
      "Test: 0.7623 MAE: 0.6850 RMSE: 0.8731\n",
      "Val: 0.8368 MAE: 0.7048 RMSE: 0.9148\n",
      "Epoch 34 Step 10465: Train 0.4041 Reg: 0.4251\n",
      "Test: 0.7698 MAE: 0.6860 RMSE: 0.8774\n",
      "Val: 0.8452 MAE: 0.7077 RMSE: 0.9194\n",
      "Epoch 35 Step 10764: Train 0.3996 Reg: 0.4239\n",
      "Test: 0.7843 MAE: 0.6929 RMSE: 0.8856\n",
      "Val: 0.8515 MAE: 0.7107 RMSE: 0.9228\n",
      "Epoch 36 Step 11063: Train 0.3955 Reg: 0.4224\n",
      "Test: 0.7837 MAE: 0.6908 RMSE: 0.8853\n",
      "Val: 0.8592 MAE: 0.7129 RMSE: 0.9269\n",
      "Epoch 37 Step 11362: Train 0.3919 Reg: 0.4208\n",
      "Test: 0.7863 MAE: 0.6923 RMSE: 0.8867\n",
      "Val: 0.8649 MAE: 0.7148 RMSE: 0.9300\n",
      "Epoch 38 Step 11661: Train 0.3887 Reg: 0.4191\n",
      "Test: 0.7952 MAE: 0.6971 RMSE: 0.8917\n",
      "Val: 0.8699 MAE: 0.7174 RMSE: 0.9327\n",
      "Epoch 39 Step 11960: Train 0.3856 Reg: 0.4174\n",
      "Test: 0.8053 MAE: 0.7013 RMSE: 0.8974\n",
      "Val: 0.8751 MAE: 0.7187 RMSE: 0.9355\n",
      "Epoch 40 Step 12259: Train 0.3828 Reg: 0.4155\n",
      "Test: 0.8126 MAE: 0.7058 RMSE: 0.9014\n",
      "Val: 0.8806 MAE: 0.7210 RMSE: 0.9384\n",
      "Epoch 41 Step 12558: Train 0.3802 Reg: 0.4138\n",
      "Test: 0.8128 MAE: 0.7032 RMSE: 0.9016\n",
      "Val: 0.8849 MAE: 0.7221 RMSE: 0.9407\n",
      "Epoch 42 Step 12857: Train 0.3777 Reg: 0.4121\n",
      "Test: 0.8171 MAE: 0.7045 RMSE: 0.9040\n",
      "Val: 0.8901 MAE: 0.7236 RMSE: 0.9435\n",
      "Epoch 43 Step 13156: Train 0.3756 Reg: 0.4103\n",
      "Test: 0.8213 MAE: 0.7076 RMSE: 0.9063\n",
      "Val: 0.8937 MAE: 0.7253 RMSE: 0.9454\n",
      "Epoch 44 Step 13455: Train 0.3733 Reg: 0.4086\n",
      "Test: 0.8319 MAE: 0.7131 RMSE: 0.9121\n",
      "Val: 0.8991 MAE: 0.7275 RMSE: 0.9482\n",
      "Epoch 45 Step 13754: Train 0.3712 Reg: 0.4069\n",
      "Test: 0.8313 MAE: 0.7109 RMSE: 0.9117\n",
      "Val: 0.9030 MAE: 0.7284 RMSE: 0.9503\n",
      "Epoch 46 Step 14053: Train 0.3692 Reg: 0.4054\n",
      "Test: 0.8372 MAE: 0.7123 RMSE: 0.9150\n",
      "Val: 0.9064 MAE: 0.7293 RMSE: 0.9521\n",
      "Epoch 47 Step 14352: Train 0.3673 Reg: 0.4038\n",
      "Test: 0.8391 MAE: 0.7130 RMSE: 0.9160\n",
      "Val: 0.9085 MAE: 0.7304 RMSE: 0.9531\n",
      "Epoch 48 Step 14651: Train 0.3654 Reg: 0.4024\n",
      "Test: 0.8419 MAE: 0.7143 RMSE: 0.9176\n",
      "Val: 0.9130 MAE: 0.7318 RMSE: 0.9555\n",
      "Epoch 49 Step 14950: Train 0.3635 Reg: 0.4010\n",
      "Test: 0.8415 MAE: 0.7132 RMSE: 0.9173\n",
      "Val: 0.9168 MAE: 0.7325 RMSE: 0.9575\n",
      "Epoch 50 Step 15249: Train 0.3618 Reg: 0.3997\n",
      "Test: 0.8449 MAE: 0.7153 RMSE: 0.9192\n",
      "Val: 0.9199 MAE: 0.7336 RMSE: 0.9591\n",
      "Epoch 51 Step 15548: Train 0.3599 Reg: 0.3984\n",
      "Test: 0.8462 MAE: 0.7148 RMSE: 0.9199\n",
      "Val: 0.9235 MAE: 0.7346 RMSE: 0.9610\n",
      "Epoch 52 Step 15847: Train 0.3584 Reg: 0.3972\n",
      "Test: 0.8508 MAE: 0.7174 RMSE: 0.9224\n",
      "Val: 0.9259 MAE: 0.7357 RMSE: 0.9623\n",
      "Epoch 53 Step 16146: Train 0.3566 Reg: 0.3961\n",
      "Test: 0.8578 MAE: 0.7206 RMSE: 0.9262\n",
      "Val: 0.9287 MAE: 0.7370 RMSE: 0.9637\n",
      "Epoch 54 Step 16445: Train 0.3551 Reg: 0.3950\n",
      "Test: 0.8629 MAE: 0.7221 RMSE: 0.9289\n",
      "Val: 0.9316 MAE: 0.7380 RMSE: 0.9652\n",
      "Epoch 55 Step 16744: Train 0.3537 Reg: 0.3938\n",
      "Test: 0.8701 MAE: 0.7264 RMSE: 0.9328\n",
      "Val: 0.9359 MAE: 0.7402 RMSE: 0.9674\n",
      "Epoch 56 Step 17043: Train 0.3524 Reg: 0.3928\n",
      "Test: 0.8693 MAE: 0.7249 RMSE: 0.9324\n",
      "Val: 0.9372 MAE: 0.7402 RMSE: 0.9681\n",
      "Epoch 57 Step 17342: Train 0.3510 Reg: 0.3918\n",
      "Test: 0.8702 MAE: 0.7248 RMSE: 0.9329\n",
      "Val: 0.9398 MAE: 0.7407 RMSE: 0.9694\n",
      "Epoch 58 Step 17641: Train 0.3499 Reg: 0.3907\n",
      "Test: 0.8684 MAE: 0.7230 RMSE: 0.9319\n",
      "Val: 0.9423 MAE: 0.7410 RMSE: 0.9707\n",
      "Epoch 59 Step 17940: Train 0.3488 Reg: 0.3897\n",
      "Test: 0.8729 MAE: 0.7251 RMSE: 0.9343\n",
      "Val: 0.9438 MAE: 0.7417 RMSE: 0.9715\n",
      "Epoch 60 Step 18239: Train 0.3478 Reg: 0.3887\n",
      "Test: 0.8746 MAE: 0.7258 RMSE: 0.9352\n",
      "Val: 0.9454 MAE: 0.7425 RMSE: 0.9723\n",
      "Epoch 61 Step 18538: Train 0.3468 Reg: 0.3878\n",
      "Test: 0.8720 MAE: 0.7241 RMSE: 0.9338\n",
      "Val: 0.9478 MAE: 0.7427 RMSE: 0.9736\n",
      "Epoch 62 Step 18837: Train 0.3459 Reg: 0.3869\n",
      "Test: 0.8783 MAE: 0.7274 RMSE: 0.9372\n",
      "Val: 0.9496 MAE: 0.7438 RMSE: 0.9745\n",
      "Epoch 63 Step 19136: Train 0.3451 Reg: 0.3860\n",
      "Test: 0.8814 MAE: 0.7285 RMSE: 0.9388\n",
      "Val: 0.9517 MAE: 0.7448 RMSE: 0.9755\n",
      "Epoch 64 Step 19435: Train 0.3443 Reg: 0.3851\n",
      "Test: 0.8802 MAE: 0.7275 RMSE: 0.9382\n",
      "Val: 0.9533 MAE: 0.7450 RMSE: 0.9764\n",
      "Epoch 65 Step 19734: Train 0.3435 Reg: 0.3843\n",
      "Test: 0.8827 MAE: 0.7285 RMSE: 0.9395\n",
      "Val: 0.9549 MAE: 0.7455 RMSE: 0.9772\n",
      "Epoch 66 Step 20033: Train 0.3428 Reg: 0.3835\n",
      "Test: 0.8842 MAE: 0.7287 RMSE: 0.9403\n",
      "Val: 0.9565 MAE: 0.7460 RMSE: 0.9780\n",
      "Epoch 67 Step 20332: Train 0.3422 Reg: 0.3827\n",
      "Test: 0.8878 MAE: 0.7298 RMSE: 0.9422\n",
      "Val: 0.9578 MAE: 0.7466 RMSE: 0.9787\n",
      "Epoch 68 Step 20631: Train 0.3415 Reg: 0.3820\n",
      "Test: 0.8873 MAE: 0.7298 RMSE: 0.9420\n",
      "Val: 0.9595 MAE: 0.7471 RMSE: 0.9796\n",
      "Epoch 69 Step 20930: Train 0.3409 Reg: 0.3813\n",
      "Test: 0.8920 MAE: 0.7319 RMSE: 0.9444\n",
      "Val: 0.9606 MAE: 0.7476 RMSE: 0.9801\n",
      "Epoch 70 Step 21229: Train 0.3404 Reg: 0.3807\n",
      "Test: 0.8898 MAE: 0.7304 RMSE: 0.9433\n",
      "Val: 0.9619 MAE: 0.7476 RMSE: 0.9807\n",
      "Epoch 71 Step 21528: Train 0.3398 Reg: 0.3800\n",
      "Test: 0.8918 MAE: 0.7317 RMSE: 0.9444\n",
      "Val: 0.9632 MAE: 0.7483 RMSE: 0.9814\n",
      "Epoch 72 Step 21827: Train 0.3393 Reg: 0.3794\n",
      "Test: 0.8960 MAE: 0.7334 RMSE: 0.9466\n",
      "Val: 0.9642 MAE: 0.7490 RMSE: 0.9819\n",
      "Epoch 73 Step 22126: Train 0.3389 Reg: 0.3788\n",
      "Test: 0.8956 MAE: 0.7328 RMSE: 0.9464\n",
      "Val: 0.9651 MAE: 0.7490 RMSE: 0.9824\n",
      "Epoch 74 Step 22425: Train 0.3384 Reg: 0.3783\n",
      "Test: 0.8946 MAE: 0.7321 RMSE: 0.9458\n",
      "Val: 0.9663 MAE: 0.7492 RMSE: 0.9830\n",
      "Epoch 75 Step 22724: Train 0.3380 Reg: 0.3777\n",
      "Test: 0.8976 MAE: 0.7335 RMSE: 0.9474\n",
      "Val: 0.9672 MAE: 0.7498 RMSE: 0.9835\n",
      "Epoch 76 Step 23023: Train 0.3376 Reg: 0.3772\n",
      "Test: 0.8982 MAE: 0.7335 RMSE: 0.9477\n",
      "Val: 0.9678 MAE: 0.7498 RMSE: 0.9838\n",
      "Epoch 77 Step 23322: Train 0.3372 Reg: 0.3767\n",
      "Test: 0.8999 MAE: 0.7340 RMSE: 0.9486\n",
      "Val: 0.9688 MAE: 0.7502 RMSE: 0.9843\n",
      "Epoch 78 Step 23621: Train 0.3369 Reg: 0.3762\n",
      "Test: 0.9005 MAE: 0.7345 RMSE: 0.9489\n",
      "Val: 0.9696 MAE: 0.7505 RMSE: 0.9847\n",
      "Epoch 79 Step 23920: Train 0.3365 Reg: 0.3758\n",
      "Test: 0.8991 MAE: 0.7334 RMSE: 0.9482\n",
      "Val: 0.9703 MAE: 0.7505 RMSE: 0.9851\n",
      "Epoch 80 Step 24219: Train 0.3362 Reg: 0.3753\n",
      "Test: 0.9021 MAE: 0.7348 RMSE: 0.9498\n",
      "Val: 0.9710 MAE: 0.7509 RMSE: 0.9854\n",
      "Epoch 81 Step 24518: Train 0.3359 Reg: 0.3750\n",
      "Test: 0.9020 MAE: 0.7345 RMSE: 0.9497\n",
      "Val: 0.9719 MAE: 0.7511 RMSE: 0.9859\n",
      "Epoch 82 Step 24817: Train 0.3356 Reg: 0.3746\n",
      "Test: 0.9025 MAE: 0.7345 RMSE: 0.9500\n",
      "Val: 0.9725 MAE: 0.7513 RMSE: 0.9861\n",
      "Epoch 83 Step 25116: Train 0.3353 Reg: 0.3742\n",
      "Test: 0.9042 MAE: 0.7353 RMSE: 0.9509\n",
      "Val: 0.9732 MAE: 0.7515 RMSE: 0.9865\n",
      "Epoch 84 Step 25415: Train 0.3351 Reg: 0.3738\n",
      "Test: 0.9067 MAE: 0.7367 RMSE: 0.9522\n",
      "Val: 0.9741 MAE: 0.7521 RMSE: 0.9870\n",
      "Epoch 85 Step 25714: Train 0.3348 Reg: 0.3735\n",
      "Test: 0.9044 MAE: 0.7352 RMSE: 0.9510\n",
      "Val: 0.9745 MAE: 0.7518 RMSE: 0.9872\n",
      "Epoch 86 Step 26013: Train 0.3346 Reg: 0.3732\n",
      "Test: 0.9070 MAE: 0.7365 RMSE: 0.9524\n",
      "Val: 0.9750 MAE: 0.7523 RMSE: 0.9874\n",
      "Epoch 87 Step 26312: Train 0.3344 Reg: 0.3729\n",
      "Test: 0.9049 MAE: 0.7351 RMSE: 0.9513\n",
      "Val: 0.9754 MAE: 0.7520 RMSE: 0.9876\n",
      "Epoch 88 Step 26611: Train 0.3342 Reg: 0.3726\n",
      "Test: 0.9054 MAE: 0.7352 RMSE: 0.9515\n",
      "Val: 0.9758 MAE: 0.7522 RMSE: 0.9878\n",
      "Epoch 89 Step 26910: Train 0.3340 Reg: 0.3723\n",
      "Test: 0.9060 MAE: 0.7354 RMSE: 0.9518\n",
      "Val: 0.9762 MAE: 0.7523 RMSE: 0.9880\n",
      "Epoch 90 Step 27209: Train 0.3338 Reg: 0.3720\n",
      "Test: 0.9064 MAE: 0.7355 RMSE: 0.9521\n",
      "Val: 0.9768 MAE: 0.7525 RMSE: 0.9883\n",
      "Epoch 91 Step 27508: Train 0.3336 Reg: 0.3718\n",
      "Test: 0.9088 MAE: 0.7367 RMSE: 0.9533\n",
      "Val: 0.9772 MAE: 0.7528 RMSE: 0.9886\n",
      "Epoch 92 Step 27807: Train 0.3334 Reg: 0.3715\n",
      "Test: 0.9081 MAE: 0.7362 RMSE: 0.9529\n",
      "Val: 0.9776 MAE: 0.7528 RMSE: 0.9887\n",
      "Epoch 93 Step 28106: Train 0.3332 Reg: 0.3713\n",
      "Test: 0.9089 MAE: 0.7366 RMSE: 0.9534\n",
      "Val: 0.9780 MAE: 0.7529 RMSE: 0.9889\n",
      "Epoch 94 Step 28405: Train 0.3331 Reg: 0.3711\n",
      "Test: 0.9079 MAE: 0.7359 RMSE: 0.9529\n",
      "Val: 0.9782 MAE: 0.7529 RMSE: 0.9891\n",
      "Epoch 95 Step 28704: Train 0.3329 Reg: 0.3709\n",
      "Test: 0.9088 MAE: 0.7364 RMSE: 0.9533\n",
      "Val: 0.9786 MAE: 0.7530 RMSE: 0.9892\n",
      "Epoch 96 Step 29003: Train 0.3328 Reg: 0.3707\n",
      "Test: 0.9088 MAE: 0.7362 RMSE: 0.9533\n",
      "Val: 0.9789 MAE: 0.7531 RMSE: 0.9894\n",
      "Epoch 97 Step 29302: Train 0.3327 Reg: 0.3705\n",
      "Test: 0.9109 MAE: 0.7373 RMSE: 0.9544\n",
      "Val: 0.9793 MAE: 0.7534 RMSE: 0.9896\n",
      "Epoch 98 Step 29601: Train 0.3325 Reg: 0.3703\n",
      "Test: 0.9108 MAE: 0.7372 RMSE: 0.9544\n",
      "Val: 0.9796 MAE: 0.7535 RMSE: 0.9897\n",
      "Epoch 99 Step 29900: Train 0.3324 Reg: 0.3702\n",
      "Test: 0.9103 MAE: 0.7368 RMSE: 0.9541\n",
      "Val: 0.9798 MAE: 0.7535 RMSE: 0.9898\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 321973/19100\n",
      "test set size: support/query 523/809\n",
      "Epoch 0: TrainLoss 1.0571 RecLoss: 0.0000 (left: 0:33:42)\n",
      "TestLoss: 1.0762 MAE: 0.8208 RMSE: 1.0374\n",
      "ValLoss: 1.1268 MAE: 0.8486 RMSE: 1.0615\n",
      "Epoch 1: TrainLoss 1.0460 RecLoss: 0.0000 (left: 0:28:29)\n",
      "TestLoss: 1.0732 MAE: 0.8223 RMSE: 1.0360\n",
      "ValLoss: 1.1193 MAE: 0.8487 RMSE: 1.0580\n",
      "Epoch 2: TrainLoss 1.0401 RecLoss: 0.0000 (left: 0:26:41)\n",
      "TestLoss: 1.0722 MAE: 0.8240 RMSE: 1.0355\n",
      "ValLoss: 1.1151 MAE: 0.8490 RMSE: 1.0560\n",
      "Epoch 3: TrainLoss 1.0373 RecLoss: 0.0000 (left: 0:26:16)\n",
      "TestLoss: 1.0640 MAE: 0.8146 RMSE: 1.0315\n",
      "ValLoss: 1.1180 MAE: 0.8428 RMSE: 1.0574\n",
      "Epoch 4: TrainLoss 1.0337 RecLoss: 0.0000 (left: 0:26:18)\n",
      "TestLoss: 1.0657 MAE: 0.8221 RMSE: 1.0323\n",
      "ValLoss: 1.1093 MAE: 0.8473 RMSE: 1.0532\n",
      "Epoch 5: TrainLoss 1.0283 RecLoss: 0.0000 (left: 0:26:06)\n",
      "TestLoss: 1.0634 MAE: 0.8224 RMSE: 1.0312\n",
      "ValLoss: 1.1058 MAE: 0.8468 RMSE: 1.0516\n",
      "Epoch 6: TrainLoss 1.0231 RecLoss: 0.0000 (left: 0:25:48)\n",
      "TestLoss: 1.0556 MAE: 0.8123 RMSE: 1.0274\n",
      "ValLoss: 1.1066 MAE: 0.8401 RMSE: 1.0519\n",
      "Epoch 7: TrainLoss 1.0195 RecLoss: 0.0000 (left: 0:25:21)\n",
      "TestLoss: 1.0529 MAE: 0.8116 RMSE: 1.0261\n",
      "ValLoss: 1.1028 MAE: 0.8396 RMSE: 1.0501\n",
      "Epoch 8: TrainLoss 1.0166 RecLoss: 0.0000 (left: 0:25:08)\n",
      "TestLoss: 1.0528 MAE: 0.8156 RMSE: 1.0260\n",
      "ValLoss: 1.0972 MAE: 0.8412 RMSE: 1.0475\n",
      "Epoch 9: TrainLoss 1.0140 RecLoss: 0.0000 (left: 0:24:56)\n",
      "TestLoss: 1.0479 MAE: 0.8087 RMSE: 1.0237\n",
      "ValLoss: 1.0996 MAE: 0.8364 RMSE: 1.0486\n",
      "Epoch 10: TrainLoss 1.0091 RecLoss: 0.0000 (left: 0:24:32)\n",
      "TestLoss: 1.0456 MAE: 0.8105 RMSE: 1.0226\n",
      "ValLoss: 1.0928 MAE: 0.8369 RMSE: 1.0454\n",
      "Epoch 11: TrainLoss 1.0058 RecLoss: 0.0000 (left: 0:24:23)\n",
      "TestLoss: 1.0477 MAE: 0.8154 RMSE: 1.0236\n",
      "ValLoss: 1.0905 MAE: 0.8399 RMSE: 1.0443\n",
      "Epoch 12: TrainLoss 1.0026 RecLoss: 0.0000 (left: 0:23:57)\n",
      "TestLoss: 1.0419 MAE: 0.8106 RMSE: 1.0207\n",
      "ValLoss: 1.0874 MAE: 0.8360 RMSE: 1.0428\n",
      "Epoch 13: TrainLoss 0.9996 RecLoss: 0.0000 (left: 0:23:34)\n",
      "TestLoss: 1.0396 MAE: 0.8068 RMSE: 1.0196\n",
      "ValLoss: 1.0879 MAE: 0.8337 RMSE: 1.0430\n",
      "Epoch 14: TrainLoss 0.9970 RecLoss: 0.0000 (left: 0:23:01)\n",
      "TestLoss: 1.0407 MAE: 0.8129 RMSE: 1.0201\n",
      "ValLoss: 1.0832 MAE: 0.8368 RMSE: 1.0408\n",
      "Epoch 15: TrainLoss 0.9934 RecLoss: 0.0000 (left: 0:22:29)\n",
      "TestLoss: 1.0364 MAE: 0.8085 RMSE: 1.0180\n",
      "ValLoss: 1.0806 MAE: 0.8335 RMSE: 1.0395\n",
      "Epoch 16: TrainLoss 0.9911 RecLoss: 0.0000 (left: 0:22:06)\n",
      "TestLoss: 1.0363 MAE: 0.8109 RMSE: 1.0180\n",
      "ValLoss: 1.0785 MAE: 0.8349 RMSE: 1.0385\n",
      "Epoch 17: TrainLoss 0.9887 RecLoss: 0.0000 (left: 0:21:44)\n",
      "TestLoss: 1.0322 MAE: 0.8030 RMSE: 1.0160\n",
      "ValLoss: 1.0817 MAE: 0.8309 RMSE: 1.0400\n",
      "Epoch 18: TrainLoss 0.9863 RecLoss: 0.0000 (left: 0:21:32)\n",
      "TestLoss: 1.0306 MAE: 0.8042 RMSE: 1.0152\n",
      "ValLoss: 1.0773 MAE: 0.8304 RMSE: 1.0379\n",
      "Epoch 19: TrainLoss 0.9837 RecLoss: 0.0000 (left: 0:21:20)\n",
      "TestLoss: 1.0309 MAE: 0.8075 RMSE: 1.0153\n",
      "ValLoss: 1.0744 MAE: 0.8322 RMSE: 1.0365\n",
      "Epoch 20: TrainLoss 0.9814 RecLoss: 0.0000 (left: 0:21:00)\n",
      "TestLoss: 1.0276 MAE: 0.8038 RMSE: 1.0137\n",
      "ValLoss: 1.0731 MAE: 0.8293 RMSE: 1.0359\n",
      "Epoch 21: TrainLoss 0.9793 RecLoss: 0.0000 (left: 0:20:51)\n",
      "TestLoss: 1.0308 MAE: 0.8117 RMSE: 1.0153\n",
      "ValLoss: 1.0690 MAE: 0.8331 RMSE: 1.0339\n",
      "Epoch 22: TrainLoss 0.9776 RecLoss: 0.0000 (left: 0:20:22)\n",
      "TestLoss: 1.0252 MAE: 0.8037 RMSE: 1.0125\n",
      "ValLoss: 1.0692 MAE: 0.8284 RMSE: 1.0340\n",
      "Epoch 23: TrainLoss 0.9742 RecLoss: 0.0000 (left: 0:20:00)\n",
      "TestLoss: 1.0305 MAE: 0.8127 RMSE: 1.0151\n",
      "ValLoss: 1.0680 MAE: 0.8338 RMSE: 1.0334\n",
      "Epoch 24: TrainLoss 0.9749 RecLoss: 0.0000 (left: 0:19:38)\n",
      "TestLoss: 1.0245 MAE: 0.8069 RMSE: 1.0122\n",
      "ValLoss: 1.0655 MAE: 0.8301 RMSE: 1.0322\n",
      "Epoch 25: TrainLoss 0.9698 RecLoss: 0.0000 (left: 0:19:17)\n",
      "TestLoss: 1.0240 MAE: 0.8077 RMSE: 1.0119\n",
      "ValLoss: 1.0633 MAE: 0.8298 RMSE: 1.0312\n",
      "Epoch 26: TrainLoss 0.9691 RecLoss: 0.0000 (left: 0:18:50)\n",
      "TestLoss: 1.0229 MAE: 0.8070 RMSE: 1.0114\n",
      "ValLoss: 1.0625 MAE: 0.8293 RMSE: 1.0308\n",
      "Epoch 27: TrainLoss 0.9668 RecLoss: 0.0000 (left: 0:18:29)\n",
      "TestLoss: 1.0203 MAE: 0.8047 RMSE: 1.0101\n",
      "ValLoss: 1.0608 MAE: 0.8277 RMSE: 1.0299\n",
      "Epoch 28: TrainLoss 0.9653 RecLoss: 0.0000 (left: 0:18:10)\n",
      "TestLoss: 1.0211 MAE: 0.8068 RMSE: 1.0105\n",
      "ValLoss: 1.0600 MAE: 0.8287 RMSE: 1.0296\n",
      "Epoch 29: TrainLoss 0.9632 RecLoss: 0.0000 (left: 0:17:55)\n",
      "TestLoss: 1.0189 MAE: 0.8050 RMSE: 1.0094\n",
      "ValLoss: 1.0582 MAE: 0.8271 RMSE: 1.0287\n",
      "Epoch 30: TrainLoss 0.9622 RecLoss: 0.0000 (left: 0:17:35)\n",
      "TestLoss: 1.0158 MAE: 0.7988 RMSE: 1.0079\n",
      "ValLoss: 1.0608 MAE: 0.8248 RMSE: 1.0299\n",
      "Epoch 31: TrainLoss 0.9602 RecLoss: 0.0000 (left: 0:17:21)\n",
      "TestLoss: 1.0142 MAE: 0.7982 RMSE: 1.0071\n",
      "ValLoss: 1.0587 MAE: 0.8236 RMSE: 1.0289\n",
      "Epoch 32: TrainLoss 0.9580 RecLoss: 0.0000 (left: 0:17:03)\n",
      "TestLoss: 1.0138 MAE: 0.7998 RMSE: 1.0069\n",
      "ValLoss: 1.0563 MAE: 0.8243 RMSE: 1.0277\n",
      "Epoch 33: TrainLoss 0.9568 RecLoss: 0.0000 (left: 0:16:45)\n",
      "TestLoss: 1.0136 MAE: 0.8006 RMSE: 1.0068\n",
      "ValLoss: 1.0553 MAE: 0.8244 RMSE: 1.0273\n",
      "Epoch 34: TrainLoss 0.9562 RecLoss: 0.0000 (left: 0:16:24)\n",
      "TestLoss: 1.0122 MAE: 0.7998 RMSE: 1.0061\n",
      "ValLoss: 1.0537 MAE: 0.8234 RMSE: 1.0265\n",
      "Epoch 35: TrainLoss 0.9544 RecLoss: 0.0000 (left: 0:16:09)\n",
      "TestLoss: 1.0122 MAE: 0.8003 RMSE: 1.0061\n",
      "ValLoss: 1.0535 MAE: 0.8243 RMSE: 1.0264\n",
      "Epoch 36: TrainLoss 0.9524 RecLoss: 0.0000 (left: 0:15:49)\n",
      "TestLoss: 1.0136 MAE: 0.8040 RMSE: 1.0068\n",
      "ValLoss: 1.0515 MAE: 0.8257 RMSE: 1.0254\n",
      "Epoch 37: TrainLoss 0.9514 RecLoss: 0.0000 (left: 0:15:34)\n",
      "TestLoss: 1.0098 MAE: 0.7986 RMSE: 1.0049\n",
      "ValLoss: 1.0512 MAE: 0.8223 RMSE: 1.0253\n",
      "Epoch 38: TrainLoss 0.9496 RecLoss: 0.0000 (left: 0:15:22)\n",
      "TestLoss: 1.0102 MAE: 0.8006 RMSE: 1.0051\n",
      "ValLoss: 1.0498 MAE: 0.8236 RMSE: 1.0246\n",
      "Epoch 39: TrainLoss 0.9485 RecLoss: 0.0000 (left: 0:15:07)\n",
      "TestLoss: 1.0087 MAE: 0.7988 RMSE: 1.0043\n",
      "ValLoss: 1.0498 MAE: 0.8226 RMSE: 1.0246\n",
      "Epoch 40: TrainLoss 0.9470 RecLoss: 0.0000 (left: 0:14:53)\n",
      "TestLoss: 1.0079 MAE: 0.7975 RMSE: 1.0039\n",
      "ValLoss: 1.0500 MAE: 0.8218 RMSE: 1.0247\n",
      "Epoch 41: TrainLoss 0.9461 RecLoss: 0.0000 (left: 0:14:36)\n",
      "TestLoss: 1.0099 MAE: 0.8022 RMSE: 1.0049\n",
      "ValLoss: 1.0478 MAE: 0.8242 RMSE: 1.0236\n",
      "Epoch 42: TrainLoss 0.9454 RecLoss: 0.0000 (left: 0:14:16)\n",
      "TestLoss: 1.0066 MAE: 0.7976 RMSE: 1.0033\n",
      "ValLoss: 1.0476 MAE: 0.8214 RMSE: 1.0235\n",
      "Epoch 43: TrainLoss 0.9449 RecLoss: 0.0000 (left: 0:14:01)\n",
      "TestLoss: 1.0086 MAE: 0.8026 RMSE: 1.0043\n",
      "ValLoss: 1.0457 MAE: 0.8240 RMSE: 1.0226\n",
      "Epoch 44: TrainLoss 0.9442 RecLoss: 0.0000 (left: 0:13:47)\n",
      "TestLoss: 1.0102 MAE: 0.8046 RMSE: 1.0051\n",
      "ValLoss: 1.0455 MAE: 0.8246 RMSE: 1.0225\n",
      "Epoch 45: TrainLoss 0.9420 RecLoss: 0.0000 (left: 0:13:33)\n",
      "TestLoss: 1.0051 MAE: 0.7973 RMSE: 1.0026\n",
      "ValLoss: 1.0455 MAE: 0.8208 RMSE: 1.0225\n",
      "Epoch 46: TrainLoss 0.9408 RecLoss: 0.0000 (left: 0:13:15)\n",
      "TestLoss: 1.0060 MAE: 0.8003 RMSE: 1.0030\n",
      "ValLoss: 1.0439 MAE: 0.8224 RMSE: 1.0217\n",
      "Epoch 47: TrainLoss 0.9397 RecLoss: 0.0000 (left: 0:12:57)\n",
      "TestLoss: 1.0065 MAE: 0.8018 RMSE: 1.0032\n",
      "ValLoss: 1.0429 MAE: 0.8228 RMSE: 1.0212\n",
      "Epoch 48: TrainLoss 0.9410 RecLoss: 0.0000 (left: 0:12:41)\n",
      "TestLoss: 1.0059 MAE: 0.8014 RMSE: 1.0029\n",
      "ValLoss: 1.0422 MAE: 0.8223 RMSE: 1.0209\n",
      "Epoch 49: TrainLoss 0.9378 RecLoss: 0.0000 (left: 0:12:26)\n",
      "TestLoss: 1.0036 MAE: 0.7978 RMSE: 1.0018\n",
      "ValLoss: 1.0426 MAE: 0.8207 RMSE: 1.0211\n",
      "Epoch 50: TrainLoss 0.9373 RecLoss: 0.0000 (left: 0:12:13)\n",
      "TestLoss: 1.0026 MAE: 0.7960 RMSE: 1.0013\n",
      "ValLoss: 1.0431 MAE: 0.8198 RMSE: 1.0213\n",
      "Epoch 51: TrainLoss 0.9367 RecLoss: 0.0000 (left: 0:11:57)\n",
      "TestLoss: 1.0012 MAE: 0.7922 RMSE: 1.0006\n",
      "ValLoss: 1.0450 MAE: 0.8176 RMSE: 1.0222\n",
      "Epoch 52: TrainLoss 0.9351 RecLoss: 0.0000 (left: 0:11:40)\n",
      "TestLoss: 1.0011 MAE: 0.7942 RMSE: 1.0006\n",
      "ValLoss: 1.0426 MAE: 0.8184 RMSE: 1.0211\n",
      "Epoch 53: TrainLoss 0.9343 RecLoss: 0.0000 (left: 0:11:26)\n",
      "TestLoss: 1.0025 MAE: 0.7991 RMSE: 1.0013\n",
      "ValLoss: 1.0399 MAE: 0.8209 RMSE: 1.0197\n",
      "Epoch 54: TrainLoss 0.9335 RecLoss: 0.0000 (left: 0:11:10)\n",
      "TestLoss: 1.0003 MAE: 0.7946 RMSE: 1.0002\n",
      "ValLoss: 1.0406 MAE: 0.8182 RMSE: 1.0201\n",
      "Epoch 55: TrainLoss 0.9329 RecLoss: 0.0000 (left: 0:10:54)\n",
      "TestLoss: 1.0017 MAE: 0.7982 RMSE: 1.0009\n",
      "ValLoss: 1.0397 MAE: 0.8205 RMSE: 1.0196\n",
      "Epoch 56: TrainLoss 0.9324 RecLoss: 0.0000 (left: 0:10:39)\n",
      "TestLoss: 1.0051 MAE: 0.8034 RMSE: 1.0025\n",
      "ValLoss: 1.0397 MAE: 0.8233 RMSE: 1.0197\n",
      "Epoch 57: TrainLoss 0.9325 RecLoss: 0.0000 (left: 0:10:21)\n",
      "TestLoss: 1.0034 MAE: 0.8019 RMSE: 1.0017\n",
      "ValLoss: 1.0382 MAE: 0.8221 RMSE: 1.0189\n",
      "Epoch 58: TrainLoss 0.9316 RecLoss: 0.0000 (left: 0:10:06)\n",
      "TestLoss: 0.9990 MAE: 0.7943 RMSE: 0.9995\n",
      "ValLoss: 1.0389 MAE: 0.8178 RMSE: 1.0193\n",
      "Epoch 59: TrainLoss 0.9298 RecLoss: 0.0000 (left: 0:09:51)\n",
      "TestLoss: 0.9986 MAE: 0.7897 RMSE: 0.9993\n",
      "ValLoss: 1.0428 MAE: 0.8151 RMSE: 1.0212\n",
      "Epoch 60: TrainLoss 0.9294 RecLoss: 0.0000 (left: 0:09:36)\n",
      "TestLoss: 0.9986 MAE: 0.7946 RMSE: 0.9993\n",
      "ValLoss: 1.0384 MAE: 0.8181 RMSE: 1.0190\n",
      "Epoch 61: TrainLoss 0.9287 RecLoss: 0.0000 (left: 0:09:21)\n",
      "TestLoss: 0.9991 MAE: 0.7968 RMSE: 0.9995\n",
      "ValLoss: 1.0367 MAE: 0.8189 RMSE: 1.0182\n",
      "Epoch 62: TrainLoss 0.9279 RecLoss: 0.0000 (left: 0:09:06)\n",
      "TestLoss: 1.0001 MAE: 0.7992 RMSE: 1.0000\n",
      "ValLoss: 1.0359 MAE: 0.8200 RMSE: 1.0178\n",
      "Epoch 63: TrainLoss 0.9272 RecLoss: 0.0000 (left: 0:08:53)\n",
      "TestLoss: 0.9973 MAE: 0.7933 RMSE: 0.9987\n",
      "ValLoss: 1.0377 MAE: 0.8171 RMSE: 1.0187\n",
      "Epoch 64: TrainLoss 0.9267 RecLoss: 0.0000 (left: 0:08:39)\n",
      "TestLoss: 0.9976 MAE: 0.7950 RMSE: 0.9988\n",
      "ValLoss: 1.0367 MAE: 0.8180 RMSE: 1.0182\n",
      "Epoch 65: TrainLoss 0.9267 RecLoss: 0.0000 (left: 0:08:24)\n",
      "TestLoss: 0.9967 MAE: 0.7905 RMSE: 0.9984\n",
      "ValLoss: 1.0393 MAE: 0.8155 RMSE: 1.0195\n",
      "Epoch 66: TrainLoss 0.9257 RecLoss: 0.0000 (left: 0:08:10)\n",
      "TestLoss: 0.9976 MAE: 0.7962 RMSE: 0.9988\n",
      "ValLoss: 1.0352 MAE: 0.8183 RMSE: 1.0175\n",
      "Epoch 67: TrainLoss 0.9249 RecLoss: 0.0000 (left: 0:07:55)\n",
      "TestLoss: 1.0014 MAE: 0.8022 RMSE: 1.0007\n",
      "ValLoss: 1.0350 MAE: 0.8213 RMSE: 1.0173\n",
      "Epoch 68: TrainLoss 0.9249 RecLoss: 0.0000 (left: 0:07:41)\n",
      "TestLoss: 1.0001 MAE: 0.8006 RMSE: 1.0000\n",
      "ValLoss: 1.0343 MAE: 0.8204 RMSE: 1.0170\n",
      "Epoch 69: TrainLoss 0.9242 RecLoss: 0.0000 (left: 0:07:29)\n",
      "TestLoss: 0.9958 MAE: 0.7928 RMSE: 0.9979\n",
      "ValLoss: 1.0356 MAE: 0.8162 RMSE: 1.0177\n",
      "Epoch 70: TrainLoss 0.9236 RecLoss: 0.0000 (left: 0:07:15)\n",
      "TestLoss: 0.9955 MAE: 0.7899 RMSE: 0.9977\n",
      "ValLoss: 1.0379 MAE: 0.8145 RMSE: 1.0188\n",
      "Epoch 71: TrainLoss 0.9224 RecLoss: 0.0000 (left: 0:07:01)\n",
      "TestLoss: 0.9993 MAE: 0.8001 RMSE: 0.9996\n",
      "ValLoss: 1.0337 MAE: 0.8200 RMSE: 1.0167\n",
      "Epoch 72: TrainLoss 0.9224 RecLoss: 0.0000 (left: 0:06:47)\n",
      "TestLoss: 0.9950 MAE: 0.7900 RMSE: 0.9975\n",
      "ValLoss: 1.0371 MAE: 0.8145 RMSE: 1.0184\n",
      "Epoch 73: TrainLoss 0.9217 RecLoss: 0.0000 (left: 0:06:33)\n",
      "TestLoss: 0.9960 MAE: 0.7954 RMSE: 0.9980\n",
      "ValLoss: 1.0336 MAE: 0.8176 RMSE: 1.0167\n",
      "Epoch 74: TrainLoss 0.9221 RecLoss: 0.0000 (left: 0:06:19)\n",
      "TestLoss: 0.9949 MAE: 0.7929 RMSE: 0.9974\n",
      "ValLoss: 1.0339 MAE: 0.8158 RMSE: 1.0168\n",
      "Epoch 75: TrainLoss 0.9209 RecLoss: 0.0000 (left: 0:06:04)\n",
      "TestLoss: 0.9949 MAE: 0.7895 RMSE: 0.9975\n",
      "ValLoss: 1.0373 MAE: 0.8142 RMSE: 1.0185\n",
      "Epoch 76: TrainLoss 0.9200 RecLoss: 0.0000 (left: 0:05:49)\n",
      "TestLoss: 0.9953 MAE: 0.7945 RMSE: 0.9977\n",
      "ValLoss: 1.0330 MAE: 0.8165 RMSE: 1.0163\n",
      "Epoch 77: TrainLoss 0.9197 RecLoss: 0.0000 (left: 0:05:34)\n",
      "TestLoss: 0.9942 MAE: 0.7903 RMSE: 0.9971\n",
      "ValLoss: 1.0352 MAE: 0.8142 RMSE: 1.0174\n",
      "Epoch 78: TrainLoss 0.9195 RecLoss: 0.0000 (left: 0:05:18)\n",
      "TestLoss: 0.9952 MAE: 0.7953 RMSE: 0.9976\n",
      "ValLoss: 1.0324 MAE: 0.8170 RMSE: 1.0161\n",
      "Epoch 79: TrainLoss 0.9189 RecLoss: 0.0000 (left: 0:05:02)\n",
      "TestLoss: 0.9962 MAE: 0.7971 RMSE: 0.9981\n",
      "ValLoss: 1.0319 MAE: 0.8180 RMSE: 1.0158\n",
      "Epoch 80: TrainLoss 0.9182 RecLoss: 0.0000 (left: 0:04:47)\n",
      "TestLoss: 0.9940 MAE: 0.7896 RMSE: 0.9970\n",
      "ValLoss: 1.0360 MAE: 0.8140 RMSE: 1.0179\n",
      "Epoch 81: TrainLoss 0.9182 RecLoss: 0.0000 (left: 0:04:32)\n",
      "TestLoss: 0.9939 MAE: 0.7933 RMSE: 0.9970\n",
      "ValLoss: 1.0321 MAE: 0.8156 RMSE: 1.0159\n",
      "Epoch 82: TrainLoss 0.9185 RecLoss: 0.0000 (left: 0:04:17)\n",
      "TestLoss: 0.9950 MAE: 0.7960 RMSE: 0.9975\n",
      "ValLoss: 1.0315 MAE: 0.8173 RMSE: 1.0156\n",
      "Epoch 83: TrainLoss 0.9176 RecLoss: 0.0000 (left: 0:04:03)\n",
      "TestLoss: 0.9961 MAE: 0.7979 RMSE: 0.9981\n",
      "ValLoss: 1.0313 MAE: 0.8182 RMSE: 1.0155\n",
      "Epoch 84: TrainLoss 0.9170 RecLoss: 0.0000 (left: 0:03:48)\n",
      "TestLoss: 0.9940 MAE: 0.7939 RMSE: 0.9970\n",
      "ValLoss: 1.0320 MAE: 0.8160 RMSE: 1.0159\n",
      "Epoch 85: TrainLoss 0.9170 RecLoss: 0.0000 (left: 0:03:34)\n",
      "TestLoss: 0.9948 MAE: 0.7958 RMSE: 0.9974\n",
      "ValLoss: 1.0311 MAE: 0.8171 RMSE: 1.0154\n",
      "Epoch 86: TrainLoss 0.9165 RecLoss: 0.0000 (left: 0:03:19)\n",
      "TestLoss: 0.9933 MAE: 0.7924 RMSE: 0.9966\n",
      "ValLoss: 1.0318 MAE: 0.8148 RMSE: 1.0158\n",
      "Epoch 87: TrainLoss 0.9155 RecLoss: 0.0000 (left: 0:03:05)\n",
      "TestLoss: 0.9950 MAE: 0.7970 RMSE: 0.9975\n",
      "ValLoss: 1.0304 MAE: 0.8176 RMSE: 1.0151\n",
      "Epoch 88: TrainLoss 0.9157 RecLoss: 0.0000 (left: 0:02:50)\n",
      "TestLoss: 0.9927 MAE: 0.7908 RMSE: 0.9964\n",
      "ValLoss: 1.0326 MAE: 0.8139 RMSE: 1.0162\n",
      "Epoch 89: TrainLoss 0.9150 RecLoss: 0.0000 (left: 0:02:36)\n",
      "TestLoss: 0.9927 MAE: 0.7910 RMSE: 0.9963\n",
      "ValLoss: 1.0323 MAE: 0.8140 RMSE: 1.0160\n",
      "Epoch 90: TrainLoss 0.9149 RecLoss: 0.0000 (left: 0:02:21)\n",
      "TestLoss: 0.9925 MAE: 0.7905 RMSE: 0.9963\n",
      "ValLoss: 1.0327 MAE: 0.8137 RMSE: 1.0162\n",
      "Epoch 91: TrainLoss 0.9146 RecLoss: 0.0000 (left: 0:02:07)\n",
      "TestLoss: 0.9924 MAE: 0.7883 RMSE: 0.9962\n",
      "ValLoss: 1.0341 MAE: 0.8123 RMSE: 1.0169\n",
      "Epoch 92: TrainLoss 0.9150 RecLoss: 0.0000 (left: 0:01:53)\n",
      "TestLoss: 0.9922 MAE: 0.7900 RMSE: 0.9961\n",
      "ValLoss: 1.0326 MAE: 0.8136 RMSE: 1.0162\n",
      "Epoch 93: TrainLoss 0.9136 RecLoss: 0.0000 (left: 0:01:39)\n",
      "TestLoss: 0.9927 MAE: 0.7931 RMSE: 0.9963\n",
      "ValLoss: 1.0306 MAE: 0.8152 RMSE: 1.0152\n",
      "Epoch 94: TrainLoss 0.9136 RecLoss: 0.0000 (left: 0:01:24)\n",
      "TestLoss: 0.9928 MAE: 0.7935 RMSE: 0.9964\n",
      "ValLoss: 1.0302 MAE: 0.8152 RMSE: 1.0150\n",
      "Epoch 95: TrainLoss 0.9132 RecLoss: 0.0000 (left: 0:01:10)\n",
      "TestLoss: 0.9933 MAE: 0.7945 RMSE: 0.9966\n",
      "ValLoss: 1.0301 MAE: 0.8160 RMSE: 1.0149\n",
      "Epoch 96: TrainLoss 0.9129 RecLoss: 0.0000 (left: 0:00:56)\n",
      "TestLoss: 0.9921 MAE: 0.7917 RMSE: 0.9961\n",
      "ValLoss: 1.0309 MAE: 0.8143 RMSE: 1.0153\n",
      "Epoch 97: TrainLoss 0.9128 RecLoss: 0.0000 (left: 0:00:42)\n",
      "TestLoss: 0.9931 MAE: 0.7944 RMSE: 0.9965\n",
      "ValLoss: 1.0298 MAE: 0.8158 RMSE: 1.0148\n",
      "Epoch 98: TrainLoss 0.9122 RecLoss: 0.0000 (left: 0:00:28)\n",
      "TestLoss: 0.9920 MAE: 0.7917 RMSE: 0.9960\n",
      "ValLoss: 1.0308 MAE: 0.8141 RMSE: 1.0153\n",
      "Epoch 99: TrainLoss 0.9122 RecLoss: 0.0000 (left: 0:00:14)\n",
      "TestLoss: 0.9915 MAE: 0.7887 RMSE: 0.9958\n",
      "ValLoss: 1.0326 MAE: 0.8124 RMSE: 1.0162\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 321973/19100\n",
      "test set size: support/query 523/809\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Key Test Result: MAE: 0.6508 RMSE: 0.8165 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 6040\n",
      "NUM IS: 6040\n",
      "Que Test Result: MAE: 0.7944 RMSE: 0.9965 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7380 RMSE: 0.9300 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20% optimal cur to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = [10, 20, 40, 60]\n",
    "y_axis = [1.0013,0.9986,0.9933, 0.9923]\n",
    "x1_axis = [10, 20, 40, 60]\n",
    "y1_axis = [0.9859, 0.9859, 0.9859, 0.9859]\n",
    "x2_axis = [10, 20, 40, 60]\n",
    "y2_axis = [0.9990, 0.9935, 0.9906, 0.9883]\n",
    "\n",
    "plt.plot(x1_axis, y1_axis, label=\"Base-Line 100% SUPPORT USERS ARE USED AS CORE USERS\")\n",
    "plt.plot(x_axis, y_axis, label=\"CORE USER CALCULATED USING COSINE SIMILARITY\")\n",
    "plt.plot(x2_axis, y2_axis, label=\"CORE USER CALCULATED USING CUR DECOMPOSITION\")\n",
    "\n",
    "plt.title('RMSE VS % of core user in support')\n",
    "plt.xlabel('% of core users in support')\n",
    "plt.ylabel('RMSE')\n",
    "plt.grid()\n",
    "plt.legend(fontsize=7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
