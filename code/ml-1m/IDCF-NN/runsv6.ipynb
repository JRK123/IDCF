{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the work to generate core users and feeding it to IDCF codebase for ML-100k dataset.\n",
    "- greater than 30 interactions are taken into.\n",
    "- Less than 30 interations are taken into test set\n",
    "- some x% of coreusers are choosen as training set\n",
    "- coreusers are calculated using CUR decomposition and R matrix is taken as coreuser.\n",
    "- always the results are tested on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fileinput import filename\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from scipy.sparse.linalg import svds\n",
    "import random \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as ss\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadData(threshold=30):\n",
    "    # uncomment this line for movielens dataset\n",
    "    ml1m_dir = 'data/u.data'\n",
    "    ml1m_rating = pd.read_csv(ml1m_dir, delim_whitespace=True, header=None, names=['uid', 'mid', 'rating', 'timestamp'],  engine='python')\n",
    "    # use the below 2 lines for pinterest dataset.\n",
    "    # ml1m_dir = 'data/pin-interest-main.txt'\n",
    "    # ml1m_rating = pd.read_csv(ml1m_dir, delim_whitespace=True, header=None, names=['uid', 'mid', 'rating', 'timestamp'],  engine='python')\n",
    "\n",
    "    unique_uid = np.unique(np.array(ml1m_rating['uid'].tolist()))\n",
    "    unique_mid = np.unique(np.array(ml1m_rating['mid'].tolist()))\n",
    "    uid_dict = dict([(y,x) for x,y in enumerate(unique_uid)])\n",
    "    mid_dict = dict([(y,x) for x,y in enumerate(unique_mid)])\n",
    "    print('DICTIONARY PREPARED:')\n",
    "\n",
    "    # init user item dictionary:\n",
    "    \n",
    "    uid_list = ml1m_rating['uid'].tolist()\n",
    "    uid_list_len = len(uid_list)\n",
    "    mid_list = ml1m_rating['mid'].tolist()\n",
    "    mid_list_len = len(mid_list)\n",
    "    rating_list = ml1m_rating['rating'].tolist()\n",
    "    user_item_dict = {x:set() for x in range(len(unique_uid))}\n",
    "    item_user_dict = {x:set() for x in range(len(unique_mid))}\n",
    "    for i in range(uid_list_len):\n",
    "        uid_list[i] = uid_dict[uid_list[i]]\n",
    "        mid_list[i] = mid_dict[mid_list[i]]\n",
    "        # rating_list[i] = 1 # comment this line if you want to activate explicit ratings\n",
    "        user_item_dict[uid_list[i]].add(mid_list[i])\n",
    "        item_user_dict[mid_list[i]].add(uid_list[i])\n",
    "    tmp_df = pd.DataFrame({\"uid\":uid_list, \"mid\":mid_list, \"ratings\":rating_list})\n",
    "    v = tmp_df.uid.value_counts()\n",
    "    df = tmp_df[tmp_df.uid.isin(v.index[v.gt(threshold)])]\n",
    "### code to store less than 30 interactions:\n",
    "    df_less_30 = tmp_df[tmp_df.uid.isin(v.index[v.le(threshold)])]\n",
    "    return df, df_less_30, len(np.unique(mid_list)), len(unique_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        uid   mid  rating  timestamp\n",
      "0      196   242       3  881250949\n",
      "1      186   302       3  891717742\n",
      "2       22   377       1  878887116\n",
      "3      244    51       2  880606923\n",
      "4      166   346       1  886397596\n",
      "...    ...   ...     ...        ...\n",
      "99995  880   476       3  880175444\n",
      "99996  716   204       5  879795543\n",
      "99997  276  1090       1  874795795\n",
      "99998   13   225       2  882399156\n",
      "99999   12   203       3  879959583\n",
      "\n",
      "[100000 rows x 4 columns]>\n",
      "DICTIONARY PREPARED:\n",
      "GREATER THAN 30:\n",
      "        uid   mid  ratings\n",
      "0      195   241        3\n",
      "1      185   301        3\n",
      "2       21   376        1\n",
      "3      243    50        2\n",
      "5      297   473        4\n",
      "...    ...   ...      ...\n",
      "99995  879   475        3\n",
      "99996  715   203        5\n",
      "99997  275  1089        1\n",
      "99998   12   224        2\n",
      "99999   11   202        3\n",
      "\n",
      "[94849 rows x 3 columns]\n",
      "LESS THAN 30: \n",
      "        uid   mid  ratings\n",
      "4      165   345        1\n",
      "30      49   245        3\n",
      "32     224   192        4\n",
      "37     277   602        5\n",
      "46     241  1136        5\n",
      "...    ...   ...      ...\n",
      "99886  484   751        3\n",
      "99902  440   281        4\n",
      "99930  894    99        4\n",
      "99936  724   275        4\n",
      "99946  562   565        4\n",
      "\n",
      "[5151 rows x 3 columns]\n",
      "GREATER THAN THRESHOLD:  94849\n",
      "LESS THAN THRESHOLD:  5151\n",
      "UNIQUE MIDS:  1682\n",
      "UNIQUE UIDS:  943\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 30 #split the users into test and train by threshold number of interactions. if greater than threshold then all interactions of that user goes into train set.\n",
    "df_gt_30, df_le_30, unique_mids, unique_uids = ReadData(THRESHOLD)\n",
    "print(\"GREATER THAN 30:\\n\", df_gt_30)\n",
    "print(\"LESS THAN 30: \\n\", df_le_30)\n",
    "print(\"GREATER THAN THRESHOLD: \", len(df_gt_30))\n",
    "print(\"LESS THAN THRESHOLD: \" ,len(df_le_30))\n",
    "print(\"UNIQUE MIDS: \", unique_mids)\n",
    "print(\"UNIQUE UIDS: \", unique_uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF USERS IN SUPPORT TEST: 730\n",
      "NUMBER OF USERS IN SUPPORT TRAIN 730\n",
      "NUMBER OF USERS IN QUERY TEST: 213\n",
      "NUMBER OF USERS IN QUERY TRAIN 213\n"
     ]
    }
   ],
   "source": [
    "support_test_df = df_gt_30.groupby(\"uid\").tail(1)\n",
    "# print(len(df_gt_30['uid']))\n",
    "support_train_df = df_gt_30.drop(df_gt_30.groupby('uid').tail(1).index, inplace=False)\n",
    "assert(len(df_gt_30)== len(support_test_df) + len(support_train_df))\n",
    "# print(len(test_df))\n",
    "# print(len(train_df))\n",
    "query_test_df = df_le_30.groupby(\"uid\").tail(1)\n",
    "query_train_df = df_le_30.drop(df_le_30.groupby('uid').tail(1).index, inplace=False)\n",
    "assert(len(df_le_30)== len(query_test_df) + len(query_train_df))\n",
    "dic_support_train_df_uid_mapping = dict([(y,x) for x,y in enumerate(np.unique(support_train_df['uid']))])\n",
    "dic_support_train_df_uid_rmapping = dict([(x,y) for x,y in enumerate(np.unique(support_train_df['uid']))])\n",
    "### no need for mid mapping\n",
    "\n",
    "uid_of_train_df = support_train_df['uid'].tolist()\n",
    "for i in range(len(uid_of_train_df)):\n",
    "    uid_of_train_df[i] = dic_support_train_df_uid_mapping[uid_of_train_df[i]]\n",
    "# for index, row in train_df.iterrows():\n",
    "#     train_df['uid'][index] = dic_train_df_uid_mapping[train_df['uid'][index]]\n",
    "core_user_ko_input_train_df = pd.DataFrame({'uid':uid_of_train_df, 'mid':support_train_df['mid'], 'ratings':support_train_df['ratings']})\n",
    "print(\"NUMBER OF USERS IN SUPPORT TEST:\", len(np.unique(support_test_df['uid'])))\n",
    "print(\"NUMBER OF USERS IN SUPPORT TRAIN\", len(np.unique(support_train_df['uid'])))\n",
    "print(\"NUMBER OF USERS IN QUERY TEST:\", len(np.unique(query_test_df['uid'])))\n",
    "print(\"NUMBER OF USERS IN QUERY TRAIN\", len(np.unique(query_train_df['uid'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ui_dic = {}    \n",
    "for user in range(unique_uids):\n",
    "    train_ui_dic[user] = []\n",
    "for index,row in support_train_df.iterrows():\n",
    "        train_ui_dic[row['uid']].append(row['mid'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- utility functions for CUR coreusers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MID = 27277 + 1\n",
    "def select_cols(mat, k, dup=False):\n",
    "    # prob 1d array of probabilities of all columns\n",
    "    prob = mat.T.dot(mat)\n",
    "    prob = np.array(np.diagonal(prob))\n",
    "    denom = np.abs(prob).sum(axis = 0)\n",
    "    prob = prob/denom\n",
    "\n",
    "    C = np.zeros((mat.shape[0], k))\n",
    "    ind_cols = np.arange(0, prob.size)\n",
    "    c_ind = []\n",
    "    i = 0\n",
    "    while(i < k):\n",
    "        rand_sel = np.random.choice(ind_cols, 1, p=prob)\n",
    "        if rand_sel in c_ind:\n",
    "            continue\n",
    "        c_ind.append(rand_sel[0])\n",
    "        C[:, i] = mat[:, rand_sel[0]]\n",
    "        i += 1\n",
    "        # C[:, i] = C[:, i]/np.sqrt(k*prob[rand_sel[0]])\n",
    "\n",
    "    return C, c_ind\n",
    "\n",
    "def select_rows(mat, k, dup=False):\n",
    "\n",
    "    prob = mat.dot(mat.T)\n",
    "    prob = np.array(np.diagonal(prob))\n",
    "    denom = np.abs(prob).sum(axis=0)\n",
    "    prob = prob/denom\n",
    "    print(prob)\n",
    "    r = np.zeros((k, mat.shape[1]))\n",
    "    ind_rows = np.arange(0, prob.size)\n",
    "    r_ind = []\n",
    "    i = 0\n",
    "    while(i < k):\n",
    "        # print(ind_rows)\n",
    "        rand_sel = np.random.choice(ind_rows, 1, p=prob)\n",
    "        if rand_sel in r_ind:\n",
    "            continue\n",
    "        r_ind.append(rand_sel[0])\n",
    "        r[i, :] = mat[rand_sel[0], :]\n",
    "        i += 1\n",
    "        # r[i, :] = r[i, :]/np.sqrt(k*prob[rand_sel[0]])\n",
    "    r_ind = np.array(r_ind)\n",
    "    return r, r_ind\n",
    "\n",
    "# def matIntersection(mat, c_ind, r_ind):\n",
    "    \n",
    "#     W = np.zeros((len(r_ind), len(c_ind)))\n",
    "#     for i in range(len(r_ind)):\n",
    "#         W[i] = mat[r_ind[i], c_ind]\n",
    "    \n",
    "#     return W\n",
    "\n",
    "# def pseudoInverse(W):\n",
    "#     # U = WP (W+)\n",
    "\n",
    "#     # W = X.Z.YT\n",
    "#     X, Z, YT = np.linalg.svd(W)\n",
    "    \n",
    "#     # W+ = Y.Z+.XT\n",
    "#     XT = X.T\n",
    "#     Y = YT.T\n",
    "#     # Z+ = reciprocal(Z)\n",
    "#     ZP = np.reciprocal(Z)\n",
    "#     ZP = sp.spdiags(ZP, 0, ZP.size, ZP.size)\n",
    "#     ZP = ZP@ZP\n",
    "    \n",
    "#     # W+ = Y.Z+.XT\n",
    "#     WP = Y@ZP\n",
    "#     WP = WP@XT\n",
    "\n",
    "#     return WP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractCoreUsers(dataframe, unique_user_len, unique_item_len):\n",
    "    # print(\"# of rows in ml1m_ratings: \", len(dataframe))\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "    userItemMatrix = np.zeros(shape=(u_len, m_len))\n",
    "    # print(userItemMatrix)\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        userItemMatrix[row['uid']][row['mid']] = row['ratings']\n",
    "        # print(row['uid'], row['mid'])\n",
    "    print(\"USER ITEM MATRIX: \\n\", userItemMatrix)\n",
    "\n",
    "    df = pd.DataFrame(userItemMatrix)\n",
    "    cosineSimilarity = cosine_similarity(df)\n",
    "    print(\"SHAPE OF COSINE MATIX:\\n \", cosineSimilarity.shape)\n",
    "\n",
    "    listToStoreTopFiftyOfEveryUser = []\n",
    "    for i in range(0, cosineSimilarity.shape[0]):\n",
    "        idx = np.argpartition(cosineSimilarity[i], -50)[-50:]\n",
    "        listToStoreTopFiftyOfEveryUser.append(idx)\n",
    "    # print(\"Top fifty list: \\n\", listToStoreTopFiftyOfEveryUser)\n",
    "    # listToStoreTopFiftyOfEveryUser = np.array(listToStoreTopFiftyOfEveryUser)\n",
    "    flatten = np.concatenate(listToStoreTopFiftyOfEveryUser)\n",
    "    listToStoreTopFiftyOfEveryUser = flatten.ravel()\n",
    "\n",
    "    # print(\"List of top 50\", listToStoreTopFiftyOfEveryUser)\n",
    "    df = pd.DataFrame(listToStoreTopFiftyOfEveryUser)\n",
    "    allUserList = df.value_counts().index.tolist()\n",
    "    # print(\"ALL USERS LIST\", allUserList)\n",
    "    allUserList = list(sum(allUserList,()))\n",
    "    # print(\"ALL USERS LIST\", allUserList)\n",
    "    twentyPercentUserList = allUserList[:int(len(allUserList)*0.2)]\n",
    "    # print(\"TWENTY PERCENT USER:\", len(twentyPercentUserList))\n",
    "    # print(\"TWENTY PERCENT USER:\", (twentyPercentUserList))\n",
    "    coreusers = dataframe.iloc[np.where(dataframe.uid.isin(twentyPercentUserList))]\n",
    "    # coreusers.reset_index()\n",
    "    # print(\"CORE USERS:\\n\", coreusers)\n",
    "    return coreusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CUR_ExtractCoreUsers(dataframe, unique_user_len, unique_item_len):\n",
    "    # print(\"# of rows in ml1m_ratings: \", len(dataframe))\n",
    "    u_len = unique_user_len\n",
    "    print(\"USER LEN:\", u_len)\n",
    "    # print(user_id)\n",
    "\n",
    "    m_len = unique_item_len\n",
    "    print(\"MOVIE LEN:\", m_len)\n",
    "    userItemMatrix = np.zeros(shape=(u_len, m_len))\n",
    "    # print(userItemMatrix)\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "        userItemMatrix[row['uid']][row['mid']] = row['ratings']\n",
    "        # print(row['uid'], row['mid'])\n",
    "    print(\"USER ITEM MATRIX: \\n\", userItemMatrix)\n",
    "\n",
    "    mat = userItemMatrix\n",
    "    print(\"MAT:\", mat)\n",
    "    print(mat.shape)\n",
    "    C, c_ind = select_cols(mat, int(u_len * 0.10)) ## getting 20% core users\n",
    "    r, r_ind= select_rows(mat, int(u_len * 0.10))\n",
    "    print(\"r\", r)\n",
    "    print(\"r_ind len\", len(r_ind))\n",
    "\n",
    "    cur_coreusers = dataframe.iloc[np.where(dataframe.uid.isin(r_ind))]\n",
    "    # coreusers.reset_index()\n",
    "    # print(\"CORE USERS:\\n\", coreusers)\n",
    "    return cur_coreusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER LEN: 730\n",
      "MOVIE LEN: 1682\n",
      "USER ITEM MATRIX: \n",
      " [[5. 3. 4. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 5. 0. ... 0. 0. 0.]]\n",
      "MAT: [[5. 3. 4. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 5. 0. ... 0. 0. 0.]]\n",
      "(730, 1682)\n",
      "[0.0030804  0.0007046  0.00036897 0.00135184 0.00233006 0.00525776\n",
      " 0.00072165 0.00256493 0.00179832 0.00077901 0.00571432 0.00133324\n",
      " 0.00080304 0.00213085 0.00338115 0.00039455 0.00122937 0.00132161\n",
      " 0.00164639 0.0010007  0.00100303 0.00077824 0.00089141 0.00035811\n",
      " 0.00049841 0.00044105 0.00036819 0.00062786 0.00151539 0.00024339\n",
      " 0.000586   0.0021231  0.00253393 0.00166267 0.00050151 0.00077669\n",
      " 0.00144873 0.00080614 0.00074491 0.00204171 0.00107977 0.00191924\n",
      " 0.0049136  0.00273701 0.00217039 0.00076971 0.00213395 0.00099063\n",
      " 0.00037904 0.00030695 0.00079452 0.00127975 0.00044725 0.00165182\n",
      " 0.00076584 0.00041237 0.00076274 0.00086583 0.00080072 0.0007077\n",
      " 0.00052942 0.00139835 0.00155183 0.00080304 0.00292925 0.00247889\n",
      " 0.00101853 0.0043338  0.00120922 0.00343929 0.00446402 0.00278585\n",
      " 0.00080924 0.00088753 0.00144253 0.00046043 0.00047128 0.00123092\n",
      " 0.00072243 0.00071545 0.00033796 0.00237347 0.00102473 0.00050772\n",
      " 0.00057748 0.00050694 0.00118209 0.00110147 0.00107434 0.00120766\n",
      " 0.00232541 0.00083482 0.00078211 0.00065887 0.00188591 0.00046353\n",
      " 0.00205334 0.00459037 0.00050617 0.00050617 0.0007201  0.0007201\n",
      " 0.00111077 0.00035424 0.00228743 0.00313931 0.00088598 0.00026587\n",
      " 0.00037904 0.00405475 0.00161306 0.00063871 0.00040462 0.00061856\n",
      " 0.00207117 0.0011162  0.00150144 0.00034571 0.00043098 0.00085653\n",
      " 0.00070227 0.00068522 0.00047283 0.00060073 0.0020797  0.00043563\n",
      " 0.00071933 0.00124565 0.00304939 0.00037052 0.00083172 0.00099063\n",
      " 0.00045113 0.00273624 0.00061391 0.00093559 0.00073561 0.00129526\n",
      " 0.00244091 0.00052942 0.00036354 0.00104256 0.00231689 0.00087126\n",
      " 0.00042478 0.00115341 0.00162546 0.00034339 0.00283313 0.003068\n",
      " 0.00042245 0.00044493 0.00033796 0.00197505 0.00038059 0.00029378\n",
      " 0.00174251 0.00030773 0.0018084  0.00157275 0.00107047 0.0015619\n",
      " 0.00062399 0.00055345 0.00155803 0.00321295 0.00086273 0.0010976\n",
      " 0.0005798  0.00057205 0.00164794 0.00114333 0.00165647 0.00393615\n",
      " 0.00119061 0.00127975 0.00064957 0.00236185 0.00086273 0.00266337\n",
      " 0.00155803 0.00061313 0.00217659 0.00145493 0.00090149 0.00123945\n",
      " 0.00127123 0.00052554 0.0026905  0.00074723 0.00054802 0.00130998\n",
      " 0.00163787 0.00172778 0.00047826 0.00232076 0.00249362 0.00274864\n",
      " 0.00210062 0.00296335 0.00075343 0.00095497 0.00073406 0.00523528\n",
      " 0.00053485 0.00407335 0.00274631 0.000717   0.00046353 0.00039455\n",
      " 0.00335325 0.00085963 0.00094644 0.0013968  0.00334782 0.00177119\n",
      " 0.00308272 0.00148982 0.00281298 0.00213473 0.00190761 0.00164562\n",
      " 0.00277034 0.00284941 0.00481671 0.00218124 0.00037827 0.00132239\n",
      " 0.0045144  0.00343619 0.00344316 0.00280677 0.00279825 0.00112395\n",
      " 0.00075576 0.00198358 0.00173011 0.00139292 0.00069762 0.00096272\n",
      " 0.00098132 0.001403   0.00181227 0.00258974 0.00274941 0.00060383\n",
      " 0.00234557 0.00076119 0.00255718 0.0033982  0.00104179 0.00042245\n",
      " 0.00096195 0.00330906 0.00061701 0.0020859  0.00311915 0.00211613\n",
      " 0.00253005 0.00180375 0.00222232 0.00069142 0.00035501 0.00073638\n",
      " 0.00061236 0.00049919 0.00265795 0.00103326 0.00049066 0.00129448\n",
      " 0.00141695 0.00262384 0.00056275 0.00051624 0.00078832 0.0004178\n",
      " 0.00082475 0.00067902 0.00095962 0.00266802 0.002675   0.00039377\n",
      " 0.00358811 0.0025409  0.00137664 0.0015309  0.0005364  0.00107589\n",
      " 0.00267423 0.00298506 0.00071158 0.00308737 0.00037982 0.0014154\n",
      " 0.00149602 0.00408575 0.0018084  0.00071545 0.00050849 0.00121232\n",
      " 0.00193242 0.00228588 0.00129526 0.0008511  0.0005798  0.00039377\n",
      " 0.00295405 0.00360517 0.00222465 0.00223395 0.00066042 0.00062244\n",
      " 0.00055422 0.00609568 0.00322612 0.0004488  0.00049144 0.00075266\n",
      " 0.00095342 0.00066429 0.00043253 0.00156655 0.00118131 0.00049144\n",
      " 0.00067282 0.0039439  0.00067747 0.00070925 0.0004395  0.00051624\n",
      " 0.00354548 0.00166035 0.00287034 0.000424   0.00032866 0.00073096\n",
      " 0.00116891 0.00053097 0.00023022 0.00149059 0.00038602 0.00089141\n",
      " 0.00655069 0.00069607 0.00210372 0.00142858 0.00176809 0.00186653\n",
      " 0.00211613 0.0036509  0.00209597 0.00113248 0.00065112 0.00045191\n",
      " 0.00099683 0.00068135 0.00075343 0.00103558 0.00048214 0.00183708\n",
      " 0.00067592 0.00058678 0.00032633 0.0038098  0.00041857 0.00437488\n",
      " 0.00079142 0.00052632 0.00113868 0.00204481 0.00067282 0.00070383\n",
      " 0.00045811 0.00180297 0.00165724 0.00260989 0.00143711 0.00127123\n",
      " 0.00038912 0.00039687 0.00056275 0.00160996 0.0005767  0.00277809\n",
      " 0.00107434 0.00235797 0.00134021 0.00125495 0.00211458 0.00081545\n",
      " 0.0003054  0.00218589 0.00267965 0.00106814 0.00274399 0.00101\n",
      " 0.00103946 0.00019301 0.00231611 0.00029843 0.00034804 0.00081157\n",
      " 0.00069995 0.00121387 0.00149369 0.00314784 0.00048524 0.00062864\n",
      " 0.00164252 0.00060228 0.0004457  0.00054105 0.00379973 0.00252617\n",
      " 0.00106194 0.00273081 0.00201148 0.00347029 0.00086428 0.00070383\n",
      " 0.00068832 0.00146966 0.00133324 0.0019735  0.00020076 0.00161694\n",
      " 0.00073793 0.00179134 0.00045966 0.00420745 0.00063639 0.00138207\n",
      " 0.00116116 0.00066352 0.00064957 0.00060616 0.00081777 0.00095885\n",
      " 0.00279437 0.00079839 0.0003054  0.00056042 0.00149834 0.00198358\n",
      " 0.00078754 0.00069142 0.00055732 0.00048446 0.00035579 0.00219054\n",
      " 0.00073173 0.00048834 0.00057438 0.00091311 0.00150687 0.00074568\n",
      " 0.00267035 0.00044725 0.00049454 0.00089683 0.00454386 0.0017084\n",
      " 0.00084257 0.00044493 0.00058213 0.00095264 0.00127433 0.00055345\n",
      " 0.00106969 0.00300056 0.00041625 0.00189134 0.00085653 0.00049764\n",
      " 0.00032866 0.00128363 0.0004395  0.0007108  0.00196575 0.00094567\n",
      " 0.00132859 0.00180375 0.0022541  0.00052322 0.0014123  0.00099993\n",
      " 0.00019223 0.00167817 0.00164717 0.00101078 0.00130146 0.00050539\n",
      " 0.00127588 0.00029843 0.00061158 0.00069762 0.001141   0.00155415\n",
      " 0.00052709 0.00355478 0.00231921 0.00052089 0.00153167 0.00026277\n",
      " 0.00066507 0.00281143 0.0025316  0.00189134 0.0016805  0.00476245\n",
      " 0.00078987 0.00221302 0.00132006 0.00151307 0.00162081 0.00191227\n",
      " 0.00139137 0.0026626  0.00059531 0.00046818 0.00097125 0.00055267\n",
      " 0.00134021 0.00041625 0.00044338 0.00038989 0.00088056 0.00055422\n",
      " 0.00066972 0.00047593 0.00334317 0.00065809 0.00086118 0.00116813\n",
      " 0.00043175 0.000979   0.00045423 0.00034881 0.00127588 0.0021293\n",
      " 0.00035579 0.00124565 0.00091311 0.00119991 0.00046043 0.00019766\n",
      " 0.00049144 0.00106116 0.00132239 0.00241998 0.00094334 0.00146113\n",
      " 0.00094257 0.00271686 0.00187118 0.00044725 0.00162391 0.00335867\n",
      " 0.00107047 0.00042555 0.00055577 0.00175569 0.00044105 0.0004209\n",
      " 0.00256028 0.00033563 0.00086815 0.00084955 0.00069607 0.00049066\n",
      " 0.00041625 0.00160996 0.00040152 0.00104566 0.00039377 0.00051159\n",
      " 0.00072863 0.00400514 0.00119836 0.00330596 0.00026432 0.00176964\n",
      " 0.00066042 0.00062089 0.00031471 0.00031781 0.00093017 0.0015216\n",
      " 0.00443689 0.000424   0.00037207 0.00049841 0.00150144 0.00120689\n",
      " 0.00160143 0.00055267 0.00058755 0.00093327 0.0008325  0.00040695\n",
      " 0.00151384 0.0009573  0.00106659 0.00048136 0.00051159 0.00043718\n",
      " 0.00066972 0.00050617 0.00153012 0.00045346 0.00141773 0.00047206\n",
      " 0.00230991 0.00035889 0.00179832 0.00037517 0.00053717 0.00055732\n",
      " 0.00130223 0.00389894 0.00219752 0.00075033 0.0002837  0.00361137\n",
      " 0.0026626  0.00152857 0.00249129 0.00024572 0.00215721 0.00033021\n",
      " 0.00092784 0.00240448 0.00158438 0.00135339 0.0008635  0.00064414\n",
      " 0.00126192 0.00076506 0.00224557 0.00066817 0.0013906  0.00061546\n",
      " 0.00038602 0.00124022 0.00049841 0.00269593 0.00037207 0.0012813\n",
      " 0.00080847 0.00025967 0.00472292 0.00118596 0.00225643 0.0008294\n",
      " 0.00213163 0.00046973 0.0003054  0.00190141 0.00045191 0.00060616\n",
      " 0.000555   0.00250912 0.00096195 0.00351603 0.00036587 0.00139447\n",
      " 0.00169523 0.00035346 0.00267733 0.00115728 0.00066739 0.00038757\n",
      " 0.00124255 0.00095497 0.00122859 0.00361679 0.00247191 0.00183785\n",
      " 0.00335635 0.00048911 0.00093482 0.00232619 0.00228511 0.00316489\n",
      " 0.00147509 0.00063406 0.00293157 0.0005581  0.00260291 0.00284321\n",
      " 0.0023789  0.0013999  0.00026587 0.0015185  0.00049144 0.00165027\n",
      " 0.00053252 0.00033874 0.00045656 0.00241455 0.00073328 0.00050849\n",
      " 0.00115573 0.00061468 0.00139602 0.00297575 0.00035734 0.00098443\n",
      " 0.00217891 0.00100225 0.00120766 0.00100225 0.00092706 0.0002589\n",
      " 0.00137587 0.00053717 0.00055267 0.00048369 0.0006798  0.00311063\n",
      " 0.00119914 0.00197273 0.00047516 0.00163942 0.00039687 0.00100303\n",
      " 0.00070693 0.00106349 0.00113713 0.00171693]\n",
      "r [[0. 0. 0. ... 0. 0. 0.]\n",
      " [3. 0. 3. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "r_ind len 73\n",
      "CORE USERS:        uid   mid  ratings\n",
      "0      144   241        3\n",
      "12     148   221        5\n",
      "19     173  1183        2\n",
      "31     223    97        4\n",
      "40       7    15        4\n",
      "...    ...   ...      ...\n",
      "99830  375   312        3\n",
      "99831  511   215        4\n",
      "99863  549   863        4\n",
      "99925  723   250        4\n",
      "99968  723   286        4\n",
      "\n",
      "[14039 rows x 3 columns]\n",
      "NUMBER OF CORE USERS: 73\n"
     ]
    }
   ],
   "source": [
    "# core_users = CUR_ExtractCoreUsers(core_user_ko_input_train_df, len(np.unique(uid_of_train_df)), unique_mids)\n",
    "core_users = ExtractCoreUsers(core_user_ko_input_train_df, len(np.unique(uid_of_train_df)), unique_mids)\n",
    "support_user_list = np.unique(core_users['uid'])\n",
    "print(\"CORE USERS:\" ,core_users)\n",
    "print(\"NUMBER OF CORE USERS:\", len(support_user_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5231"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(support_user_list))\n",
    "len(np.unique(uid_of_train_df))\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORE USERS:        uid   mid  ratings\n",
      "0      144   241        3\n",
      "12     148   221        5\n",
      "19     173  1183        2\n",
      "31     223    97        4\n",
      "40       7    15        4\n",
      "...    ...   ...      ...\n",
      "99830  375   312        3\n",
      "99831  511   215        4\n",
      "99863  549   863        4\n",
      "99925  723   250        4\n",
      "99968  723   286        4\n",
      "\n",
      "[14039 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "core_users_index_list = core_users.index.to_list()\n",
    "# non_core_user_index = (train_df.index.difference(core_users.index))\n",
    "# non_core_user_index = non_core_user_index.tolist()\n",
    "\n",
    "core_users_df = support_train_df.loc[core_users_index_list]\n",
    "# non_core_user_df = train_df.loc[non_core_user_index]\n",
    "# print(\"NON CORE USERS:\" ,non_core_user_df)\n",
    "print(\"CORE USERS:\" ,core_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "SUPPORT TEST DF:        uid  mid  ratings\n",
      "87863  195  109        1\n",
      "91815  262  140        5\n",
      "92883  135  257        5\n",
      "92968  339  377        5\n",
      "95725  599  801        2\n",
      "...    ...  ...      ...\n",
      "99973  820  150        4\n",
      "99977  486  290        3\n",
      "99994  377   77        3\n",
      "99995  879  475        3\n",
      "99998   12  224        2\n",
      "\n",
      "[73 rows x 3 columns]\n",
      "QUERY TEST DF:\n",
      "        uid   mid  ratings\n",
      "54279  219   339        4\n",
      "63737  211   316        5\n",
      "68894  308   878        4\n",
      "70158  417  1312        2\n",
      "73085  126   689        1\n",
      "...    ...   ...      ...\n",
      "99886  484   751        3\n",
      "99902  440   281        4\n",
      "99930  894    99        4\n",
      "99936  724   275        4\n",
      "99946  562   565        4\n",
      "\n",
      "[213 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# print(\"TEST DF CONTAINS TEST FOR CORE AND NON CORE ENTITIES:\\n\" ,test_df)\n",
    "# print(core_users['uid'])\n",
    "unique_uids_in_support_trian = np.unique(np.array(core_users_df['uid']))\n",
    "unique_uids_in_query_trian = np.unique(query_train_df['uid'])\n",
    "print(len(unique_uids_in_support_trian))\n",
    "support_test_df = support_test_df.loc[support_test_df['uid'].isin(unique_uids_in_support_trian)]\n",
    "print(\"SUPPORT TEST DF:\" ,support_test_df)\n",
    "query_test_df = query_test_df\n",
    "print(\"QUERY TEST DF:\\n\", query_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_train = []\n",
    "for index,row in core_users_df.iterrows():\n",
    "    support_train.append([row['uid'], row['mid'], row['ratings']])\n",
    "query_train = []\n",
    "for index, row in query_train_df.iterrows():\n",
    "    query_train.append([row['uid'], row['mid'], row['ratings']])\n",
    "support_test = []\n",
    "for index, row in support_test_df.iterrows():\n",
    "    support_test.append([row['uid'], row['mid'], row['ratings']])\n",
    "query_test = []\n",
    "for index, row in query_test_df.iterrows():\n",
    "    query_test.append([row['uid'], row['mid'], row['ratings']])\n",
    "user_his_dic = {}\n",
    "for u in train_ui_dic.keys():\n",
    "    user_his_dic[u] = train_ui_dic[u]\n",
    "user_supp_list = np.unique(core_users_df['uid']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"ML100K_cur_10_support_as_core.pkl\", \"wb\") as f:\n",
    "    pickle.dump(support_train, f)\n",
    "    pickle.dump(query_train, f)\n",
    "    pickle.dump(support_test, f)\n",
    "    pickle.dump(query_test, f)\n",
    "    pickle.dump(user_supp_list, f)\n",
    "    pickle.dump(user_his_dic, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10% pin cur coreusers into IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 14039/4938\n",
      "test set size: support/query 73/213\n",
      "Epoch 0 Step 14: Train 12.3978 Reg: 0.4964\n",
      "Test: 12.7262 MAE: 3.3791 RMSE: 3.5674\n",
      "Val: 12.7031 MAE: 3.3702 RMSE: 3.5641\n",
      "Epoch 1 Step 28: Train 10.6703 Reg: 0.3973\n",
      "Test: 10.2888 MAE: 2.9994 RMSE: 3.2076\n",
      "Val: 10.2432 MAE: 2.9839 RMSE: 3.2005\n",
      "Epoch 2 Step 42: Train 7.7408 Reg: 0.3334\n",
      "Test: 6.1180 MAE: 2.2373 RMSE: 2.4735\n",
      "Val: 6.0393 MAE: 2.2188 RMSE: 2.4575\n",
      "Epoch 3 Step 56: Train 3.7693 Reg: 0.3059\n",
      "Test: 2.3146 MAE: 1.3249 RMSE: 1.5214\n",
      "Val: 2.2933 MAE: 1.3182 RMSE: 1.5144\n",
      "Epoch 4 Step 70: Train 1.5114 Reg: 0.2995\n",
      "Test: 1.2311 MAE: 0.9418 RMSE: 1.1096\n",
      "Val: 1.2683 MAE: 0.9608 RMSE: 1.1262\n",
      "Epoch 5 Step 84: Train 1.0973 Reg: 0.2925\n",
      "Test: 1.1142 MAE: 0.8832 RMSE: 1.0556\n",
      "Val: 1.1542 MAE: 0.8954 RMSE: 1.0743\n",
      "Epoch 6 Step 98: Train 1.0277 Reg: 0.2900\n",
      "Test: 1.0658 MAE: 0.8584 RMSE: 1.0324\n",
      "Val: 1.0923 MAE: 0.8658 RMSE: 1.0451\n",
      "Epoch 7 Step 112: Train 0.9576 Reg: 0.2859\n",
      "Test: 1.0173 MAE: 0.8373 RMSE: 1.0086\n",
      "Val: 1.0426 MAE: 0.8466 RMSE: 1.0211\n",
      "Epoch 8 Step 126: Train 0.9074 Reg: 0.2835\n",
      "Test: 0.9818 MAE: 0.8195 RMSE: 0.9908\n",
      "Val: 1.0094 MAE: 0.8308 RMSE: 1.0047\n",
      "Epoch 9 Step 140: Train 0.8718 Reg: 0.2827\n",
      "Test: 0.9427 MAE: 0.7960 RMSE: 0.9709\n",
      "Val: 0.9821 MAE: 0.8130 RMSE: 0.9910\n",
      "Epoch 10 Step 154: Train 0.8418 Reg: 0.2823\n",
      "Test: 0.9115 MAE: 0.7741 RMSE: 0.9547\n",
      "Val: 0.9609 MAE: 0.7955 RMSE: 0.9802\n",
      "Epoch 11 Step 168: Train 0.8179 Reg: 0.2818\n",
      "Test: 0.8842 MAE: 0.7555 RMSE: 0.9403\n",
      "Val: 0.9432 MAE: 0.7793 RMSE: 0.9712\n",
      "Epoch 12 Step 182: Train 0.7986 Reg: 0.2811\n",
      "Test: 0.8637 MAE: 0.7410 RMSE: 0.9294\n",
      "Val: 0.9309 MAE: 0.7673 RMSE: 0.9648\n",
      "Epoch 13 Step 196: Train 0.7836 Reg: 0.2803\n",
      "Test: 0.8463 MAE: 0.7301 RMSE: 0.9200\n",
      "Val: 0.9213 MAE: 0.7584 RMSE: 0.9598\n",
      "Epoch 14 Step 210: Train 0.7721 Reg: 0.2794\n",
      "Test: 0.8365 MAE: 0.7245 RMSE: 0.9146\n",
      "Val: 0.9137 MAE: 0.7518 RMSE: 0.9559\n",
      "Epoch 15 Step 224: Train 0.7625 Reg: 0.2784\n",
      "Test: 0.8276 MAE: 0.7207 RMSE: 0.9097\n",
      "Val: 0.9076 MAE: 0.7475 RMSE: 0.9527\n",
      "Epoch 16 Step 238: Train 0.7553 Reg: 0.2773\n",
      "Test: 0.8195 MAE: 0.7159 RMSE: 0.9052\n",
      "Val: 0.9028 MAE: 0.7442 RMSE: 0.9502\n",
      "Epoch 17 Step 252: Train 0.7492 Reg: 0.2761\n",
      "Test: 0.8170 MAE: 0.7159 RMSE: 0.9039\n",
      "Val: 0.8994 MAE: 0.7419 RMSE: 0.9484\n",
      "Epoch 18 Step 266: Train 0.7444 Reg: 0.2749\n",
      "Test: 0.8126 MAE: 0.7148 RMSE: 0.9014\n",
      "Val: 0.8956 MAE: 0.7403 RMSE: 0.9464\n",
      "Epoch 19 Step 280: Train 0.7403 Reg: 0.2738\n",
      "Test: 0.8122 MAE: 0.7156 RMSE: 0.9012\n",
      "Val: 0.8942 MAE: 0.7395 RMSE: 0.9456\n",
      "Epoch 20 Step 294: Train 0.7369 Reg: 0.2727\n",
      "Test: 0.8115 MAE: 0.7165 RMSE: 0.9008\n",
      "Val: 0.8911 MAE: 0.7385 RMSE: 0.9440\n",
      "Epoch 21 Step 308: Train 0.7340 Reg: 0.2716\n",
      "Test: 0.8106 MAE: 0.7174 RMSE: 0.9003\n",
      "Val: 0.8912 MAE: 0.7384 RMSE: 0.9440\n",
      "Epoch 22 Step 322: Train 0.7315 Reg: 0.2706\n",
      "Test: 0.8089 MAE: 0.7172 RMSE: 0.8994\n",
      "Val: 0.8899 MAE: 0.7380 RMSE: 0.9433\n",
      "Epoch 23 Step 336: Train 0.7293 Reg: 0.2696\n",
      "Test: 0.8121 MAE: 0.7191 RMSE: 0.9012\n",
      "Val: 0.8895 MAE: 0.7380 RMSE: 0.9431\n",
      "Epoch 24 Step 350: Train 0.7274 Reg: 0.2686\n",
      "Test: 0.8109 MAE: 0.7189 RMSE: 0.9005\n",
      "Val: 0.8882 MAE: 0.7376 RMSE: 0.9425\n",
      "Epoch 25 Step 364: Train 0.7258 Reg: 0.2678\n",
      "Test: 0.8108 MAE: 0.7197 RMSE: 0.9004\n",
      "Val: 0.8873 MAE: 0.7371 RMSE: 0.9420\n",
      "Epoch 26 Step 378: Train 0.7243 Reg: 0.2669\n",
      "Test: 0.8116 MAE: 0.7207 RMSE: 0.9009\n",
      "Val: 0.8869 MAE: 0.7369 RMSE: 0.9418\n",
      "Epoch 27 Step 392: Train 0.7230 Reg: 0.2662\n",
      "Test: 0.8130 MAE: 0.7215 RMSE: 0.9017\n",
      "Val: 0.8869 MAE: 0.7370 RMSE: 0.9418\n",
      "Epoch 28 Step 406: Train 0.7219 Reg: 0.2655\n",
      "Test: 0.8141 MAE: 0.7223 RMSE: 0.9023\n",
      "Val: 0.8869 MAE: 0.7372 RMSE: 0.9417\n",
      "Epoch 29 Step 420: Train 0.7208 Reg: 0.2648\n",
      "Test: 0.8157 MAE: 0.7236 RMSE: 0.9032\n",
      "Val: 0.8873 MAE: 0.7374 RMSE: 0.9420\n",
      "Epoch 30 Step 434: Train 0.7199 Reg: 0.2641\n",
      "Test: 0.8158 MAE: 0.7240 RMSE: 0.9032\n",
      "Val: 0.8867 MAE: 0.7373 RMSE: 0.9417\n",
      "Epoch 31 Step 448: Train 0.7191 Reg: 0.2636\n",
      "Test: 0.8182 MAE: 0.7254 RMSE: 0.9045\n",
      "Val: 0.8865 MAE: 0.7371 RMSE: 0.9416\n",
      "Epoch 32 Step 462: Train 0.7183 Reg: 0.2630\n",
      "Test: 0.8188 MAE: 0.7259 RMSE: 0.9049\n",
      "Val: 0.8865 MAE: 0.7372 RMSE: 0.9415\n",
      "Epoch 33 Step 476: Train 0.7176 Reg: 0.2624\n",
      "Test: 0.8192 MAE: 0.7265 RMSE: 0.9051\n",
      "Val: 0.8866 MAE: 0.7373 RMSE: 0.9416\n",
      "Epoch 34 Step 490: Train 0.7169 Reg: 0.2619\n",
      "Test: 0.8212 MAE: 0.7273 RMSE: 0.9062\n",
      "Val: 0.8865 MAE: 0.7372 RMSE: 0.9415\n",
      "Epoch 35 Step 504: Train 0.7162 Reg: 0.2614\n",
      "Test: 0.8210 MAE: 0.7279 RMSE: 0.9061\n",
      "Val: 0.8860 MAE: 0.7372 RMSE: 0.9413\n",
      "Epoch 36 Step 518: Train 0.7157 Reg: 0.2610\n",
      "Test: 0.8221 MAE: 0.7285 RMSE: 0.9067\n",
      "Val: 0.8869 MAE: 0.7377 RMSE: 0.9417\n",
      "Epoch 37 Step 532: Train 0.7152 Reg: 0.2605\n",
      "Test: 0.8233 MAE: 0.7290 RMSE: 0.9073\n",
      "Val: 0.8872 MAE: 0.7379 RMSE: 0.9419\n",
      "Epoch 38 Step 546: Train 0.7148 Reg: 0.2601\n",
      "Test: 0.8238 MAE: 0.7293 RMSE: 0.9076\n",
      "Val: 0.8869 MAE: 0.7377 RMSE: 0.9418\n",
      "Epoch 39 Step 560: Train 0.7144 Reg: 0.2597\n",
      "Test: 0.8243 MAE: 0.7297 RMSE: 0.9079\n",
      "Val: 0.8867 MAE: 0.7376 RMSE: 0.9416\n",
      "Epoch 40 Step 574: Train 0.7140 Reg: 0.2593\n",
      "Test: 0.8257 MAE: 0.7307 RMSE: 0.9087\n",
      "Val: 0.8867 MAE: 0.7377 RMSE: 0.9417\n",
      "Epoch 41 Step 588: Train 0.7136 Reg: 0.2590\n",
      "Test: 0.8264 MAE: 0.7310 RMSE: 0.9091\n",
      "Val: 0.8864 MAE: 0.7376 RMSE: 0.9415\n",
      "Epoch 42 Step 602: Train 0.7132 Reg: 0.2587\n",
      "Test: 0.8275 MAE: 0.7317 RMSE: 0.9097\n",
      "Val: 0.8867 MAE: 0.7377 RMSE: 0.9417\n",
      "Epoch 43 Step 616: Train 0.7129 Reg: 0.2583\n",
      "Test: 0.8277 MAE: 0.7320 RMSE: 0.9098\n",
      "Val: 0.8872 MAE: 0.7381 RMSE: 0.9419\n",
      "Epoch 44 Step 630: Train 0.7126 Reg: 0.2581\n",
      "Test: 0.8279 MAE: 0.7322 RMSE: 0.9099\n",
      "Val: 0.8869 MAE: 0.7380 RMSE: 0.9418\n",
      "Epoch 45 Step 644: Train 0.7123 Reg: 0.2578\n",
      "Test: 0.8286 MAE: 0.7324 RMSE: 0.9103\n",
      "Val: 0.8869 MAE: 0.7380 RMSE: 0.9418\n",
      "Epoch 46 Step 658: Train 0.7121 Reg: 0.2575\n",
      "Test: 0.8297 MAE: 0.7330 RMSE: 0.9109\n",
      "Val: 0.8872 MAE: 0.7382 RMSE: 0.9419\n",
      "Epoch 47 Step 672: Train 0.7118 Reg: 0.2573\n",
      "Test: 0.8307 MAE: 0.7335 RMSE: 0.9114\n",
      "Val: 0.8871 MAE: 0.7382 RMSE: 0.9419\n",
      "Epoch 48 Step 686: Train 0.7116 Reg: 0.2570\n",
      "Test: 0.8312 MAE: 0.7337 RMSE: 0.9117\n",
      "Val: 0.8868 MAE: 0.7380 RMSE: 0.9417\n",
      "Epoch 49 Step 700: Train 0.7114 Reg: 0.2568\n",
      "Test: 0.8312 MAE: 0.7337 RMSE: 0.9117\n",
      "Val: 0.8868 MAE: 0.7380 RMSE: 0.9417\n",
      "Epoch 50 Step 714: Train 0.7112 Reg: 0.2566\n",
      "Test: 0.8322 MAE: 0.7343 RMSE: 0.9123\n",
      "Val: 0.8872 MAE: 0.7383 RMSE: 0.9419\n",
      "Epoch 51 Step 728: Train 0.7110 Reg: 0.2564\n",
      "Test: 0.8324 MAE: 0.7344 RMSE: 0.9123\n",
      "Val: 0.8875 MAE: 0.7384 RMSE: 0.9421\n",
      "Epoch 52 Step 742: Train 0.7108 Reg: 0.2562\n",
      "Test: 0.8328 MAE: 0.7347 RMSE: 0.9126\n",
      "Val: 0.8873 MAE: 0.7383 RMSE: 0.9420\n",
      "Epoch 53 Step 756: Train 0.7106 Reg: 0.2560\n",
      "Test: 0.8331 MAE: 0.7347 RMSE: 0.9127\n",
      "Val: 0.8874 MAE: 0.7384 RMSE: 0.9420\n",
      "Epoch 54 Step 770: Train 0.7104 Reg: 0.2559\n",
      "Test: 0.8334 MAE: 0.7350 RMSE: 0.9129\n",
      "Val: 0.8875 MAE: 0.7385 RMSE: 0.9421\n",
      "Epoch 55 Step 784: Train 0.7103 Reg: 0.2557\n",
      "Test: 0.8343 MAE: 0.7355 RMSE: 0.9134\n",
      "Val: 0.8876 MAE: 0.7386 RMSE: 0.9421\n",
      "Epoch 56 Step 798: Train 0.7101 Reg: 0.2555\n",
      "Test: 0.8343 MAE: 0.7356 RMSE: 0.9134\n",
      "Val: 0.8875 MAE: 0.7385 RMSE: 0.9421\n",
      "Epoch 57 Step 812: Train 0.7100 Reg: 0.2554\n",
      "Test: 0.8350 MAE: 0.7359 RMSE: 0.9138\n",
      "Val: 0.8876 MAE: 0.7385 RMSE: 0.9421\n",
      "Epoch 58 Step 826: Train 0.7099 Reg: 0.2552\n",
      "Test: 0.8352 MAE: 0.7360 RMSE: 0.9139\n",
      "Val: 0.8875 MAE: 0.7385 RMSE: 0.9421\n",
      "Epoch 59 Step 840: Train 0.7098 Reg: 0.2551\n",
      "Test: 0.8357 MAE: 0.7363 RMSE: 0.9142\n",
      "Val: 0.8877 MAE: 0.7386 RMSE: 0.9422\n",
      "Epoch 60 Step 854: Train 0.7096 Reg: 0.2550\n",
      "Test: 0.8356 MAE: 0.7362 RMSE: 0.9141\n",
      "Val: 0.8876 MAE: 0.7386 RMSE: 0.9421\n",
      "Epoch 61 Step 868: Train 0.7095 Reg: 0.2549\n",
      "Test: 0.8359 MAE: 0.7364 RMSE: 0.9143\n",
      "Val: 0.8876 MAE: 0.7385 RMSE: 0.9421\n",
      "Epoch 62 Step 882: Train 0.7094 Reg: 0.2547\n",
      "Test: 0.8361 MAE: 0.7366 RMSE: 0.9144\n",
      "Val: 0.8876 MAE: 0.7386 RMSE: 0.9421\n",
      "Epoch 63 Step 896: Train 0.7093 Reg: 0.2546\n",
      "Test: 0.8366 MAE: 0.7368 RMSE: 0.9146\n",
      "Val: 0.8876 MAE: 0.7386 RMSE: 0.9421\n",
      "Epoch 64 Step 910: Train 0.7092 Reg: 0.2545\n",
      "Test: 0.8369 MAE: 0.7369 RMSE: 0.9148\n",
      "Val: 0.8877 MAE: 0.7386 RMSE: 0.9422\n",
      "Epoch 65 Step 924: Train 0.7091 Reg: 0.2544\n",
      "Test: 0.8371 MAE: 0.7370 RMSE: 0.9149\n",
      "Val: 0.8877 MAE: 0.7387 RMSE: 0.9422\n",
      "Epoch 66 Step 938: Train 0.7090 Reg: 0.2544\n",
      "Test: 0.8372 MAE: 0.7371 RMSE: 0.9150\n",
      "Val: 0.8878 MAE: 0.7387 RMSE: 0.9422\n",
      "Epoch 67 Step 952: Train 0.7090 Reg: 0.2543\n",
      "Test: 0.8377 MAE: 0.7374 RMSE: 0.9153\n",
      "Val: 0.8877 MAE: 0.7387 RMSE: 0.9422\n",
      "Epoch 68 Step 966: Train 0.7089 Reg: 0.2542\n",
      "Test: 0.8380 MAE: 0.7376 RMSE: 0.9154\n",
      "Val: 0.8877 MAE: 0.7387 RMSE: 0.9422\n",
      "Epoch 69 Step 980: Train 0.7088 Reg: 0.2541\n",
      "Test: 0.8380 MAE: 0.7376 RMSE: 0.9154\n",
      "Val: 0.8878 MAE: 0.7387 RMSE: 0.9423\n",
      "Epoch 70 Step 994: Train 0.7088 Reg: 0.2540\n",
      "Test: 0.8382 MAE: 0.7378 RMSE: 0.9155\n",
      "Val: 0.8878 MAE: 0.7387 RMSE: 0.9422\n",
      "Epoch 71 Step 1008: Train 0.7087 Reg: 0.2539\n",
      "Test: 0.8384 MAE: 0.7378 RMSE: 0.9157\n",
      "Val: 0.8878 MAE: 0.7387 RMSE: 0.9422\n",
      "Epoch 72 Step 1022: Train 0.7086 Reg: 0.2539\n",
      "Test: 0.8384 MAE: 0.7379 RMSE: 0.9156\n",
      "Val: 0.8878 MAE: 0.7387 RMSE: 0.9423\n",
      "Epoch 73 Step 1036: Train 0.7086 Reg: 0.2538\n",
      "Test: 0.8385 MAE: 0.7380 RMSE: 0.9157\n",
      "Val: 0.8879 MAE: 0.7387 RMSE: 0.9423\n",
      "Epoch 74 Step 1050: Train 0.7085 Reg: 0.2538\n",
      "Test: 0.8387 MAE: 0.7381 RMSE: 0.9158\n",
      "Val: 0.8879 MAE: 0.7387 RMSE: 0.9423\n",
      "Epoch 75 Step 1064: Train 0.7085 Reg: 0.2537\n",
      "Test: 0.8389 MAE: 0.7382 RMSE: 0.9159\n",
      "Val: 0.8879 MAE: 0.7387 RMSE: 0.9423\n",
      "Epoch 76 Step 1078: Train 0.7084 Reg: 0.2536\n",
      "Test: 0.8390 MAE: 0.7383 RMSE: 0.9160\n",
      "Val: 0.8879 MAE: 0.7388 RMSE: 0.9423\n",
      "Epoch 77 Step 1092: Train 0.7084 Reg: 0.2536\n",
      "Test: 0.8391 MAE: 0.7384 RMSE: 0.9160\n",
      "Val: 0.8879 MAE: 0.7387 RMSE: 0.9423\n",
      "Epoch 78 Step 1106: Train 0.7083 Reg: 0.2535\n",
      "Test: 0.8392 MAE: 0.7384 RMSE: 0.9161\n",
      "Val: 0.8879 MAE: 0.7387 RMSE: 0.9423\n",
      "Epoch 79 Step 1120: Train 0.7083 Reg: 0.2535\n",
      "Test: 0.8394 MAE: 0.7385 RMSE: 0.9162\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9423\n",
      "Epoch 80 Step 1134: Train 0.7082 Reg: 0.2534\n",
      "Test: 0.8395 MAE: 0.7386 RMSE: 0.9163\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9423\n",
      "Epoch 81 Step 1148: Train 0.7082 Reg: 0.2534\n",
      "Test: 0.8396 MAE: 0.7386 RMSE: 0.9163\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9423\n",
      "Epoch 82 Step 1162: Train 0.7082 Reg: 0.2534\n",
      "Test: 0.8396 MAE: 0.7387 RMSE: 0.9163\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9423\n",
      "Epoch 83 Step 1176: Train 0.7081 Reg: 0.2533\n",
      "Test: 0.8398 MAE: 0.7387 RMSE: 0.9164\n",
      "Val: 0.8879 MAE: 0.7387 RMSE: 0.9423\n",
      "Epoch 84 Step 1190: Train 0.7081 Reg: 0.2533\n",
      "Test: 0.8398 MAE: 0.7388 RMSE: 0.9164\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9423\n",
      "Epoch 85 Step 1204: Train 0.7081 Reg: 0.2532\n",
      "Test: 0.8399 MAE: 0.7388 RMSE: 0.9165\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9423\n",
      "Epoch 86 Step 1218: Train 0.7080 Reg: 0.2532\n",
      "Test: 0.8400 MAE: 0.7389 RMSE: 0.9165\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9423\n",
      "Epoch 87 Step 1232: Train 0.7080 Reg: 0.2532\n",
      "Test: 0.8401 MAE: 0.7390 RMSE: 0.9166\n",
      "Val: 0.8879 MAE: 0.7388 RMSE: 0.9423\n",
      "Epoch 88 Step 1246: Train 0.7080 Reg: 0.2532\n",
      "Test: 0.8402 MAE: 0.7390 RMSE: 0.9166\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9423\n",
      "Epoch 89 Step 1260: Train 0.7080 Reg: 0.2531\n",
      "Test: 0.8402 MAE: 0.7390 RMSE: 0.9166\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9423\n",
      "Epoch 90 Step 1274: Train 0.7079 Reg: 0.2531\n",
      "Test: 0.8403 MAE: 0.7391 RMSE: 0.9167\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9423\n",
      "Epoch 91 Step 1288: Train 0.7079 Reg: 0.2531\n",
      "Test: 0.8403 MAE: 0.7391 RMSE: 0.9167\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9423\n",
      "Epoch 92 Step 1302: Train 0.7079 Reg: 0.2530\n",
      "Test: 0.8404 MAE: 0.7391 RMSE: 0.9167\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9424\n",
      "Epoch 93 Step 1316: Train 0.7079 Reg: 0.2530\n",
      "Test: 0.8405 MAE: 0.7392 RMSE: 0.9168\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9423\n",
      "Epoch 94 Step 1330: Train 0.7079 Reg: 0.2530\n",
      "Test: 0.8405 MAE: 0.7392 RMSE: 0.9168\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9423\n",
      "Epoch 95 Step 1344: Train 0.7078 Reg: 0.2530\n",
      "Test: 0.8406 MAE: 0.7392 RMSE: 0.9168\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9424\n",
      "Epoch 96 Step 1358: Train 0.7078 Reg: 0.2530\n",
      "Test: 0.8406 MAE: 0.7393 RMSE: 0.9169\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9423\n",
      "Epoch 97 Step 1372: Train 0.7078 Reg: 0.2529\n",
      "Test: 0.8407 MAE: 0.7393 RMSE: 0.9169\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9424\n",
      "Epoch 98 Step 1386: Train 0.7078 Reg: 0.2529\n",
      "Test: 0.8407 MAE: 0.7393 RMSE: 0.9169\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9424\n",
      "Epoch 99 Step 1400: Train 0.7078 Reg: 0.2529\n",
      "Test: 0.8408 MAE: 0.7394 RMSE: 0.9170\n",
      "Val: 0.8880 MAE: 0.7388 RMSE: 0.9424\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 14039/4938\n",
      "test set size: support/query 73/213\n",
      "Epoch 0: TrainLoss 2.2975 RecLoss: 0.0000 (left: 0:03:27)\n",
      "TestLoss: 1.3656 MAE: 0.9391 RMSE: 1.1686\n",
      "ValLoss: 1.2177 MAE: 0.8954 RMSE: 1.1035\n",
      "Epoch 1: TrainLoss 1.3183 RecLoss: 0.0000 (left: 0:02:30)\n",
      "TestLoss: 1.4708 MAE: 1.0437 RMSE: 1.2128\n",
      "ValLoss: 1.3661 MAE: 1.0151 RMSE: 1.1688\n",
      "Epoch 2: TrainLoss 1.2466 RecLoss: 0.0000 (left: 0:02:27)\n",
      "TestLoss: 1.3909 MAE: 1.0013 RMSE: 1.1794\n",
      "ValLoss: 1.2728 MAE: 0.9693 RMSE: 1.1282\n",
      "Epoch 3: TrainLoss 1.1826 RecLoss: 0.0000 (left: 0:02:17)\n",
      "TestLoss: 1.3456 MAE: 0.9493 RMSE: 1.1600\n",
      "ValLoss: 1.2039 MAE: 0.9121 RMSE: 1.0972\n",
      "Epoch 4: TrainLoss 1.1610 RecLoss: 0.0000 (left: 0:02:15)\n",
      "TestLoss: 1.3136 MAE: 0.9429 RMSE: 1.1461\n",
      "ValLoss: 1.1554 MAE: 0.9015 RMSE: 1.0749\n",
      "Epoch 5: TrainLoss 1.1217 RecLoss: 0.0000 (left: 0:02:12)\n",
      "TestLoss: 1.2997 MAE: 0.9449 RMSE: 1.1400\n",
      "ValLoss: 1.1283 MAE: 0.9010 RMSE: 1.0622\n",
      "Epoch 6: TrainLoss 1.1014 RecLoss: 0.0000 (left: 0:02:06)\n",
      "TestLoss: 1.2808 MAE: 0.9315 RMSE: 1.1317\n",
      "ValLoss: 1.0935 MAE: 0.8824 RMSE: 1.0457\n",
      "Epoch 7: TrainLoss 1.0836 RecLoss: 0.0000 (left: 0:02:08)\n",
      "TestLoss: 1.2637 MAE: 0.9168 RMSE: 1.1241\n",
      "ValLoss: 1.0598 MAE: 0.8621 RMSE: 1.0295\n",
      "Epoch 8: TrainLoss 1.0717 RecLoss: 0.0000 (left: 0:02:09)\n",
      "TestLoss: 1.2542 MAE: 0.9113 RMSE: 1.1199\n",
      "ValLoss: 1.0441 MAE: 0.8561 RMSE: 1.0218\n",
      "Epoch 9: TrainLoss 1.0605 RecLoss: 0.0000 (left: 0:02:03)\n",
      "TestLoss: 1.2479 MAE: 0.9119 RMSE: 1.1171\n",
      "ValLoss: 1.0411 MAE: 0.8577 RMSE: 1.0203\n",
      "Epoch 10: TrainLoss 1.0517 RecLoss: 0.0000 (left: 0:01:59)\n",
      "TestLoss: 1.2363 MAE: 0.9053 RMSE: 1.1119\n",
      "ValLoss: 1.0319 MAE: 0.8527 RMSE: 1.0158\n",
      "Epoch 11: TrainLoss 1.0430 RecLoss: 0.0000 (left: 0:02:00)\n",
      "TestLoss: 1.2237 MAE: 0.8969 RMSE: 1.1062\n",
      "ValLoss: 1.0241 MAE: 0.8458 RMSE: 1.0120\n",
      "Epoch 12: TrainLoss 1.0350 RecLoss: 0.0000 (left: 0:02:02)\n",
      "TestLoss: 1.2166 MAE: 0.8963 RMSE: 1.1030\n",
      "ValLoss: 1.0295 MAE: 0.8518 RMSE: 1.0147\n",
      "Epoch 13: TrainLoss 1.0272 RecLoss: 0.0000 (left: 0:02:00)\n",
      "TestLoss: 1.2059 MAE: 0.8902 RMSE: 1.0981\n",
      "ValLoss: 1.0277 MAE: 0.8498 RMSE: 1.0137\n",
      "Epoch 14: TrainLoss 1.0204 RecLoss: 0.0000 (left: 0:02:00)\n",
      "TestLoss: 1.1981 MAE: 0.8861 RMSE: 1.0946\n",
      "ValLoss: 1.0251 MAE: 0.8477 RMSE: 1.0125\n",
      "Epoch 15: TrainLoss 1.0151 RecLoss: 0.0000 (left: 0:01:56)\n",
      "TestLoss: 1.1923 MAE: 0.8841 RMSE: 1.0919\n",
      "ValLoss: 1.0244 MAE: 0.8476 RMSE: 1.0121\n",
      "Epoch 16: TrainLoss 1.0101 RecLoss: 0.0000 (left: 0:01:54)\n",
      "TestLoss: 1.1869 MAE: 0.8819 RMSE: 1.0894\n",
      "ValLoss: 1.0229 MAE: 0.8463 RMSE: 1.0114\n",
      "Epoch 17: TrainLoss 1.0056 RecLoss: 0.0000 (left: 0:01:53)\n",
      "TestLoss: 1.1807 MAE: 0.8783 RMSE: 1.0866\n",
      "ValLoss: 1.0183 MAE: 0.8426 RMSE: 1.0091\n",
      "Epoch 18: TrainLoss 1.0016 RecLoss: 0.0000 (left: 0:01:52)\n",
      "TestLoss: 1.1767 MAE: 0.8766 RMSE: 1.0848\n",
      "ValLoss: 1.0171 MAE: 0.8417 RMSE: 1.0085\n",
      "Epoch 19: TrainLoss 0.9984 RecLoss: 0.0000 (left: 0:01:50)\n",
      "TestLoss: 1.1744 MAE: 0.8768 RMSE: 1.0837\n",
      "ValLoss: 1.0164 MAE: 0.8419 RMSE: 1.0082\n",
      "Epoch 20: TrainLoss 0.9951 RecLoss: 0.0000 (left: 0:01:50)\n",
      "TestLoss: 1.1693 MAE: 0.8729 RMSE: 1.0813\n",
      "ValLoss: 1.0123 MAE: 0.8380 RMSE: 1.0061\n",
      "Epoch 21: TrainLoss 0.9922 RecLoss: 0.0000 (left: 0:01:49)\n",
      "TestLoss: 1.1676 MAE: 0.8733 RMSE: 1.0805\n",
      "ValLoss: 1.0136 MAE: 0.8394 RMSE: 1.0068\n",
      "Epoch 22: TrainLoss 0.9896 RecLoss: 0.0000 (left: 0:01:49)\n",
      "TestLoss: 1.1642 MAE: 0.8713 RMSE: 1.0790\n",
      "ValLoss: 1.0097 MAE: 0.8365 RMSE: 1.0048\n",
      "Epoch 23: TrainLoss 0.9875 RecLoss: 0.0000 (left: 0:01:47)\n",
      "TestLoss: 1.1603 MAE: 0.8685 RMSE: 1.0772\n",
      "ValLoss: 1.0078 MAE: 0.8343 RMSE: 1.0039\n",
      "Epoch 24: TrainLoss 0.9858 RecLoss: 0.0000 (left: 0:01:46)\n",
      "TestLoss: 1.1568 MAE: 0.8654 RMSE: 1.0756\n",
      "ValLoss: 1.0071 MAE: 0.8321 RMSE: 1.0035\n",
      "Epoch 25: TrainLoss 0.9837 RecLoss: 0.0000 (left: 0:01:45)\n",
      "TestLoss: 1.1588 MAE: 0.8699 RMSE: 1.0765\n",
      "ValLoss: 1.0132 MAE: 0.8378 RMSE: 1.0066\n",
      "Epoch 26: TrainLoss 0.9825 RecLoss: 0.0000 (left: 0:01:44)\n",
      "TestLoss: 1.1536 MAE: 0.8647 RMSE: 1.0740\n",
      "ValLoss: 1.0063 MAE: 0.8315 RMSE: 1.0031\n",
      "Epoch 27: TrainLoss 0.9800 RecLoss: 0.0000 (left: 0:01:43)\n",
      "TestLoss: 1.1528 MAE: 0.8656 RMSE: 1.0737\n",
      "ValLoss: 1.0085 MAE: 0.8334 RMSE: 1.0042\n",
      "Epoch 28: TrainLoss 0.9785 RecLoss: 0.0000 (left: 0:01:41)\n",
      "TestLoss: 1.1512 MAE: 0.8648 RMSE: 1.0730\n",
      "ValLoss: 1.0080 MAE: 0.8327 RMSE: 1.0040\n",
      "Epoch 29: TrainLoss 0.9776 RecLoss: 0.0000 (left: 0:01:39)\n",
      "TestLoss: 1.1478 MAE: 0.8610 RMSE: 1.0713\n",
      "ValLoss: 1.0048 MAE: 0.8290 RMSE: 1.0024\n",
      "Epoch 30: TrainLoss 0.9770 RecLoss: 0.0000 (left: 0:01:38)\n",
      "TestLoss: 1.1488 MAE: 0.8633 RMSE: 1.0718\n",
      "ValLoss: 1.0068 MAE: 0.8315 RMSE: 1.0034\n",
      "Epoch 31: TrainLoss 0.9755 RecLoss: 0.0000 (left: 0:01:37)\n",
      "TestLoss: 1.1455 MAE: 0.8600 RMSE: 1.0703\n",
      "ValLoss: 1.0054 MAE: 0.8289 RMSE: 1.0027\n",
      "Epoch 32: TrainLoss 0.9743 RecLoss: 0.0000 (left: 0:01:35)\n",
      "TestLoss: 1.1455 MAE: 0.8609 RMSE: 1.0703\n",
      "ValLoss: 1.0069 MAE: 0.8304 RMSE: 1.0034\n",
      "Epoch 33: TrainLoss 0.9749 RecLoss: 0.0000 (left: 0:01:34)\n",
      "TestLoss: 1.1458 MAE: 0.8613 RMSE: 1.0704\n",
      "ValLoss: 1.0066 MAE: 0.8304 RMSE: 1.0033\n",
      "Epoch 34: TrainLoss 0.9727 RecLoss: 0.0000 (left: 0:01:32)\n",
      "TestLoss: 1.1420 MAE: 0.8557 RMSE: 1.0686\n",
      "ValLoss: 1.0009 MAE: 0.8240 RMSE: 1.0004\n",
      "Epoch 35: TrainLoss 0.9723 RecLoss: 0.0000 (left: 0:01:31)\n",
      "TestLoss: 1.1430 MAE: 0.8592 RMSE: 1.0691\n",
      "ValLoss: 1.0047 MAE: 0.8285 RMSE: 1.0024\n",
      "Epoch 36: TrainLoss 0.9724 RecLoss: 0.0000 (left: 0:01:29)\n",
      "TestLoss: 1.1412 MAE: 0.8575 RMSE: 1.0683\n",
      "ValLoss: 1.0044 MAE: 0.8274 RMSE: 1.0022\n",
      "Epoch 37: TrainLoss 0.9707 RecLoss: 0.0000 (left: 0:01:27)\n",
      "TestLoss: 1.1394 MAE: 0.8547 RMSE: 1.0674\n",
      "ValLoss: 1.0023 MAE: 0.8245 RMSE: 1.0012\n",
      "Epoch 38: TrainLoss 0.9697 RecLoss: 0.0000 (left: 0:01:26)\n",
      "TestLoss: 1.1411 MAE: 0.8581 RMSE: 1.0682\n",
      "ValLoss: 1.0064 MAE: 0.8289 RMSE: 1.0032\n",
      "Epoch 39: TrainLoss 0.9693 RecLoss: 0.0000 (left: 0:01:24)\n",
      "TestLoss: 1.1383 MAE: 0.8549 RMSE: 1.0669\n",
      "ValLoss: 1.0028 MAE: 0.8252 RMSE: 1.0014\n",
      "Epoch 40: TrainLoss 0.9686 RecLoss: 0.0000 (left: 0:01:23)\n",
      "TestLoss: 1.1375 MAE: 0.8551 RMSE: 1.0665\n",
      "ValLoss: 1.0034 MAE: 0.8260 RMSE: 1.0017\n",
      "Epoch 41: TrainLoss 0.9680 RecLoss: 0.0000 (left: 0:01:21)\n",
      "TestLoss: 1.1364 MAE: 0.8548 RMSE: 1.0660\n",
      "ValLoss: 1.0025 MAE: 0.8257 RMSE: 1.0013\n",
      "Epoch 42: TrainLoss 0.9675 RecLoss: 0.0000 (left: 0:01:20)\n",
      "TestLoss: 1.1350 MAE: 0.8541 RMSE: 1.0653\n",
      "ValLoss: 1.0006 MAE: 0.8244 RMSE: 1.0003\n",
      "Epoch 43: TrainLoss 0.9667 RecLoss: 0.0000 (left: 0:01:19)\n",
      "TestLoss: 1.1329 MAE: 0.8527 RMSE: 1.0644\n",
      "ValLoss: 0.9988 MAE: 0.8230 RMSE: 0.9994\n",
      "Epoch 44: TrainLoss 0.9666 RecLoss: 0.0000 (left: 0:01:17)\n",
      "TestLoss: 1.1299 MAE: 0.8510 RMSE: 1.0630\n",
      "ValLoss: 0.9965 MAE: 0.8213 RMSE: 0.9983\n",
      "Epoch 45: TrainLoss 0.9653 RecLoss: 0.0000 (left: 0:01:16)\n",
      "TestLoss: 1.1299 MAE: 0.8539 RMSE: 1.0630\n",
      "ValLoss: 0.9996 MAE: 0.8253 RMSE: 0.9998\n",
      "Epoch 46: TrainLoss 0.9650 RecLoss: 0.0000 (left: 0:01:15)\n",
      "TestLoss: 1.1226 MAE: 0.8482 RMSE: 1.0595\n",
      "ValLoss: 0.9966 MAE: 0.8209 RMSE: 0.9983\n",
      "Epoch 47: TrainLoss 0.9640 RecLoss: 0.0000 (left: 0:01:13)\n",
      "TestLoss: 1.1175 MAE: 0.8478 RMSE: 1.0571\n",
      "ValLoss: 0.9950 MAE: 0.8220 RMSE: 0.9975\n",
      "Epoch 48: TrainLoss 0.9631 RecLoss: 0.0000 (left: 0:01:12)\n",
      "TestLoss: 1.1108 MAE: 0.8446 RMSE: 1.0540\n",
      "ValLoss: 0.9892 MAE: 0.8187 RMSE: 0.9946\n",
      "Epoch 49: TrainLoss 0.9629 RecLoss: 0.0000 (left: 0:01:10)\n",
      "TestLoss: 1.1090 MAE: 0.8447 RMSE: 1.0531\n",
      "ValLoss: 0.9932 MAE: 0.8217 RMSE: 0.9966\n",
      "Epoch 50: TrainLoss 0.9626 RecLoss: 0.0000 (left: 0:01:09)\n",
      "TestLoss: 1.1078 MAE: 0.8424 RMSE: 1.0525\n",
      "ValLoss: 0.9968 MAE: 0.8218 RMSE: 0.9984\n",
      "Epoch 51: TrainLoss 0.9639 RecLoss: 0.0000 (left: 0:01:08)\n",
      "TestLoss: 1.1123 MAE: 0.8424 RMSE: 1.0547\n",
      "ValLoss: 1.0074 MAE: 0.8255 RMSE: 1.0037\n",
      "Epoch 52: TrainLoss 0.9634 RecLoss: 0.0000 (left: 0:01:07)\n",
      "TestLoss: 1.1103 MAE: 0.8456 RMSE: 1.0537\n",
      "ValLoss: 0.9960 MAE: 0.8235 RMSE: 0.9980\n",
      "Epoch 53: TrainLoss 0.9612 RecLoss: 0.0000 (left: 0:01:06)\n",
      "TestLoss: 1.1058 MAE: 0.8413 RMSE: 1.0516\n",
      "ValLoss: 0.9887 MAE: 0.8176 RMSE: 0.9943\n",
      "Epoch 54: TrainLoss 0.9606 RecLoss: 0.0000 (left: 0:01:04)\n",
      "TestLoss: 1.1073 MAE: 0.8420 RMSE: 1.0523\n",
      "ValLoss: 0.9979 MAE: 0.8222 RMSE: 0.9990\n",
      "Epoch 55: TrainLoss 0.9605 RecLoss: 0.0000 (left: 0:01:03)\n",
      "TestLoss: 1.1089 MAE: 0.8424 RMSE: 1.0531\n",
      "ValLoss: 1.0022 MAE: 0.8241 RMSE: 1.0011\n",
      "Epoch 56: TrainLoss 0.9589 RecLoss: 0.0000 (left: 0:01:01)\n",
      "TestLoss: 1.1058 MAE: 0.8434 RMSE: 1.0516\n",
      "ValLoss: 0.9903 MAE: 0.8201 RMSE: 0.9951\n",
      "Epoch 57: TrainLoss 0.9587 RecLoss: 0.0000 (left: 0:01:00)\n",
      "TestLoss: 1.1017 MAE: 0.8384 RMSE: 1.0496\n",
      "ValLoss: 0.9912 MAE: 0.8173 RMSE: 0.9956\n",
      "Epoch 58: TrainLoss 0.9603 RecLoss: 0.0000 (left: 0:00:58)\n",
      "TestLoss: 1.1032 MAE: 0.8395 RMSE: 1.0503\n",
      "ValLoss: 1.0002 MAE: 0.8226 RMSE: 1.0001\n",
      "Epoch 59: TrainLoss 0.9588 RecLoss: 0.0000 (left: 0:00:56)\n",
      "TestLoss: 1.1041 MAE: 0.8412 RMSE: 1.0508\n",
      "ValLoss: 1.0032 MAE: 0.8252 RMSE: 1.0016\n",
      "Epoch 60: TrainLoss 0.9590 RecLoss: 0.0000 (left: 0:00:55)\n",
      "TestLoss: 1.1020 MAE: 0.8408 RMSE: 1.0497\n",
      "ValLoss: 0.9986 MAE: 0.8231 RMSE: 0.9993\n",
      "Epoch 61: TrainLoss 0.9586 RecLoss: 0.0000 (left: 0:00:54)\n",
      "TestLoss: 1.1001 MAE: 0.8375 RMSE: 1.0489\n",
      "ValLoss: 0.9999 MAE: 0.8220 RMSE: 1.0000\n",
      "Epoch 62: TrainLoss 0.9577 RecLoss: 0.0000 (left: 0:00:53)\n",
      "TestLoss: 1.1009 MAE: 0.8417 RMSE: 1.0492\n",
      "ValLoss: 0.9975 MAE: 0.8232 RMSE: 0.9988\n",
      "Epoch 63: TrainLoss 0.9558 RecLoss: 0.0000 (left: 0:00:51)\n",
      "TestLoss: 1.0977 MAE: 0.8359 RMSE: 1.0477\n",
      "ValLoss: 0.9991 MAE: 0.8209 RMSE: 0.9996\n",
      "Epoch 64: TrainLoss 0.9555 RecLoss: 0.0000 (left: 0:00:50)\n",
      "TestLoss: 1.1005 MAE: 0.8435 RMSE: 1.0490\n",
      "ValLoss: 0.9943 MAE: 0.8230 RMSE: 0.9971\n",
      "Epoch 65: TrainLoss 0.9560 RecLoss: 0.0000 (left: 0:00:49)\n",
      "TestLoss: 1.0999 MAE: 0.8362 RMSE: 1.0488\n",
      "ValLoss: 1.0056 MAE: 0.8237 RMSE: 1.0028\n",
      "Epoch 66: TrainLoss 0.9557 RecLoss: 0.0000 (left: 0:00:48)\n",
      "TestLoss: 1.0998 MAE: 0.8423 RMSE: 1.0487\n",
      "ValLoss: 0.9992 MAE: 0.8244 RMSE: 0.9996\n",
      "Epoch 67: TrainLoss 0.9545 RecLoss: 0.0000 (left: 0:00:46)\n",
      "TestLoss: 1.0988 MAE: 0.8355 RMSE: 1.0482\n",
      "ValLoss: 1.0050 MAE: 0.8231 RMSE: 1.0025\n",
      "Epoch 68: TrainLoss 0.9551 RecLoss: 0.0000 (left: 0:00:45)\n",
      "TestLoss: 1.0989 MAE: 0.8419 RMSE: 1.0483\n",
      "ValLoss: 0.9954 MAE: 0.8219 RMSE: 0.9977\n",
      "Epoch 69: TrainLoss 0.9549 RecLoss: 0.0000 (left: 0:00:43)\n",
      "TestLoss: 1.0990 MAE: 0.8384 RMSE: 1.0483\n",
      "ValLoss: 1.0011 MAE: 0.8225 RMSE: 1.0006\n",
      "Epoch 70: TrainLoss 0.9541 RecLoss: 0.0000 (left: 0:00:42)\n",
      "TestLoss: 1.0992 MAE: 0.8397 RMSE: 1.0484\n",
      "ValLoss: 1.0002 MAE: 0.8225 RMSE: 1.0001\n",
      "Epoch 71: TrainLoss 0.9524 RecLoss: 0.0000 (left: 0:00:41)\n",
      "TestLoss: 1.0995 MAE: 0.8376 RMSE: 1.0486\n",
      "ValLoss: 1.0097 MAE: 0.8260 RMSE: 1.0048\n",
      "Epoch 72: TrainLoss 0.9521 RecLoss: 0.0000 (left: 0:00:39)\n",
      "TestLoss: 1.0978 MAE: 0.8414 RMSE: 1.0478\n",
      "ValLoss: 1.0007 MAE: 0.8237 RMSE: 1.0003\n",
      "Epoch 73: TrainLoss 0.9511 RecLoss: 0.0000 (left: 0:00:38)\n",
      "TestLoss: 1.0962 MAE: 0.8327 RMSE: 1.0470\n",
      "ValLoss: 1.0065 MAE: 0.8213 RMSE: 1.0032\n",
      "Epoch 74: TrainLoss 0.9551 RecLoss: 0.0000 (left: 0:00:36)\n",
      "TestLoss: 1.0959 MAE: 0.8414 RMSE: 1.0469\n",
      "ValLoss: 1.0032 MAE: 0.8246 RMSE: 1.0016\n",
      "Epoch 75: TrainLoss 0.9512 RecLoss: 0.0000 (left: 0:00:35)\n",
      "TestLoss: 1.0972 MAE: 0.8343 RMSE: 1.0475\n",
      "ValLoss: 1.0132 MAE: 0.8254 RMSE: 1.0066\n",
      "Epoch 76: TrainLoss 0.9529 RecLoss: 0.0000 (left: 0:00:33)\n",
      "TestLoss: 1.0962 MAE: 0.8415 RMSE: 1.0470\n",
      "ValLoss: 1.0039 MAE: 0.8245 RMSE: 1.0020\n",
      "Epoch 77: TrainLoss 0.9522 RecLoss: 0.0000 (left: 0:00:32)\n",
      "TestLoss: 1.0978 MAE: 0.8387 RMSE: 1.0478\n",
      "ValLoss: 1.0083 MAE: 0.8248 RMSE: 1.0041\n",
      "Epoch 78: TrainLoss 0.9511 RecLoss: 0.0000 (left: 0:00:31)\n",
      "TestLoss: 1.0972 MAE: 0.8370 RMSE: 1.0475\n",
      "ValLoss: 1.0039 MAE: 0.8212 RMSE: 1.0019\n",
      "Epoch 79: TrainLoss 0.9530 RecLoss: 0.0000 (left: 0:00:29)\n",
      "TestLoss: 1.1022 MAE: 0.8456 RMSE: 1.0499\n",
      "ValLoss: 1.0088 MAE: 0.8277 RMSE: 1.0044\n",
      "Epoch 80: TrainLoss 0.9527 RecLoss: 0.0000 (left: 0:00:28)\n",
      "TestLoss: 1.1016 MAE: 0.8362 RMSE: 1.0496\n",
      "ValLoss: 1.0162 MAE: 0.8263 RMSE: 1.0081\n",
      "Epoch 81: TrainLoss 0.9521 RecLoss: 0.0000 (left: 0:00:27)\n",
      "TestLoss: 1.0990 MAE: 0.8432 RMSE: 1.0483\n",
      "ValLoss: 0.9985 MAE: 0.8211 RMSE: 0.9992\n",
      "Epoch 82: TrainLoss 0.9497 RecLoss: 0.0000 (left: 0:00:25)\n",
      "TestLoss: 1.0995 MAE: 0.8380 RMSE: 1.0486\n",
      "ValLoss: 1.0122 MAE: 0.8256 RMSE: 1.0061\n",
      "Epoch 83: TrainLoss 0.9503 RecLoss: 0.0000 (left: 0:00:24)\n",
      "TestLoss: 1.0978 MAE: 0.8421 RMSE: 1.0478\n",
      "ValLoss: 1.0050 MAE: 0.8239 RMSE: 1.0025\n",
      "Epoch 84: TrainLoss 0.9498 RecLoss: 0.0000 (left: 0:00:22)\n",
      "TestLoss: 1.0966 MAE: 0.8364 RMSE: 1.0472\n",
      "ValLoss: 1.0127 MAE: 0.8250 RMSE: 1.0063\n",
      "Epoch 85: TrainLoss 0.9493 RecLoss: 0.0000 (left: 0:00:21)\n",
      "TestLoss: 1.0948 MAE: 0.8402 RMSE: 1.0463\n",
      "ValLoss: 1.0071 MAE: 0.8238 RMSE: 1.0035\n",
      "Epoch 86: TrainLoss 0.9480 RecLoss: 0.0000 (left: 0:00:19)\n",
      "TestLoss: 1.0960 MAE: 0.8358 RMSE: 1.0469\n",
      "ValLoss: 1.0174 MAE: 0.8267 RMSE: 1.0086\n",
      "Epoch 87: TrainLoss 0.9484 RecLoss: 0.0000 (left: 0:00:18)\n",
      "TestLoss: 1.0945 MAE: 0.8400 RMSE: 1.0462\n",
      "ValLoss: 1.0089 MAE: 0.8242 RMSE: 1.0045\n",
      "Epoch 88: TrainLoss 0.9481 RecLoss: 0.0000 (left: 0:00:16)\n",
      "TestLoss: 1.0947 MAE: 0.8347 RMSE: 1.0463\n",
      "ValLoss: 1.0181 MAE: 0.8262 RMSE: 1.0090\n",
      "Epoch 89: TrainLoss 0.9490 RecLoss: 0.0000 (left: 0:00:15)\n",
      "TestLoss: 1.0969 MAE: 0.8434 RMSE: 1.0473\n",
      "ValLoss: 1.0151 MAE: 0.8281 RMSE: 1.0075\n",
      "Epoch 90: TrainLoss 0.9501 RecLoss: 0.0000 (left: 0:00:14)\n",
      "TestLoss: 1.0996 MAE: 0.8341 RMSE: 1.0486\n",
      "ValLoss: 1.0244 MAE: 0.8276 RMSE: 1.0121\n",
      "Epoch 91: TrainLoss 0.9496 RecLoss: 0.0000 (left: 0:00:12)\n",
      "TestLoss: 1.0977 MAE: 0.8415 RMSE: 1.0477\n",
      "ValLoss: 1.0113 MAE: 0.8252 RMSE: 1.0057\n",
      "Epoch 92: TrainLoss 0.9487 RecLoss: 0.0000 (left: 0:00:11)\n",
      "TestLoss: 1.0969 MAE: 0.8408 RMSE: 1.0473\n",
      "ValLoss: 1.0090 MAE: 0.8234 RMSE: 1.0045\n",
      "Epoch 93: TrainLoss 0.9475 RecLoss: 0.0000 (left: 0:00:09)\n",
      "TestLoss: 1.0992 MAE: 0.8378 RMSE: 1.0484\n",
      "ValLoss: 1.0192 MAE: 0.8274 RMSE: 1.0096\n",
      "Epoch 94: TrainLoss 0.9475 RecLoss: 0.0000 (left: 0:00:08)\n",
      "TestLoss: 1.0970 MAE: 0.8395 RMSE: 1.0474\n",
      "ValLoss: 1.0149 MAE: 0.8258 RMSE: 1.0074\n",
      "Epoch 95: TrainLoss 0.9474 RecLoss: 0.0000 (left: 0:00:07)\n",
      "TestLoss: 1.0953 MAE: 0.8388 RMSE: 1.0466\n",
      "ValLoss: 1.0141 MAE: 0.8246 RMSE: 1.0070\n",
      "Epoch 96: TrainLoss 0.9468 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 1.0969 MAE: 0.8382 RMSE: 1.0473\n",
      "ValLoss: 1.0221 MAE: 0.8285 RMSE: 1.0110\n",
      "Epoch 97: TrainLoss 0.9468 RecLoss: 0.0000 (left: 0:00:04)\n",
      "TestLoss: 1.0957 MAE: 0.8394 RMSE: 1.0467\n",
      "ValLoss: 1.0189 MAE: 0.8273 RMSE: 1.0094\n",
      "Epoch 98: TrainLoss 0.9505 RecLoss: 0.0000 (left: 0:00:02)\n",
      "TestLoss: 1.1103 MAE: 0.8318 RMSE: 1.0537\n",
      "ValLoss: 1.0376 MAE: 0.8310 RMSE: 1.0186\n",
      "Epoch 99: TrainLoss 0.9576 RecLoss: 0.0000 (left: 0:00:01)\n",
      "TestLoss: 1.1057 MAE: 0.8429 RMSE: 1.0515\n",
      "ValLoss: 1.0274 MAE: 0.8334 RMSE: 1.0136\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 14039/4938\n",
      "test set size: support/query 73/213\n",
      "USER HIS DICT: 943\n",
      "NUM IS: 943\n",
      "Key Test Result: MAE: 0.7279 RMSE: 0.9061 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 943\n",
      "NUM IS: 943\n",
      "Que Test Result: MAE: 0.8413 RMSE: 1.0516 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.8124 RMSE: 1.0164 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20% CUR coueusers to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 28113/4938\n",
      "test set size: support/query 146/213\n",
      "Epoch 0 Step 27: Train 11.8516 Reg: 0.4544\n",
      "Test: 10.1840 MAE: 2.9919 RMSE: 3.1912\n",
      "Val: 9.8517 MAE: 2.9453 RMSE: 3.1387\n",
      "Epoch 1 Step 54: Train 5.9453 Reg: 0.3438\n",
      "Test: 2.2150 MAE: 1.2813 RMSE: 1.4883\n",
      "Val: 2.0449 MAE: 1.2261 RMSE: 1.4300\n",
      "Epoch 2 Step 81: Train 1.3096 Reg: 0.3353\n",
      "Test: 1.1500 MAE: 0.9070 RMSE: 1.0724\n",
      "Val: 1.1098 MAE: 0.8699 RMSE: 1.0535\n",
      "Epoch 3 Step 108: Train 1.0737 Reg: 0.3237\n",
      "Test: 1.0898 MAE: 0.8863 RMSE: 1.0440\n",
      "Val: 1.0361 MAE: 0.8436 RMSE: 1.0179\n",
      "Epoch 4 Step 135: Train 0.9819 Reg: 0.3101\n",
      "Test: 1.0423 MAE: 0.8598 RMSE: 1.0209\n",
      "Val: 0.9728 MAE: 0.8162 RMSE: 0.9863\n",
      "Epoch 5 Step 162: Train 0.9120 Reg: 0.3050\n",
      "Test: 1.0153 MAE: 0.8245 RMSE: 1.0076\n",
      "Val: 0.9274 MAE: 0.7873 RMSE: 0.9630\n",
      "Epoch 6 Step 189: Train 0.8623 Reg: 0.3028\n",
      "Test: 0.9948 MAE: 0.8002 RMSE: 0.9974\n",
      "Val: 0.9028 MAE: 0.7646 RMSE: 0.9501\n",
      "Epoch 7 Step 216: Train 0.8326 Reg: 0.3006\n",
      "Test: 0.9920 MAE: 0.7894 RMSE: 0.9960\n",
      "Val: 0.8918 MAE: 0.7533 RMSE: 0.9444\n",
      "Epoch 8 Step 243: Train 0.8135 Reg: 0.2980\n",
      "Test: 0.9859 MAE: 0.7877 RMSE: 0.9929\n",
      "Val: 0.8841 MAE: 0.7477 RMSE: 0.9403\n",
      "Epoch 9 Step 270: Train 0.8011 Reg: 0.2952\n",
      "Test: 0.9855 MAE: 0.7883 RMSE: 0.9927\n",
      "Val: 0.8810 MAE: 0.7448 RMSE: 0.9386\n",
      "Epoch 10 Step 297: Train 0.7925 Reg: 0.2922\n",
      "Test: 0.9850 MAE: 0.7856 RMSE: 0.9925\n",
      "Val: 0.8776 MAE: 0.7430 RMSE: 0.9368\n",
      "Epoch 11 Step 324: Train 0.7858 Reg: 0.2898\n",
      "Test: 0.9807 MAE: 0.7877 RMSE: 0.9903\n",
      "Val: 0.8761 MAE: 0.7420 RMSE: 0.9360\n",
      "Epoch 12 Step 351: Train 0.7812 Reg: 0.2871\n",
      "Test: 0.9814 MAE: 0.7861 RMSE: 0.9906\n",
      "Val: 0.8741 MAE: 0.7411 RMSE: 0.9349\n",
      "Epoch 13 Step 378: Train 0.7773 Reg: 0.2847\n",
      "Test: 0.9798 MAE: 0.7843 RMSE: 0.9898\n",
      "Val: 0.8734 MAE: 0.7414 RMSE: 0.9346\n",
      "Epoch 14 Step 405: Train 0.7743 Reg: 0.2825\n",
      "Test: 0.9800 MAE: 0.7838 RMSE: 0.9899\n",
      "Val: 0.8692 MAE: 0.7396 RMSE: 0.9323\n",
      "Epoch 15 Step 432: Train 0.7719 Reg: 0.2804\n",
      "Test: 0.9772 MAE: 0.7823 RMSE: 0.9885\n",
      "Val: 0.8709 MAE: 0.7395 RMSE: 0.9332\n",
      "Epoch 16 Step 459: Train 0.7698 Reg: 0.2782\n",
      "Test: 0.9731 MAE: 0.7804 RMSE: 0.9865\n",
      "Val: 0.8706 MAE: 0.7402 RMSE: 0.9331\n",
      "Epoch 17 Step 486: Train 0.7680 Reg: 0.2762\n",
      "Test: 0.9726 MAE: 0.7805 RMSE: 0.9862\n",
      "Val: 0.8700 MAE: 0.7398 RMSE: 0.9327\n",
      "Epoch 18 Step 513: Train 0.7667 Reg: 0.2745\n",
      "Test: 0.9755 MAE: 0.7804 RMSE: 0.9877\n",
      "Val: 0.8692 MAE: 0.7392 RMSE: 0.9323\n",
      "Epoch 19 Step 540: Train 0.7649 Reg: 0.2726\n",
      "Test: 0.9772 MAE: 0.7799 RMSE: 0.9886\n",
      "Val: 0.8697 MAE: 0.7393 RMSE: 0.9326\n",
      "Epoch 20 Step 567: Train 0.7639 Reg: 0.2710\n",
      "Test: 0.9737 MAE: 0.7791 RMSE: 0.9868\n",
      "Val: 0.8694 MAE: 0.7393 RMSE: 0.9324\n",
      "Epoch 21 Step 594: Train 0.7627 Reg: 0.2694\n",
      "Test: 0.9738 MAE: 0.7771 RMSE: 0.9868\n",
      "Val: 0.8690 MAE: 0.7388 RMSE: 0.9322\n",
      "Epoch 22 Step 621: Train 0.7618 Reg: 0.2678\n",
      "Test: 0.9714 MAE: 0.7770 RMSE: 0.9856\n",
      "Val: 0.8691 MAE: 0.7391 RMSE: 0.9322\n",
      "Epoch 23 Step 648: Train 0.7609 Reg: 0.2664\n",
      "Test: 0.9710 MAE: 0.7770 RMSE: 0.9854\n",
      "Val: 0.8686 MAE: 0.7383 RMSE: 0.9320\n",
      "Epoch 24 Step 675: Train 0.7599 Reg: 0.2650\n",
      "Test: 0.9734 MAE: 0.7772 RMSE: 0.9866\n",
      "Val: 0.8681 MAE: 0.7384 RMSE: 0.9317\n",
      "Epoch 25 Step 702: Train 0.7592 Reg: 0.2638\n",
      "Test: 0.9748 MAE: 0.7781 RMSE: 0.9873\n",
      "Val: 0.8692 MAE: 0.7387 RMSE: 0.9323\n",
      "Epoch 26 Step 729: Train 0.7584 Reg: 0.2625\n",
      "Test: 0.9756 MAE: 0.7781 RMSE: 0.9877\n",
      "Val: 0.8692 MAE: 0.7381 RMSE: 0.9323\n",
      "Epoch 27 Step 756: Train 0.7577 Reg: 0.2613\n",
      "Test: 0.9738 MAE: 0.7775 RMSE: 0.9868\n",
      "Val: 0.8692 MAE: 0.7386 RMSE: 0.9323\n",
      "Epoch 28 Step 783: Train 0.7570 Reg: 0.2601\n",
      "Test: 0.9746 MAE: 0.7789 RMSE: 0.9872\n",
      "Val: 0.8681 MAE: 0.7379 RMSE: 0.9317\n",
      "Epoch 29 Step 810: Train 0.7565 Reg: 0.2590\n",
      "Test: 0.9725 MAE: 0.7784 RMSE: 0.9862\n",
      "Val: 0.8680 MAE: 0.7379 RMSE: 0.9317\n",
      "Epoch 30 Step 837: Train 0.7558 Reg: 0.2581\n",
      "Test: 0.9752 MAE: 0.7782 RMSE: 0.9875\n",
      "Val: 0.8686 MAE: 0.7382 RMSE: 0.9320\n",
      "Epoch 31 Step 864: Train 0.7553 Reg: 0.2571\n",
      "Test: 0.9748 MAE: 0.7786 RMSE: 0.9873\n",
      "Val: 0.8684 MAE: 0.7378 RMSE: 0.9319\n",
      "Epoch 32 Step 891: Train 0.7547 Reg: 0.2562\n",
      "Test: 0.9765 MAE: 0.7791 RMSE: 0.9882\n",
      "Val: 0.8685 MAE: 0.7378 RMSE: 0.9320\n",
      "Epoch 33 Step 918: Train 0.7543 Reg: 0.2554\n",
      "Test: 0.9764 MAE: 0.7783 RMSE: 0.9881\n",
      "Val: 0.8685 MAE: 0.7379 RMSE: 0.9319\n",
      "Epoch 34 Step 945: Train 0.7538 Reg: 0.2545\n",
      "Test: 0.9760 MAE: 0.7785 RMSE: 0.9879\n",
      "Val: 0.8682 MAE: 0.7374 RMSE: 0.9317\n",
      "Epoch 35 Step 972: Train 0.7534 Reg: 0.2538\n",
      "Test: 0.9760 MAE: 0.7781 RMSE: 0.9879\n",
      "Val: 0.8684 MAE: 0.7377 RMSE: 0.9319\n",
      "Epoch 36 Step 999: Train 0.7529 Reg: 0.2531\n",
      "Test: 0.9765 MAE: 0.7794 RMSE: 0.9882\n",
      "Val: 0.8681 MAE: 0.7374 RMSE: 0.9317\n",
      "Epoch 37 Step 1026: Train 0.7525 Reg: 0.2523\n",
      "Test: 0.9768 MAE: 0.7793 RMSE: 0.9883\n",
      "Val: 0.8682 MAE: 0.7374 RMSE: 0.9318\n",
      "Epoch 38 Step 1053: Train 0.7521 Reg: 0.2517\n",
      "Test: 0.9766 MAE: 0.7788 RMSE: 0.9882\n",
      "Val: 0.8685 MAE: 0.7376 RMSE: 0.9319\n",
      "Epoch 39 Step 1080: Train 0.7518 Reg: 0.2510\n",
      "Test: 0.9763 MAE: 0.7789 RMSE: 0.9881\n",
      "Val: 0.8678 MAE: 0.7372 RMSE: 0.9316\n",
      "Epoch 40 Step 1107: Train 0.7515 Reg: 0.2505\n",
      "Test: 0.9767 MAE: 0.7788 RMSE: 0.9883\n",
      "Val: 0.8679 MAE: 0.7372 RMSE: 0.9316\n",
      "Epoch 41 Step 1134: Train 0.7510 Reg: 0.2499\n",
      "Test: 0.9789 MAE: 0.7796 RMSE: 0.9894\n",
      "Val: 0.8680 MAE: 0.7372 RMSE: 0.9316\n",
      "Epoch 42 Step 1161: Train 0.7506 Reg: 0.2494\n",
      "Test: 0.9791 MAE: 0.7794 RMSE: 0.9895\n",
      "Val: 0.8678 MAE: 0.7370 RMSE: 0.9316\n",
      "Epoch 43 Step 1188: Train 0.7504 Reg: 0.2488\n",
      "Test: 0.9782 MAE: 0.7794 RMSE: 0.9890\n",
      "Val: 0.8676 MAE: 0.7370 RMSE: 0.9315\n",
      "Epoch 44 Step 1215: Train 0.7502 Reg: 0.2484\n",
      "Test: 0.9776 MAE: 0.7793 RMSE: 0.9887\n",
      "Val: 0.8680 MAE: 0.7370 RMSE: 0.9317\n",
      "Epoch 45 Step 1242: Train 0.7498 Reg: 0.2479\n",
      "Test: 0.9783 MAE: 0.7792 RMSE: 0.9891\n",
      "Val: 0.8679 MAE: 0.7370 RMSE: 0.9316\n",
      "Epoch 46 Step 1269: Train 0.7496 Reg: 0.2475\n",
      "Test: 0.9795 MAE: 0.7799 RMSE: 0.9897\n",
      "Val: 0.8679 MAE: 0.7371 RMSE: 0.9316\n",
      "Epoch 47 Step 1296: Train 0.7494 Reg: 0.2471\n",
      "Test: 0.9786 MAE: 0.7796 RMSE: 0.9892\n",
      "Val: 0.8678 MAE: 0.7370 RMSE: 0.9316\n",
      "Epoch 48 Step 1323: Train 0.7491 Reg: 0.2467\n",
      "Test: 0.9790 MAE: 0.7797 RMSE: 0.9895\n",
      "Val: 0.8679 MAE: 0.7369 RMSE: 0.9316\n",
      "Epoch 49 Step 1350: Train 0.7489 Reg: 0.2464\n",
      "Test: 0.9793 MAE: 0.7800 RMSE: 0.9896\n",
      "Val: 0.8679 MAE: 0.7369 RMSE: 0.9316\n",
      "Epoch 50 Step 1377: Train 0.7487 Reg: 0.2460\n",
      "Test: 0.9793 MAE: 0.7800 RMSE: 0.9896\n",
      "Val: 0.8676 MAE: 0.7368 RMSE: 0.9315\n",
      "Epoch 51 Step 1404: Train 0.7484 Reg: 0.2457\n",
      "Test: 0.9797 MAE: 0.7801 RMSE: 0.9898\n",
      "Val: 0.8675 MAE: 0.7367 RMSE: 0.9314\n",
      "Epoch 52 Step 1431: Train 0.7483 Reg: 0.2454\n",
      "Test: 0.9800 MAE: 0.7800 RMSE: 0.9900\n",
      "Val: 0.8677 MAE: 0.7368 RMSE: 0.9315\n",
      "Epoch 53 Step 1458: Train 0.7480 Reg: 0.2451\n",
      "Test: 0.9791 MAE: 0.7801 RMSE: 0.9895\n",
      "Val: 0.8677 MAE: 0.7368 RMSE: 0.9315\n",
      "Epoch 54 Step 1485: Train 0.7479 Reg: 0.2448\n",
      "Test: 0.9795 MAE: 0.7800 RMSE: 0.9897\n",
      "Val: 0.8676 MAE: 0.7369 RMSE: 0.9314\n",
      "Epoch 55 Step 1512: Train 0.7477 Reg: 0.2445\n",
      "Test: 0.9799 MAE: 0.7800 RMSE: 0.9899\n",
      "Val: 0.8674 MAE: 0.7367 RMSE: 0.9313\n",
      "Epoch 56 Step 1539: Train 0.7475 Reg: 0.2443\n",
      "Test: 0.9802 MAE: 0.7801 RMSE: 0.9900\n",
      "Val: 0.8676 MAE: 0.7367 RMSE: 0.9314\n",
      "Epoch 57 Step 1566: Train 0.7474 Reg: 0.2440\n",
      "Test: 0.9795 MAE: 0.7799 RMSE: 0.9897\n",
      "Val: 0.8675 MAE: 0.7367 RMSE: 0.9314\n",
      "Epoch 58 Step 1593: Train 0.7472 Reg: 0.2438\n",
      "Test: 0.9799 MAE: 0.7801 RMSE: 0.9899\n",
      "Val: 0.8674 MAE: 0.7367 RMSE: 0.9314\n",
      "Epoch 59 Step 1620: Train 0.7471 Reg: 0.2436\n",
      "Test: 0.9796 MAE: 0.7799 RMSE: 0.9897\n",
      "Val: 0.8674 MAE: 0.7366 RMSE: 0.9313\n",
      "Epoch 60 Step 1647: Train 0.7469 Reg: 0.2434\n",
      "Test: 0.9799 MAE: 0.7803 RMSE: 0.9899\n",
      "Val: 0.8674 MAE: 0.7367 RMSE: 0.9314\n",
      "Epoch 61 Step 1674: Train 0.7468 Reg: 0.2432\n",
      "Test: 0.9805 MAE: 0.7803 RMSE: 0.9902\n",
      "Val: 0.8674 MAE: 0.7367 RMSE: 0.9313\n",
      "Epoch 62 Step 1701: Train 0.7466 Reg: 0.2430\n",
      "Test: 0.9807 MAE: 0.7802 RMSE: 0.9903\n",
      "Val: 0.8675 MAE: 0.7366 RMSE: 0.9314\n",
      "Epoch 63 Step 1728: Train 0.7466 Reg: 0.2428\n",
      "Test: 0.9806 MAE: 0.7805 RMSE: 0.9902\n",
      "Val: 0.8674 MAE: 0.7368 RMSE: 0.9313\n",
      "Epoch 64 Step 1755: Train 0.7464 Reg: 0.2426\n",
      "Test: 0.9799 MAE: 0.7800 RMSE: 0.9899\n",
      "Val: 0.8673 MAE: 0.7366 RMSE: 0.9313\n",
      "Epoch 65 Step 1782: Train 0.7463 Reg: 0.2425\n",
      "Test: 0.9805 MAE: 0.7802 RMSE: 0.9902\n",
      "Val: 0.8674 MAE: 0.7366 RMSE: 0.9313\n",
      "Epoch 66 Step 1809: Train 0.7462 Reg: 0.2424\n",
      "Test: 0.9803 MAE: 0.7801 RMSE: 0.9901\n",
      "Val: 0.8674 MAE: 0.7365 RMSE: 0.9313\n",
      "Epoch 67 Step 1836: Train 0.7461 Reg: 0.2422\n",
      "Test: 0.9801 MAE: 0.7801 RMSE: 0.9900\n",
      "Val: 0.8673 MAE: 0.7365 RMSE: 0.9313\n",
      "Epoch 68 Step 1863: Train 0.7460 Reg: 0.2421\n",
      "Test: 0.9805 MAE: 0.7803 RMSE: 0.9902\n",
      "Val: 0.8673 MAE: 0.7365 RMSE: 0.9313\n",
      "Epoch 69 Step 1890: Train 0.7459 Reg: 0.2419\n",
      "Test: 0.9803 MAE: 0.7802 RMSE: 0.9901\n",
      "Val: 0.8673 MAE: 0.7365 RMSE: 0.9313\n",
      "Epoch 70 Step 1917: Train 0.7458 Reg: 0.2418\n",
      "Test: 0.9805 MAE: 0.7803 RMSE: 0.9902\n",
      "Val: 0.8674 MAE: 0.7365 RMSE: 0.9313\n",
      "Epoch 71 Step 1944: Train 0.7458 Reg: 0.2417\n",
      "Test: 0.9803 MAE: 0.7804 RMSE: 0.9901\n",
      "Val: 0.8674 MAE: 0.7366 RMSE: 0.9313\n",
      "Epoch 72 Step 1971: Train 0.7457 Reg: 0.2416\n",
      "Test: 0.9805 MAE: 0.7802 RMSE: 0.9902\n",
      "Val: 0.8674 MAE: 0.7365 RMSE: 0.9314\n",
      "Epoch 73 Step 1998: Train 0.7456 Reg: 0.2415\n",
      "Test: 0.9807 MAE: 0.7804 RMSE: 0.9903\n",
      "Val: 0.8673 MAE: 0.7365 RMSE: 0.9313\n",
      "Epoch 74 Step 2025: Train 0.7455 Reg: 0.2414\n",
      "Test: 0.9806 MAE: 0.7803 RMSE: 0.9903\n",
      "Val: 0.8673 MAE: 0.7365 RMSE: 0.9313\n",
      "Epoch 75 Step 2052: Train 0.7455 Reg: 0.2413\n",
      "Test: 0.9809 MAE: 0.7804 RMSE: 0.9904\n",
      "Val: 0.8673 MAE: 0.7364 RMSE: 0.9313\n",
      "Epoch 76 Step 2079: Train 0.7454 Reg: 0.2412\n",
      "Test: 0.9805 MAE: 0.7802 RMSE: 0.9902\n",
      "Val: 0.8674 MAE: 0.7365 RMSE: 0.9313\n",
      "Epoch 77 Step 2106: Train 0.7453 Reg: 0.2411\n",
      "Test: 0.9807 MAE: 0.7803 RMSE: 0.9903\n",
      "Val: 0.8673 MAE: 0.7365 RMSE: 0.9313\n",
      "Epoch 78 Step 2133: Train 0.7453 Reg: 0.2411\n",
      "Test: 0.9806 MAE: 0.7804 RMSE: 0.9902\n",
      "Val: 0.8673 MAE: 0.7365 RMSE: 0.9313\n",
      "Epoch 79 Step 2160: Train 0.7452 Reg: 0.2410\n",
      "Test: 0.9808 MAE: 0.7803 RMSE: 0.9903\n",
      "Val: 0.8673 MAE: 0.7364 RMSE: 0.9313\n",
      "Epoch 80 Step 2187: Train 0.7452 Reg: 0.2409\n",
      "Test: 0.9807 MAE: 0.7803 RMSE: 0.9903\n",
      "Val: 0.8673 MAE: 0.7364 RMSE: 0.9313\n",
      "Epoch 81 Step 2214: Train 0.7451 Reg: 0.2408\n",
      "Test: 0.9808 MAE: 0.7804 RMSE: 0.9903\n",
      "Val: 0.8673 MAE: 0.7364 RMSE: 0.9313\n",
      "Epoch 82 Step 2241: Train 0.7451 Reg: 0.2408\n",
      "Test: 0.9807 MAE: 0.7803 RMSE: 0.9903\n",
      "Val: 0.8673 MAE: 0.7364 RMSE: 0.9313\n",
      "Epoch 83 Step 2268: Train 0.7450 Reg: 0.2407\n",
      "Test: 0.9806 MAE: 0.7802 RMSE: 0.9903\n",
      "Val: 0.8673 MAE: 0.7364 RMSE: 0.9313\n",
      "Epoch 84 Step 2295: Train 0.7450 Reg: 0.2407\n",
      "Test: 0.9809 MAE: 0.7804 RMSE: 0.9904\n",
      "Val: 0.8672 MAE: 0.7364 RMSE: 0.9313\n",
      "Epoch 85 Step 2322: Train 0.7449 Reg: 0.2406\n",
      "Test: 0.9808 MAE: 0.7803 RMSE: 0.9904\n",
      "Val: 0.8673 MAE: 0.7364 RMSE: 0.9313\n",
      "Epoch 86 Step 2349: Train 0.7449 Reg: 0.2405\n",
      "Test: 0.9810 MAE: 0.7804 RMSE: 0.9904\n",
      "Val: 0.8673 MAE: 0.7364 RMSE: 0.9313\n",
      "Epoch 87 Step 2376: Train 0.7449 Reg: 0.2405\n",
      "Test: 0.9809 MAE: 0.7804 RMSE: 0.9904\n",
      "Val: 0.8673 MAE: 0.7364 RMSE: 0.9313\n",
      "Epoch 88 Step 2403: Train 0.7448 Reg: 0.2404\n",
      "Test: 0.9810 MAE: 0.7804 RMSE: 0.9904\n",
      "Val: 0.8672 MAE: 0.7364 RMSE: 0.9312\n",
      "Epoch 89 Step 2430: Train 0.7448 Reg: 0.2404\n",
      "Test: 0.9809 MAE: 0.7804 RMSE: 0.9904\n",
      "Val: 0.8672 MAE: 0.7364 RMSE: 0.9312\n",
      "Epoch 90 Step 2457: Train 0.7448 Reg: 0.2404\n",
      "Test: 0.9809 MAE: 0.7803 RMSE: 0.9904\n",
      "Val: 0.8673 MAE: 0.7364 RMSE: 0.9313\n",
      "Epoch 91 Step 2484: Train 0.7447 Reg: 0.2403\n",
      "Test: 0.9810 MAE: 0.7804 RMSE: 0.9904\n",
      "Val: 0.8673 MAE: 0.7364 RMSE: 0.9313\n",
      "Epoch 92 Step 2511: Train 0.7447 Reg: 0.2403\n",
      "Test: 0.9809 MAE: 0.7803 RMSE: 0.9904\n",
      "Val: 0.8673 MAE: 0.7364 RMSE: 0.9313\n",
      "Epoch 93 Step 2538: Train 0.7447 Reg: 0.2402\n",
      "Test: 0.9810 MAE: 0.7805 RMSE: 0.9905\n",
      "Val: 0.8672 MAE: 0.7364 RMSE: 0.9312\n",
      "Epoch 94 Step 2565: Train 0.7446 Reg: 0.2402\n",
      "Test: 0.9810 MAE: 0.7804 RMSE: 0.9904\n",
      "Val: 0.8672 MAE: 0.7364 RMSE: 0.9312\n",
      "Epoch 95 Step 2592: Train 0.7446 Reg: 0.2402\n",
      "Test: 0.9809 MAE: 0.7804 RMSE: 0.9904\n",
      "Val: 0.8672 MAE: 0.7363 RMSE: 0.9313\n",
      "Epoch 96 Step 2619: Train 0.7446 Reg: 0.2401\n",
      "Test: 0.9810 MAE: 0.7804 RMSE: 0.9905\n",
      "Val: 0.8672 MAE: 0.7364 RMSE: 0.9313\n",
      "Epoch 97 Step 2646: Train 0.7446 Reg: 0.2401\n",
      "Test: 0.9809 MAE: 0.7804 RMSE: 0.9904\n",
      "Val: 0.8672 MAE: 0.7364 RMSE: 0.9313\n",
      "Epoch 98 Step 2673: Train 0.7445 Reg: 0.2401\n",
      "Test: 0.9810 MAE: 0.7804 RMSE: 0.9904\n",
      "Val: 0.8672 MAE: 0.7363 RMSE: 0.9313\n",
      "Epoch 99 Step 2700: Train 0.7445 Reg: 0.2401\n",
      "Test: 0.9810 MAE: 0.7804 RMSE: 0.9905\n",
      "Val: 0.8672 MAE: 0.7363 RMSE: 0.9313\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 28113/4938\n",
      "test set size: support/query 146/213\n",
      "Epoch 0: TrainLoss 2.0179 RecLoss: 0.0000 (left: 0:03:24)\n",
      "TestLoss: 1.8639 MAE: 1.1503 RMSE: 1.3653\n",
      "ValLoss: 1.6110 MAE: 1.0606 RMSE: 1.2692\n",
      "Epoch 1: TrainLoss 1.3587 RecLoss: 0.0000 (left: 0:03:12)\n",
      "TestLoss: 1.2990 MAE: 0.9174 RMSE: 1.1397\n",
      "ValLoss: 1.1655 MAE: 0.8948 RMSE: 1.0796\n",
      "Epoch 2: TrainLoss 1.1810 RecLoss: 0.0000 (left: 0:03:09)\n",
      "TestLoss: 1.2885 MAE: 0.9477 RMSE: 1.1351\n",
      "ValLoss: 1.1746 MAE: 0.9289 RMSE: 1.0838\n",
      "Epoch 3: TrainLoss 1.1462 RecLoss: 0.0000 (left: 0:02:52)\n",
      "TestLoss: 1.2904 MAE: 0.9635 RMSE: 1.1360\n",
      "ValLoss: 1.1574 MAE: 0.9314 RMSE: 1.0758\n",
      "Epoch 4: TrainLoss 1.1203 RecLoss: 0.0000 (left: 0:02:47)\n",
      "TestLoss: 1.2075 MAE: 0.8972 RMSE: 1.0989\n",
      "ValLoss: 1.0840 MAE: 0.8790 RMSE: 1.0411\n",
      "Epoch 5: TrainLoss 1.0987 RecLoss: 0.0000 (left: 0:02:45)\n",
      "TestLoss: 1.1958 MAE: 0.8737 RMSE: 1.0935\n",
      "ValLoss: 1.0289 MAE: 0.8422 RMSE: 1.0144\n",
      "Epoch 6: TrainLoss 1.0769 RecLoss: 0.0000 (left: 0:02:47)\n",
      "TestLoss: 1.1714 MAE: 0.8735 RMSE: 1.0823\n",
      "ValLoss: 1.0263 MAE: 0.8504 RMSE: 1.0130\n",
      "Epoch 7: TrainLoss 1.0542 RecLoss: 0.0000 (left: 0:02:42)\n",
      "TestLoss: 1.1695 MAE: 0.8836 RMSE: 1.0815\n",
      "ValLoss: 1.0321 MAE: 0.8621 RMSE: 1.0159\n",
      "Epoch 8: TrainLoss 1.0422 RecLoss: 0.0000 (left: 0:02:40)\n",
      "TestLoss: 1.1564 MAE: 0.8730 RMSE: 1.0753\n",
      "ValLoss: 1.0293 MAE: 0.8573 RMSE: 1.0146\n",
      "Epoch 9: TrainLoss 1.0275 RecLoss: 0.0000 (left: 0:02:37)\n",
      "TestLoss: 1.1454 MAE: 0.8661 RMSE: 1.0702\n",
      "ValLoss: 0.9987 MAE: 0.8425 RMSE: 0.9993\n",
      "Epoch 10: TrainLoss 1.0159 RecLoss: 0.0000 (left: 0:02:37)\n",
      "TestLoss: 1.1300 MAE: 0.8528 RMSE: 1.0630\n",
      "ValLoss: 0.9827 MAE: 0.8292 RMSE: 0.9913\n",
      "Epoch 11: TrainLoss 1.0076 RecLoss: 0.0000 (left: 0:02:35)\n",
      "TestLoss: 1.1357 MAE: 0.8605 RMSE: 1.0657\n",
      "ValLoss: 0.9718 MAE: 0.8261 RMSE: 0.9858\n",
      "Epoch 12: TrainLoss 0.9981 RecLoss: 0.0000 (left: 0:02:32)\n",
      "TestLoss: 1.1234 MAE: 0.8444 RMSE: 1.0599\n",
      "ValLoss: 0.9957 MAE: 0.8304 RMSE: 0.9978\n",
      "Epoch 13: TrainLoss 0.9942 RecLoss: 0.0000 (left: 0:02:29)\n",
      "TestLoss: 1.1236 MAE: 0.8560 RMSE: 1.0600\n",
      "ValLoss: 0.9778 MAE: 0.8297 RMSE: 0.9888\n",
      "Epoch 14: TrainLoss 0.9887 RecLoss: 0.0000 (left: 0:02:28)\n",
      "TestLoss: 1.1215 MAE: 0.8550 RMSE: 1.0590\n",
      "ValLoss: 0.9738 MAE: 0.8268 RMSE: 0.9868\n",
      "Epoch 15: TrainLoss 0.9808 RecLoss: 0.0000 (left: 0:02:25)\n",
      "TestLoss: 1.1028 MAE: 0.8361 RMSE: 1.0502\n",
      "ValLoss: 0.9699 MAE: 0.8185 RMSE: 0.9848\n",
      "Epoch 16: TrainLoss 0.9747 RecLoss: 0.0000 (left: 0:02:23)\n",
      "TestLoss: 1.0991 MAE: 0.8342 RMSE: 1.0484\n",
      "ValLoss: 0.9690 MAE: 0.8173 RMSE: 0.9844\n",
      "Epoch 17: TrainLoss 0.9721 RecLoss: 0.0000 (left: 0:02:23)\n",
      "TestLoss: 1.0962 MAE: 0.8343 RMSE: 1.0470\n",
      "ValLoss: 0.9673 MAE: 0.8172 RMSE: 0.9835\n",
      "Epoch 18: TrainLoss 0.9649 RecLoss: 0.0000 (left: 0:02:18)\n",
      "TestLoss: 1.1105 MAE: 0.8479 RMSE: 1.0538\n",
      "ValLoss: 0.9713 MAE: 0.8225 RMSE: 0.9855\n",
      "Epoch 19: TrainLoss 0.9665 RecLoss: 0.0000 (left: 0:02:16)\n",
      "TestLoss: 1.0931 MAE: 0.8260 RMSE: 1.0455\n",
      "ValLoss: 0.9770 MAE: 0.8162 RMSE: 0.9884\n",
      "Epoch 20: TrainLoss 0.9602 RecLoss: 0.0000 (left: 0:02:15)\n",
      "TestLoss: 1.0898 MAE: 0.8313 RMSE: 1.0439\n",
      "ValLoss: 0.9636 MAE: 0.8129 RMSE: 0.9816\n",
      "Epoch 21: TrainLoss 0.9560 RecLoss: 0.0000 (left: 0:02:12)\n",
      "TestLoss: 1.0997 MAE: 0.8398 RMSE: 1.0487\n",
      "ValLoss: 0.9701 MAE: 0.8186 RMSE: 0.9850\n",
      "Epoch 22: TrainLoss 0.9534 RecLoss: 0.0000 (left: 0:02:10)\n",
      "TestLoss: 1.0869 MAE: 0.8218 RMSE: 1.0425\n",
      "ValLoss: 0.9743 MAE: 0.8128 RMSE: 0.9871\n",
      "Epoch 23: TrainLoss 0.9605 RecLoss: 0.0000 (left: 0:02:08)\n",
      "TestLoss: 1.0854 MAE: 0.8208 RMSE: 1.0418\n",
      "ValLoss: 0.9775 MAE: 0.8142 RMSE: 0.9887\n",
      "Epoch 24: TrainLoss 0.9514 RecLoss: 0.0000 (left: 0:02:06)\n",
      "TestLoss: 1.1199 MAE: 0.8543 RMSE: 1.0582\n",
      "ValLoss: 0.9872 MAE: 0.8270 RMSE: 0.9936\n",
      "Epoch 25: TrainLoss 0.9546 RecLoss: 0.0000 (left: 0:02:04)\n",
      "TestLoss: 1.0865 MAE: 0.8172 RMSE: 1.0424\n",
      "ValLoss: 0.9846 MAE: 0.8144 RMSE: 0.9923\n",
      "Epoch 26: TrainLoss 0.9493 RecLoss: 0.0000 (left: 0:02:02)\n",
      "TestLoss: 1.1044 MAE: 0.8422 RMSE: 1.0509\n",
      "ValLoss: 0.9708 MAE: 0.8148 RMSE: 0.9853\n",
      "Epoch 27: TrainLoss 0.9551 RecLoss: 0.0000 (left: 0:02:00)\n",
      "TestLoss: 1.0797 MAE: 0.8240 RMSE: 1.0391\n",
      "ValLoss: 0.9697 MAE: 0.8118 RMSE: 0.9847\n",
      "Epoch 28: TrainLoss 0.9438 RecLoss: 0.0000 (left: 0:01:58)\n",
      "TestLoss: 1.0774 MAE: 0.8208 RMSE: 1.0380\n",
      "ValLoss: 0.9708 MAE: 0.8112 RMSE: 0.9853\n",
      "Epoch 29: TrainLoss 0.9425 RecLoss: 0.0000 (left: 0:01:56)\n",
      "TestLoss: 1.0904 MAE: 0.8329 RMSE: 1.0442\n",
      "ValLoss: 0.9686 MAE: 0.8113 RMSE: 0.9842\n",
      "Epoch 30: TrainLoss 0.9475 RecLoss: 0.0000 (left: 0:01:54)\n",
      "TestLoss: 1.0851 MAE: 0.8111 RMSE: 1.0417\n",
      "ValLoss: 0.9886 MAE: 0.8104 RMSE: 0.9943\n",
      "Epoch 31: TrainLoss 0.9508 RecLoss: 0.0000 (left: 0:01:52)\n",
      "TestLoss: 1.1378 MAE: 0.8639 RMSE: 1.0667\n",
      "ValLoss: 1.0161 MAE: 0.8388 RMSE: 1.0080\n",
      "Epoch 32: TrainLoss 0.9611 RecLoss: 0.0000 (left: 0:01:50)\n",
      "TestLoss: 1.0831 MAE: 0.8099 RMSE: 1.0407\n",
      "ValLoss: 0.9966 MAE: 0.8144 RMSE: 0.9983\n",
      "Epoch 33: TrainLoss 0.9510 RecLoss: 0.0000 (left: 0:01:49)\n",
      "TestLoss: 1.0967 MAE: 0.8368 RMSE: 1.0472\n",
      "ValLoss: 0.9819 MAE: 0.8180 RMSE: 0.9909\n",
      "Epoch 34: TrainLoss 0.9405 RecLoss: 0.0000 (left: 0:01:48)\n",
      "TestLoss: 1.0737 MAE: 0.8096 RMSE: 1.0362\n",
      "ValLoss: 0.9756 MAE: 0.8055 RMSE: 0.9877\n",
      "Epoch 35: TrainLoss 0.9410 RecLoss: 0.0000 (left: 0:01:46)\n",
      "TestLoss: 1.0867 MAE: 0.8289 RMSE: 1.0424\n",
      "ValLoss: 0.9698 MAE: 0.8090 RMSE: 0.9848\n",
      "Epoch 36: TrainLoss 0.9389 RecLoss: 0.0000 (left: 0:01:45)\n",
      "TestLoss: 1.0738 MAE: 0.8104 RMSE: 1.0362\n",
      "ValLoss: 0.9812 MAE: 0.8088 RMSE: 0.9905\n",
      "Epoch 37: TrainLoss 0.9404 RecLoss: 0.0000 (left: 0:01:43)\n",
      "TestLoss: 1.0924 MAE: 0.8343 RMSE: 1.0452\n",
      "ValLoss: 0.9823 MAE: 0.8173 RMSE: 0.9911\n",
      "Epoch 38: TrainLoss 0.9373 RecLoss: 0.0000 (left: 0:01:41)\n",
      "TestLoss: 1.0732 MAE: 0.8111 RMSE: 1.0359\n",
      "ValLoss: 0.9748 MAE: 0.8055 RMSE: 0.9873\n",
      "Epoch 39: TrainLoss 0.9376 RecLoss: 0.0000 (left: 0:01:39)\n",
      "TestLoss: 1.0883 MAE: 0.8307 RMSE: 1.0432\n",
      "ValLoss: 0.9728 MAE: 0.8106 RMSE: 0.9863\n",
      "Epoch 40: TrainLoss 0.9369 RecLoss: 0.0000 (left: 0:01:38)\n",
      "TestLoss: 1.0725 MAE: 0.8141 RMSE: 1.0356\n",
      "ValLoss: 0.9723 MAE: 0.8064 RMSE: 0.9861\n",
      "Epoch 41: TrainLoss 0.9343 RecLoss: 0.0000 (left: 0:01:36)\n",
      "TestLoss: 1.0831 MAE: 0.8275 RMSE: 1.0407\n",
      "ValLoss: 0.9747 MAE: 0.8116 RMSE: 0.9873\n",
      "Epoch 42: TrainLoss 0.9330 RecLoss: 0.0000 (left: 0:01:34)\n",
      "TestLoss: 1.0732 MAE: 0.8148 RMSE: 1.0359\n",
      "ValLoss: 0.9722 MAE: 0.8062 RMSE: 0.9860\n",
      "Epoch 43: TrainLoss 0.9331 RecLoss: 0.0000 (left: 0:01:32)\n",
      "TestLoss: 1.0811 MAE: 0.8251 RMSE: 1.0398\n",
      "ValLoss: 0.9710 MAE: 0.8084 RMSE: 0.9854\n",
      "Epoch 44: TrainLoss 0.9324 RecLoss: 0.0000 (left: 0:01:31)\n",
      "TestLoss: 1.0757 MAE: 0.8187 RMSE: 1.0371\n",
      "ValLoss: 0.9711 MAE: 0.8066 RMSE: 0.9855\n",
      "Epoch 45: TrainLoss 0.9306 RecLoss: 0.0000 (left: 0:01:29)\n",
      "TestLoss: 1.0820 MAE: 0.8256 RMSE: 1.0402\n",
      "ValLoss: 0.9743 MAE: 0.8097 RMSE: 0.9870\n",
      "Epoch 46: TrainLoss 0.9321 RecLoss: 0.0000 (left: 0:01:27)\n",
      "TestLoss: 1.0783 MAE: 0.8209 RMSE: 1.0384\n",
      "ValLoss: 0.9761 MAE: 0.8094 RMSE: 0.9880\n",
      "Epoch 47: TrainLoss 0.9310 RecLoss: 0.0000 (left: 0:01:25)\n",
      "TestLoss: 1.0782 MAE: 0.8210 RMSE: 1.0384\n",
      "ValLoss: 0.9750 MAE: 0.8086 RMSE: 0.9874\n",
      "Epoch 48: TrainLoss 0.9307 RecLoss: 0.0000 (left: 0:01:24)\n",
      "TestLoss: 1.0800 MAE: 0.8224 RMSE: 1.0392\n",
      "ValLoss: 0.9713 MAE: 0.8061 RMSE: 0.9855\n",
      "Epoch 49: TrainLoss 0.9292 RecLoss: 0.0000 (left: 0:01:22)\n",
      "TestLoss: 1.0806 MAE: 0.8233 RMSE: 1.0395\n",
      "ValLoss: 0.9741 MAE: 0.8078 RMSE: 0.9869\n",
      "Epoch 50: TrainLoss 0.9293 RecLoss: 0.0000 (left: 0:01:20)\n",
      "TestLoss: 1.0775 MAE: 0.8176 RMSE: 1.0380\n",
      "ValLoss: 0.9749 MAE: 0.8060 RMSE: 0.9874\n",
      "Epoch 51: TrainLoss 0.9308 RecLoss: 0.0000 (left: 0:01:18)\n",
      "TestLoss: 1.0899 MAE: 0.8320 RMSE: 1.0440\n",
      "ValLoss: 0.9868 MAE: 0.8169 RMSE: 0.9934\n",
      "Epoch 52: TrainLoss 0.9317 RecLoss: 0.0000 (left: 0:01:16)\n",
      "TestLoss: 1.0791 MAE: 0.8119 RMSE: 1.0388\n",
      "ValLoss: 0.9818 MAE: 0.8056 RMSE: 0.9909\n",
      "Epoch 53: TrainLoss 0.9331 RecLoss: 0.0000 (left: 0:01:14)\n",
      "TestLoss: 1.0979 MAE: 0.8375 RMSE: 1.0478\n",
      "ValLoss: 0.9884 MAE: 0.8174 RMSE: 0.9942\n",
      "Epoch 54: TrainLoss 0.9347 RecLoss: 0.0000 (left: 0:01:13)\n",
      "TestLoss: 1.0791 MAE: 0.8102 RMSE: 1.0388\n",
      "ValLoss: 0.9846 MAE: 0.8058 RMSE: 0.9922\n",
      "Epoch 55: TrainLoss 0.9337 RecLoss: 0.0000 (left: 0:01:11)\n",
      "TestLoss: 1.0887 MAE: 0.8303 RMSE: 1.0434\n",
      "ValLoss: 0.9865 MAE: 0.8156 RMSE: 0.9932\n",
      "Epoch 56: TrainLoss 0.9289 RecLoss: 0.0000 (left: 0:01:09)\n",
      "TestLoss: 1.0773 MAE: 0.8129 RMSE: 1.0379\n",
      "ValLoss: 0.9820 MAE: 0.8070 RMSE: 0.9910\n",
      "Epoch 57: TrainLoss 0.9297 RecLoss: 0.0000 (left: 0:01:08)\n",
      "TestLoss: 1.0845 MAE: 0.8264 RMSE: 1.0414\n",
      "ValLoss: 0.9815 MAE: 0.8115 RMSE: 0.9907\n",
      "Epoch 58: TrainLoss 0.9310 RecLoss: 0.0000 (left: 0:01:06)\n",
      "TestLoss: 1.0776 MAE: 0.8128 RMSE: 1.0381\n",
      "ValLoss: 0.9805 MAE: 0.8058 RMSE: 0.9902\n",
      "Epoch 59: TrainLoss 0.9317 RecLoss: 0.0000 (left: 0:01:04)\n",
      "TestLoss: 1.0917 MAE: 0.8319 RMSE: 1.0449\n",
      "ValLoss: 0.9867 MAE: 0.8147 RMSE: 0.9933\n",
      "Epoch 60: TrainLoss 0.9331 RecLoss: 0.0000 (left: 0:01:03)\n",
      "TestLoss: 1.0783 MAE: 0.8127 RMSE: 1.0384\n",
      "ValLoss: 0.9838 MAE: 0.8075 RMSE: 0.9919\n",
      "Epoch 61: TrainLoss 0.9347 RecLoss: 0.0000 (left: 0:01:01)\n",
      "TestLoss: 1.0870 MAE: 0.8279 RMSE: 1.0426\n",
      "ValLoss: 0.9935 MAE: 0.8182 RMSE: 0.9967\n",
      "Epoch 62: TrainLoss 0.9336 RecLoss: 0.0000 (left: 0:00:59)\n",
      "TestLoss: 1.0780 MAE: 0.8162 RMSE: 1.0383\n",
      "ValLoss: 0.9824 MAE: 0.8088 RMSE: 0.9912\n",
      "Epoch 63: TrainLoss 0.9315 RecLoss: 0.0000 (left: 0:00:58)\n",
      "TestLoss: 1.0805 MAE: 0.8198 RMSE: 1.0395\n",
      "ValLoss: 0.9763 MAE: 0.8063 RMSE: 0.9881\n",
      "Epoch 64: TrainLoss 0.9281 RecLoss: 0.0000 (left: 0:00:56)\n",
      "TestLoss: 1.0804 MAE: 0.8208 RMSE: 1.0394\n",
      "ValLoss: 0.9816 MAE: 0.8098 RMSE: 0.9908\n",
      "Epoch 65: TrainLoss 0.9280 RecLoss: 0.0000 (left: 0:00:54)\n",
      "TestLoss: 1.0797 MAE: 0.8185 RMSE: 1.0391\n",
      "ValLoss: 0.9862 MAE: 0.8116 RMSE: 0.9931\n",
      "Epoch 66: TrainLoss 0.9279 RecLoss: 0.0000 (left: 0:00:52)\n",
      "TestLoss: 1.0836 MAE: 0.8239 RMSE: 1.0410\n",
      "ValLoss: 0.9868 MAE: 0.8130 RMSE: 0.9934\n",
      "Epoch 67: TrainLoss 0.9276 RecLoss: 0.0000 (left: 0:00:51)\n",
      "TestLoss: 1.0792 MAE: 0.8165 RMSE: 1.0388\n",
      "ValLoss: 0.9818 MAE: 0.8079 RMSE: 0.9909\n",
      "Epoch 68: TrainLoss 0.9277 RecLoss: 0.0000 (left: 0:00:49)\n",
      "TestLoss: 1.0840 MAE: 0.8239 RMSE: 1.0412\n",
      "ValLoss: 0.9836 MAE: 0.8108 RMSE: 0.9918\n",
      "Epoch 69: TrainLoss 0.9278 RecLoss: 0.0000 (left: 0:00:48)\n",
      "TestLoss: 1.0806 MAE: 0.8189 RMSE: 1.0395\n",
      "ValLoss: 0.9840 MAE: 0.8096 RMSE: 0.9920\n",
      "Epoch 70: TrainLoss 0.9269 RecLoss: 0.0000 (left: 0:00:46)\n",
      "TestLoss: 1.0852 MAE: 0.8255 RMSE: 1.0417\n",
      "ValLoss: 0.9850 MAE: 0.8116 RMSE: 0.9925\n",
      "Epoch 71: TrainLoss 0.9277 RecLoss: 0.0000 (left: 0:00:44)\n",
      "TestLoss: 1.0804 MAE: 0.8181 RMSE: 1.0394\n",
      "ValLoss: 0.9843 MAE: 0.8092 RMSE: 0.9921\n",
      "Epoch 72: TrainLoss 0.9271 RecLoss: 0.0000 (left: 0:00:42)\n",
      "TestLoss: 1.0853 MAE: 0.8252 RMSE: 1.0418\n",
      "ValLoss: 0.9907 MAE: 0.8146 RMSE: 0.9953\n",
      "Epoch 73: TrainLoss 0.9276 RecLoss: 0.0000 (left: 0:00:41)\n",
      "TestLoss: 1.0807 MAE: 0.8165 RMSE: 1.0396\n",
      "ValLoss: 0.9861 MAE: 0.8092 RMSE: 0.9930\n",
      "Epoch 74: TrainLoss 0.9300 RecLoss: 0.0000 (left: 0:00:39)\n",
      "TestLoss: 1.0853 MAE: 0.8245 RMSE: 1.0418\n",
      "ValLoss: 0.9860 MAE: 0.8116 RMSE: 0.9930\n",
      "Epoch 75: TrainLoss 0.9272 RecLoss: 0.0000 (left: 0:00:37)\n",
      "TestLoss: 1.0817 MAE: 0.8188 RMSE: 1.0400\n",
      "ValLoss: 0.9840 MAE: 0.8090 RMSE: 0.9920\n",
      "Epoch 76: TrainLoss 0.9275 RecLoss: 0.0000 (left: 0:00:36)\n",
      "TestLoss: 1.0853 MAE: 0.8248 RMSE: 1.0418\n",
      "ValLoss: 0.9865 MAE: 0.8120 RMSE: 0.9932\n",
      "Epoch 77: TrainLoss 0.9268 RecLoss: 0.0000 (left: 0:00:34)\n",
      "TestLoss: 1.0822 MAE: 0.8198 RMSE: 1.0403\n",
      "ValLoss: 0.9891 MAE: 0.8122 RMSE: 0.9945\n",
      "Epoch 78: TrainLoss 0.9267 RecLoss: 0.0000 (left: 0:00:33)\n",
      "TestLoss: 1.0825 MAE: 0.8205 RMSE: 1.0404\n",
      "ValLoss: 0.9857 MAE: 0.8105 RMSE: 0.9928\n",
      "Epoch 79: TrainLoss 0.9270 RecLoss: 0.0000 (left: 0:00:31)\n",
      "TestLoss: 1.0855 MAE: 0.8251 RMSE: 1.0419\n",
      "ValLoss: 0.9887 MAE: 0.8130 RMSE: 0.9943\n",
      "Epoch 80: TrainLoss 0.9278 RecLoss: 0.0000 (left: 0:00:30)\n",
      "TestLoss: 1.0816 MAE: 0.8182 RMSE: 1.0400\n",
      "ValLoss: 0.9835 MAE: 0.8080 RMSE: 0.9917\n",
      "Epoch 81: TrainLoss 0.9284 RecLoss: 0.0000 (left: 0:00:28)\n",
      "TestLoss: 1.0855 MAE: 0.8242 RMSE: 1.0419\n",
      "ValLoss: 0.9839 MAE: 0.8099 RMSE: 0.9919\n",
      "Epoch 82: TrainLoss 0.9270 RecLoss: 0.0000 (left: 0:00:27)\n",
      "TestLoss: 1.0824 MAE: 0.8200 RMSE: 1.0404\n",
      "ValLoss: 0.9892 MAE: 0.8119 RMSE: 0.9946\n",
      "Epoch 83: TrainLoss 0.9284 RecLoss: 0.0000 (left: 0:00:25)\n",
      "TestLoss: 1.0826 MAE: 0.8203 RMSE: 1.0405\n",
      "ValLoss: 0.9922 MAE: 0.8137 RMSE: 0.9961\n",
      "Epoch 84: TrainLoss 0.9276 RecLoss: 0.0000 (left: 0:00:24)\n",
      "TestLoss: 1.0858 MAE: 0.8246 RMSE: 1.0420\n",
      "ValLoss: 0.9890 MAE: 0.8128 RMSE: 0.9945\n",
      "Epoch 85: TrainLoss 0.9269 RecLoss: 0.0000 (left: 0:00:22)\n",
      "TestLoss: 1.0823 MAE: 0.8176 RMSE: 1.0403\n",
      "ValLoss: 0.9819 MAE: 0.8066 RMSE: 0.9909\n",
      "Epoch 86: TrainLoss 0.9276 RecLoss: 0.0000 (left: 0:00:20)\n",
      "TestLoss: 1.0855 MAE: 0.8240 RMSE: 1.0419\n",
      "ValLoss: 0.9879 MAE: 0.8120 RMSE: 0.9939\n",
      "Epoch 87: TrainLoss 0.9262 RecLoss: 0.0000 (left: 0:00:19)\n",
      "TestLoss: 1.0813 MAE: 0.8172 RMSE: 1.0399\n",
      "ValLoss: 0.9885 MAE: 0.8103 RMSE: 0.9942\n",
      "Epoch 88: TrainLoss 0.9265 RecLoss: 0.0000 (left: 0:00:18)\n",
      "TestLoss: 1.0864 MAE: 0.8254 RMSE: 1.0423\n",
      "ValLoss: 0.9928 MAE: 0.8150 RMSE: 0.9964\n",
      "Epoch 89: TrainLoss 0.9265 RecLoss: 0.0000 (left: 0:00:16)\n",
      "TestLoss: 1.0831 MAE: 0.8202 RMSE: 1.0407\n",
      "ValLoss: 0.9877 MAE: 0.8108 RMSE: 0.9938\n",
      "Epoch 90: TrainLoss 0.9264 RecLoss: 0.0000 (left: 0:00:15)\n",
      "TestLoss: 1.0839 MAE: 0.8214 RMSE: 1.0411\n",
      "ValLoss: 0.9861 MAE: 0.8102 RMSE: 0.9930\n",
      "Epoch 91: TrainLoss 0.9273 RecLoss: 0.0000 (left: 0:00:13)\n",
      "TestLoss: 1.0834 MAE: 0.8198 RMSE: 1.0409\n",
      "ValLoss: 0.9856 MAE: 0.8092 RMSE: 0.9928\n",
      "Epoch 92: TrainLoss 0.9273 RecLoss: 0.0000 (left: 0:00:12)\n",
      "TestLoss: 1.0847 MAE: 0.8226 RMSE: 1.0415\n",
      "ValLoss: 0.9891 MAE: 0.8122 RMSE: 0.9945\n",
      "Epoch 93: TrainLoss 0.9268 RecLoss: 0.0000 (left: 0:00:10)\n",
      "TestLoss: 1.0852 MAE: 0.8232 RMSE: 1.0417\n",
      "ValLoss: 0.9925 MAE: 0.8141 RMSE: 0.9962\n",
      "Epoch 94: TrainLoss 0.9263 RecLoss: 0.0000 (left: 0:00:09)\n",
      "TestLoss: 1.0824 MAE: 0.8187 RMSE: 1.0404\n",
      "ValLoss: 0.9888 MAE: 0.8108 RMSE: 0.9944\n",
      "Epoch 95: TrainLoss 0.9260 RecLoss: 0.0000 (left: 0:00:07)\n",
      "TestLoss: 1.0869 MAE: 0.8255 RMSE: 1.0425\n",
      "ValLoss: 0.9900 MAE: 0.8130 RMSE: 0.9950\n",
      "Epoch 96: TrainLoss 0.9266 RecLoss: 0.0000 (left: 0:00:06)\n",
      "TestLoss: 1.0827 MAE: 0.8194 RMSE: 1.0405\n",
      "ValLoss: 0.9883 MAE: 0.8107 RMSE: 0.9941\n",
      "Epoch 97: TrainLoss 0.9261 RecLoss: 0.0000 (left: 0:00:04)\n",
      "TestLoss: 1.0835 MAE: 0.8212 RMSE: 1.0409\n",
      "ValLoss: 0.9902 MAE: 0.8123 RMSE: 0.9951\n",
      "Epoch 98: TrainLoss 0.9279 RecLoss: 0.0000 (left: 0:00:03)\n",
      "TestLoss: 1.0832 MAE: 0.8199 RMSE: 1.0408\n",
      "ValLoss: 0.9867 MAE: 0.8098 RMSE: 0.9933\n",
      "Epoch 99: TrainLoss 0.9267 RecLoss: 0.0000 (left: 0:00:01)\n",
      "TestLoss: 1.0837 MAE: 0.8205 RMSE: 1.0410\n",
      "ValLoss: 0.9886 MAE: 0.8111 RMSE: 0.9943\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 28113/4938\n",
      "test set size: support/query 146/213\n",
      "USER HIS DICT: 943\n",
      "NUM IS: 943\n",
      "Key Test Result: MAE: 0.7805 RMSE: 0.9905 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 943\n",
      "NUM IS: 943\n",
      "Que Test Result: MAE: 0.8313 RMSE: 1.0439 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.8106 RMSE: 1.0225 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 40% CUR core user as input to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 54098/4938\n",
      "test set size: support/query 292/213\n",
      "Epoch 0 Step 51: Train 9.2581 Reg: 0.4232\n",
      "Test: 2.3255 MAE: 1.3308 RMSE: 1.5250\n",
      "Val: 2.1361 MAE: 1.2580 RMSE: 1.4615\n",
      "Epoch 1 Step 102: Train 1.1975 Reg: 0.3854\n",
      "Test: 1.0648 MAE: 0.8606 RMSE: 1.0319\n",
      "Val: 1.0284 MAE: 0.8364 RMSE: 1.0141\n",
      "Epoch 2 Step 153: Train 0.9472 Reg: 0.3603\n",
      "Test: 0.9743 MAE: 0.7931 RMSE: 0.9871\n",
      "Val: 0.9354 MAE: 0.7747 RMSE: 0.9672\n",
      "Epoch 3 Step 204: Train 0.8730 Reg: 0.3485\n",
      "Test: 0.9331 MAE: 0.7668 RMSE: 0.9660\n",
      "Val: 0.9028 MAE: 0.7526 RMSE: 0.9502\n",
      "Epoch 4 Step 255: Train 0.8457 Reg: 0.3388\n",
      "Test: 0.9246 MAE: 0.7617 RMSE: 0.9616\n",
      "Val: 0.8867 MAE: 0.7450 RMSE: 0.9417\n",
      "Epoch 5 Step 306: Train 0.8326 Reg: 0.3300\n",
      "Test: 0.9147 MAE: 0.7567 RMSE: 0.9564\n",
      "Val: 0.8801 MAE: 0.7424 RMSE: 0.9381\n",
      "Epoch 6 Step 357: Train 0.8252 Reg: 0.3229\n",
      "Test: 0.9110 MAE: 0.7535 RMSE: 0.9544\n",
      "Val: 0.8772 MAE: 0.7404 RMSE: 0.9366\n",
      "Epoch 7 Step 408: Train 0.8206 Reg: 0.3165\n",
      "Test: 0.9088 MAE: 0.7513 RMSE: 0.9533\n",
      "Val: 0.8733 MAE: 0.7392 RMSE: 0.9345\n",
      "Epoch 8 Step 459: Train 0.8179 Reg: 0.3105\n",
      "Test: 0.9097 MAE: 0.7515 RMSE: 0.9538\n",
      "Val: 0.8724 MAE: 0.7383 RMSE: 0.9340\n",
      "Epoch 9 Step 510: Train 0.8151 Reg: 0.3049\n",
      "Test: 0.9063 MAE: 0.7493 RMSE: 0.9520\n",
      "Val: 0.8698 MAE: 0.7369 RMSE: 0.9326\n",
      "Epoch 10 Step 561: Train 0.8134 Reg: 0.3000\n",
      "Test: 0.9068 MAE: 0.7502 RMSE: 0.9523\n",
      "Val: 0.8702 MAE: 0.7370 RMSE: 0.9329\n",
      "Epoch 11 Step 612: Train 0.8114 Reg: 0.2950\n",
      "Test: 0.9078 MAE: 0.7495 RMSE: 0.9528\n",
      "Val: 0.8683 MAE: 0.7367 RMSE: 0.9318\n",
      "Epoch 12 Step 663: Train 0.8102 Reg: 0.2911\n",
      "Test: 0.9118 MAE: 0.7516 RMSE: 0.9549\n",
      "Val: 0.8653 MAE: 0.7344 RMSE: 0.9302\n",
      "Epoch 13 Step 714: Train 0.8087 Reg: 0.2866\n",
      "Test: 0.9110 MAE: 0.7517 RMSE: 0.9545\n",
      "Val: 0.8648 MAE: 0.7338 RMSE: 0.9299\n",
      "Epoch 14 Step 765: Train 0.8071 Reg: 0.2831\n",
      "Test: 0.9103 MAE: 0.7511 RMSE: 0.9541\n",
      "Val: 0.8651 MAE: 0.7345 RMSE: 0.9301\n",
      "Epoch 15 Step 816: Train 0.8058 Reg: 0.2792\n",
      "Test: 0.9107 MAE: 0.7512 RMSE: 0.9543\n",
      "Val: 0.8644 MAE: 0.7337 RMSE: 0.9297\n",
      "Epoch 16 Step 867: Train 0.8045 Reg: 0.2761\n",
      "Test: 0.9091 MAE: 0.7517 RMSE: 0.9534\n",
      "Val: 0.8626 MAE: 0.7337 RMSE: 0.9288\n",
      "Epoch 17 Step 918: Train 0.8031 Reg: 0.2731\n",
      "Test: 0.9150 MAE: 0.7525 RMSE: 0.9565\n",
      "Val: 0.8629 MAE: 0.7329 RMSE: 0.9289\n",
      "Epoch 18 Step 969: Train 0.8012 Reg: 0.2704\n",
      "Test: 0.9102 MAE: 0.7498 RMSE: 0.9540\n",
      "Val: 0.8616 MAE: 0.7328 RMSE: 0.9282\n",
      "Epoch 19 Step 1020: Train 0.8004 Reg: 0.2677\n",
      "Test: 0.9099 MAE: 0.7513 RMSE: 0.9539\n",
      "Val: 0.8610 MAE: 0.7326 RMSE: 0.9279\n",
      "Epoch 20 Step 1071: Train 0.7989 Reg: 0.2655\n",
      "Test: 0.9089 MAE: 0.7510 RMSE: 0.9533\n",
      "Val: 0.8602 MAE: 0.7318 RMSE: 0.9275\n",
      "Epoch 21 Step 1122: Train 0.7978 Reg: 0.2632\n",
      "Test: 0.9119 MAE: 0.7522 RMSE: 0.9549\n",
      "Val: 0.8600 MAE: 0.7307 RMSE: 0.9273\n",
      "Epoch 22 Step 1173: Train 0.7964 Reg: 0.2613\n",
      "Test: 0.9088 MAE: 0.7512 RMSE: 0.9533\n",
      "Val: 0.8592 MAE: 0.7317 RMSE: 0.9270\n",
      "Epoch 23 Step 1224: Train 0.7951 Reg: 0.2594\n",
      "Test: 0.9072 MAE: 0.7502 RMSE: 0.9525\n",
      "Val: 0.8588 MAE: 0.7318 RMSE: 0.9267\n",
      "Epoch 24 Step 1275: Train 0.7939 Reg: 0.2578\n",
      "Test: 0.9091 MAE: 0.7493 RMSE: 0.9534\n",
      "Val: 0.8569 MAE: 0.7294 RMSE: 0.9257\n",
      "Epoch 25 Step 1326: Train 0.7923 Reg: 0.2562\n",
      "Test: 0.9081 MAE: 0.7504 RMSE: 0.9529\n",
      "Val: 0.8575 MAE: 0.7306 RMSE: 0.9260\n",
      "Epoch 26 Step 1377: Train 0.7909 Reg: 0.2548\n",
      "Test: 0.9065 MAE: 0.7511 RMSE: 0.9521\n",
      "Val: 0.8566 MAE: 0.7300 RMSE: 0.9255\n",
      "Epoch 27 Step 1428: Train 0.7896 Reg: 0.2537\n",
      "Test: 0.9068 MAE: 0.7501 RMSE: 0.9522\n",
      "Val: 0.8552 MAE: 0.7288 RMSE: 0.9248\n",
      "Epoch 28 Step 1479: Train 0.7880 Reg: 0.2525\n",
      "Test: 0.9033 MAE: 0.7491 RMSE: 0.9504\n",
      "Val: 0.8549 MAE: 0.7290 RMSE: 0.9246\n",
      "Epoch 29 Step 1530: Train 0.7864 Reg: 0.2515\n",
      "Test: 0.9083 MAE: 0.7502 RMSE: 0.9530\n",
      "Val: 0.8536 MAE: 0.7275 RMSE: 0.9239\n",
      "Epoch 30 Step 1581: Train 0.7851 Reg: 0.2506\n",
      "Test: 0.9056 MAE: 0.7493 RMSE: 0.9516\n",
      "Val: 0.8534 MAE: 0.7275 RMSE: 0.9238\n",
      "Epoch 31 Step 1632: Train 0.7836 Reg: 0.2497\n",
      "Test: 0.9037 MAE: 0.7489 RMSE: 0.9506\n",
      "Val: 0.8523 MAE: 0.7276 RMSE: 0.9232\n",
      "Epoch 32 Step 1683: Train 0.7822 Reg: 0.2491\n",
      "Test: 0.9034 MAE: 0.7492 RMSE: 0.9505\n",
      "Val: 0.8523 MAE: 0.7272 RMSE: 0.9232\n",
      "Epoch 33 Step 1734: Train 0.7806 Reg: 0.2485\n",
      "Test: 0.9019 MAE: 0.7485 RMSE: 0.9497\n",
      "Val: 0.8520 MAE: 0.7264 RMSE: 0.9231\n",
      "Epoch 34 Step 1785: Train 0.7790 Reg: 0.2480\n",
      "Test: 0.9023 MAE: 0.7490 RMSE: 0.9499\n",
      "Val: 0.8509 MAE: 0.7269 RMSE: 0.9225\n",
      "Epoch 35 Step 1836: Train 0.7775 Reg: 0.2475\n",
      "Test: 0.8997 MAE: 0.7480 RMSE: 0.9485\n",
      "Val: 0.8498 MAE: 0.7260 RMSE: 0.9218\n",
      "Epoch 36 Step 1887: Train 0.7760 Reg: 0.2471\n",
      "Test: 0.8987 MAE: 0.7477 RMSE: 0.9480\n",
      "Val: 0.8496 MAE: 0.7257 RMSE: 0.9217\n",
      "Epoch 37 Step 1938: Train 0.7746 Reg: 0.2466\n",
      "Test: 0.8986 MAE: 0.7478 RMSE: 0.9480\n",
      "Val: 0.8491 MAE: 0.7254 RMSE: 0.9215\n",
      "Epoch 38 Step 1989: Train 0.7731 Reg: 0.2464\n",
      "Test: 0.8963 MAE: 0.7470 RMSE: 0.9468\n",
      "Val: 0.8485 MAE: 0.7246 RMSE: 0.9211\n",
      "Epoch 39 Step 2040: Train 0.7717 Reg: 0.2462\n",
      "Test: 0.8967 MAE: 0.7482 RMSE: 0.9469\n",
      "Val: 0.8484 MAE: 0.7251 RMSE: 0.9211\n",
      "Epoch 40 Step 2091: Train 0.7702 Reg: 0.2459\n",
      "Test: 0.8961 MAE: 0.7479 RMSE: 0.9466\n",
      "Val: 0.8479 MAE: 0.7247 RMSE: 0.9208\n",
      "Epoch 41 Step 2142: Train 0.7689 Reg: 0.2457\n",
      "Test: 0.8961 MAE: 0.7480 RMSE: 0.9466\n",
      "Val: 0.8470 MAE: 0.7244 RMSE: 0.9203\n",
      "Epoch 42 Step 2193: Train 0.7675 Reg: 0.2455\n",
      "Test: 0.8950 MAE: 0.7471 RMSE: 0.9460\n",
      "Val: 0.8472 MAE: 0.7240 RMSE: 0.9204\n",
      "Epoch 43 Step 2244: Train 0.7662 Reg: 0.2453\n",
      "Test: 0.8922 MAE: 0.7464 RMSE: 0.9446\n",
      "Val: 0.8468 MAE: 0.7238 RMSE: 0.9202\n",
      "Epoch 44 Step 2295: Train 0.7649 Reg: 0.2453\n",
      "Test: 0.8927 MAE: 0.7469 RMSE: 0.9448\n",
      "Val: 0.8469 MAE: 0.7244 RMSE: 0.9203\n",
      "Epoch 45 Step 2346: Train 0.7636 Reg: 0.2452\n",
      "Test: 0.8926 MAE: 0.7465 RMSE: 0.9448\n",
      "Val: 0.8458 MAE: 0.7232 RMSE: 0.9197\n",
      "Epoch 46 Step 2397: Train 0.7624 Reg: 0.2451\n",
      "Test: 0.8924 MAE: 0.7468 RMSE: 0.9447\n",
      "Val: 0.8461 MAE: 0.7240 RMSE: 0.9198\n",
      "Epoch 47 Step 2448: Train 0.7612 Reg: 0.2451\n",
      "Test: 0.8921 MAE: 0.7463 RMSE: 0.9445\n",
      "Val: 0.8460 MAE: 0.7237 RMSE: 0.9198\n",
      "Epoch 48 Step 2499: Train 0.7600 Reg: 0.2450\n",
      "Test: 0.8910 MAE: 0.7458 RMSE: 0.9439\n",
      "Val: 0.8454 MAE: 0.7230 RMSE: 0.9194\n",
      "Epoch 49 Step 2550: Train 0.7589 Reg: 0.2449\n",
      "Test: 0.8905 MAE: 0.7456 RMSE: 0.9437\n",
      "Val: 0.8448 MAE: 0.7226 RMSE: 0.9191\n",
      "Epoch 50 Step 2601: Train 0.7578 Reg: 0.2449\n",
      "Test: 0.8901 MAE: 0.7455 RMSE: 0.9434\n",
      "Val: 0.8445 MAE: 0.7224 RMSE: 0.9189\n",
      "Epoch 51 Step 2652: Train 0.7568 Reg: 0.2449\n",
      "Test: 0.8895 MAE: 0.7456 RMSE: 0.9431\n",
      "Val: 0.8444 MAE: 0.7224 RMSE: 0.9189\n",
      "Epoch 52 Step 2703: Train 0.7558 Reg: 0.2449\n",
      "Test: 0.8888 MAE: 0.7454 RMSE: 0.9427\n",
      "Val: 0.8447 MAE: 0.7228 RMSE: 0.9191\n",
      "Epoch 53 Step 2754: Train 0.7548 Reg: 0.2448\n",
      "Test: 0.8883 MAE: 0.7450 RMSE: 0.9425\n",
      "Val: 0.8440 MAE: 0.7218 RMSE: 0.9187\n",
      "Epoch 54 Step 2805: Train 0.7539 Reg: 0.2449\n",
      "Test: 0.8879 MAE: 0.7447 RMSE: 0.9423\n",
      "Val: 0.8435 MAE: 0.7216 RMSE: 0.9184\n",
      "Epoch 55 Step 2856: Train 0.7529 Reg: 0.2448\n",
      "Test: 0.8876 MAE: 0.7447 RMSE: 0.9421\n",
      "Val: 0.8436 MAE: 0.7218 RMSE: 0.9185\n",
      "Epoch 56 Step 2907: Train 0.7521 Reg: 0.2448\n",
      "Test: 0.8872 MAE: 0.7448 RMSE: 0.9419\n",
      "Val: 0.8432 MAE: 0.7213 RMSE: 0.9183\n",
      "Epoch 57 Step 2958: Train 0.7513 Reg: 0.2448\n",
      "Test: 0.8872 MAE: 0.7446 RMSE: 0.9419\n",
      "Val: 0.8433 MAE: 0.7214 RMSE: 0.9183\n",
      "Epoch 58 Step 3009: Train 0.7504 Reg: 0.2448\n",
      "Test: 0.8860 MAE: 0.7442 RMSE: 0.9413\n",
      "Val: 0.8427 MAE: 0.7208 RMSE: 0.9180\n",
      "Epoch 59 Step 3060: Train 0.7497 Reg: 0.2449\n",
      "Test: 0.8866 MAE: 0.7448 RMSE: 0.9416\n",
      "Val: 0.8429 MAE: 0.7213 RMSE: 0.9181\n",
      "Epoch 60 Step 3111: Train 0.7489 Reg: 0.2449\n",
      "Test: 0.8857 MAE: 0.7443 RMSE: 0.9411\n",
      "Val: 0.8426 MAE: 0.7210 RMSE: 0.9179\n",
      "Epoch 61 Step 3162: Train 0.7482 Reg: 0.2449\n",
      "Test: 0.8858 MAE: 0.7446 RMSE: 0.9412\n",
      "Val: 0.8428 MAE: 0.7212 RMSE: 0.9181\n",
      "Epoch 62 Step 3213: Train 0.7476 Reg: 0.2449\n",
      "Test: 0.8851 MAE: 0.7443 RMSE: 0.9408\n",
      "Val: 0.8425 MAE: 0.7209 RMSE: 0.9179\n",
      "Epoch 63 Step 3264: Train 0.7469 Reg: 0.2449\n",
      "Test: 0.8851 MAE: 0.7441 RMSE: 0.9408\n",
      "Val: 0.8422 MAE: 0.7205 RMSE: 0.9177\n",
      "Epoch 64 Step 3315: Train 0.7463 Reg: 0.2449\n",
      "Test: 0.8847 MAE: 0.7441 RMSE: 0.9406\n",
      "Val: 0.8422 MAE: 0.7206 RMSE: 0.9177\n",
      "Epoch 65 Step 3366: Train 0.7457 Reg: 0.2449\n",
      "Test: 0.8847 MAE: 0.7441 RMSE: 0.9406\n",
      "Val: 0.8421 MAE: 0.7204 RMSE: 0.9177\n",
      "Epoch 66 Step 3417: Train 0.7451 Reg: 0.2449\n",
      "Test: 0.8846 MAE: 0.7442 RMSE: 0.9405\n",
      "Val: 0.8420 MAE: 0.7205 RMSE: 0.9176\n",
      "Epoch 67 Step 3468: Train 0.7446 Reg: 0.2449\n",
      "Test: 0.8844 MAE: 0.7439 RMSE: 0.9404\n",
      "Val: 0.8419 MAE: 0.7202 RMSE: 0.9175\n",
      "Epoch 68 Step 3519: Train 0.7440 Reg: 0.2449\n",
      "Test: 0.8841 MAE: 0.7439 RMSE: 0.9403\n",
      "Val: 0.8418 MAE: 0.7203 RMSE: 0.9175\n",
      "Epoch 69 Step 3570: Train 0.7436 Reg: 0.2449\n",
      "Test: 0.8842 MAE: 0.7442 RMSE: 0.9403\n",
      "Val: 0.8417 MAE: 0.7203 RMSE: 0.9175\n",
      "Epoch 70 Step 3621: Train 0.7431 Reg: 0.2449\n",
      "Test: 0.8837 MAE: 0.7438 RMSE: 0.9400\n",
      "Val: 0.8417 MAE: 0.7202 RMSE: 0.9174\n",
      "Epoch 71 Step 3672: Train 0.7426 Reg: 0.2450\n",
      "Test: 0.8830 MAE: 0.7436 RMSE: 0.9397\n",
      "Val: 0.8415 MAE: 0.7200 RMSE: 0.9174\n",
      "Epoch 72 Step 3723: Train 0.7422 Reg: 0.2450\n",
      "Test: 0.8835 MAE: 0.7438 RMSE: 0.9399\n",
      "Val: 0.8415 MAE: 0.7201 RMSE: 0.9174\n",
      "Epoch 73 Step 3774: Train 0.7418 Reg: 0.2450\n",
      "Test: 0.8830 MAE: 0.7436 RMSE: 0.9397\n",
      "Val: 0.8414 MAE: 0.7199 RMSE: 0.9173\n",
      "Epoch 74 Step 3825: Train 0.7414 Reg: 0.2450\n",
      "Test: 0.8834 MAE: 0.7438 RMSE: 0.9399\n",
      "Val: 0.8413 MAE: 0.7198 RMSE: 0.9172\n",
      "Epoch 75 Step 3876: Train 0.7410 Reg: 0.2450\n",
      "Test: 0.8827 MAE: 0.7435 RMSE: 0.9395\n",
      "Val: 0.8413 MAE: 0.7197 RMSE: 0.9172\n",
      "Epoch 76 Step 3927: Train 0.7406 Reg: 0.2450\n",
      "Test: 0.8824 MAE: 0.7433 RMSE: 0.9394\n",
      "Val: 0.8413 MAE: 0.7198 RMSE: 0.9172\n",
      "Epoch 77 Step 3978: Train 0.7403 Reg: 0.2450\n",
      "Test: 0.8826 MAE: 0.7435 RMSE: 0.9395\n",
      "Val: 0.8412 MAE: 0.7198 RMSE: 0.9172\n",
      "Epoch 78 Step 4029: Train 0.7399 Reg: 0.2450\n",
      "Test: 0.8825 MAE: 0.7435 RMSE: 0.9394\n",
      "Val: 0.8412 MAE: 0.7197 RMSE: 0.9172\n",
      "Epoch 79 Step 4080: Train 0.7396 Reg: 0.2450\n",
      "Test: 0.8825 MAE: 0.7435 RMSE: 0.9394\n",
      "Val: 0.8411 MAE: 0.7197 RMSE: 0.9171\n",
      "Epoch 80 Step 4131: Train 0.7393 Reg: 0.2450\n",
      "Test: 0.8822 MAE: 0.7434 RMSE: 0.9392\n",
      "Val: 0.8412 MAE: 0.7196 RMSE: 0.9171\n",
      "Epoch 81 Step 4182: Train 0.7390 Reg: 0.2451\n",
      "Test: 0.8821 MAE: 0.7433 RMSE: 0.9392\n",
      "Val: 0.8410 MAE: 0.7195 RMSE: 0.9170\n",
      "Epoch 82 Step 4233: Train 0.7388 Reg: 0.2451\n",
      "Test: 0.8822 MAE: 0.7435 RMSE: 0.9393\n",
      "Val: 0.8410 MAE: 0.7197 RMSE: 0.9171\n",
      "Epoch 83 Step 4284: Train 0.7385 Reg: 0.2451\n",
      "Test: 0.8821 MAE: 0.7434 RMSE: 0.9392\n",
      "Val: 0.8410 MAE: 0.7195 RMSE: 0.9170\n",
      "Epoch 84 Step 4335: Train 0.7382 Reg: 0.2451\n",
      "Test: 0.8819 MAE: 0.7433 RMSE: 0.9391\n",
      "Val: 0.8411 MAE: 0.7195 RMSE: 0.9171\n",
      "Epoch 85 Step 4386: Train 0.7380 Reg: 0.2451\n",
      "Test: 0.8818 MAE: 0.7433 RMSE: 0.9390\n",
      "Val: 0.8409 MAE: 0.7194 RMSE: 0.9170\n",
      "Epoch 86 Step 4437: Train 0.7378 Reg: 0.2451\n",
      "Test: 0.8818 MAE: 0.7432 RMSE: 0.9390\n",
      "Val: 0.8409 MAE: 0.7194 RMSE: 0.9170\n",
      "Epoch 87 Step 4488: Train 0.7376 Reg: 0.2451\n",
      "Test: 0.8815 MAE: 0.7432 RMSE: 0.9389\n",
      "Val: 0.8409 MAE: 0.7194 RMSE: 0.9170\n",
      "Epoch 88 Step 4539: Train 0.7373 Reg: 0.2451\n",
      "Test: 0.8817 MAE: 0.7432 RMSE: 0.9390\n",
      "Val: 0.8409 MAE: 0.7193 RMSE: 0.9170\n",
      "Epoch 89 Step 4590: Train 0.7372 Reg: 0.2451\n",
      "Test: 0.8816 MAE: 0.7433 RMSE: 0.9389\n",
      "Val: 0.8409 MAE: 0.7194 RMSE: 0.9170\n",
      "Epoch 90 Step 4641: Train 0.7370 Reg: 0.2451\n",
      "Test: 0.8815 MAE: 0.7432 RMSE: 0.9389\n",
      "Val: 0.8408 MAE: 0.7193 RMSE: 0.9170\n",
      "Epoch 91 Step 4692: Train 0.7368 Reg: 0.2451\n",
      "Test: 0.8813 MAE: 0.7431 RMSE: 0.9388\n",
      "Val: 0.8408 MAE: 0.7193 RMSE: 0.9169\n",
      "Epoch 92 Step 4743: Train 0.7366 Reg: 0.2451\n",
      "Test: 0.8813 MAE: 0.7432 RMSE: 0.9388\n",
      "Val: 0.8408 MAE: 0.7193 RMSE: 0.9169\n",
      "Epoch 93 Step 4794: Train 0.7364 Reg: 0.2451\n",
      "Test: 0.8813 MAE: 0.7431 RMSE: 0.9388\n",
      "Val: 0.8408 MAE: 0.7193 RMSE: 0.9169\n",
      "Epoch 94 Step 4845: Train 0.7363 Reg: 0.2451\n",
      "Test: 0.8812 MAE: 0.7431 RMSE: 0.9387\n",
      "Val: 0.8407 MAE: 0.7192 RMSE: 0.9169\n",
      "Epoch 95 Step 4896: Train 0.7361 Reg: 0.2451\n",
      "Test: 0.8811 MAE: 0.7430 RMSE: 0.9387\n",
      "Val: 0.8407 MAE: 0.7191 RMSE: 0.9169\n",
      "Epoch 96 Step 4947: Train 0.7360 Reg: 0.2451\n",
      "Test: 0.8812 MAE: 0.7431 RMSE: 0.9387\n",
      "Val: 0.8407 MAE: 0.7193 RMSE: 0.9169\n",
      "Epoch 97 Step 4998: Train 0.7359 Reg: 0.2451\n",
      "Test: 0.8811 MAE: 0.7431 RMSE: 0.9387\n",
      "Val: 0.8407 MAE: 0.7192 RMSE: 0.9169\n",
      "Epoch 98 Step 5049: Train 0.7357 Reg: 0.2451\n",
      "Test: 0.8810 MAE: 0.7430 RMSE: 0.9386\n",
      "Val: 0.8406 MAE: 0.7191 RMSE: 0.9168\n",
      "Epoch 99 Step 5100: Train 0.7356 Reg: 0.2451\n",
      "Test: 0.8810 MAE: 0.7430 RMSE: 0.9386\n",
      "Val: 0.8406 MAE: 0.7191 RMSE: 0.9169\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 54098/4938\n",
      "test set size: support/query 292/213\n",
      "Epoch 0: TrainLoss 2.0457 RecLoss: 0.0000 (left: 0:03:07)\n",
      "TestLoss: 2.1886 MAE: 1.2360 RMSE: 1.4794\n",
      "ValLoss: 1.8588 MAE: 1.1379 RMSE: 1.3634\n",
      "Epoch 1: TrainLoss 1.3764 RecLoss: 0.0000 (left: 0:03:17)\n",
      "TestLoss: 1.3903 MAE: 0.9290 RMSE: 1.1791\n",
      "ValLoss: 1.1740 MAE: 0.8625 RMSE: 1.0835\n",
      "Epoch 2: TrainLoss 1.1939 RecLoss: 0.0000 (left: 0:02:50)\n",
      "TestLoss: 1.3310 MAE: 0.9585 RMSE: 1.1537\n",
      "ValLoss: 1.1280 MAE: 0.9051 RMSE: 1.0621\n",
      "Epoch 3: TrainLoss 1.1515 RecLoss: 0.0000 (left: 0:02:40)\n",
      "TestLoss: 1.2970 MAE: 0.9416 RMSE: 1.1389\n",
      "ValLoss: 1.0972 MAE: 0.8910 RMSE: 1.0475\n",
      "Epoch 4: TrainLoss 1.0889 RecLoss: 0.0000 (left: 0:02:38)\n",
      "TestLoss: 1.2597 MAE: 0.9009 RMSE: 1.1223\n",
      "ValLoss: 1.0676 MAE: 0.8476 RMSE: 1.0332\n",
      "Epoch 5: TrainLoss 1.0790 RecLoss: 0.0000 (left: 0:02:34)\n",
      "TestLoss: 1.2520 MAE: 0.9136 RMSE: 1.1189\n",
      "ValLoss: 1.0391 MAE: 0.8606 RMSE: 1.0193\n",
      "Epoch 6: TrainLoss 1.0603 RecLoss: 0.0000 (left: 0:02:32)\n",
      "TestLoss: 1.2288 MAE: 0.9032 RMSE: 1.1085\n",
      "ValLoss: 1.0304 MAE: 0.8559 RMSE: 1.0151\n",
      "Epoch 7: TrainLoss 1.0415 RecLoss: 0.0000 (left: 0:02:31)\n",
      "TestLoss: 1.2078 MAE: 0.8891 RMSE: 1.0990\n",
      "ValLoss: 1.0284 MAE: 0.8468 RMSE: 1.0141\n",
      "Epoch 8: TrainLoss 1.0292 RecLoss: 0.0000 (left: 0:02:28)\n",
      "TestLoss: 1.2070 MAE: 0.8960 RMSE: 1.0986\n",
      "ValLoss: 1.0242 MAE: 0.8555 RMSE: 1.0120\n",
      "Epoch 9: TrainLoss 1.0189 RecLoss: 0.0000 (left: 0:02:22)\n",
      "TestLoss: 1.1918 MAE: 0.8862 RMSE: 1.0917\n",
      "ValLoss: 1.0104 MAE: 0.8453 RMSE: 1.0052\n",
      "Epoch 10: TrainLoss 1.0077 RecLoss: 0.0000 (left: 0:02:18)\n",
      "TestLoss: 1.1830 MAE: 0.8806 RMSE: 1.0877\n",
      "ValLoss: 0.9986 MAE: 0.8387 RMSE: 0.9993\n",
      "Epoch 11: TrainLoss 0.9991 RecLoss: 0.0000 (left: 0:02:19)\n",
      "TestLoss: 1.1770 MAE: 0.8780 RMSE: 1.0849\n",
      "ValLoss: 0.9934 MAE: 0.8370 RMSE: 0.9967\n",
      "Epoch 12: TrainLoss 0.9913 RecLoss: 0.0000 (left: 0:02:19)\n",
      "TestLoss: 1.1746 MAE: 0.8785 RMSE: 1.0838\n",
      "ValLoss: 0.9926 MAE: 0.8384 RMSE: 0.9963\n",
      "Epoch 13: TrainLoss 0.9841 RecLoss: 0.0000 (left: 0:02:17)\n",
      "TestLoss: 1.1633 MAE: 0.8696 RMSE: 1.0786\n",
      "ValLoss: 0.9869 MAE: 0.8320 RMSE: 0.9934\n",
      "Epoch 14: TrainLoss 0.9768 RecLoss: 0.0000 (left: 0:02:14)\n",
      "TestLoss: 1.1681 MAE: 0.8754 RMSE: 1.0808\n",
      "ValLoss: 0.9855 MAE: 0.8359 RMSE: 0.9927\n",
      "Epoch 15: TrainLoss 0.9715 RecLoss: 0.0000 (left: 0:02:11)\n",
      "TestLoss: 1.1560 MAE: 0.8655 RMSE: 1.0752\n",
      "ValLoss: 0.9765 MAE: 0.8271 RMSE: 0.9882\n",
      "Epoch 16: TrainLoss 0.9670 RecLoss: 0.0000 (left: 0:02:10)\n",
      "TestLoss: 1.1561 MAE: 0.8678 RMSE: 1.0752\n",
      "ValLoss: 0.9783 MAE: 0.8303 RMSE: 0.9891\n",
      "Epoch 17: TrainLoss 0.9616 RecLoss: 0.0000 (left: 0:02:07)\n",
      "TestLoss: 1.1495 MAE: 0.8627 RMSE: 1.0722\n",
      "ValLoss: 0.9755 MAE: 0.8269 RMSE: 0.9877\n",
      "Epoch 18: TrainLoss 0.9582 RecLoss: 0.0000 (left: 0:02:06)\n",
      "TestLoss: 1.1504 MAE: 0.8642 RMSE: 1.0726\n",
      "ValLoss: 0.9744 MAE: 0.8281 RMSE: 0.9871\n",
      "Epoch 19: TrainLoss 0.9558 RecLoss: 0.0000 (left: 0:02:06)\n",
      "TestLoss: 1.1451 MAE: 0.8596 RMSE: 1.0701\n",
      "ValLoss: 0.9673 MAE: 0.8225 RMSE: 0.9835\n",
      "Epoch 20: TrainLoss 0.9514 RecLoss: 0.0000 (left: 0:02:04)\n",
      "TestLoss: 1.1462 MAE: 0.8613 RMSE: 1.0706\n",
      "ValLoss: 0.9668 MAE: 0.8236 RMSE: 0.9832\n",
      "Epoch 21: TrainLoss 0.9477 RecLoss: 0.0000 (left: 0:02:03)\n",
      "TestLoss: 1.1438 MAE: 0.8605 RMSE: 1.0695\n",
      "ValLoss: 0.9694 MAE: 0.8248 RMSE: 0.9846\n",
      "Epoch 22: TrainLoss 0.9443 RecLoss: 0.0000 (left: 0:02:02)\n",
      "TestLoss: 1.1392 MAE: 0.8563 RMSE: 1.0673\n",
      "ValLoss: 0.9639 MAE: 0.8203 RMSE: 0.9818\n",
      "Epoch 23: TrainLoss 0.9430 RecLoss: 0.0000 (left: 0:02:01)\n",
      "TestLoss: 1.1382 MAE: 0.8561 RMSE: 1.0668\n",
      "ValLoss: 0.9631 MAE: 0.8202 RMSE: 0.9814\n",
      "Epoch 24: TrainLoss 0.9417 RecLoss: 0.0000 (left: 0:02:00)\n",
      "TestLoss: 1.1386 MAE: 0.8573 RMSE: 1.0670\n",
      "ValLoss: 0.9649 MAE: 0.8216 RMSE: 0.9823\n",
      "Epoch 25: TrainLoss 0.9403 RecLoss: 0.0000 (left: 0:01:58)\n",
      "TestLoss: 1.1370 MAE: 0.8552 RMSE: 1.0663\n",
      "ValLoss: 0.9578 MAE: 0.8174 RMSE: 0.9787\n",
      "Epoch 26: TrainLoss 0.9396 RecLoss: 0.0000 (left: 0:01:57)\n",
      "TestLoss: 1.1414 MAE: 0.8591 RMSE: 1.0684\n",
      "ValLoss: 0.9571 MAE: 0.8194 RMSE: 0.9783\n",
      "Epoch 27: TrainLoss 0.9355 RecLoss: 0.0000 (left: 0:01:56)\n",
      "TestLoss: 1.1340 MAE: 0.8545 RMSE: 1.0649\n",
      "ValLoss: 0.9615 MAE: 0.8192 RMSE: 0.9805\n",
      "Epoch 28: TrainLoss 0.9332 RecLoss: 0.0000 (left: 0:01:53)\n",
      "TestLoss: 1.1332 MAE: 0.8541 RMSE: 1.0645\n",
      "ValLoss: 0.9632 MAE: 0.8198 RMSE: 0.9814\n",
      "Epoch 29: TrainLoss 0.9317 RecLoss: 0.0000 (left: 0:01:52)\n",
      "TestLoss: 1.1353 MAE: 0.8554 RMSE: 1.0655\n",
      "ValLoss: 0.9572 MAE: 0.8174 RMSE: 0.9784\n",
      "Epoch 30: TrainLoss 0.9321 RecLoss: 0.0000 (left: 0:01:50)\n",
      "TestLoss: 1.1299 MAE: 0.8485 RMSE: 1.0630\n",
      "ValLoss: 0.9545 MAE: 0.8120 RMSE: 0.9770\n",
      "Epoch 31: TrainLoss 0.9348 RecLoss: 0.0000 (left: 0:01:49)\n",
      "TestLoss: 1.1483 MAE: 0.8649 RMSE: 1.0716\n",
      "ValLoss: 0.9741 MAE: 0.8283 RMSE: 0.9870\n",
      "Epoch 32: TrainLoss 0.9341 RecLoss: 0.0000 (left: 0:01:47)\n",
      "TestLoss: 1.1275 MAE: 0.8470 RMSE: 1.0618\n",
      "ValLoss: 0.9561 MAE: 0.8125 RMSE: 0.9778\n",
      "Epoch 33: TrainLoss 0.9297 RecLoss: 0.0000 (left: 0:01:45)\n",
      "TestLoss: 1.1351 MAE: 0.8550 RMSE: 1.0654\n",
      "ValLoss: 0.9534 MAE: 0.8152 RMSE: 0.9764\n",
      "Epoch 34: TrainLoss 0.9271 RecLoss: 0.0000 (left: 0:01:44)\n",
      "TestLoss: 1.1276 MAE: 0.8481 RMSE: 1.0619\n",
      "ValLoss: 0.9547 MAE: 0.8126 RMSE: 0.9771\n",
      "Epoch 35: TrainLoss 0.9265 RecLoss: 0.0000 (left: 0:01:42)\n",
      "TestLoss: 1.1302 MAE: 0.8516 RMSE: 1.0631\n",
      "ValLoss: 0.9551 MAE: 0.8145 RMSE: 0.9773\n",
      "Epoch 36: TrainLoss 0.9264 RecLoss: 0.0000 (left: 0:01:41)\n",
      "TestLoss: 1.1247 MAE: 0.8457 RMSE: 1.0605\n",
      "ValLoss: 0.9604 MAE: 0.8143 RMSE: 0.9800\n",
      "Epoch 37: TrainLoss 0.9258 RecLoss: 0.0000 (left: 0:01:40)\n",
      "TestLoss: 1.1400 MAE: 0.8592 RMSE: 1.0677\n",
      "ValLoss: 0.9587 MAE: 0.8187 RMSE: 0.9791\n",
      "Epoch 38: TrainLoss 0.9250 RecLoss: 0.0000 (left: 0:01:38)\n",
      "TestLoss: 1.1257 MAE: 0.8448 RMSE: 1.0610\n",
      "ValLoss: 0.9541 MAE: 0.8098 RMSE: 0.9768\n",
      "Epoch 39: TrainLoss 0.9253 RecLoss: 0.0000 (left: 0:01:37)\n",
      "TestLoss: 1.1400 MAE: 0.8592 RMSE: 1.0677\n",
      "ValLoss: 0.9595 MAE: 0.8187 RMSE: 0.9795\n",
      "Epoch 40: TrainLoss 0.9262 RecLoss: 0.0000 (left: 0:01:36)\n",
      "TestLoss: 1.1237 MAE: 0.8447 RMSE: 1.0600\n",
      "ValLoss: 0.9594 MAE: 0.8133 RMSE: 0.9795\n",
      "Epoch 41: TrainLoss 0.9235 RecLoss: 0.0000 (left: 0:01:34)\n",
      "TestLoss: 1.1369 MAE: 0.8567 RMSE: 1.0663\n",
      "ValLoss: 0.9552 MAE: 0.8157 RMSE: 0.9774\n",
      "Epoch 42: TrainLoss 0.9228 RecLoss: 0.0000 (left: 0:01:33)\n",
      "TestLoss: 1.1246 MAE: 0.8449 RMSE: 1.0605\n",
      "ValLoss: 0.9527 MAE: 0.8095 RMSE: 0.9761\n",
      "Epoch 43: TrainLoss 0.9228 RecLoss: 0.0000 (left: 0:01:31)\n",
      "TestLoss: 1.1327 MAE: 0.8539 RMSE: 1.0643\n",
      "ValLoss: 0.9567 MAE: 0.8154 RMSE: 0.9781\n",
      "Epoch 44: TrainLoss 0.9231 RecLoss: 0.0000 (left: 0:01:30)\n",
      "TestLoss: 1.1262 MAE: 0.8480 RMSE: 1.0612\n",
      "ValLoss: 0.9545 MAE: 0.8121 RMSE: 0.9770\n",
      "Epoch 45: TrainLoss 0.9211 RecLoss: 0.0000 (left: 0:01:28)\n",
      "TestLoss: 1.1320 MAE: 0.8529 RMSE: 1.0639\n",
      "ValLoss: 0.9557 MAE: 0.8145 RMSE: 0.9776\n",
      "Epoch 46: TrainLoss 0.9220 RecLoss: 0.0000 (left: 0:01:25)\n",
      "TestLoss: 1.1274 MAE: 0.8491 RMSE: 1.0618\n",
      "ValLoss: 0.9555 MAE: 0.8132 RMSE: 0.9775\n",
      "Epoch 47: TrainLoss 0.9215 RecLoss: 0.0000 (left: 0:01:23)\n",
      "TestLoss: 1.1261 MAE: 0.8481 RMSE: 1.0612\n",
      "ValLoss: 0.9556 MAE: 0.8128 RMSE: 0.9776\n",
      "Epoch 48: TrainLoss 0.9208 RecLoss: 0.0000 (left: 0:01:21)\n",
      "TestLoss: 1.1291 MAE: 0.8503 RMSE: 1.0626\n",
      "ValLoss: 0.9516 MAE: 0.8113 RMSE: 0.9755\n",
      "Epoch 49: TrainLoss 0.9199 RecLoss: 0.0000 (left: 0:01:19)\n",
      "TestLoss: 1.1297 MAE: 0.8511 RMSE: 1.0629\n",
      "ValLoss: 0.9537 MAE: 0.8125 RMSE: 0.9766\n",
      "Epoch 50: TrainLoss 0.9202 RecLoss: 0.0000 (left: 0:01:17)\n",
      "TestLoss: 1.1238 MAE: 0.8442 RMSE: 1.0601\n",
      "ValLoss: 0.9563 MAE: 0.8099 RMSE: 0.9779\n",
      "Epoch 51: TrainLoss 0.9218 RecLoss: 0.0000 (left: 0:01:15)\n",
      "TestLoss: 1.1408 MAE: 0.8592 RMSE: 1.0681\n",
      "ValLoss: 0.9630 MAE: 0.8188 RMSE: 0.9813\n",
      "Epoch 52: TrainLoss 0.9232 RecLoss: 0.0000 (left: 0:01:13)\n",
      "TestLoss: 1.1242 MAE: 0.8401 RMSE: 1.0603\n",
      "ValLoss: 0.9583 MAE: 0.8053 RMSE: 0.9789\n",
      "Epoch 53: TrainLoss 0.9246 RecLoss: 0.0000 (left: 0:01:11)\n",
      "TestLoss: 1.1490 MAE: 0.8637 RMSE: 1.0719\n",
      "ValLoss: 0.9677 MAE: 0.8219 RMSE: 0.9837\n",
      "Epoch 54: TrainLoss 0.9253 RecLoss: 0.0000 (left: 0:01:09)\n",
      "TestLoss: 1.1223 MAE: 0.8380 RMSE: 1.0594\n",
      "ValLoss: 0.9646 MAE: 0.8071 RMSE: 0.9821\n",
      "Epoch 55: TrainLoss 0.9250 RecLoss: 0.0000 (left: 0:01:08)\n",
      "TestLoss: 1.1344 MAE: 0.8553 RMSE: 1.0651\n",
      "ValLoss: 0.9665 MAE: 0.8197 RMSE: 0.9831\n",
      "Epoch 56: TrainLoss 0.9208 RecLoss: 0.0000 (left: 0:01:06)\n",
      "TestLoss: 1.1211 MAE: 0.8404 RMSE: 1.0588\n",
      "ValLoss: 0.9559 MAE: 0.8071 RMSE: 0.9777\n",
      "Epoch 57: TrainLoss 0.9211 RecLoss: 0.0000 (left: 0:01:05)\n",
      "TestLoss: 1.1306 MAE: 0.8520 RMSE: 1.0633\n",
      "ValLoss: 0.9542 MAE: 0.8130 RMSE: 0.9768\n",
      "Epoch 58: TrainLoss 0.9223 RecLoss: 0.0000 (left: 0:01:03)\n",
      "TestLoss: 1.1201 MAE: 0.8405 RMSE: 1.0583\n",
      "ValLoss: 0.9574 MAE: 0.8084 RMSE: 0.9785\n",
      "Epoch 59: TrainLoss 0.9225 RecLoss: 0.0000 (left: 0:01:01)\n",
      "TestLoss: 1.1323 MAE: 0.8533 RMSE: 1.0641\n",
      "ValLoss: 0.9627 MAE: 0.8175 RMSE: 0.9812\n",
      "Epoch 60: TrainLoss 0.9228 RecLoss: 0.0000 (left: 0:01:00)\n",
      "TestLoss: 1.1210 MAE: 0.8421 RMSE: 1.0588\n",
      "ValLoss: 0.9580 MAE: 0.8106 RMSE: 0.9788\n",
      "Epoch 61: TrainLoss 0.9235 RecLoss: 0.0000 (left: 0:00:58)\n",
      "TestLoss: 1.1251 MAE: 0.8474 RMSE: 1.0607\n",
      "ValLoss: 0.9635 MAE: 0.8162 RMSE: 0.9816\n",
      "Epoch 62: TrainLoss 0.9223 RecLoss: 0.0000 (left: 0:00:56)\n",
      "TestLoss: 1.1240 MAE: 0.8461 RMSE: 1.0602\n",
      "ValLoss: 0.9559 MAE: 0.8117 RMSE: 0.9777\n",
      "Epoch 63: TrainLoss 0.9203 RecLoss: 0.0000 (left: 0:00:54)\n",
      "TestLoss: 1.1239 MAE: 0.8450 RMSE: 1.0602\n",
      "ValLoss: 0.9508 MAE: 0.8079 RMSE: 0.9751\n",
      "Epoch 64: TrainLoss 0.9187 RecLoss: 0.0000 (left: 0:00:53)\n",
      "TestLoss: 1.1267 MAE: 0.8487 RMSE: 1.0615\n",
      "ValLoss: 0.9583 MAE: 0.8138 RMSE: 0.9789\n",
      "Epoch 65: TrainLoss 0.9191 RecLoss: 0.0000 (left: 0:00:51)\n",
      "TestLoss: 1.1218 MAE: 0.8434 RMSE: 1.0591\n",
      "ValLoss: 0.9596 MAE: 0.8124 RMSE: 0.9796\n",
      "Epoch 66: TrainLoss 0.9193 RecLoss: 0.0000 (left: 0:00:50)\n",
      "TestLoss: 1.1272 MAE: 0.8489 RMSE: 1.0617\n",
      "ValLoss: 0.9587 MAE: 0.8142 RMSE: 0.9791\n",
      "Epoch 67: TrainLoss 0.9185 RecLoss: 0.0000 (left: 0:00:48)\n",
      "TestLoss: 1.1215 MAE: 0.8425 RMSE: 1.0590\n",
      "ValLoss: 0.9561 MAE: 0.8097 RMSE: 0.9778\n",
      "Epoch 68: TrainLoss 0.9187 RecLoss: 0.0000 (left: 0:00:47)\n",
      "TestLoss: 1.1275 MAE: 0.8487 RMSE: 1.0618\n",
      "ValLoss: 0.9567 MAE: 0.8130 RMSE: 0.9781\n",
      "Epoch 69: TrainLoss 0.9187 RecLoss: 0.0000 (left: 0:00:46)\n",
      "TestLoss: 1.1234 MAE: 0.8446 RMSE: 1.0599\n",
      "ValLoss: 0.9555 MAE: 0.8104 RMSE: 0.9775\n",
      "Epoch 70: TrainLoss 0.9180 RecLoss: 0.0000 (left: 0:00:44)\n",
      "TestLoss: 1.1303 MAE: 0.8506 RMSE: 1.0631\n",
      "ValLoss: 0.9564 MAE: 0.8131 RMSE: 0.9780\n",
      "Epoch 71: TrainLoss 0.9187 RecLoss: 0.0000 (left: 0:00:42)\n",
      "TestLoss: 1.1226 MAE: 0.8434 RMSE: 1.0595\n",
      "ValLoss: 0.9567 MAE: 0.8103 RMSE: 0.9781\n",
      "Epoch 72: TrainLoss 0.9184 RecLoss: 0.0000 (left: 0:00:41)\n",
      "TestLoss: 1.1270 MAE: 0.8481 RMSE: 1.0616\n",
      "ValLoss: 0.9633 MAE: 0.8160 RMSE: 0.9815\n",
      "Epoch 73: TrainLoss 0.9194 RecLoss: 0.0000 (left: 0:00:39)\n",
      "TestLoss: 1.1230 MAE: 0.8429 RMSE: 1.0597\n",
      "ValLoss: 0.9561 MAE: 0.8090 RMSE: 0.9778\n",
      "Epoch 74: TrainLoss 0.9206 RecLoss: 0.0000 (left: 0:00:38)\n",
      "TestLoss: 1.1284 MAE: 0.8485 RMSE: 1.0623\n",
      "ValLoss: 0.9555 MAE: 0.8116 RMSE: 0.9775\n",
      "Epoch 75: TrainLoss 0.9183 RecLoss: 0.0000 (left: 0:00:36)\n",
      "TestLoss: 1.1252 MAE: 0.8454 RMSE: 1.0607\n",
      "ValLoss: 0.9535 MAE: 0.8092 RMSE: 0.9765\n",
      "Epoch 76: TrainLoss 0.9183 RecLoss: 0.0000 (left: 0:00:35)\n",
      "TestLoss: 1.1272 MAE: 0.8482 RMSE: 1.0617\n",
      "ValLoss: 0.9619 MAE: 0.8153 RMSE: 0.9808\n",
      "Epoch 77: TrainLoss 0.9180 RecLoss: 0.0000 (left: 0:00:33)\n",
      "TestLoss: 1.1236 MAE: 0.8446 RMSE: 1.0600\n",
      "ValLoss: 0.9613 MAE: 0.8132 RMSE: 0.9805\n",
      "Epoch 78: TrainLoss 0.9178 RecLoss: 0.0000 (left: 0:00:32)\n",
      "TestLoss: 1.1259 MAE: 0.8462 RMSE: 1.0611\n",
      "ValLoss: 0.9533 MAE: 0.8090 RMSE: 0.9764\n",
      "Epoch 79: TrainLoss 0.9179 RecLoss: 0.0000 (left: 0:00:30)\n",
      "TestLoss: 1.1301 MAE: 0.8501 RMSE: 1.0631\n",
      "ValLoss: 0.9573 MAE: 0.8130 RMSE: 0.9784\n",
      "Epoch 80: TrainLoss 0.9186 RecLoss: 0.0000 (left: 0:00:29)\n",
      "TestLoss: 1.1242 MAE: 0.8443 RMSE: 1.0603\n",
      "ValLoss: 0.9541 MAE: 0.8084 RMSE: 0.9768\n",
      "Epoch 81: TrainLoss 0.9195 RecLoss: 0.0000 (left: 0:00:27)\n",
      "TestLoss: 1.1289 MAE: 0.8487 RMSE: 1.0625\n",
      "ValLoss: 0.9565 MAE: 0.8122 RMSE: 0.9780\n",
      "Epoch 82: TrainLoss 0.9183 RecLoss: 0.0000 (left: 0:00:26)\n",
      "TestLoss: 1.1244 MAE: 0.8449 RMSE: 1.0604\n",
      "ValLoss: 0.9588 MAE: 0.8118 RMSE: 0.9792\n",
      "Epoch 83: TrainLoss 0.9194 RecLoss: 0.0000 (left: 0:00:24)\n",
      "TestLoss: 1.1231 MAE: 0.8436 RMSE: 1.0598\n",
      "ValLoss: 0.9592 MAE: 0.8114 RMSE: 0.9794\n",
      "Epoch 84: TrainLoss 0.9183 RecLoss: 0.0000 (left: 0:00:23)\n",
      "TestLoss: 1.1306 MAE: 0.8500 RMSE: 1.0633\n",
      "ValLoss: 0.9585 MAE: 0.8137 RMSE: 0.9790\n",
      "Epoch 85: TrainLoss 0.9174 RecLoss: 0.0000 (left: 0:00:21)\n",
      "TestLoss: 1.1249 MAE: 0.8436 RMSE: 1.0606\n",
      "ValLoss: 0.9513 MAE: 0.8058 RMSE: 0.9753\n",
      "Epoch 86: TrainLoss 0.9187 RecLoss: 0.0000 (left: 0:00:20)\n",
      "TestLoss: 1.1282 MAE: 0.8480 RMSE: 1.0622\n",
      "ValLoss: 0.9587 MAE: 0.8130 RMSE: 0.9791\n",
      "Epoch 87: TrainLoss 0.9172 RecLoss: 0.0000 (left: 0:00:18)\n",
      "TestLoss: 1.1235 MAE: 0.8432 RMSE: 1.0599\n",
      "ValLoss: 0.9588 MAE: 0.8102 RMSE: 0.9792\n",
      "Epoch 88: TrainLoss 0.9174 RecLoss: 0.0000 (left: 0:00:17)\n",
      "TestLoss: 1.1286 MAE: 0.8484 RMSE: 1.0624\n",
      "ValLoss: 0.9597 MAE: 0.8138 RMSE: 0.9797\n",
      "Epoch 89: TrainLoss 0.9174 RecLoss: 0.0000 (left: 0:00:15)\n",
      "TestLoss: 1.1261 MAE: 0.8461 RMSE: 1.0612\n",
      "ValLoss: 0.9561 MAE: 0.8107 RMSE: 0.9778\n",
      "Epoch 90: TrainLoss 0.9173 RecLoss: 0.0000 (left: 0:00:14)\n",
      "TestLoss: 1.1258 MAE: 0.8458 RMSE: 1.0610\n",
      "ValLoss: 0.9570 MAE: 0.8109 RMSE: 0.9783\n",
      "Epoch 91: TrainLoss 0.9182 RecLoss: 0.0000 (left: 0:00:12)\n",
      "TestLoss: 1.1259 MAE: 0.8456 RMSE: 1.0611\n",
      "ValLoss: 0.9562 MAE: 0.8102 RMSE: 0.9778\n",
      "Epoch 92: TrainLoss 0.9180 RecLoss: 0.0000 (left: 0:00:11)\n",
      "TestLoss: 1.1267 MAE: 0.8465 RMSE: 1.0615\n",
      "ValLoss: 0.9577 MAE: 0.8117 RMSE: 0.9786\n",
      "Epoch 93: TrainLoss 0.9175 RecLoss: 0.0000 (left: 0:00:10)\n",
      "TestLoss: 1.1272 MAE: 0.8471 RMSE: 1.0617\n",
      "ValLoss: 0.9602 MAE: 0.8135 RMSE: 0.9799\n",
      "Epoch 94: TrainLoss 0.9173 RecLoss: 0.0000 (left: 0:00:08)\n",
      "TestLoss: 1.1240 MAE: 0.8437 RMSE: 1.0602\n",
      "ValLoss: 0.9563 MAE: 0.8092 RMSE: 0.9779\n",
      "Epoch 95: TrainLoss 0.9170 RecLoss: 0.0000 (left: 0:00:07)\n",
      "TestLoss: 1.1300 MAE: 0.8492 RMSE: 1.0630\n",
      "ValLoss: 0.9572 MAE: 0.8127 RMSE: 0.9784\n",
      "Epoch 96: TrainLoss 0.9177 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 1.1240 MAE: 0.8440 RMSE: 1.0602\n",
      "ValLoss: 0.9589 MAE: 0.8112 RMSE: 0.9792\n",
      "Epoch 97: TrainLoss 0.9171 RecLoss: 0.0000 (left: 0:00:04)\n",
      "TestLoss: 1.1255 MAE: 0.8456 RMSE: 1.0609\n",
      "ValLoss: 0.9608 MAE: 0.8132 RMSE: 0.9802\n",
      "Epoch 98: TrainLoss 0.9184 RecLoss: 0.0000 (left: 0:00:02)\n",
      "TestLoss: 1.1255 MAE: 0.8450 RMSE: 1.0609\n",
      "ValLoss: 0.9547 MAE: 0.8091 RMSE: 0.9771\n",
      "Epoch 99: TrainLoss 0.9176 RecLoss: 0.0000 (left: 0:00:01)\n",
      "TestLoss: 1.1267 MAE: 0.8463 RMSE: 1.0614\n",
      "ValLoss: 0.9572 MAE: 0.8112 RMSE: 0.9784\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 54098/4938\n",
      "test set size: support/query 292/213\n",
      "USER HIS DICT: 943\n",
      "NUM IS: 943\n",
      "Key Test Result: MAE: 0.7430 RMSE: 0.9386 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 943\n",
      "NUM IS: 943\n",
      "Que Test Result: MAE: 0.8450 RMSE: 1.0602 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7860 RMSE: 0.9917 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 60% CUR coreusers input to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 71238/4938\n",
      "test set size: support/query 438/213\n",
      "Epoch 0 Step 67: Train 7.5163 Reg: 0.4335\n",
      "Test: 1.2103 MAE: 0.9155 RMSE: 1.1001\n",
      "Val: 1.1605 MAE: 0.8884 RMSE: 1.0772\n",
      "Epoch 1 Step 134: Train 1.0571 Reg: 0.4197\n",
      "Test: 1.0416 MAE: 0.8259 RMSE: 1.0206\n",
      "Val: 0.9722 MAE: 0.7989 RMSE: 0.9860\n",
      "Epoch 2 Step 201: Train 0.9068 Reg: 0.3951\n",
      "Test: 0.9691 MAE: 0.7668 RMSE: 0.9844\n",
      "Val: 0.9059 MAE: 0.7478 RMSE: 0.9518\n",
      "Epoch 3 Step 268: Train 0.8621 Reg: 0.3814\n",
      "Test: 0.9531 MAE: 0.7622 RMSE: 0.9763\n",
      "Val: 0.8868 MAE: 0.7391 RMSE: 0.9417\n",
      "Epoch 4 Step 335: Train 0.8479 Reg: 0.3683\n",
      "Test: 0.9422 MAE: 0.7586 RMSE: 0.9707\n",
      "Val: 0.8817 MAE: 0.7373 RMSE: 0.9390\n",
      "Epoch 5 Step 402: Train 0.8408 Reg: 0.3573\n",
      "Test: 0.9490 MAE: 0.7616 RMSE: 0.9742\n",
      "Val: 0.8764 MAE: 0.7347 RMSE: 0.9362\n",
      "Epoch 6 Step 469: Train 0.8366 Reg: 0.3476\n",
      "Test: 0.9453 MAE: 0.7599 RMSE: 0.9723\n",
      "Val: 0.8756 MAE: 0.7348 RMSE: 0.9357\n",
      "Epoch 7 Step 536: Train 0.8339 Reg: 0.3386\n",
      "Test: 0.9416 MAE: 0.7581 RMSE: 0.9704\n",
      "Val: 0.8745 MAE: 0.7334 RMSE: 0.9351\n",
      "Epoch 8 Step 603: Train 0.8318 Reg: 0.3300\n",
      "Test: 0.9444 MAE: 0.7580 RMSE: 0.9718\n",
      "Val: 0.8719 MAE: 0.7328 RMSE: 0.9337\n",
      "Epoch 9 Step 670: Train 0.8301 Reg: 0.3228\n",
      "Test: 0.9463 MAE: 0.7578 RMSE: 0.9728\n",
      "Val: 0.8722 MAE: 0.7321 RMSE: 0.9339\n",
      "Epoch 10 Step 737: Train 0.8284 Reg: 0.3158\n",
      "Test: 0.9408 MAE: 0.7562 RMSE: 0.9700\n",
      "Val: 0.8711 MAE: 0.7325 RMSE: 0.9333\n",
      "Epoch 11 Step 804: Train 0.8267 Reg: 0.3093\n",
      "Test: 0.9477 MAE: 0.7572 RMSE: 0.9735\n",
      "Val: 0.8735 MAE: 0.7318 RMSE: 0.9346\n",
      "Epoch 12 Step 871: Train 0.8249 Reg: 0.3034\n",
      "Test: 0.9435 MAE: 0.7560 RMSE: 0.9714\n",
      "Val: 0.8717 MAE: 0.7328 RMSE: 0.9336\n",
      "Epoch 13 Step 938: Train 0.8235 Reg: 0.2981\n",
      "Test: 0.9423 MAE: 0.7574 RMSE: 0.9707\n",
      "Val: 0.8699 MAE: 0.7323 RMSE: 0.9327\n",
      "Epoch 14 Step 1005: Train 0.8218 Reg: 0.2928\n",
      "Test: 0.9419 MAE: 0.7571 RMSE: 0.9705\n",
      "Val: 0.8705 MAE: 0.7327 RMSE: 0.9330\n",
      "Epoch 15 Step 1072: Train 0.8209 Reg: 0.2879\n",
      "Test: 0.9456 MAE: 0.7582 RMSE: 0.9724\n",
      "Val: 0.8687 MAE: 0.7317 RMSE: 0.9320\n",
      "Epoch 16 Step 1139: Train 0.8193 Reg: 0.2833\n",
      "Test: 0.9438 MAE: 0.7567 RMSE: 0.9715\n",
      "Val: 0.8696 MAE: 0.7309 RMSE: 0.9325\n",
      "Epoch 17 Step 1206: Train 0.8177 Reg: 0.2797\n",
      "Test: 0.9438 MAE: 0.7564 RMSE: 0.9715\n",
      "Val: 0.8697 MAE: 0.7309 RMSE: 0.9326\n",
      "Epoch 18 Step 1273: Train 0.8163 Reg: 0.2761\n",
      "Test: 0.9459 MAE: 0.7576 RMSE: 0.9726\n",
      "Val: 0.8687 MAE: 0.7317 RMSE: 0.9320\n",
      "Epoch 19 Step 1340: Train 0.8148 Reg: 0.2729\n",
      "Test: 0.9416 MAE: 0.7547 RMSE: 0.9704\n",
      "Val: 0.8679 MAE: 0.7297 RMSE: 0.9316\n",
      "Epoch 20 Step 1407: Train 0.8136 Reg: 0.2699\n",
      "Test: 0.9459 MAE: 0.7549 RMSE: 0.9726\n",
      "Val: 0.8678 MAE: 0.7286 RMSE: 0.9315\n",
      "Epoch 21 Step 1474: Train 0.8118 Reg: 0.2669\n",
      "Test: 0.9418 MAE: 0.7550 RMSE: 0.9705\n",
      "Val: 0.8670 MAE: 0.7297 RMSE: 0.9311\n",
      "Epoch 22 Step 1541: Train 0.8100 Reg: 0.2646\n",
      "Test: 0.9432 MAE: 0.7567 RMSE: 0.9712\n",
      "Val: 0.8664 MAE: 0.7307 RMSE: 0.9308\n",
      "Epoch 23 Step 1608: Train 0.8086 Reg: 0.2624\n",
      "Test: 0.9435 MAE: 0.7554 RMSE: 0.9714\n",
      "Val: 0.8674 MAE: 0.7292 RMSE: 0.9314\n",
      "Epoch 24 Step 1675: Train 0.8069 Reg: 0.2604\n",
      "Test: 0.9419 MAE: 0.7540 RMSE: 0.9705\n",
      "Val: 0.8659 MAE: 0.7276 RMSE: 0.9305\n",
      "Epoch 25 Step 1742: Train 0.8050 Reg: 0.2587\n",
      "Test: 0.9382 MAE: 0.7527 RMSE: 0.9686\n",
      "Val: 0.8654 MAE: 0.7278 RMSE: 0.9303\n",
      "Epoch 26 Step 1809: Train 0.8035 Reg: 0.2572\n",
      "Test: 0.9414 MAE: 0.7543 RMSE: 0.9702\n",
      "Val: 0.8636 MAE: 0.7283 RMSE: 0.9293\n",
      "Epoch 27 Step 1876: Train 0.8014 Reg: 0.2558\n",
      "Test: 0.9405 MAE: 0.7531 RMSE: 0.9698\n",
      "Val: 0.8647 MAE: 0.7273 RMSE: 0.9299\n",
      "Epoch 28 Step 1943: Train 0.7996 Reg: 0.2547\n",
      "Test: 0.9378 MAE: 0.7511 RMSE: 0.9684\n",
      "Val: 0.8639 MAE: 0.7266 RMSE: 0.9295\n",
      "Epoch 29 Step 2010: Train 0.7978 Reg: 0.2538\n",
      "Test: 0.9377 MAE: 0.7516 RMSE: 0.9684\n",
      "Val: 0.8635 MAE: 0.7269 RMSE: 0.9292\n",
      "Epoch 30 Step 2077: Train 0.7958 Reg: 0.2528\n",
      "Test: 0.9378 MAE: 0.7517 RMSE: 0.9684\n",
      "Val: 0.8632 MAE: 0.7263 RMSE: 0.9291\n",
      "Epoch 31 Step 2144: Train 0.7938 Reg: 0.2523\n",
      "Test: 0.9369 MAE: 0.7510 RMSE: 0.9679\n",
      "Val: 0.8628 MAE: 0.7259 RMSE: 0.9289\n",
      "Epoch 32 Step 2211: Train 0.7918 Reg: 0.2515\n",
      "Test: 0.9341 MAE: 0.7510 RMSE: 0.9665\n",
      "Val: 0.8614 MAE: 0.7261 RMSE: 0.9281\n",
      "Epoch 33 Step 2278: Train 0.7896 Reg: 0.2513\n",
      "Test: 0.9327 MAE: 0.7495 RMSE: 0.9657\n",
      "Val: 0.8618 MAE: 0.7261 RMSE: 0.9283\n",
      "Epoch 34 Step 2345: Train 0.7874 Reg: 0.2510\n",
      "Test: 0.9318 MAE: 0.7486 RMSE: 0.9653\n",
      "Val: 0.8614 MAE: 0.7250 RMSE: 0.9281\n",
      "Epoch 35 Step 2412: Train 0.7853 Reg: 0.2508\n",
      "Test: 0.9313 MAE: 0.7481 RMSE: 0.9650\n",
      "Val: 0.8613 MAE: 0.7250 RMSE: 0.9281\n",
      "Epoch 36 Step 2479: Train 0.7831 Reg: 0.2508\n",
      "Test: 0.9310 MAE: 0.7476 RMSE: 0.9649\n",
      "Val: 0.8612 MAE: 0.7247 RMSE: 0.9280\n",
      "Epoch 37 Step 2546: Train 0.7809 Reg: 0.2509\n",
      "Test: 0.9296 MAE: 0.7475 RMSE: 0.9642\n",
      "Val: 0.8606 MAE: 0.7246 RMSE: 0.9277\n",
      "Epoch 38 Step 2613: Train 0.7786 Reg: 0.2509\n",
      "Test: 0.9263 MAE: 0.7462 RMSE: 0.9625\n",
      "Val: 0.8609 MAE: 0.7241 RMSE: 0.9278\n",
      "Epoch 39 Step 2680: Train 0.7765 Reg: 0.2511\n",
      "Test: 0.9294 MAE: 0.7465 RMSE: 0.9641\n",
      "Val: 0.8606 MAE: 0.7234 RMSE: 0.9277\n",
      "Epoch 40 Step 2747: Train 0.7742 Reg: 0.2513\n",
      "Test: 0.9265 MAE: 0.7456 RMSE: 0.9626\n",
      "Val: 0.8599 MAE: 0.7238 RMSE: 0.9273\n",
      "Epoch 41 Step 2814: Train 0.7719 Reg: 0.2515\n",
      "Test: 0.9245 MAE: 0.7446 RMSE: 0.9615\n",
      "Val: 0.8604 MAE: 0.7235 RMSE: 0.9276\n",
      "Epoch 42 Step 2881: Train 0.7697 Reg: 0.2518\n",
      "Test: 0.9249 MAE: 0.7451 RMSE: 0.9617\n",
      "Val: 0.8592 MAE: 0.7241 RMSE: 0.9269\n",
      "Epoch 43 Step 2948: Train 0.7674 Reg: 0.2521\n",
      "Test: 0.9229 MAE: 0.7432 RMSE: 0.9607\n",
      "Val: 0.8604 MAE: 0.7230 RMSE: 0.9276\n",
      "Epoch 44 Step 3015: Train 0.7652 Reg: 0.2524\n",
      "Test: 0.9224 MAE: 0.7436 RMSE: 0.9604\n",
      "Val: 0.8594 MAE: 0.7236 RMSE: 0.9270\n",
      "Epoch 45 Step 3082: Train 0.7630 Reg: 0.2527\n",
      "Test: 0.9209 MAE: 0.7427 RMSE: 0.9597\n",
      "Val: 0.8603 MAE: 0.7232 RMSE: 0.9275\n",
      "Epoch 46 Step 3149: Train 0.7609 Reg: 0.2532\n",
      "Test: 0.9206 MAE: 0.7425 RMSE: 0.9595\n",
      "Val: 0.8605 MAE: 0.7233 RMSE: 0.9276\n",
      "Epoch 47 Step 3216: Train 0.7587 Reg: 0.2536\n",
      "Test: 0.9185 MAE: 0.7416 RMSE: 0.9584\n",
      "Val: 0.8604 MAE: 0.7234 RMSE: 0.9276\n",
      "Epoch 48 Step 3283: Train 0.7564 Reg: 0.2540\n",
      "Test: 0.9183 MAE: 0.7409 RMSE: 0.9583\n",
      "Val: 0.8607 MAE: 0.7232 RMSE: 0.9277\n",
      "Epoch 49 Step 3350: Train 0.7544 Reg: 0.2544\n",
      "Test: 0.9186 MAE: 0.7407 RMSE: 0.9584\n",
      "Val: 0.8610 MAE: 0.7228 RMSE: 0.9279\n",
      "Epoch 50 Step 3417: Train 0.7523 Reg: 0.2548\n",
      "Test: 0.9177 MAE: 0.7403 RMSE: 0.9580\n",
      "Val: 0.8609 MAE: 0.7229 RMSE: 0.9278\n",
      "Epoch 51 Step 3484: Train 0.7503 Reg: 0.2552\n",
      "Test: 0.9177 MAE: 0.7417 RMSE: 0.9580\n",
      "Val: 0.8606 MAE: 0.7238 RMSE: 0.9277\n",
      "Epoch 52 Step 3551: Train 0.7483 Reg: 0.2556\n",
      "Test: 0.9164 MAE: 0.7398 RMSE: 0.9573\n",
      "Val: 0.8614 MAE: 0.7225 RMSE: 0.9281\n",
      "Epoch 53 Step 3618: Train 0.7464 Reg: 0.2560\n",
      "Test: 0.9165 MAE: 0.7407 RMSE: 0.9574\n",
      "Val: 0.8612 MAE: 0.7237 RMSE: 0.9280\n",
      "Epoch 54 Step 3685: Train 0.7444 Reg: 0.2564\n",
      "Test: 0.9163 MAE: 0.7406 RMSE: 0.9572\n",
      "Val: 0.8614 MAE: 0.7237 RMSE: 0.9281\n",
      "Epoch 55 Step 3752: Train 0.7425 Reg: 0.2568\n",
      "Test: 0.9152 MAE: 0.7397 RMSE: 0.9567\n",
      "Val: 0.8619 MAE: 0.7233 RMSE: 0.9284\n",
      "Epoch 56 Step 3819: Train 0.7407 Reg: 0.2572\n",
      "Test: 0.9143 MAE: 0.7395 RMSE: 0.9562\n",
      "Val: 0.8624 MAE: 0.7233 RMSE: 0.9286\n",
      "Epoch 57 Step 3886: Train 0.7389 Reg: 0.2575\n",
      "Test: 0.9140 MAE: 0.7394 RMSE: 0.9560\n",
      "Val: 0.8626 MAE: 0.7238 RMSE: 0.9288\n",
      "Epoch 58 Step 3953: Train 0.7372 Reg: 0.2579\n",
      "Test: 0.9141 MAE: 0.7397 RMSE: 0.9561\n",
      "Val: 0.8624 MAE: 0.7239 RMSE: 0.9287\n",
      "Epoch 59 Step 4020: Train 0.7355 Reg: 0.2582\n",
      "Test: 0.9134 MAE: 0.7392 RMSE: 0.9557\n",
      "Val: 0.8629 MAE: 0.7238 RMSE: 0.9289\n",
      "Epoch 60 Step 4087: Train 0.7337 Reg: 0.2585\n",
      "Test: 0.9129 MAE: 0.7384 RMSE: 0.9555\n",
      "Val: 0.8640 MAE: 0.7233 RMSE: 0.9295\n",
      "Epoch 61 Step 4154: Train 0.7321 Reg: 0.2589\n",
      "Test: 0.9123 MAE: 0.7384 RMSE: 0.9551\n",
      "Val: 0.8637 MAE: 0.7235 RMSE: 0.9294\n",
      "Epoch 62 Step 4221: Train 0.7306 Reg: 0.2592\n",
      "Test: 0.9125 MAE: 0.7389 RMSE: 0.9552\n",
      "Val: 0.8638 MAE: 0.7240 RMSE: 0.9294\n",
      "Epoch 63 Step 4288: Train 0.7291 Reg: 0.2595\n",
      "Test: 0.9123 MAE: 0.7387 RMSE: 0.9551\n",
      "Val: 0.8644 MAE: 0.7238 RMSE: 0.9297\n",
      "Epoch 64 Step 4355: Train 0.7276 Reg: 0.2598\n",
      "Test: 0.9114 MAE: 0.7381 RMSE: 0.9547\n",
      "Val: 0.8647 MAE: 0.7237 RMSE: 0.9299\n",
      "Epoch 65 Step 4422: Train 0.7261 Reg: 0.2600\n",
      "Test: 0.9117 MAE: 0.7388 RMSE: 0.9548\n",
      "Val: 0.8645 MAE: 0.7243 RMSE: 0.9298\n",
      "Epoch 66 Step 4489: Train 0.7248 Reg: 0.2603\n",
      "Test: 0.9110 MAE: 0.7382 RMSE: 0.9545\n",
      "Val: 0.8652 MAE: 0.7241 RMSE: 0.9301\n",
      "Epoch 67 Step 4556: Train 0.7234 Reg: 0.2605\n",
      "Test: 0.9109 MAE: 0.7381 RMSE: 0.9544\n",
      "Val: 0.8654 MAE: 0.7241 RMSE: 0.9303\n",
      "Epoch 68 Step 4623: Train 0.7222 Reg: 0.2608\n",
      "Test: 0.9100 MAE: 0.7377 RMSE: 0.9540\n",
      "Val: 0.8660 MAE: 0.7241 RMSE: 0.9306\n",
      "Epoch 69 Step 4690: Train 0.7209 Reg: 0.2610\n",
      "Test: 0.9100 MAE: 0.7376 RMSE: 0.9539\n",
      "Val: 0.8663 MAE: 0.7241 RMSE: 0.9308\n",
      "Epoch 70 Step 4757: Train 0.7197 Reg: 0.2613\n",
      "Test: 0.9099 MAE: 0.7380 RMSE: 0.9539\n",
      "Val: 0.8661 MAE: 0.7245 RMSE: 0.9306\n",
      "Epoch 71 Step 4824: Train 0.7186 Reg: 0.2615\n",
      "Test: 0.9103 MAE: 0.7382 RMSE: 0.9541\n",
      "Val: 0.8663 MAE: 0.7245 RMSE: 0.9307\n",
      "Epoch 72 Step 4891: Train 0.7175 Reg: 0.2617\n",
      "Test: 0.9098 MAE: 0.7378 RMSE: 0.9538\n",
      "Val: 0.8668 MAE: 0.7245 RMSE: 0.9310\n",
      "Epoch 73 Step 4958: Train 0.7164 Reg: 0.2619\n",
      "Test: 0.9098 MAE: 0.7384 RMSE: 0.9539\n",
      "Val: 0.8667 MAE: 0.7248 RMSE: 0.9309\n",
      "Epoch 74 Step 5025: Train 0.7154 Reg: 0.2620\n",
      "Test: 0.9093 MAE: 0.7376 RMSE: 0.9536\n",
      "Val: 0.8674 MAE: 0.7245 RMSE: 0.9313\n",
      "Epoch 75 Step 5092: Train 0.7144 Reg: 0.2622\n",
      "Test: 0.9088 MAE: 0.7376 RMSE: 0.9533\n",
      "Val: 0.8674 MAE: 0.7246 RMSE: 0.9313\n",
      "Epoch 76 Step 5159: Train 0.7135 Reg: 0.2624\n",
      "Test: 0.9092 MAE: 0.7381 RMSE: 0.9535\n",
      "Val: 0.8674 MAE: 0.7249 RMSE: 0.9314\n",
      "Epoch 77 Step 5226: Train 0.7126 Reg: 0.2626\n",
      "Test: 0.9088 MAE: 0.7377 RMSE: 0.9533\n",
      "Val: 0.8680 MAE: 0.7248 RMSE: 0.9317\n",
      "Epoch 78 Step 5293: Train 0.7117 Reg: 0.2627\n",
      "Test: 0.9086 MAE: 0.7380 RMSE: 0.9532\n",
      "Val: 0.8678 MAE: 0.7251 RMSE: 0.9316\n",
      "Epoch 79 Step 5360: Train 0.7109 Reg: 0.2628\n",
      "Test: 0.9082 MAE: 0.7374 RMSE: 0.9530\n",
      "Val: 0.8684 MAE: 0.7248 RMSE: 0.9319\n",
      "Epoch 80 Step 5427: Train 0.7101 Reg: 0.2630\n",
      "Test: 0.9084 MAE: 0.7378 RMSE: 0.9531\n",
      "Val: 0.8683 MAE: 0.7251 RMSE: 0.9318\n",
      "Epoch 81 Step 5494: Train 0.7094 Reg: 0.2631\n",
      "Test: 0.9084 MAE: 0.7376 RMSE: 0.9531\n",
      "Val: 0.8687 MAE: 0.7249 RMSE: 0.9321\n",
      "Epoch 82 Step 5561: Train 0.7086 Reg: 0.2633\n",
      "Test: 0.9083 MAE: 0.7376 RMSE: 0.9530\n",
      "Val: 0.8688 MAE: 0.7251 RMSE: 0.9321\n",
      "Epoch 83 Step 5628: Train 0.7080 Reg: 0.2634\n",
      "Test: 0.9081 MAE: 0.7377 RMSE: 0.9529\n",
      "Val: 0.8689 MAE: 0.7252 RMSE: 0.9322\n",
      "Epoch 84 Step 5695: Train 0.7073 Reg: 0.2635\n",
      "Test: 0.9081 MAE: 0.7377 RMSE: 0.9530\n",
      "Val: 0.8691 MAE: 0.7253 RMSE: 0.9323\n",
      "Epoch 85 Step 5762: Train 0.7067 Reg: 0.2636\n",
      "Test: 0.9081 MAE: 0.7378 RMSE: 0.9529\n",
      "Val: 0.8691 MAE: 0.7254 RMSE: 0.9323\n",
      "Epoch 86 Step 5829: Train 0.7061 Reg: 0.2637\n",
      "Test: 0.9079 MAE: 0.7377 RMSE: 0.9528\n",
      "Val: 0.8694 MAE: 0.7254 RMSE: 0.9324\n",
      "Epoch 87 Step 5896: Train 0.7055 Reg: 0.2638\n",
      "Test: 0.9080 MAE: 0.7378 RMSE: 0.9529\n",
      "Val: 0.8695 MAE: 0.7254 RMSE: 0.9325\n",
      "Epoch 88 Step 5963: Train 0.7049 Reg: 0.2639\n",
      "Test: 0.9077 MAE: 0.7375 RMSE: 0.9527\n",
      "Val: 0.8698 MAE: 0.7253 RMSE: 0.9327\n",
      "Epoch 89 Step 6030: Train 0.7044 Reg: 0.2640\n",
      "Test: 0.9077 MAE: 0.7376 RMSE: 0.9527\n",
      "Val: 0.8699 MAE: 0.7255 RMSE: 0.9327\n",
      "Epoch 90 Step 6097: Train 0.7039 Reg: 0.2640\n",
      "Test: 0.9077 MAE: 0.7376 RMSE: 0.9527\n",
      "Val: 0.8700 MAE: 0.7255 RMSE: 0.9328\n",
      "Epoch 91 Step 6164: Train 0.7034 Reg: 0.2641\n",
      "Test: 0.9075 MAE: 0.7374 RMSE: 0.9526\n",
      "Val: 0.8703 MAE: 0.7254 RMSE: 0.9329\n",
      "Epoch 92 Step 6231: Train 0.7030 Reg: 0.2642\n",
      "Test: 0.9075 MAE: 0.7376 RMSE: 0.9526\n",
      "Val: 0.8703 MAE: 0.7256 RMSE: 0.9329\n",
      "Epoch 93 Step 6298: Train 0.7025 Reg: 0.2643\n",
      "Test: 0.9075 MAE: 0.7375 RMSE: 0.9526\n",
      "Val: 0.8705 MAE: 0.7256 RMSE: 0.9330\n",
      "Epoch 94 Step 6365: Train 0.7021 Reg: 0.2643\n",
      "Test: 0.9073 MAE: 0.7374 RMSE: 0.9525\n",
      "Val: 0.8706 MAE: 0.7256 RMSE: 0.9330\n",
      "Epoch 95 Step 6432: Train 0.7017 Reg: 0.2644\n",
      "Test: 0.9073 MAE: 0.7375 RMSE: 0.9525\n",
      "Val: 0.8707 MAE: 0.7257 RMSE: 0.9331\n",
      "Epoch 96 Step 6499: Train 0.7013 Reg: 0.2645\n",
      "Test: 0.9072 MAE: 0.7376 RMSE: 0.9525\n",
      "Val: 0.8707 MAE: 0.7258 RMSE: 0.9331\n",
      "Epoch 97 Step 6566: Train 0.7010 Reg: 0.2645\n",
      "Test: 0.9072 MAE: 0.7375 RMSE: 0.9525\n",
      "Val: 0.8708 MAE: 0.7258 RMSE: 0.9332\n",
      "Epoch 98 Step 6633: Train 0.7006 Reg: 0.2646\n",
      "Test: 0.9071 MAE: 0.7375 RMSE: 0.9524\n",
      "Val: 0.8709 MAE: 0.7258 RMSE: 0.9332\n",
      "Epoch 99 Step 6700: Train 0.7003 Reg: 0.2646\n",
      "Test: 0.9071 MAE: 0.7374 RMSE: 0.9524\n",
      "Val: 0.8711 MAE: 0.7257 RMSE: 0.9333\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 71238/4938\n",
      "test set size: support/query 438/213\n",
      "Epoch 0: TrainLoss 1.7740 RecLoss: 0.0000 (left: 0:04:07)\n",
      "TestLoss: 1.8874 MAE: 1.1822 RMSE: 1.3738\n",
      "ValLoss: 1.6647 MAE: 1.1002 RMSE: 1.2902\n",
      "Epoch 1: TrainLoss 1.2760 RecLoss: 0.0000 (left: 0:03:04)\n",
      "TestLoss: 1.3701 MAE: 0.9157 RMSE: 1.1705\n",
      "ValLoss: 1.1146 MAE: 0.8410 RMSE: 1.0557\n",
      "Epoch 2: TrainLoss 1.1655 RecLoss: 0.0000 (left: 0:02:48)\n",
      "TestLoss: 1.3717 MAE: 0.9612 RMSE: 1.1712\n",
      "ValLoss: 1.0988 MAE: 0.8802 RMSE: 1.0483\n",
      "Epoch 3: TrainLoss 1.1298 RecLoss: 0.0000 (left: 0:02:31)\n",
      "TestLoss: 1.2562 MAE: 0.9055 RMSE: 1.1208\n",
      "ValLoss: 1.0635 MAE: 0.8520 RMSE: 1.0313\n",
      "Epoch 4: TrainLoss 1.0962 RecLoss: 0.0000 (left: 0:02:18)\n",
      "TestLoss: 1.2388 MAE: 0.9074 RMSE: 1.1130\n",
      "ValLoss: 1.0595 MAE: 0.8632 RMSE: 1.0293\n",
      "Epoch 5: TrainLoss 1.0624 RecLoss: 0.0000 (left: 0:02:14)\n",
      "TestLoss: 1.2365 MAE: 0.9131 RMSE: 1.1120\n",
      "ValLoss: 1.0433 MAE: 0.8654 RMSE: 1.0214\n",
      "Epoch 6: TrainLoss 1.0445 RecLoss: 0.0000 (left: 0:02:18)\n",
      "TestLoss: 1.2024 MAE: 0.8835 RMSE: 1.0966\n",
      "ValLoss: 1.0009 MAE: 0.8339 RMSE: 1.0005\n",
      "Epoch 7: TrainLoss 1.0294 RecLoss: 0.0000 (left: 0:02:13)\n",
      "TestLoss: 1.1949 MAE: 0.8796 RMSE: 1.0931\n",
      "ValLoss: 0.9867 MAE: 0.8306 RMSE: 0.9933\n",
      "Epoch 8: TrainLoss 1.0167 RecLoss: 0.0000 (left: 0:02:08)\n",
      "TestLoss: 1.1885 MAE: 0.8790 RMSE: 1.0902\n",
      "ValLoss: 0.9858 MAE: 0.8344 RMSE: 0.9929\n",
      "Epoch 9: TrainLoss 1.0052 RecLoss: 0.0000 (left: 0:02:06)\n",
      "TestLoss: 1.1710 MAE: 0.8683 RMSE: 1.0821\n",
      "ValLoss: 0.9807 MAE: 0.8285 RMSE: 0.9903\n",
      "Epoch 10: TrainLoss 0.9965 RecLoss: 0.0000 (left: 0:02:05)\n",
      "TestLoss: 1.1651 MAE: 0.8678 RMSE: 1.0794\n",
      "ValLoss: 0.9803 MAE: 0.8312 RMSE: 0.9901\n",
      "Epoch 11: TrainLoss 0.9880 RecLoss: 0.0000 (left: 0:02:03)\n",
      "TestLoss: 1.1553 MAE: 0.8606 RMSE: 1.0748\n",
      "ValLoss: 0.9738 MAE: 0.8268 RMSE: 0.9868\n",
      "Epoch 12: TrainLoss 0.9804 RecLoss: 0.0000 (left: 0:02:02)\n",
      "TestLoss: 1.1532 MAE: 0.8612 RMSE: 1.0739\n",
      "ValLoss: 0.9704 MAE: 0.8273 RMSE: 0.9851\n",
      "Epoch 13: TrainLoss 0.9735 RecLoss: 0.0000 (left: 0:01:58)\n",
      "TestLoss: 1.1437 MAE: 0.8533 RMSE: 1.0694\n",
      "ValLoss: 0.9603 MAE: 0.8194 RMSE: 0.9799\n",
      "Epoch 14: TrainLoss 0.9670 RecLoss: 0.0000 (left: 0:01:55)\n",
      "TestLoss: 1.1439 MAE: 0.8550 RMSE: 1.0695\n",
      "ValLoss: 0.9595 MAE: 0.8227 RMSE: 0.9796\n",
      "Epoch 15: TrainLoss 0.9622 RecLoss: 0.0000 (left: 0:01:55)\n",
      "TestLoss: 1.1363 MAE: 0.8502 RMSE: 1.0660\n",
      "ValLoss: 0.9538 MAE: 0.8179 RMSE: 0.9766\n",
      "Epoch 16: TrainLoss 0.9572 RecLoss: 0.0000 (left: 0:01:53)\n",
      "TestLoss: 1.1318 MAE: 0.8486 RMSE: 1.0638\n",
      "ValLoss: 0.9568 MAE: 0.8196 RMSE: 0.9781\n",
      "Epoch 17: TrainLoss 0.9530 RecLoss: 0.0000 (left: 0:01:52)\n",
      "TestLoss: 1.1277 MAE: 0.8463 RMSE: 1.0619\n",
      "ValLoss: 0.9552 MAE: 0.8186 RMSE: 0.9774\n",
      "Epoch 18: TrainLoss 0.9498 RecLoss: 0.0000 (left: 0:01:50)\n",
      "TestLoss: 1.1258 MAE: 0.8456 RMSE: 1.0610\n",
      "ValLoss: 0.9539 MAE: 0.8185 RMSE: 0.9767\n",
      "Epoch 19: TrainLoss 0.9470 RecLoss: 0.0000 (left: 0:01:47)\n",
      "TestLoss: 1.1234 MAE: 0.8435 RMSE: 1.0599\n",
      "ValLoss: 0.9472 MAE: 0.8145 RMSE: 0.9733\n",
      "Epoch 20: TrainLoss 0.9437 RecLoss: 0.0000 (left: 0:01:45)\n",
      "TestLoss: 1.1211 MAE: 0.8423 RMSE: 1.0588\n",
      "ValLoss: 0.9471 MAE: 0.8139 RMSE: 0.9732\n",
      "Epoch 21: TrainLoss 0.9406 RecLoss: 0.0000 (left: 0:01:44)\n",
      "TestLoss: 1.1211 MAE: 0.8436 RMSE: 1.0588\n",
      "ValLoss: 0.9508 MAE: 0.8179 RMSE: 0.9751\n",
      "Epoch 22: TrainLoss 0.9379 RecLoss: 0.0000 (left: 0:01:42)\n",
      "TestLoss: 1.1157 MAE: 0.8386 RMSE: 1.0563\n",
      "ValLoss: 0.9442 MAE: 0.8107 RMSE: 0.9717\n",
      "Epoch 23: TrainLoss 0.9369 RecLoss: 0.0000 (left: 0:01:41)\n",
      "TestLoss: 1.1148 MAE: 0.8392 RMSE: 1.0558\n",
      "ValLoss: 0.9462 MAE: 0.8136 RMSE: 0.9727\n",
      "Epoch 24: TrainLoss 0.9349 RecLoss: 0.0000 (left: 0:01:41)\n",
      "TestLoss: 1.1127 MAE: 0.8379 RMSE: 1.0549\n",
      "ValLoss: 0.9476 MAE: 0.8135 RMSE: 0.9734\n",
      "Epoch 25: TrainLoss 0.9337 RecLoss: 0.0000 (left: 0:01:40)\n",
      "TestLoss: 1.1155 MAE: 0.8394 RMSE: 1.0562\n",
      "ValLoss: 0.9434 MAE: 0.8125 RMSE: 0.9713\n",
      "Epoch 26: TrainLoss 0.9327 RecLoss: 0.0000 (left: 0:01:38)\n",
      "TestLoss: 1.1119 MAE: 0.8365 RMSE: 1.0545\n",
      "ValLoss: 0.9397 MAE: 0.8079 RMSE: 0.9694\n",
      "Epoch 27: TrainLoss 0.9295 RecLoss: 0.0000 (left: 0:01:36)\n",
      "TestLoss: 1.1145 MAE: 0.8396 RMSE: 1.0557\n",
      "ValLoss: 0.9466 MAE: 0.8148 RMSE: 0.9730\n",
      "Epoch 28: TrainLoss 0.9287 RecLoss: 0.0000 (left: 0:01:34)\n",
      "TestLoss: 1.1075 MAE: 0.8339 RMSE: 1.0524\n",
      "ValLoss: 0.9456 MAE: 0.8090 RMSE: 0.9724\n",
      "Epoch 29: TrainLoss 0.9271 RecLoss: 0.0000 (left: 0:01:32)\n",
      "TestLoss: 1.1124 MAE: 0.8381 RMSE: 1.0547\n",
      "ValLoss: 0.9460 MAE: 0.8136 RMSE: 0.9726\n",
      "Epoch 30: TrainLoss 0.9286 RecLoss: 0.0000 (left: 0:01:31)\n",
      "TestLoss: 1.1072 MAE: 0.8327 RMSE: 1.0522\n",
      "ValLoss: 0.9381 MAE: 0.8032 RMSE: 0.9685\n",
      "Epoch 31: TrainLoss 0.9311 RecLoss: 0.0000 (left: 0:01:30)\n",
      "TestLoss: 1.1116 MAE: 0.8384 RMSE: 1.0543\n",
      "ValLoss: 0.9514 MAE: 0.8164 RMSE: 0.9754\n",
      "Epoch 32: TrainLoss 0.9267 RecLoss: 0.0000 (left: 0:01:29)\n",
      "TestLoss: 1.1070 MAE: 0.8338 RMSE: 1.0521\n",
      "ValLoss: 0.9414 MAE: 0.8079 RMSE: 0.9702\n",
      "Epoch 33: TrainLoss 0.9235 RecLoss: 0.0000 (left: 0:01:28)\n",
      "TestLoss: 1.1064 MAE: 0.8324 RMSE: 1.0519\n",
      "ValLoss: 0.9382 MAE: 0.8039 RMSE: 0.9686\n",
      "Epoch 34: TrainLoss 0.9231 RecLoss: 0.0000 (left: 0:01:27)\n",
      "TestLoss: 1.1075 MAE: 0.8336 RMSE: 1.0524\n",
      "ValLoss: 0.9398 MAE: 0.8067 RMSE: 0.9694\n",
      "Epoch 35: TrainLoss 0.9224 RecLoss: 0.0000 (left: 0:01:26)\n",
      "TestLoss: 1.1047 MAE: 0.8314 RMSE: 1.0510\n",
      "ValLoss: 0.9404 MAE: 0.8048 RMSE: 0.9697\n",
      "Epoch 36: TrainLoss 0.9228 RecLoss: 0.0000 (left: 0:01:25)\n",
      "TestLoss: 1.1034 MAE: 0.8309 RMSE: 1.0504\n",
      "ValLoss: 0.9444 MAE: 0.8068 RMSE: 0.9718\n",
      "Epoch 37: TrainLoss 0.9217 RecLoss: 0.0000 (left: 0:01:23)\n",
      "TestLoss: 1.1072 MAE: 0.8338 RMSE: 1.0522\n",
      "ValLoss: 0.9427 MAE: 0.8084 RMSE: 0.9709\n",
      "Epoch 38: TrainLoss 0.9210 RecLoss: 0.0000 (left: 0:01:21)\n",
      "TestLoss: 1.1050 MAE: 0.8311 RMSE: 1.0512\n",
      "ValLoss: 0.9385 MAE: 0.8031 RMSE: 0.9688\n",
      "Epoch 39: TrainLoss 0.9206 RecLoss: 0.0000 (left: 0:01:19)\n",
      "TestLoss: 1.1059 MAE: 0.8320 RMSE: 1.0516\n",
      "ValLoss: 0.9393 MAE: 0.8047 RMSE: 0.9692\n",
      "Epoch 40: TrainLoss 0.9202 RecLoss: 0.0000 (left: 0:01:18)\n",
      "TestLoss: 1.1049 MAE: 0.8319 RMSE: 1.0511\n",
      "ValLoss: 0.9426 MAE: 0.8068 RMSE: 0.9709\n",
      "Epoch 41: TrainLoss 0.9196 RecLoss: 0.0000 (left: 0:01:17)\n",
      "TestLoss: 1.1041 MAE: 0.8306 RMSE: 1.0508\n",
      "ValLoss: 0.9391 MAE: 0.8037 RMSE: 0.9691\n",
      "Epoch 42: TrainLoss 0.9195 RecLoss: 0.0000 (left: 0:01:16)\n",
      "TestLoss: 1.1046 MAE: 0.8313 RMSE: 1.0510\n",
      "ValLoss: 0.9398 MAE: 0.8051 RMSE: 0.9694\n",
      "Epoch 43: TrainLoss 0.9187 RecLoss: 0.0000 (left: 0:01:15)\n",
      "TestLoss: 1.1023 MAE: 0.8292 RMSE: 1.0499\n",
      "ValLoss: 0.9393 MAE: 0.8026 RMSE: 0.9692\n",
      "Epoch 44: TrainLoss 0.9186 RecLoss: 0.0000 (left: 0:01:13)\n",
      "TestLoss: 1.1048 MAE: 0.8317 RMSE: 1.0511\n",
      "ValLoss: 0.9410 MAE: 0.8064 RMSE: 0.9701\n",
      "Epoch 45: TrainLoss 0.9184 RecLoss: 0.0000 (left: 0:01:12)\n",
      "TestLoss: 1.1035 MAE: 0.8302 RMSE: 1.0505\n",
      "ValLoss: 0.9397 MAE: 0.8039 RMSE: 0.9694\n",
      "Epoch 46: TrainLoss 0.9191 RecLoss: 0.0000 (left: 0:01:11)\n",
      "TestLoss: 1.1033 MAE: 0.8305 RMSE: 1.0504\n",
      "ValLoss: 0.9428 MAE: 0.8058 RMSE: 0.9710\n",
      "Epoch 47: TrainLoss 0.9188 RecLoss: 0.0000 (left: 0:01:10)\n",
      "TestLoss: 1.1017 MAE: 0.8290 RMSE: 1.0496\n",
      "ValLoss: 0.9411 MAE: 0.8036 RMSE: 0.9701\n",
      "Epoch 48: TrainLoss 0.9180 RecLoss: 0.0000 (left: 0:01:09)\n",
      "TestLoss: 1.1029 MAE: 0.8294 RMSE: 1.0502\n",
      "ValLoss: 0.9377 MAE: 0.8017 RMSE: 0.9683\n",
      "Epoch 49: TrainLoss 0.9173 RecLoss: 0.0000 (left: 0:01:07)\n",
      "TestLoss: 1.1049 MAE: 0.8312 RMSE: 1.0512\n",
      "ValLoss: 0.9399 MAE: 0.8051 RMSE: 0.9695\n",
      "Epoch 50: TrainLoss 0.9173 RecLoss: 0.0000 (left: 0:01:06)\n",
      "TestLoss: 1.1004 MAE: 0.8272 RMSE: 1.0490\n",
      "ValLoss: 0.9387 MAE: 0.7983 RMSE: 0.9688\n",
      "Epoch 51: TrainLoss 0.9192 RecLoss: 0.0000 (left: 0:01:04)\n",
      "TestLoss: 1.1070 MAE: 0.8335 RMSE: 1.0521\n",
      "ValLoss: 0.9479 MAE: 0.8110 RMSE: 0.9736\n",
      "Epoch 52: TrainLoss 0.9201 RecLoss: 0.0000 (left: 0:01:03)\n",
      "TestLoss: 1.1000 MAE: 0.8263 RMSE: 1.0488\n",
      "ValLoss: 0.9390 MAE: 0.7964 RMSE: 0.9690\n",
      "Epoch 53: TrainLoss 0.9201 RecLoss: 0.0000 (left: 0:01:02)\n",
      "TestLoss: 1.1076 MAE: 0.8328 RMSE: 1.0524\n",
      "ValLoss: 0.9424 MAE: 0.8079 RMSE: 0.9708\n",
      "Epoch 54: TrainLoss 0.9195 RecLoss: 0.0000 (left: 0:01:00)\n",
      "TestLoss: 1.0991 MAE: 0.8260 RMSE: 1.0484\n",
      "ValLoss: 0.9399 MAE: 0.7985 RMSE: 0.9695\n",
      "Epoch 55: TrainLoss 0.9181 RecLoss: 0.0000 (left: 0:00:59)\n",
      "TestLoss: 1.1006 MAE: 0.8281 RMSE: 1.0491\n",
      "ValLoss: 0.9432 MAE: 0.8044 RMSE: 0.9712\n",
      "Epoch 56: TrainLoss 0.9175 RecLoss: 0.0000 (left: 0:00:58)\n",
      "TestLoss: 1.1000 MAE: 0.8274 RMSE: 1.0488\n",
      "ValLoss: 0.9405 MAE: 0.8021 RMSE: 0.9698\n",
      "Epoch 57: TrainLoss 0.9165 RecLoss: 0.0000 (left: 0:00:57)\n",
      "TestLoss: 1.0993 MAE: 0.8267 RMSE: 1.0485\n",
      "ValLoss: 0.9379 MAE: 0.7994 RMSE: 0.9684\n",
      "Epoch 58: TrainLoss 0.9180 RecLoss: 0.0000 (left: 0:00:55)\n",
      "TestLoss: 1.0999 MAE: 0.8272 RMSE: 1.0487\n",
      "ValLoss: 0.9387 MAE: 0.8009 RMSE: 0.9688\n",
      "Epoch 59: TrainLoss 0.9179 RecLoss: 0.0000 (left: 0:00:54)\n",
      "TestLoss: 1.1014 MAE: 0.8280 RMSE: 1.0495\n",
      "ValLoss: 0.9392 MAE: 0.8024 RMSE: 0.9691\n",
      "Epoch 60: TrainLoss 0.9177 RecLoss: 0.0000 (left: 0:00:52)\n",
      "TestLoss: 1.1007 MAE: 0.8276 RMSE: 1.0492\n",
      "ValLoss: 0.9418 MAE: 0.8034 RMSE: 0.9705\n",
      "Epoch 61: TrainLoss 0.9185 RecLoss: 0.0000 (left: 0:00:51)\n",
      "TestLoss: 1.0989 MAE: 0.8263 RMSE: 1.0483\n",
      "ValLoss: 0.9448 MAE: 0.8033 RMSE: 0.9720\n",
      "Epoch 62: TrainLoss 0.9177 RecLoss: 0.0000 (left: 0:00:49)\n",
      "TestLoss: 1.1018 MAE: 0.8286 RMSE: 1.0496\n",
      "ValLoss: 0.9422 MAE: 0.8048 RMSE: 0.9707\n",
      "Epoch 63: TrainLoss 0.9165 RecLoss: 0.0000 (left: 0:00:48)\n",
      "TestLoss: 1.0998 MAE: 0.8258 RMSE: 1.0487\n",
      "ValLoss: 0.9348 MAE: 0.7964 RMSE: 0.9668\n",
      "Epoch 64: TrainLoss 0.9160 RecLoss: 0.0000 (left: 0:00:46)\n",
      "TestLoss: 1.1024 MAE: 0.8291 RMSE: 1.0499\n",
      "ValLoss: 0.9424 MAE: 0.8054 RMSE: 0.9708\n",
      "Epoch 65: TrainLoss 0.9165 RecLoss: 0.0000 (left: 0:00:45)\n",
      "TestLoss: 1.0990 MAE: 0.8261 RMSE: 1.0483\n",
      "ValLoss: 0.9418 MAE: 0.8015 RMSE: 0.9704\n",
      "Epoch 66: TrainLoss 0.9161 RecLoss: 0.0000 (left: 0:00:44)\n",
      "TestLoss: 1.1019 MAE: 0.8285 RMSE: 1.0497\n",
      "ValLoss: 0.9425 MAE: 0.8050 RMSE: 0.9708\n",
      "Epoch 67: TrainLoss 0.9158 RecLoss: 0.0000 (left: 0:00:42)\n",
      "TestLoss: 1.0983 MAE: 0.8254 RMSE: 1.0480\n",
      "ValLoss: 0.9406 MAE: 0.7995 RMSE: 0.9698\n",
      "Epoch 68: TrainLoss 0.9161 RecLoss: 0.0000 (left: 0:00:41)\n",
      "TestLoss: 1.1013 MAE: 0.8279 RMSE: 1.0494\n",
      "ValLoss: 0.9412 MAE: 0.8037 RMSE: 0.9702\n",
      "Epoch 69: TrainLoss 0.9160 RecLoss: 0.0000 (left: 0:00:40)\n",
      "TestLoss: 1.0992 MAE: 0.8264 RMSE: 1.0484\n",
      "ValLoss: 0.9396 MAE: 0.8006 RMSE: 0.9694\n",
      "Epoch 70: TrainLoss 0.9156 RecLoss: 0.0000 (left: 0:00:39)\n",
      "TestLoss: 1.1023 MAE: 0.8285 RMSE: 1.0499\n",
      "ValLoss: 0.9404 MAE: 0.8040 RMSE: 0.9697\n",
      "Epoch 71: TrainLoss 0.9161 RecLoss: 0.0000 (left: 0:00:37)\n",
      "TestLoss: 1.0985 MAE: 0.8259 RMSE: 1.0481\n",
      "ValLoss: 0.9401 MAE: 0.8002 RMSE: 0.9696\n",
      "Epoch 72: TrainLoss 0.9156 RecLoss: 0.0000 (left: 0:00:36)\n",
      "TestLoss: 1.1004 MAE: 0.8276 RMSE: 1.0490\n",
      "ValLoss: 0.9443 MAE: 0.8051 RMSE: 0.9717\n",
      "Epoch 73: TrainLoss 0.9166 RecLoss: 0.0000 (left: 0:00:35)\n",
      "TestLoss: 1.0984 MAE: 0.8253 RMSE: 1.0480\n",
      "ValLoss: 0.9398 MAE: 0.7987 RMSE: 0.9695\n",
      "Epoch 74: TrainLoss 0.9178 RecLoss: 0.0000 (left: 0:00:33)\n",
      "TestLoss: 1.1013 MAE: 0.8274 RMSE: 1.0494\n",
      "ValLoss: 0.9398 MAE: 0.8022 RMSE: 0.9694\n",
      "Epoch 75: TrainLoss 0.9156 RecLoss: 0.0000 (left: 0:00:32)\n",
      "TestLoss: 1.0998 MAE: 0.8264 RMSE: 1.0487\n",
      "ValLoss: 0.9378 MAE: 0.7997 RMSE: 0.9684\n",
      "Epoch 76: TrainLoss 0.9158 RecLoss: 0.0000 (left: 0:00:31)\n",
      "TestLoss: 1.1010 MAE: 0.8277 RMSE: 1.0493\n",
      "ValLoss: 0.9419 MAE: 0.8042 RMSE: 0.9705\n",
      "Epoch 77: TrainLoss 0.9155 RecLoss: 0.0000 (left: 0:00:29)\n",
      "TestLoss: 1.0985 MAE: 0.8259 RMSE: 1.0481\n",
      "ValLoss: 0.9428 MAE: 0.8022 RMSE: 0.9710\n",
      "Epoch 78: TrainLoss 0.9156 RecLoss: 0.0000 (left: 0:00:28)\n",
      "TestLoss: 1.0992 MAE: 0.8262 RMSE: 1.0484\n",
      "ValLoss: 0.9383 MAE: 0.7997 RMSE: 0.9686\n",
      "Epoch 79: TrainLoss 0.9155 RecLoss: 0.0000 (left: 0:00:27)\n",
      "TestLoss: 1.1017 MAE: 0.8283 RMSE: 1.0496\n",
      "ValLoss: 0.9416 MAE: 0.8043 RMSE: 0.9704\n",
      "Epoch 80: TrainLoss 0.9162 RecLoss: 0.0000 (left: 0:00:25)\n",
      "TestLoss: 1.0988 MAE: 0.8256 RMSE: 1.0482\n",
      "ValLoss: 0.9374 MAE: 0.7981 RMSE: 0.9682\n",
      "Epoch 81: TrainLoss 0.9170 RecLoss: 0.0000 (left: 0:00:24)\n",
      "TestLoss: 1.1014 MAE: 0.8275 RMSE: 1.0495\n",
      "ValLoss: 0.9386 MAE: 0.8016 RMSE: 0.9688\n",
      "Epoch 82: TrainLoss 0.9159 RecLoss: 0.0000 (left: 0:00:23)\n",
      "TestLoss: 1.0986 MAE: 0.8260 RMSE: 1.0481\n",
      "ValLoss: 0.9418 MAE: 0.8019 RMSE: 0.9705\n",
      "Epoch 83: TrainLoss 0.9169 RecLoss: 0.0000 (left: 0:00:21)\n",
      "TestLoss: 1.0973 MAE: 0.8249 RMSE: 1.0475\n",
      "ValLoss: 0.9437 MAE: 0.8013 RMSE: 0.9715\n",
      "Epoch 84: TrainLoss 0.9160 RecLoss: 0.0000 (left: 0:00:20)\n",
      "TestLoss: 1.1023 MAE: 0.8287 RMSE: 1.0499\n",
      "ValLoss: 0.9444 MAE: 0.8062 RMSE: 0.9718\n",
      "Epoch 85: TrainLoss 0.9151 RecLoss: 0.0000 (left: 0:00:19)\n",
      "TestLoss: 1.0990 MAE: 0.8246 RMSE: 1.0483\n",
      "ValLoss: 0.9353 MAE: 0.7947 RMSE: 0.9671\n",
      "Epoch 86: TrainLoss 0.9165 RecLoss: 0.0000 (left: 0:00:17)\n",
      "TestLoss: 1.1017 MAE: 0.8277 RMSE: 1.0496\n",
      "ValLoss: 0.9402 MAE: 0.8031 RMSE: 0.9696\n",
      "Epoch 87: TrainLoss 0.9152 RecLoss: 0.0000 (left: 0:00:16)\n",
      "TestLoss: 1.0978 MAE: 0.8248 RMSE: 1.0478\n",
      "ValLoss: 0.9402 MAE: 0.7987 RMSE: 0.9696\n",
      "Epoch 88: TrainLoss 0.9153 RecLoss: 0.0000 (left: 0:00:15)\n",
      "TestLoss: 1.1004 MAE: 0.8272 RMSE: 1.0490\n",
      "ValLoss: 0.9438 MAE: 0.8047 RMSE: 0.9715\n",
      "Epoch 89: TrainLoss 0.9152 RecLoss: 0.0000 (left: 0:00:13)\n",
      "TestLoss: 1.0989 MAE: 0.8261 RMSE: 1.0483\n",
      "ValLoss: 0.9419 MAE: 0.8022 RMSE: 0.9705\n",
      "Epoch 90: TrainLoss 0.9151 RecLoss: 0.0000 (left: 0:00:12)\n",
      "TestLoss: 1.0985 MAE: 0.8256 RMSE: 1.0481\n",
      "ValLoss: 0.9401 MAE: 0.8004 RMSE: 0.9696\n",
      "Epoch 91: TrainLoss 0.9158 RecLoss: 0.0000 (left: 0:00:11)\n",
      "TestLoss: 1.0999 MAE: 0.8264 RMSE: 1.0488\n",
      "ValLoss: 0.9385 MAE: 0.8002 RMSE: 0.9687\n",
      "Epoch 92: TrainLoss 0.9157 RecLoss: 0.0000 (left: 0:00:10)\n",
      "TestLoss: 1.0994 MAE: 0.8262 RMSE: 1.0485\n",
      "ValLoss: 0.9396 MAE: 0.8009 RMSE: 0.9693\n",
      "Epoch 93: TrainLoss 0.9154 RecLoss: 0.0000 (left: 0:00:08)\n",
      "TestLoss: 1.0998 MAE: 0.8268 RMSE: 1.0487\n",
      "ValLoss: 0.9424 MAE: 0.8035 RMSE: 0.9708\n",
      "Epoch 94: TrainLoss 0.9150 RecLoss: 0.0000 (left: 0:00:07)\n",
      "TestLoss: 1.0974 MAE: 0.8246 RMSE: 1.0476\n",
      "ValLoss: 0.9406 MAE: 0.7992 RMSE: 0.9698\n",
      "Epoch 95: TrainLoss 0.9148 RecLoss: 0.0000 (left: 0:00:06)\n",
      "TestLoss: 1.1013 MAE: 0.8276 RMSE: 1.0494\n",
      "ValLoss: 0.9423 MAE: 0.8044 RMSE: 0.9707\n",
      "Epoch 96: TrainLoss 0.9155 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 1.0980 MAE: 0.8253 RMSE: 1.0479\n",
      "ValLoss: 0.9411 MAE: 0.8006 RMSE: 0.9701\n",
      "Epoch 97: TrainLoss 0.9148 RecLoss: 0.0000 (left: 0:00:03)\n",
      "TestLoss: 1.0981 MAE: 0.8255 RMSE: 1.0479\n",
      "ValLoss: 0.9418 MAE: 0.8013 RMSE: 0.9704\n",
      "Epoch 98: TrainLoss 0.9162 RecLoss: 0.0000 (left: 0:00:02)\n",
      "TestLoss: 1.0993 MAE: 0.8261 RMSE: 1.0485\n",
      "ValLoss: 0.9383 MAE: 0.8001 RMSE: 0.9687\n",
      "Epoch 99: TrainLoss 0.9153 RecLoss: 0.0000 (left: 0:00:01)\n",
      "TestLoss: 1.0987 MAE: 0.8257 RMSE: 1.0482\n",
      "ValLoss: 0.9391 MAE: 0.7997 RMSE: 0.9691\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 71238/4938\n",
      "test set size: support/query 438/213\n",
      "USER HIS DICT: 943\n",
      "NUM IS: 943\n",
      "Key Test Result: MAE: 0.7451 RMSE: 0.9617 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 943\n",
      "NUM IS: 943\n",
      "Que Test Result: MAE: 0.8258 RMSE: 1.0487 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7715 RMSE: 0.9910 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 80% cur into IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 84997/4938\n",
      "test set size: support/query 584/213\n",
      "Epoch 0 Step 79: Train 6.6028 Reg: 0.4592\n",
      "Test: 1.1456 MAE: 0.8695 RMSE: 1.0703\n",
      "Val: 1.1703 MAE: 0.8688 RMSE: 1.0818\n",
      "Epoch 1 Step 158: Train 1.0108 Reg: 0.4572\n",
      "Test: 0.9544 MAE: 0.7821 RMSE: 0.9769\n",
      "Val: 0.9422 MAE: 0.7755 RMSE: 0.9707\n",
      "Epoch 2 Step 237: Train 0.8862 Reg: 0.4287\n",
      "Test: 0.9027 MAE: 0.7476 RMSE: 0.9501\n",
      "Val: 0.8970 MAE: 0.7449 RMSE: 0.9471\n",
      "Epoch 3 Step 316: Train 0.8556 Reg: 0.4094\n",
      "Test: 0.8874 MAE: 0.7436 RMSE: 0.9420\n",
      "Val: 0.8798 MAE: 0.7384 RMSE: 0.9380\n",
      "Epoch 4 Step 395: Train 0.8451 Reg: 0.3925\n",
      "Test: 0.8758 MAE: 0.7390 RMSE: 0.9359\n",
      "Val: 0.8752 MAE: 0.7361 RMSE: 0.9355\n",
      "Epoch 5 Step 474: Train 0.8399 Reg: 0.3775\n",
      "Test: 0.8745 MAE: 0.7379 RMSE: 0.9352\n",
      "Val: 0.8731 MAE: 0.7347 RMSE: 0.9344\n",
      "Epoch 6 Step 553: Train 0.8369 Reg: 0.3643\n",
      "Test: 0.8760 MAE: 0.7383 RMSE: 0.9360\n",
      "Val: 0.8677 MAE: 0.7334 RMSE: 0.9315\n",
      "Epoch 7 Step 632: Train 0.8344 Reg: 0.3521\n",
      "Test: 0.8750 MAE: 0.7367 RMSE: 0.9354\n",
      "Val: 0.8676 MAE: 0.7318 RMSE: 0.9314\n",
      "Epoch 8 Step 711: Train 0.8320 Reg: 0.3413\n",
      "Test: 0.8755 MAE: 0.7376 RMSE: 0.9357\n",
      "Val: 0.8655 MAE: 0.7333 RMSE: 0.9303\n",
      "Epoch 9 Step 790: Train 0.8301 Reg: 0.3317\n",
      "Test: 0.8719 MAE: 0.7350 RMSE: 0.9337\n",
      "Val: 0.8656 MAE: 0.7311 RMSE: 0.9304\n",
      "Epoch 10 Step 869: Train 0.8277 Reg: 0.3226\n",
      "Test: 0.8745 MAE: 0.7371 RMSE: 0.9352\n",
      "Val: 0.8643 MAE: 0.7326 RMSE: 0.9297\n",
      "Epoch 11 Step 948: Train 0.8259 Reg: 0.3143\n",
      "Test: 0.8698 MAE: 0.7321 RMSE: 0.9326\n",
      "Val: 0.8655 MAE: 0.7306 RMSE: 0.9303\n",
      "Epoch 12 Step 1027: Train 0.8241 Reg: 0.3066\n",
      "Test: 0.8684 MAE: 0.7333 RMSE: 0.9319\n",
      "Val: 0.8621 MAE: 0.7305 RMSE: 0.9285\n",
      "Epoch 13 Step 1106: Train 0.8220 Reg: 0.3002\n",
      "Test: 0.8710 MAE: 0.7353 RMSE: 0.9333\n",
      "Val: 0.8615 MAE: 0.7310 RMSE: 0.9282\n",
      "Epoch 14 Step 1185: Train 0.8199 Reg: 0.2938\n",
      "Test: 0.8711 MAE: 0.7326 RMSE: 0.9333\n",
      "Val: 0.8601 MAE: 0.7290 RMSE: 0.9274\n",
      "Epoch 15 Step 1264: Train 0.8179 Reg: 0.2886\n",
      "Test: 0.8710 MAE: 0.7342 RMSE: 0.9333\n",
      "Val: 0.8564 MAE: 0.7276 RMSE: 0.9254\n",
      "Epoch 16 Step 1343: Train 0.8156 Reg: 0.2837\n",
      "Test: 0.8718 MAE: 0.7330 RMSE: 0.9337\n",
      "Val: 0.8583 MAE: 0.7271 RMSE: 0.9264\n",
      "Epoch 17 Step 1422: Train 0.8129 Reg: 0.2798\n",
      "Test: 0.8660 MAE: 0.7323 RMSE: 0.9306\n",
      "Val: 0.8558 MAE: 0.7280 RMSE: 0.9251\n",
      "Epoch 18 Step 1501: Train 0.8103 Reg: 0.2755\n",
      "Test: 0.8691 MAE: 0.7310 RMSE: 0.9322\n",
      "Val: 0.8540 MAE: 0.7258 RMSE: 0.9241\n",
      "Epoch 19 Step 1580: Train 0.8072 Reg: 0.2724\n",
      "Test: 0.8667 MAE: 0.7316 RMSE: 0.9310\n",
      "Val: 0.8533 MAE: 0.7265 RMSE: 0.9238\n",
      "Epoch 20 Step 1659: Train 0.8039 Reg: 0.2695\n",
      "Test: 0.8655 MAE: 0.7302 RMSE: 0.9303\n",
      "Val: 0.8524 MAE: 0.7255 RMSE: 0.9233\n",
      "Epoch 21 Step 1738: Train 0.8001 Reg: 0.2678\n",
      "Test: 0.8616 MAE: 0.7300 RMSE: 0.9282\n",
      "Val: 0.8503 MAE: 0.7249 RMSE: 0.9221\n",
      "Epoch 22 Step 1817: Train 0.7960 Reg: 0.2660\n",
      "Test: 0.8628 MAE: 0.7286 RMSE: 0.9288\n",
      "Val: 0.8484 MAE: 0.7227 RMSE: 0.9211\n",
      "Epoch 23 Step 1896: Train 0.7915 Reg: 0.2647\n",
      "Test: 0.8577 MAE: 0.7251 RMSE: 0.9261\n",
      "Val: 0.8450 MAE: 0.7211 RMSE: 0.9193\n",
      "Epoch 24 Step 1975: Train 0.7871 Reg: 0.2636\n",
      "Test: 0.8556 MAE: 0.7262 RMSE: 0.9250\n",
      "Val: 0.8446 MAE: 0.7218 RMSE: 0.9190\n",
      "Epoch 25 Step 2054: Train 0.7817 Reg: 0.2633\n",
      "Test: 0.8528 MAE: 0.7249 RMSE: 0.9235\n",
      "Val: 0.8418 MAE: 0.7210 RMSE: 0.9175\n",
      "Epoch 26 Step 2133: Train 0.7766 Reg: 0.2629\n",
      "Test: 0.8509 MAE: 0.7230 RMSE: 0.9224\n",
      "Val: 0.8404 MAE: 0.7189 RMSE: 0.9167\n",
      "Epoch 27 Step 2212: Train 0.7712 Reg: 0.2631\n",
      "Test: 0.8496 MAE: 0.7220 RMSE: 0.9218\n",
      "Val: 0.8383 MAE: 0.7174 RMSE: 0.9156\n",
      "Epoch 28 Step 2291: Train 0.7657 Reg: 0.2630\n",
      "Test: 0.8455 MAE: 0.7210 RMSE: 0.9195\n",
      "Val: 0.8371 MAE: 0.7171 RMSE: 0.9149\n",
      "Epoch 29 Step 2370: Train 0.7600 Reg: 0.2635\n",
      "Test: 0.8438 MAE: 0.7202 RMSE: 0.9186\n",
      "Val: 0.8353 MAE: 0.7156 RMSE: 0.9139\n",
      "Epoch 30 Step 2449: Train 0.7544 Reg: 0.2638\n",
      "Test: 0.8423 MAE: 0.7193 RMSE: 0.9178\n",
      "Val: 0.8335 MAE: 0.7149 RMSE: 0.9129\n",
      "Epoch 31 Step 2528: Train 0.7489 Reg: 0.2643\n",
      "Test: 0.8395 MAE: 0.7170 RMSE: 0.9162\n",
      "Val: 0.8333 MAE: 0.7142 RMSE: 0.9128\n",
      "Epoch 32 Step 2607: Train 0.7435 Reg: 0.2648\n",
      "Test: 0.8404 MAE: 0.7177 RMSE: 0.9167\n",
      "Val: 0.8317 MAE: 0.7138 RMSE: 0.9120\n",
      "Epoch 33 Step 2686: Train 0.7381 Reg: 0.2653\n",
      "Test: 0.8392 MAE: 0.7161 RMSE: 0.9161\n",
      "Val: 0.8308 MAE: 0.7123 RMSE: 0.9115\n",
      "Epoch 34 Step 2765: Train 0.7332 Reg: 0.2660\n",
      "Test: 0.8362 MAE: 0.7158 RMSE: 0.9144\n",
      "Val: 0.8296 MAE: 0.7124 RMSE: 0.9108\n",
      "Epoch 35 Step 2844: Train 0.7280 Reg: 0.2666\n",
      "Test: 0.8393 MAE: 0.7176 RMSE: 0.9161\n",
      "Val: 0.8282 MAE: 0.7130 RMSE: 0.9101\n",
      "Epoch 36 Step 2923: Train 0.7231 Reg: 0.2671\n",
      "Test: 0.8370 MAE: 0.7153 RMSE: 0.9148\n",
      "Val: 0.8289 MAE: 0.7114 RMSE: 0.9104\n",
      "Epoch 37 Step 3002: Train 0.7185 Reg: 0.2677\n",
      "Test: 0.8394 MAE: 0.7170 RMSE: 0.9162\n",
      "Val: 0.8290 MAE: 0.7123 RMSE: 0.9105\n",
      "Epoch 38 Step 3081: Train 0.7140 Reg: 0.2685\n",
      "Test: 0.8377 MAE: 0.7165 RMSE: 0.9152\n",
      "Val: 0.8279 MAE: 0.7120 RMSE: 0.9099\n",
      "Epoch 39 Step 3160: Train 0.7097 Reg: 0.2691\n",
      "Test: 0.8372 MAE: 0.7151 RMSE: 0.9150\n",
      "Val: 0.8291 MAE: 0.7106 RMSE: 0.9106\n",
      "Epoch 40 Step 3239: Train 0.7056 Reg: 0.2697\n",
      "Test: 0.8385 MAE: 0.7166 RMSE: 0.9157\n",
      "Val: 0.8286 MAE: 0.7114 RMSE: 0.9103\n",
      "Epoch 41 Step 3318: Train 0.7014 Reg: 0.2704\n",
      "Test: 0.8376 MAE: 0.7163 RMSE: 0.9152\n",
      "Val: 0.8288 MAE: 0.7121 RMSE: 0.9104\n",
      "Epoch 42 Step 3397: Train 0.6973 Reg: 0.2711\n",
      "Test: 0.8395 MAE: 0.7174 RMSE: 0.9163\n",
      "Val: 0.8288 MAE: 0.7125 RMSE: 0.9104\n",
      "Epoch 43 Step 3476: Train 0.6934 Reg: 0.2718\n",
      "Test: 0.8399 MAE: 0.7169 RMSE: 0.9165\n",
      "Val: 0.8292 MAE: 0.7123 RMSE: 0.9106\n",
      "Epoch 44 Step 3555: Train 0.6896 Reg: 0.2725\n",
      "Test: 0.8400 MAE: 0.7158 RMSE: 0.9165\n",
      "Val: 0.8302 MAE: 0.7119 RMSE: 0.9111\n",
      "Epoch 45 Step 3634: Train 0.6858 Reg: 0.2732\n",
      "Test: 0.8402 MAE: 0.7171 RMSE: 0.9166\n",
      "Val: 0.8298 MAE: 0.7129 RMSE: 0.9109\n",
      "Epoch 46 Step 3713: Train 0.6822 Reg: 0.2739\n",
      "Test: 0.8427 MAE: 0.7176 RMSE: 0.9180\n",
      "Val: 0.8302 MAE: 0.7124 RMSE: 0.9112\n",
      "Epoch 47 Step 3792: Train 0.6786 Reg: 0.2746\n",
      "Test: 0.8424 MAE: 0.7173 RMSE: 0.9178\n",
      "Val: 0.8311 MAE: 0.7131 RMSE: 0.9117\n",
      "Epoch 48 Step 3871: Train 0.6750 Reg: 0.2752\n",
      "Test: 0.8435 MAE: 0.7180 RMSE: 0.9184\n",
      "Val: 0.8314 MAE: 0.7140 RMSE: 0.9118\n",
      "Epoch 49 Step 3950: Train 0.6717 Reg: 0.2759\n",
      "Test: 0.8444 MAE: 0.7176 RMSE: 0.9189\n",
      "Val: 0.8323 MAE: 0.7132 RMSE: 0.9123\n",
      "Epoch 50 Step 4029: Train 0.6684 Reg: 0.2766\n",
      "Test: 0.8447 MAE: 0.7174 RMSE: 0.9191\n",
      "Val: 0.8329 MAE: 0.7132 RMSE: 0.9126\n",
      "Epoch 51 Step 4108: Train 0.6652 Reg: 0.2773\n",
      "Test: 0.8461 MAE: 0.7182 RMSE: 0.9199\n",
      "Val: 0.8332 MAE: 0.7139 RMSE: 0.9128\n",
      "Epoch 52 Step 4187: Train 0.6621 Reg: 0.2779\n",
      "Test: 0.8466 MAE: 0.7185 RMSE: 0.9201\n",
      "Val: 0.8335 MAE: 0.7138 RMSE: 0.9130\n",
      "Epoch 53 Step 4266: Train 0.6590 Reg: 0.2785\n",
      "Test: 0.8470 MAE: 0.7184 RMSE: 0.9203\n",
      "Val: 0.8346 MAE: 0.7143 RMSE: 0.9136\n",
      "Epoch 54 Step 4345: Train 0.6563 Reg: 0.2791\n",
      "Test: 0.8490 MAE: 0.7195 RMSE: 0.9214\n",
      "Val: 0.8351 MAE: 0.7149 RMSE: 0.9138\n",
      "Epoch 55 Step 4424: Train 0.6532 Reg: 0.2797\n",
      "Test: 0.8496 MAE: 0.7198 RMSE: 0.9218\n",
      "Val: 0.8356 MAE: 0.7156 RMSE: 0.9141\n",
      "Epoch 56 Step 4503: Train 0.6505 Reg: 0.2803\n",
      "Test: 0.8497 MAE: 0.7196 RMSE: 0.9218\n",
      "Val: 0.8362 MAE: 0.7157 RMSE: 0.9144\n",
      "Epoch 57 Step 4582: Train 0.6478 Reg: 0.2809\n",
      "Test: 0.8501 MAE: 0.7196 RMSE: 0.9220\n",
      "Val: 0.8365 MAE: 0.7158 RMSE: 0.9146\n",
      "Epoch 58 Step 4661: Train 0.6452 Reg: 0.2814\n",
      "Test: 0.8513 MAE: 0.7197 RMSE: 0.9227\n",
      "Val: 0.8375 MAE: 0.7157 RMSE: 0.9152\n",
      "Epoch 59 Step 4740: Train 0.6427 Reg: 0.2819\n",
      "Test: 0.8523 MAE: 0.7204 RMSE: 0.9232\n",
      "Val: 0.8379 MAE: 0.7159 RMSE: 0.9154\n",
      "Epoch 60 Step 4819: Train 0.6403 Reg: 0.2824\n",
      "Test: 0.8531 MAE: 0.7203 RMSE: 0.9236\n",
      "Val: 0.8385 MAE: 0.7161 RMSE: 0.9157\n",
      "Epoch 61 Step 4898: Train 0.6380 Reg: 0.2829\n",
      "Test: 0.8539 MAE: 0.7209 RMSE: 0.9240\n",
      "Val: 0.8392 MAE: 0.7168 RMSE: 0.9161\n",
      "Epoch 62 Step 4977: Train 0.6358 Reg: 0.2834\n",
      "Test: 0.8548 MAE: 0.7209 RMSE: 0.9245\n",
      "Val: 0.8398 MAE: 0.7164 RMSE: 0.9164\n",
      "Epoch 63 Step 5056: Train 0.6336 Reg: 0.2838\n",
      "Test: 0.8552 MAE: 0.7206 RMSE: 0.9248\n",
      "Val: 0.8405 MAE: 0.7165 RMSE: 0.9168\n",
      "Epoch 64 Step 5135: Train 0.6316 Reg: 0.2843\n",
      "Test: 0.8557 MAE: 0.7210 RMSE: 0.9251\n",
      "Val: 0.8409 MAE: 0.7169 RMSE: 0.9170\n",
      "Epoch 65 Step 5214: Train 0.6296 Reg: 0.2847\n",
      "Test: 0.8568 MAE: 0.7217 RMSE: 0.9256\n",
      "Val: 0.8413 MAE: 0.7173 RMSE: 0.9172\n",
      "Epoch 66 Step 5293: Train 0.6277 Reg: 0.2851\n",
      "Test: 0.8568 MAE: 0.7214 RMSE: 0.9257\n",
      "Val: 0.8421 MAE: 0.7173 RMSE: 0.9176\n",
      "Epoch 67 Step 5372: Train 0.6259 Reg: 0.2854\n",
      "Test: 0.8581 MAE: 0.7220 RMSE: 0.9264\n",
      "Val: 0.8425 MAE: 0.7176 RMSE: 0.9179\n",
      "Epoch 68 Step 5451: Train 0.6241 Reg: 0.2858\n",
      "Test: 0.8582 MAE: 0.7220 RMSE: 0.9264\n",
      "Val: 0.8430 MAE: 0.7178 RMSE: 0.9182\n",
      "Epoch 69 Step 5530: Train 0.6224 Reg: 0.2861\n",
      "Test: 0.8594 MAE: 0.7226 RMSE: 0.9270\n",
      "Val: 0.8435 MAE: 0.7182 RMSE: 0.9184\n",
      "Epoch 70 Step 5609: Train 0.6208 Reg: 0.2864\n",
      "Test: 0.8600 MAE: 0.7227 RMSE: 0.9273\n",
      "Val: 0.8439 MAE: 0.7183 RMSE: 0.9187\n",
      "Epoch 71 Step 5688: Train 0.6194 Reg: 0.2868\n",
      "Test: 0.8601 MAE: 0.7224 RMSE: 0.9274\n",
      "Val: 0.8447 MAE: 0.7181 RMSE: 0.9191\n",
      "Epoch 72 Step 5767: Train 0.6178 Reg: 0.2871\n",
      "Test: 0.8612 MAE: 0.7236 RMSE: 0.9280\n",
      "Val: 0.8449 MAE: 0.7191 RMSE: 0.9192\n",
      "Epoch 73 Step 5846: Train 0.6165 Reg: 0.2873\n",
      "Test: 0.8612 MAE: 0.7232 RMSE: 0.9280\n",
      "Val: 0.8454 MAE: 0.7189 RMSE: 0.9195\n",
      "Epoch 74 Step 5925: Train 0.6151 Reg: 0.2876\n",
      "Test: 0.8613 MAE: 0.7225 RMSE: 0.9281\n",
      "Val: 0.8461 MAE: 0.7184 RMSE: 0.9198\n",
      "Epoch 75 Step 6004: Train 0.6139 Reg: 0.2879\n",
      "Test: 0.8621 MAE: 0.7231 RMSE: 0.9285\n",
      "Val: 0.8464 MAE: 0.7189 RMSE: 0.9200\n",
      "Epoch 76 Step 6083: Train 0.6127 Reg: 0.2881\n",
      "Test: 0.8626 MAE: 0.7235 RMSE: 0.9287\n",
      "Val: 0.8467 MAE: 0.7192 RMSE: 0.9202\n",
      "Epoch 77 Step 6162: Train 0.6115 Reg: 0.2883\n",
      "Test: 0.8630 MAE: 0.7237 RMSE: 0.9290\n",
      "Val: 0.8471 MAE: 0.7194 RMSE: 0.9204\n",
      "Epoch 78 Step 6241: Train 0.6104 Reg: 0.2885\n",
      "Test: 0.8632 MAE: 0.7234 RMSE: 0.9291\n",
      "Val: 0.8477 MAE: 0.7192 RMSE: 0.9207\n",
      "Epoch 79 Step 6320: Train 0.6094 Reg: 0.2888\n",
      "Test: 0.8636 MAE: 0.7236 RMSE: 0.9293\n",
      "Val: 0.8479 MAE: 0.7194 RMSE: 0.9208\n",
      "Epoch 80 Step 6399: Train 0.6084 Reg: 0.2889\n",
      "Test: 0.8637 MAE: 0.7234 RMSE: 0.9294\n",
      "Val: 0.8483 MAE: 0.7193 RMSE: 0.9211\n",
      "Epoch 81 Step 6478: Train 0.6074 Reg: 0.2891\n",
      "Test: 0.8641 MAE: 0.7237 RMSE: 0.9296\n",
      "Val: 0.8487 MAE: 0.7196 RMSE: 0.9213\n",
      "Epoch 82 Step 6557: Train 0.6065 Reg: 0.2893\n",
      "Test: 0.8645 MAE: 0.7239 RMSE: 0.9298\n",
      "Val: 0.8490 MAE: 0.7198 RMSE: 0.9214\n",
      "Epoch 83 Step 6636: Train 0.6056 Reg: 0.2895\n",
      "Test: 0.8650 MAE: 0.7242 RMSE: 0.9300\n",
      "Val: 0.8492 MAE: 0.7200 RMSE: 0.9215\n",
      "Epoch 84 Step 6715: Train 0.6048 Reg: 0.2896\n",
      "Test: 0.8652 MAE: 0.7241 RMSE: 0.9302\n",
      "Val: 0.8496 MAE: 0.7200 RMSE: 0.9218\n",
      "Epoch 85 Step 6794: Train 0.6041 Reg: 0.2898\n",
      "Test: 0.8656 MAE: 0.7244 RMSE: 0.9304\n",
      "Val: 0.8499 MAE: 0.7203 RMSE: 0.9219\n",
      "Epoch 86 Step 6873: Train 0.6033 Reg: 0.2899\n",
      "Test: 0.8656 MAE: 0.7242 RMSE: 0.9304\n",
      "Val: 0.8501 MAE: 0.7202 RMSE: 0.9220\n",
      "Epoch 87 Step 6952: Train 0.6026 Reg: 0.2901\n",
      "Test: 0.8662 MAE: 0.7247 RMSE: 0.9307\n",
      "Val: 0.8504 MAE: 0.7206 RMSE: 0.9222\n",
      "Epoch 88 Step 7031: Train 0.6019 Reg: 0.2902\n",
      "Test: 0.8662 MAE: 0.7244 RMSE: 0.9307\n",
      "Val: 0.8507 MAE: 0.7203 RMSE: 0.9224\n",
      "Epoch 89 Step 7110: Train 0.6013 Reg: 0.2903\n",
      "Test: 0.8667 MAE: 0.7246 RMSE: 0.9309\n",
      "Val: 0.8510 MAE: 0.7205 RMSE: 0.9225\n",
      "Epoch 90 Step 7189: Train 0.6007 Reg: 0.2904\n",
      "Test: 0.8669 MAE: 0.7247 RMSE: 0.9311\n",
      "Val: 0.8512 MAE: 0.7206 RMSE: 0.9226\n",
      "Epoch 91 Step 7268: Train 0.6001 Reg: 0.2906\n",
      "Test: 0.8671 MAE: 0.7249 RMSE: 0.9312\n",
      "Val: 0.8514 MAE: 0.7208 RMSE: 0.9227\n",
      "Epoch 92 Step 7347: Train 0.5995 Reg: 0.2907\n",
      "Test: 0.8673 MAE: 0.7249 RMSE: 0.9313\n",
      "Val: 0.8516 MAE: 0.7208 RMSE: 0.9228\n",
      "Epoch 93 Step 7426: Train 0.5990 Reg: 0.2908\n",
      "Test: 0.8675 MAE: 0.7249 RMSE: 0.9314\n",
      "Val: 0.8519 MAE: 0.7207 RMSE: 0.9230\n",
      "Epoch 94 Step 7505: Train 0.5985 Reg: 0.2909\n",
      "Test: 0.8677 MAE: 0.7250 RMSE: 0.9315\n",
      "Val: 0.8521 MAE: 0.7209 RMSE: 0.9231\n",
      "Epoch 95 Step 7584: Train 0.5980 Reg: 0.2909\n",
      "Test: 0.8678 MAE: 0.7251 RMSE: 0.9316\n",
      "Val: 0.8523 MAE: 0.7210 RMSE: 0.9232\n",
      "Epoch 96 Step 7663: Train 0.5976 Reg: 0.2910\n",
      "Test: 0.8680 MAE: 0.7251 RMSE: 0.9317\n",
      "Val: 0.8524 MAE: 0.7210 RMSE: 0.9233\n",
      "Epoch 97 Step 7742: Train 0.5972 Reg: 0.2911\n",
      "Test: 0.8681 MAE: 0.7252 RMSE: 0.9317\n",
      "Val: 0.8526 MAE: 0.7211 RMSE: 0.9234\n",
      "Epoch 98 Step 7821: Train 0.5968 Reg: 0.2912\n",
      "Test: 0.8684 MAE: 0.7252 RMSE: 0.9319\n",
      "Val: 0.8528 MAE: 0.7212 RMSE: 0.9235\n",
      "Epoch 99 Step 7900: Train 0.5964 Reg: 0.2913\n",
      "Test: 0.8684 MAE: 0.7252 RMSE: 0.9319\n",
      "Val: 0.8530 MAE: 0.7211 RMSE: 0.9236\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 84997/4938\n",
      "test set size: support/query 584/213\n",
      "Epoch 0: TrainLoss 1.6848 RecLoss: 0.0000 (left: 0:03:48)\n",
      "TestLoss: 1.8112 MAE: 1.1545 RMSE: 1.3458\n",
      "ValLoss: 1.5788 MAE: 1.0761 RMSE: 1.2565\n",
      "Epoch 1: TrainLoss 1.2859 RecLoss: 0.0000 (left: 0:03:30)\n",
      "TestLoss: 1.4261 MAE: 0.9298 RMSE: 1.1942\n",
      "ValLoss: 1.1453 MAE: 0.8459 RMSE: 1.0702\n",
      "Epoch 2: TrainLoss 1.1925 RecLoss: 0.0000 (left: 0:03:19)\n",
      "TestLoss: 1.4229 MAE: 1.0024 RMSE: 1.1929\n",
      "ValLoss: 1.1983 MAE: 0.9381 RMSE: 1.0947\n",
      "Epoch 3: TrainLoss 1.1393 RecLoss: 0.0000 (left: 0:02:57)\n",
      "TestLoss: 1.2702 MAE: 0.9004 RMSE: 1.1270\n",
      "ValLoss: 1.0919 MAE: 0.8484 RMSE: 1.0449\n",
      "Epoch 4: TrainLoss 1.1098 RecLoss: 0.0000 (left: 0:02:56)\n",
      "TestLoss: 1.2361 MAE: 0.9133 RMSE: 1.1118\n",
      "ValLoss: 1.0470 MAE: 0.8663 RMSE: 1.0232\n",
      "Epoch 5: TrainLoss 1.0668 RecLoss: 0.0000 (left: 0:02:52)\n",
      "TestLoss: 1.2268 MAE: 0.9071 RMSE: 1.1076\n",
      "ValLoss: 1.0224 MAE: 0.8553 RMSE: 1.0111\n",
      "Epoch 6: TrainLoss 1.0441 RecLoss: 0.0000 (left: 0:02:41)\n",
      "TestLoss: 1.2003 MAE: 0.8825 RMSE: 1.0956\n",
      "ValLoss: 0.9901 MAE: 0.8240 RMSE: 0.9951\n",
      "Epoch 7: TrainLoss 1.0308 RecLoss: 0.0000 (left: 0:02:36)\n",
      "TestLoss: 1.1921 MAE: 0.8864 RMSE: 1.0918\n",
      "ValLoss: 0.9905 MAE: 0.8368 RMSE: 0.9952\n",
      "Epoch 8: TrainLoss 1.0181 RecLoss: 0.0000 (left: 0:02:31)\n",
      "TestLoss: 1.1798 MAE: 0.8814 RMSE: 1.0862\n",
      "ValLoss: 0.9882 MAE: 0.8367 RMSE: 0.9941\n",
      "Epoch 9: TrainLoss 1.0053 RecLoss: 0.0000 (left: 0:02:26)\n",
      "TestLoss: 1.1644 MAE: 0.8705 RMSE: 1.0791\n",
      "ValLoss: 0.9801 MAE: 0.8274 RMSE: 0.9900\n",
      "Epoch 10: TrainLoss 0.9981 RecLoss: 0.0000 (left: 0:02:24)\n",
      "TestLoss: 1.1609 MAE: 0.8724 RMSE: 1.0774\n",
      "ValLoss: 0.9800 MAE: 0.8327 RMSE: 0.9900\n",
      "Epoch 11: TrainLoss 0.9895 RecLoss: 0.0000 (left: 0:02:24)\n",
      "TestLoss: 1.1497 MAE: 0.8642 RMSE: 1.0722\n",
      "ValLoss: 0.9696 MAE: 0.8243 RMSE: 0.9847\n",
      "Epoch 12: TrainLoss 0.9817 RecLoss: 0.0000 (left: 0:02:21)\n",
      "TestLoss: 1.1458 MAE: 0.8634 RMSE: 1.0704\n",
      "ValLoss: 0.9678 MAE: 0.8252 RMSE: 0.9838\n",
      "Epoch 13: TrainLoss 0.9751 RecLoss: 0.0000 (left: 0:02:17)\n",
      "TestLoss: 1.1376 MAE: 0.8573 RMSE: 1.0666\n",
      "ValLoss: 0.9607 MAE: 0.8202 RMSE: 0.9802\n",
      "Epoch 14: TrainLoss 0.9688 RecLoss: 0.0000 (left: 0:02:15)\n",
      "TestLoss: 1.1354 MAE: 0.8572 RMSE: 1.0656\n",
      "ValLoss: 0.9611 MAE: 0.8220 RMSE: 0.9804\n",
      "Epoch 15: TrainLoss 0.9639 RecLoss: 0.0000 (left: 0:02:11)\n",
      "TestLoss: 1.1289 MAE: 0.8526 RMSE: 1.0625\n",
      "ValLoss: 0.9557 MAE: 0.8183 RMSE: 0.9776\n",
      "Epoch 16: TrainLoss 0.9593 RecLoss: 0.0000 (left: 0:02:09)\n",
      "TestLoss: 1.1241 MAE: 0.8502 RMSE: 1.0602\n",
      "ValLoss: 0.9578 MAE: 0.8192 RMSE: 0.9787\n",
      "Epoch 17: TrainLoss 0.9553 RecLoss: 0.0000 (left: 0:02:06)\n",
      "TestLoss: 1.1196 MAE: 0.8475 RMSE: 1.0581\n",
      "ValLoss: 0.9562 MAE: 0.8179 RMSE: 0.9778\n",
      "Epoch 18: TrainLoss 0.9522 RecLoss: 0.0000 (left: 0:02:05)\n",
      "TestLoss: 1.1173 MAE: 0.8465 RMSE: 1.0570\n",
      "ValLoss: 0.9575 MAE: 0.8187 RMSE: 0.9785\n",
      "Epoch 19: TrainLoss 0.9493 RecLoss: 0.0000 (left: 0:02:05)\n",
      "TestLoss: 1.1144 MAE: 0.8443 RMSE: 1.0556\n",
      "ValLoss: 0.9530 MAE: 0.8160 RMSE: 0.9762\n",
      "Epoch 20: TrainLoss 0.9464 RecLoss: 0.0000 (left: 0:02:04)\n",
      "TestLoss: 1.1115 MAE: 0.8421 RMSE: 1.0543\n",
      "ValLoss: 0.9504 MAE: 0.8140 RMSE: 0.9749\n",
      "Epoch 21: TrainLoss 0.9432 RecLoss: 0.0000 (left: 0:02:02)\n",
      "TestLoss: 1.1121 MAE: 0.8440 RMSE: 1.0545\n",
      "ValLoss: 0.9548 MAE: 0.8182 RMSE: 0.9771\n",
      "Epoch 22: TrainLoss 0.9408 RecLoss: 0.0000 (left: 0:01:59)\n",
      "TestLoss: 1.1062 MAE: 0.8384 RMSE: 1.0518\n",
      "ValLoss: 0.9477 MAE: 0.8113 RMSE: 0.9735\n",
      "Epoch 23: TrainLoss 0.9397 RecLoss: 0.0000 (left: 0:01:56)\n",
      "TestLoss: 1.1039 MAE: 0.8382 RMSE: 1.0507\n",
      "ValLoss: 0.9519 MAE: 0.8141 RMSE: 0.9756\n",
      "Epoch 24: TrainLoss 0.9374 RecLoss: 0.0000 (left: 0:01:56)\n",
      "TestLoss: 1.1018 MAE: 0.8366 RMSE: 1.0497\n",
      "ValLoss: 0.9523 MAE: 0.8134 RMSE: 0.9759\n",
      "Epoch 25: TrainLoss 0.9363 RecLoss: 0.0000 (left: 0:01:54)\n",
      "TestLoss: 1.1037 MAE: 0.8384 RMSE: 1.0506\n",
      "ValLoss: 0.9503 MAE: 0.8148 RMSE: 0.9748\n",
      "Epoch 26: TrainLoss 0.9352 RecLoss: 0.0000 (left: 0:01:52)\n",
      "TestLoss: 1.1000 MAE: 0.8346 RMSE: 1.0488\n",
      "ValLoss: 0.9451 MAE: 0.8096 RMSE: 0.9721\n",
      "Epoch 27: TrainLoss 0.9325 RecLoss: 0.0000 (left: 0:01:50)\n",
      "TestLoss: 1.1019 MAE: 0.8381 RMSE: 1.0497\n",
      "ValLoss: 0.9515 MAE: 0.8158 RMSE: 0.9754\n",
      "Epoch 28: TrainLoss 0.9314 RecLoss: 0.0000 (left: 0:01:49)\n",
      "TestLoss: 1.0951 MAE: 0.8319 RMSE: 1.0465\n",
      "ValLoss: 0.9507 MAE: 0.8102 RMSE: 0.9750\n",
      "Epoch 29: TrainLoss 0.9304 RecLoss: 0.0000 (left: 0:01:48)\n",
      "TestLoss: 1.0977 MAE: 0.8359 RMSE: 1.0477\n",
      "ValLoss: 0.9535 MAE: 0.8150 RMSE: 0.9765\n",
      "Epoch 30: TrainLoss 0.9321 RecLoss: 0.0000 (left: 0:01:47)\n",
      "TestLoss: 1.0944 MAE: 0.8313 RMSE: 1.0461\n",
      "ValLoss: 0.9465 MAE: 0.8069 RMSE: 0.9729\n",
      "Epoch 31: TrainLoss 0.9333 RecLoss: 0.0000 (left: 0:01:45)\n",
      "TestLoss: 1.0956 MAE: 0.8349 RMSE: 1.0467\n",
      "ValLoss: 0.9566 MAE: 0.8159 RMSE: 0.9781\n",
      "Epoch 32: TrainLoss 0.9285 RecLoss: 0.0000 (left: 0:01:43)\n",
      "TestLoss: 1.0945 MAE: 0.8328 RMSE: 1.0462\n",
      "ValLoss: 0.9504 MAE: 0.8123 RMSE: 0.9749\n",
      "Epoch 33: TrainLoss 0.9265 RecLoss: 0.0000 (left: 0:01:41)\n",
      "TestLoss: 1.0921 MAE: 0.8284 RMSE: 1.0450\n",
      "ValLoss: 0.9454 MAE: 0.8058 RMSE: 0.9723\n",
      "Epoch 34: TrainLoss 0.9264 RecLoss: 0.0000 (left: 0:01:39)\n",
      "TestLoss: 1.0933 MAE: 0.8316 RMSE: 1.0456\n",
      "ValLoss: 0.9487 MAE: 0.8103 RMSE: 0.9740\n",
      "Epoch 35: TrainLoss 0.9259 RecLoss: 0.0000 (left: 0:01:38)\n",
      "TestLoss: 1.0903 MAE: 0.8283 RMSE: 1.0442\n",
      "ValLoss: 0.9482 MAE: 0.8071 RMSE: 0.9737\n",
      "Epoch 36: TrainLoss 0.9254 RecLoss: 0.0000 (left: 0:01:37)\n",
      "TestLoss: 1.0889 MAE: 0.8275 RMSE: 1.0435\n",
      "ValLoss: 0.9514 MAE: 0.8081 RMSE: 0.9754\n",
      "Epoch 37: TrainLoss 0.9246 RecLoss: 0.0000 (left: 0:01:35)\n",
      "TestLoss: 1.0922 MAE: 0.8318 RMSE: 1.0451\n",
      "ValLoss: 0.9533 MAE: 0.8127 RMSE: 0.9764\n",
      "Epoch 38: TrainLoss 0.9240 RecLoss: 0.0000 (left: 0:01:33)\n",
      "TestLoss: 1.0890 MAE: 0.8271 RMSE: 1.0435\n",
      "ValLoss: 0.9494 MAE: 0.8074 RMSE: 0.9744\n",
      "Epoch 39: TrainLoss 0.9237 RecLoss: 0.0000 (left: 0:01:31)\n",
      "TestLoss: 1.0898 MAE: 0.8287 RMSE: 1.0439\n",
      "ValLoss: 0.9506 MAE: 0.8095 RMSE: 0.9750\n",
      "Epoch 40: TrainLoss 0.9233 RecLoss: 0.0000 (left: 0:01:30)\n",
      "TestLoss: 1.0892 MAE: 0.8287 RMSE: 1.0437\n",
      "ValLoss: 0.9522 MAE: 0.8102 RMSE: 0.9758\n",
      "Epoch 41: TrainLoss 0.9227 RecLoss: 0.0000 (left: 0:01:28)\n",
      "TestLoss: 1.0878 MAE: 0.8270 RMSE: 1.0430\n",
      "ValLoss: 0.9492 MAE: 0.8069 RMSE: 0.9743\n",
      "Epoch 42: TrainLoss 0.9227 RecLoss: 0.0000 (left: 0:01:27)\n",
      "TestLoss: 1.0889 MAE: 0.8286 RMSE: 1.0435\n",
      "ValLoss: 0.9505 MAE: 0.8092 RMSE: 0.9749\n",
      "Epoch 43: TrainLoss 0.9220 RecLoss: 0.0000 (left: 0:01:26)\n",
      "TestLoss: 1.0862 MAE: 0.8250 RMSE: 1.0422\n",
      "ValLoss: 0.9502 MAE: 0.8061 RMSE: 0.9748\n",
      "Epoch 44: TrainLoss 0.9220 RecLoss: 0.0000 (left: 0:01:24)\n",
      "TestLoss: 1.0880 MAE: 0.8290 RMSE: 1.0431\n",
      "ValLoss: 0.9541 MAE: 0.8105 RMSE: 0.9768\n",
      "Epoch 45: TrainLoss 0.9217 RecLoss: 0.0000 (left: 0:01:23)\n",
      "TestLoss: 1.0869 MAE: 0.8273 RMSE: 1.0425\n",
      "ValLoss: 0.9524 MAE: 0.8082 RMSE: 0.9759\n",
      "Epoch 46: TrainLoss 0.9220 RecLoss: 0.0000 (left: 0:01:21)\n",
      "TestLoss: 1.0862 MAE: 0.8265 RMSE: 1.0422\n",
      "ValLoss: 0.9540 MAE: 0.8087 RMSE: 0.9767\n",
      "Epoch 47: TrainLoss 0.9218 RecLoss: 0.0000 (left: 0:01:19)\n",
      "TestLoss: 1.0857 MAE: 0.8260 RMSE: 1.0420\n",
      "ValLoss: 0.9532 MAE: 0.8081 RMSE: 0.9763\n",
      "Epoch 48: TrainLoss 0.9213 RecLoss: 0.0000 (left: 0:01:18)\n",
      "TestLoss: 1.0858 MAE: 0.8248 RMSE: 1.0420\n",
      "ValLoss: 0.9502 MAE: 0.8054 RMSE: 0.9748\n",
      "Epoch 49: TrainLoss 0.9201 RecLoss: 0.0000 (left: 0:01:16)\n",
      "TestLoss: 1.0886 MAE: 0.8289 RMSE: 1.0434\n",
      "ValLoss: 0.9533 MAE: 0.8100 RMSE: 0.9764\n",
      "Epoch 50: TrainLoss 0.9207 RecLoss: 0.0000 (left: 0:01:15)\n",
      "TestLoss: 1.0835 MAE: 0.8219 RMSE: 1.0409\n",
      "ValLoss: 0.9509 MAE: 0.8020 RMSE: 0.9752\n",
      "Epoch 51: TrainLoss 0.9222 RecLoss: 0.0000 (left: 0:01:13)\n",
      "TestLoss: 1.0894 MAE: 0.8311 RMSE: 1.0437\n",
      "ValLoss: 0.9604 MAE: 0.8138 RMSE: 0.9800\n",
      "Epoch 52: TrainLoss 0.9230 RecLoss: 0.0000 (left: 0:01:11)\n",
      "TestLoss: 1.0828 MAE: 0.8207 RMSE: 1.0406\n",
      "ValLoss: 0.9514 MAE: 0.8010 RMSE: 0.9754\n",
      "Epoch 53: TrainLoss 0.9228 RecLoss: 0.0000 (left: 0:01:09)\n",
      "TestLoss: 1.0893 MAE: 0.8303 RMSE: 1.0437\n",
      "ValLoss: 0.9563 MAE: 0.8111 RMSE: 0.9779\n",
      "Epoch 54: TrainLoss 0.9224 RecLoss: 0.0000 (left: 0:01:08)\n",
      "TestLoss: 1.0827 MAE: 0.8217 RMSE: 1.0405\n",
      "ValLoss: 0.9513 MAE: 0.8030 RMSE: 0.9754\n",
      "Epoch 55: TrainLoss 0.9206 RecLoss: 0.0000 (left: 0:01:07)\n",
      "TestLoss: 1.0824 MAE: 0.8229 RMSE: 1.0404\n",
      "ValLoss: 0.9552 MAE: 0.8066 RMSE: 0.9773\n",
      "Epoch 56: TrainLoss 0.9204 RecLoss: 0.0000 (left: 0:01:05)\n",
      "TestLoss: 1.0836 MAE: 0.8240 RMSE: 1.0410\n",
      "ValLoss: 0.9549 MAE: 0.8081 RMSE: 0.9772\n",
      "Epoch 57: TrainLoss 0.9195 RecLoss: 0.0000 (left: 0:01:04)\n",
      "TestLoss: 1.0817 MAE: 0.8205 RMSE: 1.0400\n",
      "ValLoss: 0.9513 MAE: 0.8030 RMSE: 0.9753\n",
      "Epoch 58: TrainLoss 0.9209 RecLoss: 0.0000 (left: 0:01:02)\n",
      "TestLoss: 1.0838 MAE: 0.8238 RMSE: 1.0410\n",
      "ValLoss: 0.9524 MAE: 0.8060 RMSE: 0.9759\n",
      "Epoch 59: TrainLoss 0.9211 RecLoss: 0.0000 (left: 0:01:01)\n",
      "TestLoss: 1.0841 MAE: 0.8241 RMSE: 1.0412\n",
      "ValLoss: 0.9521 MAE: 0.8053 RMSE: 0.9758\n",
      "Epoch 60: TrainLoss 0.9208 RecLoss: 0.0000 (left: 0:00:59)\n",
      "TestLoss: 1.0844 MAE: 0.8251 RMSE: 1.0414\n",
      "ValLoss: 0.9555 MAE: 0.8078 RMSE: 0.9775\n",
      "Epoch 61: TrainLoss 0.9219 RecLoss: 0.0000 (left: 0:00:57)\n",
      "TestLoss: 1.0814 MAE: 0.8211 RMSE: 1.0399\n",
      "ValLoss: 0.9584 MAE: 0.8067 RMSE: 0.9790\n",
      "Epoch 62: TrainLoss 0.9205 RecLoss: 0.0000 (left: 0:00:56)\n",
      "TestLoss: 1.0850 MAE: 0.8261 RMSE: 1.0416\n",
      "ValLoss: 0.9580 MAE: 0.8105 RMSE: 0.9788\n",
      "Epoch 63: TrainLoss 0.9196 RecLoss: 0.0000 (left: 0:00:54)\n",
      "TestLoss: 1.0827 MAE: 0.8201 RMSE: 1.0405\n",
      "ValLoss: 0.9493 MAE: 0.8007 RMSE: 0.9743\n",
      "Epoch 64: TrainLoss 0.9189 RecLoss: 0.0000 (left: 0:00:53)\n",
      "TestLoss: 1.0857 MAE: 0.8262 RMSE: 1.0420\n",
      "ValLoss: 0.9555 MAE: 0.8089 RMSE: 0.9775\n",
      "Epoch 65: TrainLoss 0.9195 RecLoss: 0.0000 (left: 0:00:51)\n",
      "TestLoss: 1.0822 MAE: 0.8218 RMSE: 1.0403\n",
      "ValLoss: 0.9554 MAE: 0.8050 RMSE: 0.9775\n",
      "Epoch 66: TrainLoss 0.9190 RecLoss: 0.0000 (left: 0:00:50)\n",
      "TestLoss: 1.0843 MAE: 0.8255 RMSE: 1.0413\n",
      "ValLoss: 0.9591 MAE: 0.8095 RMSE: 0.9793\n",
      "Epoch 67: TrainLoss 0.9187 RecLoss: 0.0000 (left: 0:00:48)\n",
      "TestLoss: 1.0807 MAE: 0.8202 RMSE: 1.0396\n",
      "ValLoss: 0.9563 MAE: 0.8040 RMSE: 0.9779\n",
      "Epoch 68: TrainLoss 0.9189 RecLoss: 0.0000 (left: 0:00:47)\n",
      "TestLoss: 1.0840 MAE: 0.8246 RMSE: 1.0412\n",
      "ValLoss: 0.9563 MAE: 0.8078 RMSE: 0.9779\n",
      "Epoch 69: TrainLoss 0.9188 RecLoss: 0.0000 (left: 0:00:45)\n",
      "TestLoss: 1.0818 MAE: 0.8218 RMSE: 1.0401\n",
      "ValLoss: 0.9540 MAE: 0.8041 RMSE: 0.9767\n",
      "Epoch 70: TrainLoss 0.9186 RecLoss: 0.0000 (left: 0:00:43)\n",
      "TestLoss: 1.0854 MAE: 0.8259 RMSE: 1.0418\n",
      "ValLoss: 0.9557 MAE: 0.8079 RMSE: 0.9776\n",
      "Epoch 71: TrainLoss 0.9191 RecLoss: 0.0000 (left: 0:00:42)\n",
      "TestLoss: 1.0815 MAE: 0.8212 RMSE: 1.0399\n",
      "ValLoss: 0.9537 MAE: 0.8036 RMSE: 0.9766\n",
      "Epoch 72: TrainLoss 0.9186 RecLoss: 0.0000 (left: 0:00:40)\n",
      "TestLoss: 1.0827 MAE: 0.8236 RMSE: 1.0405\n",
      "ValLoss: 0.9592 MAE: 0.8086 RMSE: 0.9794\n",
      "Epoch 73: TrainLoss 0.9196 RecLoss: 0.0000 (left: 0:00:39)\n",
      "TestLoss: 1.0807 MAE: 0.8204 RMSE: 1.0396\n",
      "ValLoss: 0.9564 MAE: 0.8040 RMSE: 0.9779\n",
      "Epoch 74: TrainLoss 0.9204 RecLoss: 0.0000 (left: 0:00:38)\n",
      "TestLoss: 1.0827 MAE: 0.8232 RMSE: 1.0405\n",
      "ValLoss: 0.9565 MAE: 0.8062 RMSE: 0.9780\n",
      "Epoch 75: TrainLoss 0.9184 RecLoss: 0.0000 (left: 0:00:36)\n",
      "TestLoss: 1.0825 MAE: 0.8222 RMSE: 1.0404\n",
      "ValLoss: 0.9542 MAE: 0.8047 RMSE: 0.9768\n",
      "Epoch 76: TrainLoss 0.9185 RecLoss: 0.0000 (left: 0:00:35)\n",
      "TestLoss: 1.0836 MAE: 0.8244 RMSE: 1.0410\n",
      "ValLoss: 0.9569 MAE: 0.8076 RMSE: 0.9782\n",
      "Epoch 77: TrainLoss 0.9185 RecLoss: 0.0000 (left: 0:00:33)\n",
      "TestLoss: 1.0807 MAE: 0.8217 RMSE: 1.0396\n",
      "ValLoss: 0.9583 MAE: 0.8057 RMSE: 0.9789\n",
      "Epoch 78: TrainLoss 0.9182 RecLoss: 0.0000 (left: 0:00:32)\n",
      "TestLoss: 1.0808 MAE: 0.8220 RMSE: 1.0396\n",
      "ValLoss: 0.9568 MAE: 0.8050 RMSE: 0.9781\n",
      "Epoch 79: TrainLoss 0.9184 RecLoss: 0.0000 (left: 0:00:30)\n",
      "TestLoss: 1.0832 MAE: 0.8250 RMSE: 1.0408\n",
      "ValLoss: 0.9590 MAE: 0.8088 RMSE: 0.9793\n",
      "Epoch 80: TrainLoss 0.9190 RecLoss: 0.0000 (left: 0:00:29)\n",
      "TestLoss: 1.0809 MAE: 0.8203 RMSE: 1.0397\n",
      "ValLoss: 0.9528 MAE: 0.8025 RMSE: 0.9761\n",
      "Epoch 81: TrainLoss 0.9196 RecLoss: 0.0000 (left: 0:00:27)\n",
      "TestLoss: 1.0830 MAE: 0.8229 RMSE: 1.0407\n",
      "ValLoss: 0.9537 MAE: 0.8048 RMSE: 0.9766\n",
      "Epoch 82: TrainLoss 0.9186 RecLoss: 0.0000 (left: 0:00:26)\n",
      "TestLoss: 1.0815 MAE: 0.8224 RMSE: 1.0399\n",
      "ValLoss: 0.9572 MAE: 0.8057 RMSE: 0.9784\n",
      "Epoch 83: TrainLoss 0.9191 RecLoss: 0.0000 (left: 0:00:24)\n",
      "TestLoss: 1.0795 MAE: 0.8194 RMSE: 1.0390\n",
      "ValLoss: 0.9585 MAE: 0.8043 RMSE: 0.9790\n",
      "Epoch 84: TrainLoss 0.9188 RecLoss: 0.0000 (left: 0:00:23)\n",
      "TestLoss: 1.0848 MAE: 0.8261 RMSE: 1.0416\n",
      "ValLoss: 0.9613 MAE: 0.8102 RMSE: 0.9805\n",
      "Epoch 85: TrainLoss 0.9179 RecLoss: 0.0000 (left: 0:00:21)\n",
      "TestLoss: 1.0810 MAE: 0.8195 RMSE: 1.0397\n",
      "ValLoss: 0.9529 MAE: 0.8003 RMSE: 0.9762\n",
      "Epoch 86: TrainLoss 0.9189 RecLoss: 0.0000 (left: 0:00:20)\n",
      "TestLoss: 1.0839 MAE: 0.8245 RMSE: 1.0411\n",
      "ValLoss: 0.9572 MAE: 0.8069 RMSE: 0.9784\n",
      "Epoch 87: TrainLoss 0.9180 RecLoss: 0.0000 (left: 0:00:19)\n",
      "TestLoss: 1.0805 MAE: 0.8198 RMSE: 1.0394\n",
      "ValLoss: 0.9554 MAE: 0.8027 RMSE: 0.9774\n",
      "Epoch 88: TrainLoss 0.9179 RecLoss: 0.0000 (left: 0:00:17)\n",
      "TestLoss: 1.0831 MAE: 0.8238 RMSE: 1.0407\n",
      "ValLoss: 0.9584 MAE: 0.8075 RMSE: 0.9790\n",
      "Epoch 89: TrainLoss 0.9179 RecLoss: 0.0000 (left: 0:00:16)\n",
      "TestLoss: 1.0814 MAE: 0.8220 RMSE: 1.0399\n",
      "ValLoss: 0.9582 MAE: 0.8062 RMSE: 0.9789\n",
      "Epoch 90: TrainLoss 0.9178 RecLoss: 0.0000 (left: 0:00:14)\n",
      "TestLoss: 1.0810 MAE: 0.8211 RMSE: 1.0397\n",
      "ValLoss: 0.9567 MAE: 0.8044 RMSE: 0.9781\n",
      "Epoch 91: TrainLoss 0.9187 RecLoss: 0.0000 (left: 0:00:13)\n",
      "TestLoss: 1.0819 MAE: 0.8222 RMSE: 1.0402\n",
      "ValLoss: 0.9562 MAE: 0.8047 RMSE: 0.9779\n",
      "Epoch 92: TrainLoss 0.9182 RecLoss: 0.0000 (left: 0:00:11)\n",
      "TestLoss: 1.0815 MAE: 0.8217 RMSE: 1.0400\n",
      "ValLoss: 0.9564 MAE: 0.8046 RMSE: 0.9779\n",
      "Epoch 93: TrainLoss 0.9179 RecLoss: 0.0000 (left: 0:00:10)\n",
      "TestLoss: 1.0827 MAE: 0.8236 RMSE: 1.0405\n",
      "ValLoss: 0.9595 MAE: 0.8074 RMSE: 0.9795\n",
      "Epoch 94: TrainLoss 0.9177 RecLoss: 0.0000 (left: 0:00:08)\n",
      "TestLoss: 1.0802 MAE: 0.8201 RMSE: 1.0393\n",
      "ValLoss: 0.9567 MAE: 0.8031 RMSE: 0.9781\n",
      "Epoch 95: TrainLoss 0.9175 RecLoss: 0.0000 (left: 0:00:07)\n",
      "TestLoss: 1.0831 MAE: 0.8241 RMSE: 1.0407\n",
      "ValLoss: 0.9590 MAE: 0.8074 RMSE: 0.9793\n",
      "Epoch 96: TrainLoss 0.9180 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 1.0809 MAE: 0.8216 RMSE: 1.0397\n",
      "ValLoss: 0.9580 MAE: 0.8050 RMSE: 0.9788\n",
      "Epoch 97: TrainLoss 0.9175 RecLoss: 0.0000 (left: 0:00:04)\n",
      "TestLoss: 1.0805 MAE: 0.8209 RMSE: 1.0395\n",
      "ValLoss: 0.9583 MAE: 0.8051 RMSE: 0.9789\n",
      "Epoch 98: TrainLoss 0.9187 RecLoss: 0.0000 (left: 0:00:02)\n",
      "TestLoss: 1.0820 MAE: 0.8218 RMSE: 1.0402\n",
      "ValLoss: 0.9558 MAE: 0.8046 RMSE: 0.9776\n",
      "Epoch 99: TrainLoss 0.9178 RecLoss: 0.0000 (left: 0:00:01)\n",
      "TestLoss: 1.0811 MAE: 0.8210 RMSE: 1.0397\n",
      "ValLoss: 0.9557 MAE: 0.8034 RMSE: 0.9776\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 84997/4938\n",
      "test set size: support/query 584/213\n",
      "USER HIS DICT: 943\n",
      "NUM IS: 943\n",
      "Key Test Result: MAE: 0.7165 RMSE: 0.9152 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 943\n",
      "NUM IS: 943\n",
      "Que Test Result: MAE: 0.8345 RMSE: 1.0488 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7480 RMSE: 0.9528 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 100% cur to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 94119/4938\n",
      "test set size: support/query 730/213\n",
      "Epoch 0 Step 88: Train 6.3013 Reg: 0.4731\n",
      "Test: 1.1631 MAE: 0.8794 RMSE: 1.0785\n",
      "Val: 1.1481 MAE: 0.8679 RMSE: 1.0715\n",
      "Epoch 1 Step 176: Train 0.9799 Reg: 0.4807\n",
      "Test: 0.9898 MAE: 0.7880 RMSE: 0.9949\n",
      "Val: 0.9420 MAE: 0.7761 RMSE: 0.9706\n",
      "Epoch 2 Step 264: Train 0.8817 Reg: 0.4511\n",
      "Test: 0.9535 MAE: 0.7665 RMSE: 0.9765\n",
      "Val: 0.9005 MAE: 0.7492 RMSE: 0.9489\n",
      "Epoch 3 Step 352: Train 0.8594 Reg: 0.4284\n",
      "Test: 0.9378 MAE: 0.7609 RMSE: 0.9684\n",
      "Val: 0.8895 MAE: 0.7459 RMSE: 0.9431\n",
      "Epoch 4 Step 440: Train 0.8520 Reg: 0.4085\n",
      "Test: 0.9343 MAE: 0.7601 RMSE: 0.9666\n",
      "Val: 0.8844 MAE: 0.7432 RMSE: 0.9404\n",
      "Epoch 5 Step 528: Train 0.8474 Reg: 0.3909\n",
      "Test: 0.9287 MAE: 0.7562 RMSE: 0.9637\n",
      "Val: 0.8821 MAE: 0.7417 RMSE: 0.9392\n",
      "Epoch 6 Step 616: Train 0.8449 Reg: 0.3749\n",
      "Test: 0.9285 MAE: 0.7568 RMSE: 0.9636\n",
      "Val: 0.8819 MAE: 0.7411 RMSE: 0.9391\n",
      "Epoch 7 Step 704: Train 0.8423 Reg: 0.3614\n",
      "Test: 0.9306 MAE: 0.7566 RMSE: 0.9647\n",
      "Val: 0.8803 MAE: 0.7413 RMSE: 0.9382\n",
      "Epoch 8 Step 792: Train 0.8400 Reg: 0.3480\n",
      "Test: 0.9289 MAE: 0.7557 RMSE: 0.9638\n",
      "Val: 0.8783 MAE: 0.7398 RMSE: 0.9372\n",
      "Epoch 9 Step 880: Train 0.8383 Reg: 0.3364\n",
      "Test: 0.9309 MAE: 0.7565 RMSE: 0.9648\n",
      "Val: 0.8761 MAE: 0.7385 RMSE: 0.9360\n",
      "Epoch 10 Step 968: Train 0.8362 Reg: 0.3262\n",
      "Test: 0.9301 MAE: 0.7561 RMSE: 0.9644\n",
      "Val: 0.8758 MAE: 0.7371 RMSE: 0.9358\n",
      "Epoch 11 Step 1056: Train 0.8340 Reg: 0.3166\n",
      "Test: 0.9226 MAE: 0.7518 RMSE: 0.9605\n",
      "Val: 0.8749 MAE: 0.7369 RMSE: 0.9354\n",
      "Epoch 12 Step 1144: Train 0.8323 Reg: 0.3087\n",
      "Test: 0.9237 MAE: 0.7525 RMSE: 0.9611\n",
      "Val: 0.8744 MAE: 0.7370 RMSE: 0.9351\n",
      "Epoch 13 Step 1232: Train 0.8299 Reg: 0.3009\n",
      "Test: 0.9251 MAE: 0.7509 RMSE: 0.9618\n",
      "Val: 0.8740 MAE: 0.7358 RMSE: 0.9349\n",
      "Epoch 14 Step 1320: Train 0.8272 Reg: 0.2947\n",
      "Test: 0.9210 MAE: 0.7514 RMSE: 0.9597\n",
      "Val: 0.8720 MAE: 0.7370 RMSE: 0.9338\n",
      "Epoch 15 Step 1408: Train 0.8247 Reg: 0.2890\n",
      "Test: 0.9188 MAE: 0.7504 RMSE: 0.9585\n",
      "Val: 0.8695 MAE: 0.7356 RMSE: 0.9325\n",
      "Epoch 16 Step 1496: Train 0.8212 Reg: 0.2844\n",
      "Test: 0.9179 MAE: 0.7515 RMSE: 0.9580\n",
      "Val: 0.8682 MAE: 0.7360 RMSE: 0.9318\n",
      "Epoch 17 Step 1584: Train 0.8180 Reg: 0.2807\n",
      "Test: 0.9154 MAE: 0.7483 RMSE: 0.9568\n",
      "Val: 0.8669 MAE: 0.7326 RMSE: 0.9311\n",
      "Epoch 18 Step 1672: Train 0.8138 Reg: 0.2775\n",
      "Test: 0.9088 MAE: 0.7445 RMSE: 0.9533\n",
      "Val: 0.8675 MAE: 0.7331 RMSE: 0.9314\n",
      "Epoch 19 Step 1760: Train 0.8096 Reg: 0.2757\n",
      "Test: 0.9091 MAE: 0.7445 RMSE: 0.9535\n",
      "Val: 0.8663 MAE: 0.7329 RMSE: 0.9308\n",
      "Epoch 20 Step 1848: Train 0.8046 Reg: 0.2743\n",
      "Test: 0.9090 MAE: 0.7452 RMSE: 0.9534\n",
      "Val: 0.8620 MAE: 0.7321 RMSE: 0.9284\n",
      "Epoch 21 Step 1936: Train 0.7993 Reg: 0.2731\n",
      "Test: 0.9038 MAE: 0.7418 RMSE: 0.9507\n",
      "Val: 0.8602 MAE: 0.7308 RMSE: 0.9274\n",
      "Epoch 22 Step 2024: Train 0.7940 Reg: 0.2726\n",
      "Test: 0.8999 MAE: 0.7409 RMSE: 0.9486\n",
      "Val: 0.8603 MAE: 0.7310 RMSE: 0.9275\n",
      "Epoch 23 Step 2112: Train 0.7886 Reg: 0.2727\n",
      "Test: 0.8998 MAE: 0.7404 RMSE: 0.9486\n",
      "Val: 0.8578 MAE: 0.7287 RMSE: 0.9262\n",
      "Epoch 24 Step 2200: Train 0.7828 Reg: 0.2732\n",
      "Test: 0.8992 MAE: 0.7399 RMSE: 0.9482\n",
      "Val: 0.8570 MAE: 0.7278 RMSE: 0.9258\n",
      "Epoch 25 Step 2288: Train 0.7766 Reg: 0.2731\n",
      "Test: 0.8999 MAE: 0.7417 RMSE: 0.9486\n",
      "Val: 0.8556 MAE: 0.7289 RMSE: 0.9250\n",
      "Epoch 26 Step 2376: Train 0.7707 Reg: 0.2740\n",
      "Test: 0.8951 MAE: 0.7374 RMSE: 0.9461\n",
      "Val: 0.8554 MAE: 0.7257 RMSE: 0.9249\n",
      "Epoch 27 Step 2464: Train 0.7647 Reg: 0.2748\n",
      "Test: 0.8962 MAE: 0.7397 RMSE: 0.9467\n",
      "Val: 0.8534 MAE: 0.7271 RMSE: 0.9238\n",
      "Epoch 28 Step 2552: Train 0.7583 Reg: 0.2755\n",
      "Test: 0.8926 MAE: 0.7376 RMSE: 0.9448\n",
      "Val: 0.8522 MAE: 0.7258 RMSE: 0.9232\n",
      "Epoch 29 Step 2640: Train 0.7517 Reg: 0.2766\n",
      "Test: 0.8918 MAE: 0.7371 RMSE: 0.9444\n",
      "Val: 0.8517 MAE: 0.7256 RMSE: 0.9229\n",
      "Epoch 30 Step 2728: Train 0.7448 Reg: 0.2778\n",
      "Test: 0.8887 MAE: 0.7350 RMSE: 0.9427\n",
      "Val: 0.8518 MAE: 0.7246 RMSE: 0.9229\n",
      "Epoch 31 Step 2816: Train 0.7384 Reg: 0.2790\n",
      "Test: 0.8875 MAE: 0.7343 RMSE: 0.9421\n",
      "Val: 0.8497 MAE: 0.7238 RMSE: 0.9218\n",
      "Epoch 32 Step 2904: Train 0.7313 Reg: 0.2802\n",
      "Test: 0.8860 MAE: 0.7338 RMSE: 0.9413\n",
      "Val: 0.8498 MAE: 0.7235 RMSE: 0.9218\n",
      "Epoch 33 Step 2992: Train 0.7243 Reg: 0.2815\n",
      "Test: 0.8847 MAE: 0.7325 RMSE: 0.9406\n",
      "Val: 0.8493 MAE: 0.7232 RMSE: 0.9216\n",
      "Epoch 34 Step 3080: Train 0.7174 Reg: 0.2829\n",
      "Test: 0.8836 MAE: 0.7310 RMSE: 0.9400\n",
      "Val: 0.8498 MAE: 0.7231 RMSE: 0.9218\n",
      "Epoch 35 Step 3168: Train 0.7106 Reg: 0.2844\n",
      "Test: 0.8841 MAE: 0.7333 RMSE: 0.9403\n",
      "Val: 0.8498 MAE: 0.7256 RMSE: 0.9219\n",
      "Epoch 36 Step 3256: Train 0.7040 Reg: 0.2856\n",
      "Test: 0.8829 MAE: 0.7308 RMSE: 0.9396\n",
      "Val: 0.8492 MAE: 0.7238 RMSE: 0.9215\n",
      "Epoch 37 Step 3344: Train 0.6975 Reg: 0.2870\n",
      "Test: 0.8816 MAE: 0.7286 RMSE: 0.9389\n",
      "Val: 0.8511 MAE: 0.7232 RMSE: 0.9226\n",
      "Epoch 38 Step 3432: Train 0.6913 Reg: 0.2883\n",
      "Test: 0.8825 MAE: 0.7304 RMSE: 0.9394\n",
      "Val: 0.8518 MAE: 0.7248 RMSE: 0.9229\n",
      "Epoch 39 Step 3520: Train 0.6852 Reg: 0.2897\n",
      "Test: 0.8823 MAE: 0.7298 RMSE: 0.9393\n",
      "Val: 0.8516 MAE: 0.7239 RMSE: 0.9228\n",
      "Epoch 40 Step 3608: Train 0.6797 Reg: 0.2909\n",
      "Test: 0.8838 MAE: 0.7316 RMSE: 0.9401\n",
      "Val: 0.8531 MAE: 0.7256 RMSE: 0.9236\n",
      "Epoch 41 Step 3696: Train 0.6741 Reg: 0.2921\n",
      "Test: 0.8852 MAE: 0.7312 RMSE: 0.9408\n",
      "Val: 0.8537 MAE: 0.7252 RMSE: 0.9240\n",
      "Epoch 42 Step 3784: Train 0.6689 Reg: 0.2932\n",
      "Test: 0.8837 MAE: 0.7297 RMSE: 0.9400\n",
      "Val: 0.8553 MAE: 0.7248 RMSE: 0.9248\n",
      "Epoch 43 Step 3872: Train 0.6639 Reg: 0.2944\n",
      "Test: 0.8851 MAE: 0.7311 RMSE: 0.9408\n",
      "Val: 0.8561 MAE: 0.7249 RMSE: 0.9253\n",
      "Epoch 44 Step 3960: Train 0.6591 Reg: 0.2955\n",
      "Test: 0.8864 MAE: 0.7315 RMSE: 0.9415\n",
      "Val: 0.8575 MAE: 0.7254 RMSE: 0.9260\n",
      "Epoch 45 Step 4048: Train 0.6544 Reg: 0.2965\n",
      "Test: 0.8865 MAE: 0.7319 RMSE: 0.9415\n",
      "Val: 0.8593 MAE: 0.7264 RMSE: 0.9270\n",
      "Epoch 46 Step 4136: Train 0.6500 Reg: 0.2975\n",
      "Test: 0.8879 MAE: 0.7329 RMSE: 0.9423\n",
      "Val: 0.8602 MAE: 0.7267 RMSE: 0.9275\n",
      "Epoch 47 Step 4224: Train 0.6456 Reg: 0.2985\n",
      "Test: 0.8884 MAE: 0.7329 RMSE: 0.9426\n",
      "Val: 0.8616 MAE: 0.7269 RMSE: 0.9282\n",
      "Epoch 48 Step 4312: Train 0.6416 Reg: 0.2994\n",
      "Test: 0.8893 MAE: 0.7330 RMSE: 0.9431\n",
      "Val: 0.8631 MAE: 0.7273 RMSE: 0.9290\n",
      "Epoch 49 Step 4400: Train 0.6375 Reg: 0.3004\n",
      "Test: 0.8920 MAE: 0.7351 RMSE: 0.9445\n",
      "Val: 0.8648 MAE: 0.7289 RMSE: 0.9299\n",
      "Epoch 50 Step 4488: Train 0.6336 Reg: 0.3013\n",
      "Test: 0.8917 MAE: 0.7342 RMSE: 0.9443\n",
      "Val: 0.8662 MAE: 0.7286 RMSE: 0.9307\n",
      "Epoch 51 Step 4576: Train 0.6298 Reg: 0.3022\n",
      "Test: 0.8920 MAE: 0.7348 RMSE: 0.9445\n",
      "Val: 0.8676 MAE: 0.7295 RMSE: 0.9315\n",
      "Epoch 52 Step 4664: Train 0.6262 Reg: 0.3029\n",
      "Test: 0.8929 MAE: 0.7347 RMSE: 0.9449\n",
      "Val: 0.8687 MAE: 0.7292 RMSE: 0.9320\n",
      "Epoch 53 Step 4752: Train 0.6226 Reg: 0.3038\n",
      "Test: 0.8937 MAE: 0.7338 RMSE: 0.9454\n",
      "Val: 0.8704 MAE: 0.7288 RMSE: 0.9329\n",
      "Epoch 54 Step 4840: Train 0.6194 Reg: 0.3045\n",
      "Test: 0.8944 MAE: 0.7346 RMSE: 0.9457\n",
      "Val: 0.8714 MAE: 0.7296 RMSE: 0.9335\n",
      "Epoch 55 Step 4928: Train 0.6160 Reg: 0.3053\n",
      "Test: 0.8958 MAE: 0.7354 RMSE: 0.9464\n",
      "Val: 0.8730 MAE: 0.7305 RMSE: 0.9343\n",
      "Epoch 56 Step 5016: Train 0.6128 Reg: 0.3061\n",
      "Test: 0.8979 MAE: 0.7369 RMSE: 0.9476\n",
      "Val: 0.8739 MAE: 0.7314 RMSE: 0.9348\n",
      "Epoch 57 Step 5104: Train 0.6098 Reg: 0.3067\n",
      "Test: 0.8986 MAE: 0.7366 RMSE: 0.9479\n",
      "Val: 0.8751 MAE: 0.7314 RMSE: 0.9355\n",
      "Epoch 58 Step 5192: Train 0.6068 Reg: 0.3074\n",
      "Test: 0.8999 MAE: 0.7367 RMSE: 0.9486\n",
      "Val: 0.8765 MAE: 0.7314 RMSE: 0.9362\n",
      "Epoch 59 Step 5280: Train 0.6040 Reg: 0.3081\n",
      "Test: 0.8997 MAE: 0.7361 RMSE: 0.9485\n",
      "Val: 0.8780 MAE: 0.7316 RMSE: 0.9370\n",
      "Epoch 60 Step 5368: Train 0.6013 Reg: 0.3087\n",
      "Test: 0.9013 MAE: 0.7380 RMSE: 0.9493\n",
      "Val: 0.8790 MAE: 0.7331 RMSE: 0.9376\n",
      "Epoch 61 Step 5456: Train 0.5988 Reg: 0.3093\n",
      "Test: 0.9014 MAE: 0.7377 RMSE: 0.9494\n",
      "Val: 0.8800 MAE: 0.7331 RMSE: 0.9381\n",
      "Epoch 62 Step 5544: Train 0.5962 Reg: 0.3099\n",
      "Test: 0.9023 MAE: 0.7376 RMSE: 0.9499\n",
      "Val: 0.8812 MAE: 0.7330 RMSE: 0.9387\n",
      "Epoch 63 Step 5632: Train 0.5939 Reg: 0.3104\n",
      "Test: 0.9037 MAE: 0.7385 RMSE: 0.9506\n",
      "Val: 0.8823 MAE: 0.7338 RMSE: 0.9393\n",
      "Epoch 64 Step 5720: Train 0.5916 Reg: 0.3109\n",
      "Test: 0.9042 MAE: 0.7383 RMSE: 0.9509\n",
      "Val: 0.8836 MAE: 0.7340 RMSE: 0.9400\n",
      "Epoch 65 Step 5808: Train 0.5894 Reg: 0.3114\n",
      "Test: 0.9045 MAE: 0.7381 RMSE: 0.9510\n",
      "Val: 0.8845 MAE: 0.7340 RMSE: 0.9405\n",
      "Epoch 66 Step 5896: Train 0.5873 Reg: 0.3119\n",
      "Test: 0.9052 MAE: 0.7379 RMSE: 0.9514\n",
      "Val: 0.8857 MAE: 0.7341 RMSE: 0.9411\n",
      "Epoch 67 Step 5984: Train 0.5853 Reg: 0.3123\n",
      "Test: 0.9066 MAE: 0.7396 RMSE: 0.9521\n",
      "Val: 0.8865 MAE: 0.7354 RMSE: 0.9416\n",
      "Epoch 68 Step 6072: Train 0.5834 Reg: 0.3127\n",
      "Test: 0.9070 MAE: 0.7395 RMSE: 0.9524\n",
      "Val: 0.8874 MAE: 0.7353 RMSE: 0.9420\n",
      "Epoch 69 Step 6160: Train 0.5816 Reg: 0.3131\n",
      "Test: 0.9076 MAE: 0.7397 RMSE: 0.9527\n",
      "Val: 0.8884 MAE: 0.7355 RMSE: 0.9425\n",
      "Epoch 70 Step 6248: Train 0.5798 Reg: 0.3135\n",
      "Test: 0.9081 MAE: 0.7395 RMSE: 0.9530\n",
      "Val: 0.8893 MAE: 0.7356 RMSE: 0.9430\n",
      "Epoch 71 Step 6336: Train 0.5782 Reg: 0.3139\n",
      "Test: 0.9089 MAE: 0.7399 RMSE: 0.9534\n",
      "Val: 0.8901 MAE: 0.7360 RMSE: 0.9434\n",
      "Epoch 72 Step 6424: Train 0.5766 Reg: 0.3143\n",
      "Test: 0.9094 MAE: 0.7402 RMSE: 0.9536\n",
      "Val: 0.8911 MAE: 0.7364 RMSE: 0.9440\n",
      "Epoch 73 Step 6512: Train 0.5751 Reg: 0.3146\n",
      "Test: 0.9106 MAE: 0.7409 RMSE: 0.9542\n",
      "Val: 0.8919 MAE: 0.7370 RMSE: 0.9444\n",
      "Epoch 74 Step 6600: Train 0.5737 Reg: 0.3149\n",
      "Test: 0.9102 MAE: 0.7398 RMSE: 0.9540\n",
      "Val: 0.8927 MAE: 0.7363 RMSE: 0.9448\n",
      "Epoch 75 Step 6688: Train 0.5723 Reg: 0.3152\n",
      "Test: 0.9112 MAE: 0.7409 RMSE: 0.9546\n",
      "Val: 0.8932 MAE: 0.7371 RMSE: 0.9451\n",
      "Epoch 76 Step 6776: Train 0.5710 Reg: 0.3155\n",
      "Test: 0.9115 MAE: 0.7405 RMSE: 0.9547\n",
      "Val: 0.8939 MAE: 0.7369 RMSE: 0.9455\n",
      "Epoch 77 Step 6864: Train 0.5698 Reg: 0.3157\n",
      "Test: 0.9123 MAE: 0.7411 RMSE: 0.9551\n",
      "Val: 0.8947 MAE: 0.7373 RMSE: 0.9459\n",
      "Epoch 78 Step 6952: Train 0.5686 Reg: 0.3160\n",
      "Test: 0.9130 MAE: 0.7420 RMSE: 0.9555\n",
      "Val: 0.8953 MAE: 0.7382 RMSE: 0.9462\n",
      "Epoch 79 Step 7040: Train 0.5675 Reg: 0.3162\n",
      "Test: 0.9133 MAE: 0.7418 RMSE: 0.9557\n",
      "Val: 0.8960 MAE: 0.7381 RMSE: 0.9466\n",
      "Epoch 80 Step 7128: Train 0.5664 Reg: 0.3165\n",
      "Test: 0.9135 MAE: 0.7415 RMSE: 0.9558\n",
      "Val: 0.8965 MAE: 0.7378 RMSE: 0.9468\n",
      "Epoch 81 Step 7216: Train 0.5654 Reg: 0.3167\n",
      "Test: 0.9143 MAE: 0.7423 RMSE: 0.9562\n",
      "Val: 0.8971 MAE: 0.7385 RMSE: 0.9472\n",
      "Epoch 82 Step 7304: Train 0.5644 Reg: 0.3169\n",
      "Test: 0.9142 MAE: 0.7418 RMSE: 0.9561\n",
      "Val: 0.8976 MAE: 0.7382 RMSE: 0.9474\n",
      "Epoch 83 Step 7392: Train 0.5635 Reg: 0.3171\n",
      "Test: 0.9145 MAE: 0.7418 RMSE: 0.9563\n",
      "Val: 0.8981 MAE: 0.7382 RMSE: 0.9477\n",
      "Epoch 84 Step 7480: Train 0.5626 Reg: 0.3173\n",
      "Test: 0.9150 MAE: 0.7418 RMSE: 0.9566\n",
      "Val: 0.8987 MAE: 0.7383 RMSE: 0.9480\n",
      "Epoch 85 Step 7568: Train 0.5618 Reg: 0.3175\n",
      "Test: 0.9153 MAE: 0.7421 RMSE: 0.9567\n",
      "Val: 0.8992 MAE: 0.7386 RMSE: 0.9482\n",
      "Epoch 86 Step 7656: Train 0.5610 Reg: 0.3176\n",
      "Test: 0.9159 MAE: 0.7424 RMSE: 0.9570\n",
      "Val: 0.8996 MAE: 0.7388 RMSE: 0.9485\n",
      "Epoch 87 Step 7744: Train 0.5603 Reg: 0.3178\n",
      "Test: 0.9159 MAE: 0.7423 RMSE: 0.9570\n",
      "Val: 0.9001 MAE: 0.7389 RMSE: 0.9487\n",
      "Epoch 88 Step 7832: Train 0.5596 Reg: 0.3179\n",
      "Test: 0.9165 MAE: 0.7427 RMSE: 0.9573\n",
      "Val: 0.9004 MAE: 0.7391 RMSE: 0.9489\n",
      "Epoch 89 Step 7920: Train 0.5589 Reg: 0.3181\n",
      "Test: 0.9168 MAE: 0.7427 RMSE: 0.9575\n",
      "Val: 0.9008 MAE: 0.7391 RMSE: 0.9491\n",
      "Epoch 90 Step 8008: Train 0.5582 Reg: 0.3182\n",
      "Test: 0.9173 MAE: 0.7432 RMSE: 0.9577\n",
      "Val: 0.9012 MAE: 0.7396 RMSE: 0.9493\n",
      "Epoch 91 Step 8096: Train 0.5577 Reg: 0.3183\n",
      "Test: 0.9174 MAE: 0.7430 RMSE: 0.9578\n",
      "Val: 0.9015 MAE: 0.7395 RMSE: 0.9495\n",
      "Epoch 92 Step 8184: Train 0.5571 Reg: 0.3185\n",
      "Test: 0.9176 MAE: 0.7429 RMSE: 0.9579\n",
      "Val: 0.9019 MAE: 0.7395 RMSE: 0.9497\n",
      "Epoch 93 Step 8272: Train 0.5565 Reg: 0.3186\n",
      "Test: 0.9178 MAE: 0.7428 RMSE: 0.9580\n",
      "Val: 0.9022 MAE: 0.7394 RMSE: 0.9498\n",
      "Epoch 94 Step 8360: Train 0.5560 Reg: 0.3187\n",
      "Test: 0.9181 MAE: 0.7430 RMSE: 0.9582\n",
      "Val: 0.9026 MAE: 0.7396 RMSE: 0.9500\n",
      "Epoch 95 Step 8448: Train 0.5555 Reg: 0.3188\n",
      "Test: 0.9183 MAE: 0.7430 RMSE: 0.9583\n",
      "Val: 0.9028 MAE: 0.7397 RMSE: 0.9502\n",
      "Epoch 96 Step 8536: Train 0.5550 Reg: 0.3189\n",
      "Test: 0.9185 MAE: 0.7432 RMSE: 0.9584\n",
      "Val: 0.9031 MAE: 0.7398 RMSE: 0.9503\n",
      "Epoch 97 Step 8624: Train 0.5546 Reg: 0.3190\n",
      "Test: 0.9189 MAE: 0.7435 RMSE: 0.9586\n",
      "Val: 0.9034 MAE: 0.7401 RMSE: 0.9505\n",
      "Epoch 98 Step 8712: Train 0.5541 Reg: 0.3191\n",
      "Test: 0.9189 MAE: 0.7435 RMSE: 0.9586\n",
      "Val: 0.9036 MAE: 0.7401 RMSE: 0.9506\n",
      "Epoch 99 Step 8800: Train 0.5537 Reg: 0.3192\n",
      "Test: 0.9192 MAE: 0.7434 RMSE: 0.9587\n",
      "Val: 0.9039 MAE: 0.7401 RMSE: 0.9507\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 94119/4938\n",
      "test set size: support/query 730/213\n",
      "Epoch 0: TrainLoss 1.5980 RecLoss: 0.0000 (left: 0:03:42)\n",
      "TestLoss: 1.7020 MAE: 1.1216 RMSE: 1.3046\n",
      "ValLoss: 1.4999 MAE: 1.0497 RMSE: 1.2247\n",
      "Epoch 1: TrainLoss 1.2431 RecLoss: 0.0000 (left: 0:02:51)\n",
      "TestLoss: 1.4160 MAE: 0.9329 RMSE: 1.1900\n",
      "ValLoss: 1.1406 MAE: 0.8461 RMSE: 1.0680\n",
      "Epoch 2: TrainLoss 1.1707 RecLoss: 0.0000 (left: 0:02:40)\n",
      "TestLoss: 1.4041 MAE: 0.9925 RMSE: 1.1850\n",
      "ValLoss: 1.1977 MAE: 0.9343 RMSE: 1.0944\n",
      "Epoch 3: TrainLoss 1.1246 RecLoss: 0.0000 (left: 0:02:25)\n",
      "TestLoss: 1.2640 MAE: 0.8989 RMSE: 1.1243\n",
      "ValLoss: 1.0566 MAE: 0.8387 RMSE: 1.0279\n",
      "Epoch 4: TrainLoss 1.0958 RecLoss: 0.0000 (left: 0:02:25)\n",
      "TestLoss: 1.2326 MAE: 0.9115 RMSE: 1.1102\n",
      "ValLoss: 1.0169 MAE: 0.8490 RMSE: 1.0084\n",
      "Epoch 5: TrainLoss 1.0599 RecLoss: 0.0000 (left: 0:02:22)\n",
      "TestLoss: 1.2160 MAE: 0.9037 RMSE: 1.1027\n",
      "ValLoss: 1.0066 MAE: 0.8447 RMSE: 1.0033\n",
      "Epoch 6: TrainLoss 1.0389 RecLoss: 0.0000 (left: 0:02:16)\n",
      "TestLoss: 1.1946 MAE: 0.8850 RMSE: 1.0930\n",
      "ValLoss: 0.9994 MAE: 0.8308 RMSE: 0.9997\n",
      "Epoch 7: TrainLoss 1.0232 RecLoss: 0.0000 (left: 0:02:17)\n",
      "TestLoss: 1.1916 MAE: 0.8935 RMSE: 1.0916\n",
      "ValLoss: 1.0048 MAE: 0.8455 RMSE: 1.0024\n",
      "Epoch 8: TrainLoss 1.0126 RecLoss: 0.0000 (left: 0:02:11)\n",
      "TestLoss: 1.1713 MAE: 0.8793 RMSE: 1.0823\n",
      "ValLoss: 0.9827 MAE: 0.8288 RMSE: 0.9913\n",
      "Epoch 9: TrainLoss 0.9997 RecLoss: 0.0000 (left: 0:02:14)\n",
      "TestLoss: 1.1621 MAE: 0.8746 RMSE: 1.0780\n",
      "ValLoss: 0.9725 MAE: 0.8231 RMSE: 0.9861\n",
      "Epoch 10: TrainLoss 0.9921 RecLoss: 0.0000 (left: 0:02:11)\n",
      "TestLoss: 1.1588 MAE: 0.8746 RMSE: 1.0765\n",
      "ValLoss: 0.9698 MAE: 0.8251 RMSE: 0.9848\n",
      "Epoch 11: TrainLoss 0.9842 RecLoss: 0.0000 (left: 0:02:13)\n",
      "TestLoss: 1.1453 MAE: 0.8631 RMSE: 1.0702\n",
      "ValLoss: 0.9666 MAE: 0.8185 RMSE: 0.9832\n",
      "Epoch 12: TrainLoss 0.9774 RecLoss: 0.0000 (left: 0:02:13)\n",
      "TestLoss: 1.1459 MAE: 0.8680 RMSE: 1.0705\n",
      "ValLoss: 0.9725 MAE: 0.8274 RMSE: 0.9862\n",
      "Epoch 13: TrainLoss 0.9702 RecLoss: 0.0000 (left: 0:02:13)\n",
      "TestLoss: 1.1321 MAE: 0.8565 RMSE: 1.0640\n",
      "ValLoss: 0.9602 MAE: 0.8157 RMSE: 0.9799\n",
      "Epoch 14: TrainLoss 0.9634 RecLoss: 0.0000 (left: 0:02:13)\n",
      "TestLoss: 1.1327 MAE: 0.8592 RMSE: 1.0643\n",
      "ValLoss: 0.9584 MAE: 0.8196 RMSE: 0.9790\n",
      "Epoch 15: TrainLoss 0.9588 RecLoss: 0.0000 (left: 0:02:12)\n",
      "TestLoss: 1.1248 MAE: 0.8531 RMSE: 1.0606\n",
      "ValLoss: 0.9509 MAE: 0.8128 RMSE: 0.9751\n",
      "Epoch 16: TrainLoss 0.9543 RecLoss: 0.0000 (left: 0:02:11)\n",
      "TestLoss: 1.1208 MAE: 0.8513 RMSE: 1.0587\n",
      "ValLoss: 0.9565 MAE: 0.8161 RMSE: 0.9780\n",
      "Epoch 17: TrainLoss 0.9499 RecLoss: 0.0000 (left: 0:02:08)\n",
      "TestLoss: 1.1165 MAE: 0.8483 RMSE: 1.0566\n",
      "ValLoss: 0.9537 MAE: 0.8140 RMSE: 0.9766\n",
      "Epoch 18: TrainLoss 0.9473 RecLoss: 0.0000 (left: 0:02:05)\n",
      "TestLoss: 1.1147 MAE: 0.8475 RMSE: 1.0558\n",
      "ValLoss: 0.9566 MAE: 0.8158 RMSE: 0.9781\n",
      "Epoch 19: TrainLoss 0.9445 RecLoss: 0.0000 (left: 0:02:03)\n",
      "TestLoss: 1.1119 MAE: 0.8450 RMSE: 1.0545\n",
      "ValLoss: 0.9484 MAE: 0.8103 RMSE: 0.9739\n",
      "Epoch 20: TrainLoss 0.9410 RecLoss: 0.0000 (left: 0:02:00)\n",
      "TestLoss: 1.1099 MAE: 0.8441 RMSE: 1.0535\n",
      "ValLoss: 0.9470 MAE: 0.8098 RMSE: 0.9731\n",
      "Epoch 21: TrainLoss 0.9383 RecLoss: 0.0000 (left: 0:01:58)\n",
      "TestLoss: 1.1085 MAE: 0.8438 RMSE: 1.0528\n",
      "ValLoss: 0.9525 MAE: 0.8132 RMSE: 0.9760\n",
      "Epoch 22: TrainLoss 0.9357 RecLoss: 0.0000 (left: 0:01:55)\n",
      "TestLoss: 1.1040 MAE: 0.8399 RMSE: 1.0507\n",
      "ValLoss: 0.9444 MAE: 0.8067 RMSE: 0.9718\n",
      "Epoch 23: TrainLoss 0.9349 RecLoss: 0.0000 (left: 0:01:53)\n",
      "TestLoss: 1.1024 MAE: 0.8396 RMSE: 1.0500\n",
      "ValLoss: 0.9501 MAE: 0.8100 RMSE: 0.9747\n",
      "Epoch 24: TrainLoss 0.9330 RecLoss: 0.0000 (left: 0:01:51)\n",
      "TestLoss: 1.1006 MAE: 0.8383 RMSE: 1.0491\n",
      "ValLoss: 0.9504 MAE: 0.8095 RMSE: 0.9749\n",
      "Epoch 25: TrainLoss 0.9320 RecLoss: 0.0000 (left: 0:01:49)\n",
      "TestLoss: 1.1017 MAE: 0.8389 RMSE: 1.0496\n",
      "ValLoss: 0.9433 MAE: 0.8069 RMSE: 0.9713\n",
      "Epoch 26: TrainLoss 0.9313 RecLoss: 0.0000 (left: 0:01:48)\n",
      "TestLoss: 1.1003 MAE: 0.8377 RMSE: 1.0490\n",
      "ValLoss: 0.9396 MAE: 0.8042 RMSE: 0.9693\n",
      "Epoch 27: TrainLoss 0.9281 RecLoss: 0.0000 (left: 0:01:45)\n",
      "TestLoss: 1.0996 MAE: 0.8385 RMSE: 1.0486\n",
      "ValLoss: 0.9496 MAE: 0.8101 RMSE: 0.9745\n",
      "Epoch 28: TrainLoss 0.9267 RecLoss: 0.0000 (left: 0:01:43)\n",
      "TestLoss: 1.0946 MAE: 0.8345 RMSE: 1.0462\n",
      "ValLoss: 0.9506 MAE: 0.8071 RMSE: 0.9750\n",
      "Epoch 29: TrainLoss 0.9253 RecLoss: 0.0000 (left: 0:01:41)\n",
      "TestLoss: 1.0987 MAE: 0.8382 RMSE: 1.0482\n",
      "ValLoss: 0.9500 MAE: 0.8096 RMSE: 0.9747\n",
      "Epoch 30: TrainLoss 0.9270 RecLoss: 0.0000 (left: 0:01:39)\n",
      "TestLoss: 1.0951 MAE: 0.8334 RMSE: 1.0465\n",
      "ValLoss: 0.9420 MAE: 0.8002 RMSE: 0.9706\n",
      "Epoch 31: TrainLoss 0.9281 RecLoss: 0.0000 (left: 0:01:37)\n",
      "TestLoss: 1.0996 MAE: 0.8401 RMSE: 1.0486\n",
      "ValLoss: 0.9554 MAE: 0.8131 RMSE: 0.9774\n",
      "Epoch 32: TrainLoss 0.9252 RecLoss: 0.0000 (left: 0:01:35)\n",
      "TestLoss: 1.0924 MAE: 0.8330 RMSE: 1.0452\n",
      "ValLoss: 0.9434 MAE: 0.8031 RMSE: 0.9713\n",
      "Epoch 33: TrainLoss 0.9227 RecLoss: 0.0000 (left: 0:01:34)\n",
      "TestLoss: 1.0931 MAE: 0.8335 RMSE: 1.0455\n",
      "ValLoss: 0.9419 MAE: 0.8028 RMSE: 0.9705\n",
      "Epoch 34: TrainLoss 0.9217 RecLoss: 0.0000 (left: 0:01:33)\n",
      "TestLoss: 1.0929 MAE: 0.8335 RMSE: 1.0454\n",
      "ValLoss: 0.9459 MAE: 0.8042 RMSE: 0.9726\n",
      "Epoch 35: TrainLoss 0.9211 RecLoss: 0.0000 (left: 0:01:32)\n",
      "TestLoss: 1.0914 MAE: 0.8323 RMSE: 1.0447\n",
      "ValLoss: 0.9458 MAE: 0.8031 RMSE: 0.9725\n",
      "Epoch 36: TrainLoss 0.9216 RecLoss: 0.0000 (left: 0:01:31)\n",
      "TestLoss: 1.0895 MAE: 0.8307 RMSE: 1.0438\n",
      "ValLoss: 0.9472 MAE: 0.8025 RMSE: 0.9732\n",
      "Epoch 37: TrainLoss 0.9204 RecLoss: 0.0000 (left: 0:01:29)\n",
      "TestLoss: 1.0940 MAE: 0.8348 RMSE: 1.0460\n",
      "ValLoss: 0.9452 MAE: 0.8050 RMSE: 0.9722\n",
      "Epoch 38: TrainLoss 0.9199 RecLoss: 0.0000 (left: 0:01:27)\n",
      "TestLoss: 1.0897 MAE: 0.8304 RMSE: 1.0439\n",
      "ValLoss: 0.9425 MAE: 0.8002 RMSE: 0.9708\n",
      "Epoch 39: TrainLoss 0.9197 RecLoss: 0.0000 (left: 0:01:25)\n",
      "TestLoss: 1.0921 MAE: 0.8332 RMSE: 1.0450\n",
      "ValLoss: 0.9470 MAE: 0.8046 RMSE: 0.9732\n",
      "Epoch 40: TrainLoss 0.9193 RecLoss: 0.0000 (left: 0:01:24)\n",
      "TestLoss: 1.0893 MAE: 0.8310 RMSE: 1.0437\n",
      "ValLoss: 0.9482 MAE: 0.8039 RMSE: 0.9738\n",
      "Epoch 41: TrainLoss 0.9186 RecLoss: 0.0000 (left: 0:01:23)\n",
      "TestLoss: 1.0909 MAE: 0.8322 RMSE: 1.0445\n",
      "ValLoss: 0.9452 MAE: 0.8027 RMSE: 0.9722\n",
      "Epoch 42: TrainLoss 0.9186 RecLoss: 0.0000 (left: 0:01:21)\n",
      "TestLoss: 1.0893 MAE: 0.8309 RMSE: 1.0437\n",
      "ValLoss: 0.9409 MAE: 0.8003 RMSE: 0.9700\n",
      "Epoch 43: TrainLoss 0.9177 RecLoss: 0.0000 (left: 0:01:19)\n",
      "TestLoss: 1.0881 MAE: 0.8298 RMSE: 1.0431\n",
      "ValLoss: 0.9442 MAE: 0.8010 RMSE: 0.9717\n",
      "Epoch 44: TrainLoss 0.9174 RecLoss: 0.0000 (left: 0:01:18)\n",
      "TestLoss: 1.0904 MAE: 0.8319 RMSE: 1.0442\n",
      "ValLoss: 0.9520 MAE: 0.8054 RMSE: 0.9757\n",
      "Epoch 45: TrainLoss 0.9173 RecLoss: 0.0000 (left: 0:01:16)\n",
      "TestLoss: 1.0898 MAE: 0.8307 RMSE: 1.0439\n",
      "ValLoss: 0.9489 MAE: 0.8028 RMSE: 0.9741\n",
      "Epoch 46: TrainLoss 0.9175 RecLoss: 0.0000 (left: 0:01:15)\n",
      "TestLoss: 1.0895 MAE: 0.8308 RMSE: 1.0438\n",
      "ValLoss: 0.9459 MAE: 0.8020 RMSE: 0.9726\n",
      "Epoch 47: TrainLoss 0.9176 RecLoss: 0.0000 (left: 0:01:13)\n",
      "TestLoss: 1.0876 MAE: 0.8290 RMSE: 1.0429\n",
      "ValLoss: 0.9450 MAE: 0.8003 RMSE: 0.9721\n",
      "Epoch 48: TrainLoss 0.9169 RecLoss: 0.0000 (left: 0:01:11)\n",
      "TestLoss: 1.0885 MAE: 0.8297 RMSE: 1.0433\n",
      "ValLoss: 0.9441 MAE: 0.8004 RMSE: 0.9717\n",
      "Epoch 49: TrainLoss 0.9163 RecLoss: 0.0000 (left: 0:01:09)\n",
      "TestLoss: 1.0889 MAE: 0.8304 RMSE: 1.0435\n",
      "ValLoss: 0.9446 MAE: 0.8014 RMSE: 0.9719\n",
      "Epoch 50: TrainLoss 0.9163 RecLoss: 0.0000 (left: 0:01:08)\n",
      "TestLoss: 1.0866 MAE: 0.8274 RMSE: 1.0424\n",
      "ValLoss: 0.9459 MAE: 0.7985 RMSE: 0.9726\n",
      "Epoch 51: TrainLoss 0.9170 RecLoss: 0.0000 (left: 0:01:07)\n",
      "TestLoss: 1.0924 MAE: 0.8329 RMSE: 1.0452\n",
      "ValLoss: 0.9527 MAE: 0.8065 RMSE: 0.9760\n",
      "Epoch 52: TrainLoss 0.9184 RecLoss: 0.0000 (left: 0:01:05)\n",
      "TestLoss: 1.0863 MAE: 0.8255 RMSE: 1.0422\n",
      "ValLoss: 0.9437 MAE: 0.7954 RMSE: 0.9714\n",
      "Epoch 53: TrainLoss 0.9186 RecLoss: 0.0000 (left: 0:01:04)\n",
      "TestLoss: 1.0956 MAE: 0.8346 RMSE: 1.0467\n",
      "ValLoss: 0.9525 MAE: 0.8066 RMSE: 0.9760\n",
      "Epoch 54: TrainLoss 0.9188 RecLoss: 0.0000 (left: 0:01:02)\n",
      "TestLoss: 1.0853 MAE: 0.8249 RMSE: 1.0418\n",
      "ValLoss: 0.9469 MAE: 0.7972 RMSE: 0.9731\n",
      "Epoch 55: TrainLoss 0.9176 RecLoss: 0.0000 (left: 0:01:01)\n",
      "TestLoss: 1.0878 MAE: 0.8294 RMSE: 1.0430\n",
      "ValLoss: 0.9496 MAE: 0.8030 RMSE: 0.9745\n",
      "Epoch 56: TrainLoss 0.9166 RecLoss: 0.0000 (left: 0:01:00)\n",
      "TestLoss: 1.0848 MAE: 0.8261 RMSE: 1.0415\n",
      "ValLoss: 0.9421 MAE: 0.7975 RMSE: 0.9706\n",
      "Epoch 57: TrainLoss 0.9158 RecLoss: 0.0000 (left: 0:00:58)\n",
      "TestLoss: 1.0856 MAE: 0.8276 RMSE: 1.0419\n",
      "ValLoss: 0.9455 MAE: 0.8002 RMSE: 0.9724\n",
      "Epoch 58: TrainLoss 0.9174 RecLoss: 0.0000 (left: 0:00:57)\n",
      "TestLoss: 1.0852 MAE: 0.8265 RMSE: 1.0417\n",
      "ValLoss: 0.9461 MAE: 0.7987 RMSE: 0.9727\n",
      "Epoch 59: TrainLoss 0.9177 RecLoss: 0.0000 (left: 0:00:56)\n",
      "TestLoss: 1.0898 MAE: 0.8302 RMSE: 1.0440\n",
      "ValLoss: 0.9501 MAE: 0.8032 RMSE: 0.9747\n",
      "Epoch 60: TrainLoss 0.9175 RecLoss: 0.0000 (left: 0:00:54)\n",
      "TestLoss: 1.0868 MAE: 0.8275 RMSE: 1.0425\n",
      "ValLoss: 0.9475 MAE: 0.8000 RMSE: 0.9734\n",
      "Epoch 61: TrainLoss 0.9180 RecLoss: 0.0000 (left: 0:00:52)\n",
      "TestLoss: 1.0858 MAE: 0.8271 RMSE: 1.0420\n",
      "ValLoss: 0.9516 MAE: 0.8028 RMSE: 0.9755\n",
      "Epoch 62: TrainLoss 0.9171 RecLoss: 0.0000 (left: 0:00:51)\n",
      "TestLoss: 1.0866 MAE: 0.8278 RMSE: 1.0424\n",
      "ValLoss: 0.9481 MAE: 0.8014 RMSE: 0.9737\n",
      "Epoch 63: TrainLoss 0.9163 RecLoss: 0.0000 (left: 0:00:49)\n",
      "TestLoss: 1.0861 MAE: 0.8266 RMSE: 1.0422\n",
      "ValLoss: 0.9413 MAE: 0.7966 RMSE: 0.9702\n",
      "Epoch 64: TrainLoss 0.9151 RecLoss: 0.0000 (left: 0:00:48)\n",
      "TestLoss: 1.0880 MAE: 0.8289 RMSE: 1.0431\n",
      "ValLoss: 0.9486 MAE: 0.8023 RMSE: 0.9740\n",
      "Epoch 65: TrainLoss 0.9158 RecLoss: 0.0000 (left: 0:00:46)\n",
      "TestLoss: 1.0855 MAE: 0.8264 RMSE: 1.0419\n",
      "ValLoss: 0.9498 MAE: 0.8010 RMSE: 0.9746\n",
      "Epoch 66: TrainLoss 0.9156 RecLoss: 0.0000 (left: 0:00:45)\n",
      "TestLoss: 1.0885 MAE: 0.8290 RMSE: 1.0433\n",
      "ValLoss: 0.9500 MAE: 0.8029 RMSE: 0.9747\n",
      "Epoch 67: TrainLoss 0.9154 RecLoss: 0.0000 (left: 0:00:44)\n",
      "TestLoss: 1.0846 MAE: 0.8250 RMSE: 1.0414\n",
      "ValLoss: 0.9475 MAE: 0.7989 RMSE: 0.9734\n",
      "Epoch 68: TrainLoss 0.9151 RecLoss: 0.0000 (left: 0:00:42)\n",
      "TestLoss: 1.0879 MAE: 0.8283 RMSE: 1.0430\n",
      "ValLoss: 0.9480 MAE: 0.8017 RMSE: 0.9736\n",
      "Epoch 69: TrainLoss 0.9153 RecLoss: 0.0000 (left: 0:00:41)\n",
      "TestLoss: 1.0855 MAE: 0.8260 RMSE: 1.0419\n",
      "ValLoss: 0.9466 MAE: 0.7992 RMSE: 0.9729\n",
      "Epoch 70: TrainLoss 0.9149 RecLoss: 0.0000 (left: 0:00:40)\n",
      "TestLoss: 1.0900 MAE: 0.8296 RMSE: 1.0440\n",
      "ValLoss: 0.9478 MAE: 0.8020 RMSE: 0.9736\n",
      "Epoch 71: TrainLoss 0.9155 RecLoss: 0.0000 (left: 0:00:39)\n",
      "TestLoss: 1.0842 MAE: 0.8249 RMSE: 1.0412\n",
      "ValLoss: 0.9471 MAE: 0.7990 RMSE: 0.9732\n",
      "Epoch 72: TrainLoss 0.9147 RecLoss: 0.0000 (left: 0:00:37)\n",
      "TestLoss: 1.0871 MAE: 0.8280 RMSE: 1.0426\n",
      "ValLoss: 0.9528 MAE: 0.8041 RMSE: 0.9761\n",
      "Epoch 73: TrainLoss 0.9160 RecLoss: 0.0000 (left: 0:00:36)\n",
      "TestLoss: 1.0847 MAE: 0.8244 RMSE: 1.0415\n",
      "ValLoss: 0.9476 MAE: 0.7983 RMSE: 0.9735\n",
      "Epoch 74: TrainLoss 0.9172 RecLoss: 0.0000 (left: 0:00:35)\n",
      "TestLoss: 1.0876 MAE: 0.8279 RMSE: 1.0429\n",
      "ValLoss: 0.9481 MAE: 0.8012 RMSE: 0.9737\n",
      "Epoch 75: TrainLoss 0.9148 RecLoss: 0.0000 (left: 0:00:34)\n",
      "TestLoss: 1.0855 MAE: 0.8258 RMSE: 1.0419\n",
      "ValLoss: 0.9443 MAE: 0.7981 RMSE: 0.9717\n",
      "Epoch 76: TrainLoss 0.9152 RecLoss: 0.0000 (left: 0:00:32)\n",
      "TestLoss: 1.0879 MAE: 0.8284 RMSE: 1.0430\n",
      "ValLoss: 0.9513 MAE: 0.8031 RMSE: 0.9753\n",
      "Epoch 77: TrainLoss 0.9148 RecLoss: 0.0000 (left: 0:00:31)\n",
      "TestLoss: 1.0845 MAE: 0.8252 RMSE: 1.0414\n",
      "ValLoss: 0.9524 MAE: 0.8016 RMSE: 0.9759\n",
      "Epoch 78: TrainLoss 0.9146 RecLoss: 0.0000 (left: 0:00:30)\n",
      "TestLoss: 1.0862 MAE: 0.8265 RMSE: 1.0422\n",
      "ValLoss: 0.9476 MAE: 0.7997 RMSE: 0.9734\n",
      "Epoch 79: TrainLoss 0.9145 RecLoss: 0.0000 (left: 0:00:28)\n",
      "TestLoss: 1.0878 MAE: 0.8283 RMSE: 1.0430\n",
      "ValLoss: 0.9475 MAE: 0.8016 RMSE: 0.9734\n",
      "Epoch 80: TrainLoss 0.9151 RecLoss: 0.0000 (left: 0:00:27)\n",
      "TestLoss: 1.0845 MAE: 0.8248 RMSE: 1.0414\n",
      "ValLoss: 0.9431 MAE: 0.7972 RMSE: 0.9711\n",
      "Epoch 81: TrainLoss 0.9161 RecLoss: 0.0000 (left: 0:00:26)\n",
      "TestLoss: 1.0877 MAE: 0.8278 RMSE: 1.0430\n",
      "ValLoss: 0.9457 MAE: 0.8002 RMSE: 0.9725\n",
      "Epoch 82: TrainLoss 0.9150 RecLoss: 0.0000 (left: 0:00:24)\n",
      "TestLoss: 1.0855 MAE: 0.8260 RMSE: 1.0419\n",
      "ValLoss: 0.9505 MAE: 0.8012 RMSE: 0.9749\n",
      "Epoch 83: TrainLoss 0.9157 RecLoss: 0.0000 (left: 0:00:23)\n",
      "TestLoss: 1.0837 MAE: 0.8242 RMSE: 1.0410\n",
      "ValLoss: 0.9512 MAE: 0.8008 RMSE: 0.9753\n",
      "Epoch 84: TrainLoss 0.9150 RecLoss: 0.0000 (left: 0:00:22)\n",
      "TestLoss: 1.0894 MAE: 0.8289 RMSE: 1.0438\n",
      "ValLoss: 0.9523 MAE: 0.8037 RMSE: 0.9759\n",
      "Epoch 85: TrainLoss 0.9144 RecLoss: 0.0000 (left: 0:00:20)\n",
      "TestLoss: 1.0855 MAE: 0.8242 RMSE: 1.0419\n",
      "ValLoss: 0.9421 MAE: 0.7953 RMSE: 0.9706\n",
      "Epoch 86: TrainLoss 0.9154 RecLoss: 0.0000 (left: 0:00:19)\n",
      "TestLoss: 1.0883 MAE: 0.8279 RMSE: 1.0432\n",
      "ValLoss: 0.9483 MAE: 0.8012 RMSE: 0.9738\n",
      "Epoch 87: TrainLoss 0.9143 RecLoss: 0.0000 (left: 0:00:18)\n",
      "TestLoss: 1.0843 MAE: 0.8241 RMSE: 1.0413\n",
      "ValLoss: 0.9471 MAE: 0.7984 RMSE: 0.9732\n",
      "Epoch 88: TrainLoss 0.9142 RecLoss: 0.0000 (left: 0:00:16)\n",
      "TestLoss: 1.0876 MAE: 0.8277 RMSE: 1.0429\n",
      "ValLoss: 0.9524 MAE: 0.8036 RMSE: 0.9759\n",
      "Epoch 89: TrainLoss 0.9143 RecLoss: 0.0000 (left: 0:00:15)\n",
      "TestLoss: 1.0849 MAE: 0.8253 RMSE: 1.0416\n",
      "ValLoss: 0.9485 MAE: 0.8006 RMSE: 0.9739\n",
      "Epoch 90: TrainLoss 0.9144 RecLoss: 0.0000 (left: 0:00:13)\n",
      "TestLoss: 1.0853 MAE: 0.8256 RMSE: 1.0418\n",
      "ValLoss: 0.9494 MAE: 0.8006 RMSE: 0.9743\n",
      "Epoch 91: TrainLoss 0.9151 RecLoss: 0.0000 (left: 0:00:12)\n",
      "TestLoss: 1.0864 MAE: 0.8260 RMSE: 1.0423\n",
      "ValLoss: 0.9463 MAE: 0.7990 RMSE: 0.9728\n",
      "Epoch 92: TrainLoss 0.9149 RecLoss: 0.0000 (left: 0:00:11)\n",
      "TestLoss: 1.0865 MAE: 0.8262 RMSE: 1.0423\n",
      "ValLoss: 0.9471 MAE: 0.7997 RMSE: 0.9732\n",
      "Epoch 93: TrainLoss 0.9147 RecLoss: 0.0000 (left: 0:00:09)\n",
      "TestLoss: 1.0873 MAE: 0.8272 RMSE: 1.0427\n",
      "ValLoss: 0.9505 MAE: 0.8022 RMSE: 0.9749\n",
      "Epoch 94: TrainLoss 0.9143 RecLoss: 0.0000 (left: 0:00:08)\n",
      "TestLoss: 1.0840 MAE: 0.8237 RMSE: 1.0411\n",
      "ValLoss: 0.9494 MAE: 0.7993 RMSE: 0.9744\n",
      "Epoch 95: TrainLoss 0.9139 RecLoss: 0.0000 (left: 0:00:06)\n",
      "TestLoss: 1.0880 MAE: 0.8279 RMSE: 1.0431\n",
      "ValLoss: 0.9510 MAE: 0.8027 RMSE: 0.9752\n",
      "Epoch 96: TrainLoss 0.9147 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 1.0851 MAE: 0.8249 RMSE: 1.0417\n",
      "ValLoss: 0.9495 MAE: 0.8002 RMSE: 0.9744\n",
      "Epoch 97: TrainLoss 0.9140 RecLoss: 0.0000 (left: 0:00:04)\n",
      "TestLoss: 1.0849 MAE: 0.8251 RMSE: 1.0416\n",
      "ValLoss: 0.9487 MAE: 0.8003 RMSE: 0.9740\n",
      "Epoch 98: TrainLoss 0.9152 RecLoss: 0.0000 (left: 0:00:02)\n",
      "TestLoss: 1.0852 MAE: 0.8253 RMSE: 1.0417\n",
      "ValLoss: 0.9448 MAE: 0.7986 RMSE: 0.9720\n",
      "Epoch 99: TrainLoss 0.9144 RecLoss: 0.0000 (left: 0:00:01)\n",
      "TestLoss: 1.0850 MAE: 0.8251 RMSE: 1.0417\n",
      "ValLoss: 0.9470 MAE: 0.7993 RMSE: 0.9732\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 94119/4938\n",
      "test set size: support/query 730/213\n",
      "USER HIS DICT: 943\n",
      "NUM IS: 943\n",
      "Key Test Result: MAE: 0.7308 RMSE: 0.9396 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 943\n",
      "NUM IS: 943\n",
      "Que Test Result: MAE: 0.8377 RMSE: 1.0490 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.7549 RMSE: 0.9654 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10% cos input to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 21136/4938\n",
      "test set size: support/query 73/213\n",
      "Epoch 0 Step 20: Train 12.6638 Reg: 0.4718\n",
      "Test: 12.3028 MAE: 3.2904 RMSE: 3.5075\n",
      "Val: 11.9895 MAE: 3.2932 RMSE: 3.4626\n",
      "Epoch 1 Step 40: Train 9.5591 Reg: 0.3460\n",
      "Test: 7.2368 MAE: 2.4206 RMSE: 2.6901\n",
      "Val: 6.9091 MAE: 2.4159 RMSE: 2.6285\n",
      "Epoch 2 Step 60: Train 3.7124 Reg: 0.2992\n",
      "Test: 1.9068 MAE: 1.1742 RMSE: 1.3809\n",
      "Val: 1.5862 MAE: 1.0526 RMSE: 1.2594\n",
      "Epoch 3 Step 80: Train 1.1169 Reg: 0.2929\n",
      "Test: 1.3503 MAE: 1.0018 RMSE: 1.1620\n",
      "Val: 1.0567 MAE: 0.8650 RMSE: 1.0279\n",
      "Epoch 4 Step 100: Train 0.9742 Reg: 0.2849\n",
      "Test: 1.2662 MAE: 0.9685 RMSE: 1.1253\n",
      "Val: 1.0115 MAE: 0.8424 RMSE: 1.0057\n",
      "Epoch 5 Step 120: Train 0.8989 Reg: 0.2748\n",
      "Test: 1.1744 MAE: 0.9315 RMSE: 1.0837\n",
      "Val: 0.9631 MAE: 0.8255 RMSE: 0.9814\n",
      "Epoch 6 Step 140: Train 0.8318 Reg: 0.2708\n",
      "Test: 1.0948 MAE: 0.8897 RMSE: 1.0463\n",
      "Val: 0.9213 MAE: 0.8032 RMSE: 0.9599\n",
      "Epoch 7 Step 160: Train 0.7778 Reg: 0.2707\n",
      "Test: 1.0302 MAE: 0.8611 RMSE: 1.0150\n",
      "Val: 0.8893 MAE: 0.7810 RMSE: 0.9430\n",
      "Epoch 8 Step 180: Train 0.7384 Reg: 0.2717\n",
      "Test: 0.9876 MAE: 0.8404 RMSE: 0.9938\n",
      "Val: 0.8658 MAE: 0.7600 RMSE: 0.9305\n",
      "Epoch 9 Step 200: Train 0.7125 Reg: 0.2719\n",
      "Test: 0.9641 MAE: 0.8276 RMSE: 0.9819\n",
      "Val: 0.8537 MAE: 0.7467 RMSE: 0.9240\n",
      "Epoch 10 Step 220: Train 0.6952 Reg: 0.2710\n",
      "Test: 0.9564 MAE: 0.8190 RMSE: 0.9780\n",
      "Val: 0.8427 MAE: 0.7376 RMSE: 0.9180\n",
      "Epoch 11 Step 240: Train 0.6833 Reg: 0.2698\n",
      "Test: 0.9510 MAE: 0.8144 RMSE: 0.9752\n",
      "Val: 0.8369 MAE: 0.7334 RMSE: 0.9148\n",
      "Epoch 12 Step 260: Train 0.6744 Reg: 0.2682\n",
      "Test: 0.9420 MAE: 0.8093 RMSE: 0.9706\n",
      "Val: 0.8307 MAE: 0.7300 RMSE: 0.9114\n",
      "Epoch 13 Step 280: Train 0.6677 Reg: 0.2667\n",
      "Test: 0.9435 MAE: 0.8051 RMSE: 0.9713\n",
      "Val: 0.8264 MAE: 0.7274 RMSE: 0.9091\n",
      "Epoch 14 Step 300: Train 0.6625 Reg: 0.2652\n",
      "Test: 0.9447 MAE: 0.8041 RMSE: 0.9719\n",
      "Val: 0.8230 MAE: 0.7254 RMSE: 0.9072\n",
      "Epoch 15 Step 320: Train 0.6585 Reg: 0.2638\n",
      "Test: 0.9409 MAE: 0.8007 RMSE: 0.9700\n",
      "Val: 0.8210 MAE: 0.7243 RMSE: 0.9061\n",
      "Epoch 16 Step 340: Train 0.6552 Reg: 0.2622\n",
      "Test: 0.9416 MAE: 0.7978 RMSE: 0.9703\n",
      "Val: 0.8187 MAE: 0.7233 RMSE: 0.9048\n",
      "Epoch 17 Step 360: Train 0.6522 Reg: 0.2607\n",
      "Test: 0.9431 MAE: 0.7965 RMSE: 0.9711\n",
      "Val: 0.8171 MAE: 0.7228 RMSE: 0.9039\n",
      "Epoch 18 Step 380: Train 0.6500 Reg: 0.2595\n",
      "Test: 0.9348 MAE: 0.7922 RMSE: 0.9668\n",
      "Val: 0.8151 MAE: 0.7216 RMSE: 0.9028\n",
      "Epoch 19 Step 400: Train 0.6480 Reg: 0.2581\n",
      "Test: 0.9381 MAE: 0.7930 RMSE: 0.9685\n",
      "Val: 0.8149 MAE: 0.7221 RMSE: 0.9027\n",
      "Epoch 20 Step 420: Train 0.6462 Reg: 0.2567\n",
      "Test: 0.9314 MAE: 0.7891 RMSE: 0.9651\n",
      "Val: 0.8131 MAE: 0.7213 RMSE: 0.9017\n",
      "Epoch 21 Step 440: Train 0.6448 Reg: 0.2555\n",
      "Test: 0.9303 MAE: 0.7880 RMSE: 0.9645\n",
      "Val: 0.8128 MAE: 0.7216 RMSE: 0.9015\n",
      "Epoch 22 Step 460: Train 0.6436 Reg: 0.2543\n",
      "Test: 0.9287 MAE: 0.7883 RMSE: 0.9637\n",
      "Val: 0.8101 MAE: 0.7204 RMSE: 0.9001\n",
      "Epoch 23 Step 480: Train 0.6424 Reg: 0.2531\n",
      "Test: 0.9282 MAE: 0.7861 RMSE: 0.9635\n",
      "Val: 0.8101 MAE: 0.7206 RMSE: 0.9000\n",
      "Epoch 24 Step 500: Train 0.6413 Reg: 0.2522\n",
      "Test: 0.9254 MAE: 0.7836 RMSE: 0.9620\n",
      "Val: 0.8094 MAE: 0.7201 RMSE: 0.8997\n",
      "Epoch 25 Step 520: Train 0.6404 Reg: 0.2511\n",
      "Test: 0.9262 MAE: 0.7832 RMSE: 0.9624\n",
      "Val: 0.8084 MAE: 0.7196 RMSE: 0.8991\n",
      "Epoch 26 Step 540: Train 0.6395 Reg: 0.2502\n",
      "Test: 0.9217 MAE: 0.7824 RMSE: 0.9600\n",
      "Val: 0.8082 MAE: 0.7200 RMSE: 0.8990\n",
      "Epoch 27 Step 560: Train 0.6388 Reg: 0.2492\n",
      "Test: 0.9256 MAE: 0.7851 RMSE: 0.9621\n",
      "Val: 0.8077 MAE: 0.7195 RMSE: 0.8987\n",
      "Epoch 28 Step 580: Train 0.6381 Reg: 0.2483\n",
      "Test: 0.9193 MAE: 0.7807 RMSE: 0.9588\n",
      "Val: 0.8073 MAE: 0.7195 RMSE: 0.8985\n",
      "Epoch 29 Step 600: Train 0.6375 Reg: 0.2475\n",
      "Test: 0.9172 MAE: 0.7797 RMSE: 0.9577\n",
      "Val: 0.8067 MAE: 0.7191 RMSE: 0.8982\n",
      "Epoch 30 Step 620: Train 0.6369 Reg: 0.2467\n",
      "Test: 0.9192 MAE: 0.7803 RMSE: 0.9587\n",
      "Val: 0.8066 MAE: 0.7193 RMSE: 0.8981\n",
      "Epoch 31 Step 640: Train 0.6363 Reg: 0.2459\n",
      "Test: 0.9157 MAE: 0.7777 RMSE: 0.9569\n",
      "Val: 0.8058 MAE: 0.7188 RMSE: 0.8977\n",
      "Epoch 32 Step 660: Train 0.6359 Reg: 0.2451\n",
      "Test: 0.9169 MAE: 0.7781 RMSE: 0.9575\n",
      "Val: 0.8049 MAE: 0.7187 RMSE: 0.8971\n",
      "Epoch 33 Step 680: Train 0.6355 Reg: 0.2444\n",
      "Test: 0.9167 MAE: 0.7783 RMSE: 0.9574\n",
      "Val: 0.8051 MAE: 0.7186 RMSE: 0.8973\n",
      "Epoch 34 Step 700: Train 0.6350 Reg: 0.2438\n",
      "Test: 0.9164 MAE: 0.7774 RMSE: 0.9573\n",
      "Val: 0.8054 MAE: 0.7188 RMSE: 0.8974\n",
      "Epoch 35 Step 720: Train 0.6346 Reg: 0.2432\n",
      "Test: 0.9173 MAE: 0.7783 RMSE: 0.9578\n",
      "Val: 0.8049 MAE: 0.7186 RMSE: 0.8972\n",
      "Epoch 36 Step 740: Train 0.6342 Reg: 0.2426\n",
      "Test: 0.9159 MAE: 0.7771 RMSE: 0.9570\n",
      "Val: 0.8043 MAE: 0.7184 RMSE: 0.8968\n",
      "Epoch 37 Step 760: Train 0.6339 Reg: 0.2419\n",
      "Test: 0.9173 MAE: 0.7784 RMSE: 0.9577\n",
      "Val: 0.8045 MAE: 0.7186 RMSE: 0.8969\n",
      "Epoch 38 Step 780: Train 0.6335 Reg: 0.2415\n",
      "Test: 0.9158 MAE: 0.7765 RMSE: 0.9570\n",
      "Val: 0.8039 MAE: 0.7181 RMSE: 0.8966\n",
      "Epoch 39 Step 800: Train 0.6332 Reg: 0.2409\n",
      "Test: 0.9133 MAE: 0.7755 RMSE: 0.9557\n",
      "Val: 0.8039 MAE: 0.7180 RMSE: 0.8966\n",
      "Epoch 40 Step 820: Train 0.6330 Reg: 0.2404\n",
      "Test: 0.9138 MAE: 0.7753 RMSE: 0.9559\n",
      "Val: 0.8037 MAE: 0.7182 RMSE: 0.8965\n",
      "Epoch 41 Step 840: Train 0.6326 Reg: 0.2399\n",
      "Test: 0.9115 MAE: 0.7751 RMSE: 0.9547\n",
      "Val: 0.8035 MAE: 0.7181 RMSE: 0.8964\n",
      "Epoch 42 Step 860: Train 0.6324 Reg: 0.2395\n",
      "Test: 0.9118 MAE: 0.7750 RMSE: 0.9549\n",
      "Val: 0.8038 MAE: 0.7182 RMSE: 0.8966\n",
      "Epoch 43 Step 880: Train 0.6321 Reg: 0.2391\n",
      "Test: 0.9108 MAE: 0.7739 RMSE: 0.9543\n",
      "Val: 0.8032 MAE: 0.7178 RMSE: 0.8962\n",
      "Epoch 44 Step 900: Train 0.6319 Reg: 0.2387\n",
      "Test: 0.9117 MAE: 0.7745 RMSE: 0.9548\n",
      "Val: 0.8031 MAE: 0.7178 RMSE: 0.8962\n",
      "Epoch 45 Step 920: Train 0.6317 Reg: 0.2383\n",
      "Test: 0.9117 MAE: 0.7746 RMSE: 0.9548\n",
      "Val: 0.8030 MAE: 0.7178 RMSE: 0.8961\n",
      "Epoch 46 Step 940: Train 0.6315 Reg: 0.2379\n",
      "Test: 0.9124 MAE: 0.7752 RMSE: 0.9552\n",
      "Val: 0.8026 MAE: 0.7178 RMSE: 0.8959\n",
      "Epoch 47 Step 960: Train 0.6314 Reg: 0.2376\n",
      "Test: 0.9110 MAE: 0.7740 RMSE: 0.9545\n",
      "Val: 0.8029 MAE: 0.7177 RMSE: 0.8960\n",
      "Epoch 48 Step 980: Train 0.6312 Reg: 0.2372\n",
      "Test: 0.9109 MAE: 0.7742 RMSE: 0.9544\n",
      "Val: 0.8025 MAE: 0.7176 RMSE: 0.8958\n",
      "Epoch 49 Step 1000: Train 0.6309 Reg: 0.2369\n",
      "Test: 0.9099 MAE: 0.7737 RMSE: 0.9539\n",
      "Val: 0.8025 MAE: 0.7176 RMSE: 0.8958\n",
      "Epoch 50 Step 1020: Train 0.6308 Reg: 0.2366\n",
      "Test: 0.9113 MAE: 0.7740 RMSE: 0.9546\n",
      "Val: 0.8022 MAE: 0.7175 RMSE: 0.8957\n",
      "Epoch 51 Step 1040: Train 0.6306 Reg: 0.2363\n",
      "Test: 0.9105 MAE: 0.7739 RMSE: 0.9542\n",
      "Val: 0.8022 MAE: 0.7174 RMSE: 0.8956\n",
      "Epoch 52 Step 1060: Train 0.6305 Reg: 0.2361\n",
      "Test: 0.9098 MAE: 0.7735 RMSE: 0.9538\n",
      "Val: 0.8021 MAE: 0.7174 RMSE: 0.8956\n",
      "Epoch 53 Step 1080: Train 0.6303 Reg: 0.2358\n",
      "Test: 0.9089 MAE: 0.7730 RMSE: 0.9534\n",
      "Val: 0.8019 MAE: 0.7173 RMSE: 0.8955\n",
      "Epoch 54 Step 1100: Train 0.6302 Reg: 0.2356\n",
      "Test: 0.9090 MAE: 0.7728 RMSE: 0.9534\n",
      "Val: 0.8021 MAE: 0.7174 RMSE: 0.8956\n",
      "Epoch 55 Step 1120: Train 0.6301 Reg: 0.2354\n",
      "Test: 0.9097 MAE: 0.7733 RMSE: 0.9538\n",
      "Val: 0.8021 MAE: 0.7174 RMSE: 0.8956\n",
      "Epoch 56 Step 1140: Train 0.6299 Reg: 0.2351\n",
      "Test: 0.9094 MAE: 0.7729 RMSE: 0.9536\n",
      "Val: 0.8020 MAE: 0.7173 RMSE: 0.8955\n",
      "Epoch 57 Step 1160: Train 0.6298 Reg: 0.2349\n",
      "Test: 0.9095 MAE: 0.7734 RMSE: 0.9537\n",
      "Val: 0.8020 MAE: 0.7175 RMSE: 0.8956\n",
      "Epoch 58 Step 1180: Train 0.6297 Reg: 0.2347\n",
      "Test: 0.9091 MAE: 0.7729 RMSE: 0.9535\n",
      "Val: 0.8019 MAE: 0.7173 RMSE: 0.8955\n",
      "Epoch 59 Step 1200: Train 0.6296 Reg: 0.2345\n",
      "Test: 0.9086 MAE: 0.7726 RMSE: 0.9532\n",
      "Val: 0.8018 MAE: 0.7173 RMSE: 0.8954\n",
      "Epoch 60 Step 1220: Train 0.6295 Reg: 0.2343\n",
      "Test: 0.9084 MAE: 0.7725 RMSE: 0.9531\n",
      "Val: 0.8016 MAE: 0.7172 RMSE: 0.8953\n",
      "Epoch 61 Step 1240: Train 0.6294 Reg: 0.2342\n",
      "Test: 0.9084 MAE: 0.7724 RMSE: 0.9531\n",
      "Val: 0.8017 MAE: 0.7172 RMSE: 0.8954\n",
      "Epoch 62 Step 1260: Train 0.6293 Reg: 0.2340\n",
      "Test: 0.9081 MAE: 0.7723 RMSE: 0.9530\n",
      "Val: 0.8017 MAE: 0.7172 RMSE: 0.8954\n",
      "Epoch 63 Step 1280: Train 0.6292 Reg: 0.2338\n",
      "Test: 0.9081 MAE: 0.7723 RMSE: 0.9530\n",
      "Val: 0.8017 MAE: 0.7172 RMSE: 0.8954\n",
      "Epoch 64 Step 1300: Train 0.6292 Reg: 0.2337\n",
      "Test: 0.9080 MAE: 0.7721 RMSE: 0.9529\n",
      "Val: 0.8017 MAE: 0.7171 RMSE: 0.8954\n",
      "Epoch 65 Step 1320: Train 0.6291 Reg: 0.2336\n",
      "Test: 0.9086 MAE: 0.7726 RMSE: 0.9532\n",
      "Val: 0.8015 MAE: 0.7172 RMSE: 0.8953\n",
      "Epoch 66 Step 1340: Train 0.6290 Reg: 0.2334\n",
      "Test: 0.9084 MAE: 0.7725 RMSE: 0.9531\n",
      "Val: 0.8014 MAE: 0.7171 RMSE: 0.8952\n",
      "Epoch 67 Step 1360: Train 0.6289 Reg: 0.2333\n",
      "Test: 0.9083 MAE: 0.7725 RMSE: 0.9530\n",
      "Val: 0.8015 MAE: 0.7172 RMSE: 0.8953\n",
      "Epoch 68 Step 1380: Train 0.6288 Reg: 0.2332\n",
      "Test: 0.9081 MAE: 0.7722 RMSE: 0.9529\n",
      "Val: 0.8015 MAE: 0.7171 RMSE: 0.8953\n",
      "Epoch 69 Step 1400: Train 0.6288 Reg: 0.2331\n",
      "Test: 0.9078 MAE: 0.7721 RMSE: 0.9528\n",
      "Val: 0.8015 MAE: 0.7171 RMSE: 0.8953\n",
      "Epoch 70 Step 1420: Train 0.6287 Reg: 0.2330\n",
      "Test: 0.9074 MAE: 0.7719 RMSE: 0.9526\n",
      "Val: 0.8015 MAE: 0.7171 RMSE: 0.8953\n",
      "Epoch 71 Step 1440: Train 0.6287 Reg: 0.2329\n",
      "Test: 0.9075 MAE: 0.7721 RMSE: 0.9526\n",
      "Val: 0.8015 MAE: 0.7171 RMSE: 0.8952\n",
      "Epoch 72 Step 1460: Train 0.6286 Reg: 0.2328\n",
      "Test: 0.9079 MAE: 0.7722 RMSE: 0.9528\n",
      "Val: 0.8014 MAE: 0.7171 RMSE: 0.8952\n",
      "Epoch 73 Step 1480: Train 0.6286 Reg: 0.2327\n",
      "Test: 0.9077 MAE: 0.7720 RMSE: 0.9527\n",
      "Val: 0.8014 MAE: 0.7171 RMSE: 0.8952\n",
      "Epoch 74 Step 1500: Train 0.6285 Reg: 0.2326\n",
      "Test: 0.9077 MAE: 0.7721 RMSE: 0.9528\n",
      "Val: 0.8014 MAE: 0.7171 RMSE: 0.8952\n",
      "Epoch 75 Step 1520: Train 0.6285 Reg: 0.2325\n",
      "Test: 0.9077 MAE: 0.7720 RMSE: 0.9527\n",
      "Val: 0.8013 MAE: 0.7171 RMSE: 0.8952\n",
      "Epoch 76 Step 1540: Train 0.6284 Reg: 0.2324\n",
      "Test: 0.9073 MAE: 0.7719 RMSE: 0.9525\n",
      "Val: 0.8014 MAE: 0.7170 RMSE: 0.8952\n",
      "Epoch 77 Step 1560: Train 0.6284 Reg: 0.2323\n",
      "Test: 0.9074 MAE: 0.7719 RMSE: 0.9526\n",
      "Val: 0.8013 MAE: 0.7170 RMSE: 0.8952\n",
      "Epoch 78 Step 1580: Train 0.6283 Reg: 0.2323\n",
      "Test: 0.9072 MAE: 0.7718 RMSE: 0.9525\n",
      "Val: 0.8013 MAE: 0.7170 RMSE: 0.8951\n",
      "Epoch 79 Step 1600: Train 0.6283 Reg: 0.2322\n",
      "Test: 0.9073 MAE: 0.7719 RMSE: 0.9525\n",
      "Val: 0.8013 MAE: 0.7170 RMSE: 0.8952\n",
      "Epoch 80 Step 1620: Train 0.6283 Reg: 0.2321\n",
      "Test: 0.9075 MAE: 0.7719 RMSE: 0.9526\n",
      "Val: 0.8012 MAE: 0.7170 RMSE: 0.8951\n",
      "Epoch 81 Step 1640: Train 0.6282 Reg: 0.2321\n",
      "Test: 0.9073 MAE: 0.7716 RMSE: 0.9525\n",
      "Val: 0.8012 MAE: 0.7170 RMSE: 0.8951\n",
      "Epoch 82 Step 1660: Train 0.6282 Reg: 0.2320\n",
      "Test: 0.9072 MAE: 0.7717 RMSE: 0.9525\n",
      "Val: 0.8012 MAE: 0.7170 RMSE: 0.8951\n",
      "Epoch 83 Step 1680: Train 0.6282 Reg: 0.2320\n",
      "Test: 0.9070 MAE: 0.7716 RMSE: 0.9524\n",
      "Val: 0.8012 MAE: 0.7169 RMSE: 0.8951\n",
      "Epoch 84 Step 1700: Train 0.6281 Reg: 0.2319\n",
      "Test: 0.9070 MAE: 0.7716 RMSE: 0.9524\n",
      "Val: 0.8013 MAE: 0.7170 RMSE: 0.8951\n",
      "Epoch 85 Step 1720: Train 0.6281 Reg: 0.2319\n",
      "Test: 0.9070 MAE: 0.7716 RMSE: 0.9524\n",
      "Val: 0.8013 MAE: 0.7170 RMSE: 0.8951\n",
      "Epoch 86 Step 1740: Train 0.6281 Reg: 0.2318\n",
      "Test: 0.9069 MAE: 0.7715 RMSE: 0.9523\n",
      "Val: 0.8012 MAE: 0.7170 RMSE: 0.8951\n",
      "Epoch 87 Step 1760: Train 0.6280 Reg: 0.2318\n",
      "Test: 0.9071 MAE: 0.7716 RMSE: 0.9524\n",
      "Val: 0.8012 MAE: 0.7170 RMSE: 0.8951\n",
      "Epoch 88 Step 1780: Train 0.6280 Reg: 0.2317\n",
      "Test: 0.9069 MAE: 0.7715 RMSE: 0.9523\n",
      "Val: 0.8012 MAE: 0.7170 RMSE: 0.8951\n",
      "Epoch 89 Step 1800: Train 0.6280 Reg: 0.2317\n",
      "Test: 0.9070 MAE: 0.7716 RMSE: 0.9523\n",
      "Val: 0.8012 MAE: 0.7169 RMSE: 0.8951\n",
      "Epoch 90 Step 1820: Train 0.6280 Reg: 0.2316\n",
      "Test: 0.9069 MAE: 0.7714 RMSE: 0.9523\n",
      "Val: 0.8012 MAE: 0.7169 RMSE: 0.8951\n",
      "Epoch 91 Step 1840: Train 0.6279 Reg: 0.2316\n",
      "Test: 0.9069 MAE: 0.7714 RMSE: 0.9523\n",
      "Val: 0.8012 MAE: 0.7169 RMSE: 0.8951\n",
      "Epoch 92 Step 1860: Train 0.6279 Reg: 0.2316\n",
      "Test: 0.9069 MAE: 0.7715 RMSE: 0.9523\n",
      "Val: 0.8011 MAE: 0.7169 RMSE: 0.8951\n",
      "Epoch 93 Step 1880: Train 0.6279 Reg: 0.2315\n",
      "Test: 0.9068 MAE: 0.7714 RMSE: 0.9523\n",
      "Val: 0.8011 MAE: 0.7169 RMSE: 0.8951\n",
      "Epoch 94 Step 1900: Train 0.6279 Reg: 0.2315\n",
      "Test: 0.9068 MAE: 0.7713 RMSE: 0.9523\n",
      "Val: 0.8011 MAE: 0.7169 RMSE: 0.8951\n",
      "Epoch 95 Step 1920: Train 0.6279 Reg: 0.2315\n",
      "Test: 0.9068 MAE: 0.7714 RMSE: 0.9523\n",
      "Val: 0.8011 MAE: 0.7169 RMSE: 0.8950\n",
      "Epoch 96 Step 1940: Train 0.6278 Reg: 0.2314\n",
      "Test: 0.9068 MAE: 0.7714 RMSE: 0.9523\n",
      "Val: 0.8011 MAE: 0.7169 RMSE: 0.8951\n",
      "Epoch 97 Step 1960: Train 0.6278 Reg: 0.2314\n",
      "Test: 0.9067 MAE: 0.7714 RMSE: 0.9522\n",
      "Val: 0.8011 MAE: 0.7169 RMSE: 0.8951\n",
      "Epoch 98 Step 1980: Train 0.6278 Reg: 0.2314\n",
      "Test: 0.9068 MAE: 0.7714 RMSE: 0.9523\n",
      "Val: 0.8011 MAE: 0.7169 RMSE: 0.8951\n",
      "Epoch 99 Step 2000: Train 0.6278 Reg: 0.2314\n",
      "Test: 0.9067 MAE: 0.7714 RMSE: 0.9522\n",
      "Val: 0.8011 MAE: 0.7169 RMSE: 0.8951\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 21136/4938\n",
      "test set size: support/query 73/213\n",
      "Epoch 0: TrainLoss 1.9814 RecLoss: 0.0000 (left: 0:03:09)\n",
      "TestLoss: 2.0121 MAE: 1.1780 RMSE: 1.4185\n",
      "ValLoss: 1.7883 MAE: 1.1014 RMSE: 1.3373\n",
      "Epoch 1: TrainLoss 1.3337 RecLoss: 0.0000 (left: 0:02:28)\n",
      "TestLoss: 1.3699 MAE: 0.9643 RMSE: 1.1704\n",
      "ValLoss: 1.2491 MAE: 0.9349 RMSE: 1.1176\n",
      "Epoch 2: TrainLoss 1.1965 RecLoss: 0.0000 (left: 0:02:11)\n",
      "TestLoss: 1.3722 MAE: 0.9955 RMSE: 1.1714\n",
      "ValLoss: 1.2648 MAE: 0.9705 RMSE: 1.1247\n",
      "Epoch 3: TrainLoss 1.1769 RecLoss: 0.0000 (left: 0:01:58)\n",
      "TestLoss: 1.3407 MAE: 0.9831 RMSE: 1.1579\n",
      "ValLoss: 1.2249 MAE: 0.9596 RMSE: 1.1067\n",
      "Epoch 4: TrainLoss 1.1279 RecLoss: 0.0000 (left: 0:01:54)\n",
      "TestLoss: 1.2615 MAE: 0.9321 RMSE: 1.1232\n",
      "ValLoss: 1.1110 MAE: 0.8950 RMSE: 1.0540\n",
      "Epoch 5: TrainLoss 1.0898 RecLoss: 0.0000 (left: 0:01:55)\n",
      "TestLoss: 1.2416 MAE: 0.8991 RMSE: 1.1143\n",
      "ValLoss: 1.0637 MAE: 0.8519 RMSE: 1.0313\n",
      "Epoch 6: TrainLoss 1.0779 RecLoss: 0.0000 (left: 0:01:55)\n",
      "TestLoss: 1.2341 MAE: 0.9068 RMSE: 1.1109\n",
      "ValLoss: 1.0477 MAE: 0.8584 RMSE: 1.0236\n",
      "Epoch 7: TrainLoss 1.0524 RecLoss: 0.0000 (left: 0:01:58)\n",
      "TestLoss: 1.2170 MAE: 0.8956 RMSE: 1.1032\n",
      "ValLoss: 1.0618 MAE: 0.8694 RMSE: 1.0305\n",
      "Epoch 8: TrainLoss 1.0415 RecLoss: 0.0000 (left: 0:01:57)\n",
      "TestLoss: 1.2123 MAE: 0.8995 RMSE: 1.1010\n",
      "ValLoss: 1.0574 MAE: 0.8721 RMSE: 1.0283\n",
      "Epoch 9: TrainLoss 1.0299 RecLoss: 0.0000 (left: 0:01:56)\n",
      "TestLoss: 1.1952 MAE: 0.8839 RMSE: 1.0933\n",
      "ValLoss: 1.0351 MAE: 0.8564 RMSE: 1.0174\n",
      "Epoch 10: TrainLoss 1.0203 RecLoss: 0.0000 (left: 0:01:55)\n",
      "TestLoss: 1.1893 MAE: 0.8837 RMSE: 1.0905\n",
      "ValLoss: 1.0121 MAE: 0.8449 RMSE: 1.0060\n",
      "Epoch 11: TrainLoss 1.0124 RecLoss: 0.0000 (left: 0:01:56)\n",
      "TestLoss: 1.1803 MAE: 0.8778 RMSE: 1.0864\n",
      "ValLoss: 1.0053 MAE: 0.8404 RMSE: 1.0026\n",
      "Epoch 12: TrainLoss 1.0044 RecLoss: 0.0000 (left: 0:01:54)\n",
      "TestLoss: 1.1716 MAE: 0.8660 RMSE: 1.0824\n",
      "ValLoss: 1.0187 MAE: 0.8435 RMSE: 1.0093\n",
      "Epoch 13: TrainLoss 1.0009 RecLoss: 0.0000 (left: 0:01:53)\n",
      "TestLoss: 1.1823 MAE: 0.8863 RMSE: 1.0874\n",
      "ValLoss: 1.0248 MAE: 0.8553 RMSE: 1.0123\n",
      "Epoch 14: TrainLoss 0.9948 RecLoss: 0.0000 (left: 0:01:51)\n",
      "TestLoss: 1.1592 MAE: 0.8588 RMSE: 1.0767\n",
      "ValLoss: 1.0258 MAE: 0.8468 RMSE: 1.0128\n",
      "Epoch 15: TrainLoss 0.9892 RecLoss: 0.0000 (left: 0:01:47)\n",
      "TestLoss: 1.1674 MAE: 0.8774 RMSE: 1.0805\n",
      "ValLoss: 1.0126 MAE: 0.8471 RMSE: 1.0063\n",
      "Epoch 16: TrainLoss 0.9796 RecLoss: 0.0000 (left: 0:01:45)\n",
      "TestLoss: 1.1466 MAE: 0.8544 RMSE: 1.0708\n",
      "ValLoss: 1.0084 MAE: 0.8390 RMSE: 1.0042\n",
      "Epoch 17: TrainLoss 0.9774 RecLoss: 0.0000 (left: 0:01:42)\n",
      "TestLoss: 1.1461 MAE: 0.8612 RMSE: 1.0706\n",
      "ValLoss: 0.9982 MAE: 0.8371 RMSE: 0.9991\n",
      "Epoch 18: TrainLoss 0.9721 RecLoss: 0.0000 (left: 0:01:39)\n",
      "TestLoss: 1.1425 MAE: 0.8588 RMSE: 1.0689\n",
      "ValLoss: 1.0003 MAE: 0.8384 RMSE: 1.0002\n",
      "Epoch 19: TrainLoss 0.9696 RecLoss: 0.0000 (left: 0:01:38)\n",
      "TestLoss: 1.1366 MAE: 0.8473 RMSE: 1.0661\n",
      "ValLoss: 1.0055 MAE: 0.8363 RMSE: 1.0027\n",
      "Epoch 20: TrainLoss 0.9656 RecLoss: 0.0000 (left: 0:01:36)\n",
      "TestLoss: 1.1503 MAE: 0.8664 RMSE: 1.0725\n",
      "ValLoss: 1.0018 MAE: 0.8399 RMSE: 1.0009\n",
      "Epoch 21: TrainLoss 0.9647 RecLoss: 0.0000 (left: 0:01:34)\n",
      "TestLoss: 1.1315 MAE: 0.8445 RMSE: 1.0637\n",
      "ValLoss: 1.0052 MAE: 0.8358 RMSE: 1.0026\n",
      "Epoch 22: TrainLoss 0.9625 RecLoss: 0.0000 (left: 0:01:32)\n",
      "TestLoss: 1.1349 MAE: 0.8541 RMSE: 1.0653\n",
      "ValLoss: 0.9918 MAE: 0.8331 RMSE: 0.9959\n",
      "Epoch 23: TrainLoss 0.9545 RecLoss: 0.0000 (left: 0:01:30)\n",
      "TestLoss: 1.1272 MAE: 0.8421 RMSE: 1.0617\n",
      "ValLoss: 0.9971 MAE: 0.8303 RMSE: 0.9985\n",
      "Epoch 24: TrainLoss 0.9540 RecLoss: 0.0000 (left: 0:01:28)\n",
      "TestLoss: 1.1402 MAE: 0.8592 RMSE: 1.0678\n",
      "ValLoss: 0.9936 MAE: 0.8348 RMSE: 0.9968\n",
      "Epoch 25: TrainLoss 0.9553 RecLoss: 0.0000 (left: 0:01:26)\n",
      "TestLoss: 1.1265 MAE: 0.8369 RMSE: 1.0614\n",
      "ValLoss: 1.0035 MAE: 0.8305 RMSE: 1.0017\n",
      "Epoch 26: TrainLoss 0.9551 RecLoss: 0.0000 (left: 0:01:25)\n",
      "TestLoss: 1.1557 MAE: 0.8689 RMSE: 1.0750\n",
      "ValLoss: 1.0029 MAE: 0.8394 RMSE: 1.0015\n",
      "Epoch 27: TrainLoss 0.9592 RecLoss: 0.0000 (left: 0:01:24)\n",
      "TestLoss: 1.1213 MAE: 0.8365 RMSE: 1.0589\n",
      "ValLoss: 1.0058 MAE: 0.8329 RMSE: 1.0029\n",
      "Epoch 28: TrainLoss 0.9493 RecLoss: 0.0000 (left: 0:01:24)\n",
      "TestLoss: 1.1311 MAE: 0.8536 RMSE: 1.0635\n",
      "ValLoss: 0.9965 MAE: 0.8352 RMSE: 0.9982\n",
      "Epoch 29: TrainLoss 0.9508 RecLoss: 0.0000 (left: 0:01:22)\n",
      "TestLoss: 1.1194 MAE: 0.8393 RMSE: 1.0580\n",
      "ValLoss: 0.9907 MAE: 0.8266 RMSE: 0.9953\n",
      "Epoch 30: TrainLoss 0.9507 RecLoss: 0.0000 (left: 0:01:21)\n",
      "TestLoss: 1.1189 MAE: 0.8359 RMSE: 1.0578\n",
      "ValLoss: 0.9934 MAE: 0.8257 RMSE: 0.9967\n",
      "Epoch 31: TrainLoss 0.9529 RecLoss: 0.0000 (left: 0:01:20)\n",
      "TestLoss: 1.1381 MAE: 0.8591 RMSE: 1.0668\n",
      "ValLoss: 1.0057 MAE: 0.8401 RMSE: 1.0029\n",
      "Epoch 32: TrainLoss 0.9516 RecLoss: 0.0000 (left: 0:01:19)\n",
      "TestLoss: 1.1162 MAE: 0.8342 RMSE: 1.0565\n",
      "ValLoss: 1.0011 MAE: 0.8298 RMSE: 1.0005\n",
      "Epoch 33: TrainLoss 0.9453 RecLoss: 0.0000 (left: 0:01:17)\n",
      "TestLoss: 1.1220 MAE: 0.8444 RMSE: 1.0592\n",
      "ValLoss: 0.9875 MAE: 0.8267 RMSE: 0.9937\n",
      "Epoch 34: TrainLoss 0.9416 RecLoss: 0.0000 (left: 0:01:16)\n",
      "TestLoss: 1.1177 MAE: 0.8373 RMSE: 1.0572\n",
      "ValLoss: 0.9866 MAE: 0.8226 RMSE: 0.9933\n",
      "Epoch 35: TrainLoss 0.9417 RecLoss: 0.0000 (left: 0:01:15)\n",
      "TestLoss: 1.1179 MAE: 0.8393 RMSE: 1.0573\n",
      "ValLoss: 0.9871 MAE: 0.8242 RMSE: 0.9935\n",
      "Epoch 36: TrainLoss 0.9408 RecLoss: 0.0000 (left: 0:01:14)\n",
      "TestLoss: 1.1151 MAE: 0.8353 RMSE: 1.0560\n",
      "ValLoss: 0.9949 MAE: 0.8274 RMSE: 0.9975\n",
      "Epoch 37: TrainLoss 0.9396 RecLoss: 0.0000 (left: 0:01:13)\n",
      "TestLoss: 1.1262 MAE: 0.8485 RMSE: 1.0612\n",
      "ValLoss: 0.9912 MAE: 0.8301 RMSE: 0.9956\n",
      "Epoch 38: TrainLoss 0.9391 RecLoss: 0.0000 (left: 0:01:12)\n",
      "TestLoss: 1.1161 MAE: 0.8340 RMSE: 1.0565\n",
      "ValLoss: 0.9907 MAE: 0.8235 RMSE: 0.9953\n",
      "Epoch 39: TrainLoss 0.9382 RecLoss: 0.0000 (left: 0:01:11)\n",
      "TestLoss: 1.1272 MAE: 0.8475 RMSE: 1.0617\n",
      "ValLoss: 0.9870 MAE: 0.8270 RMSE: 0.9935\n",
      "Epoch 40: TrainLoss 0.9409 RecLoss: 0.0000 (left: 0:01:10)\n",
      "TestLoss: 1.1155 MAE: 0.8360 RMSE: 1.0562\n",
      "ValLoss: 0.9923 MAE: 0.8261 RMSE: 0.9961\n",
      "Epoch 41: TrainLoss 0.9368 RecLoss: 0.0000 (left: 0:01:09)\n",
      "TestLoss: 1.1208 MAE: 0.8425 RMSE: 1.0587\n",
      "ValLoss: 0.9885 MAE: 0.8258 RMSE: 0.9942\n",
      "Epoch 42: TrainLoss 0.9366 RecLoss: 0.0000 (left: 0:01:08)\n",
      "TestLoss: 1.1164 MAE: 0.8359 RMSE: 1.0566\n",
      "ValLoss: 0.9888 MAE: 0.8235 RMSE: 0.9944\n",
      "Epoch 43: TrainLoss 0.9364 RecLoss: 0.0000 (left: 0:01:06)\n",
      "TestLoss: 1.1182 MAE: 0.8381 RMSE: 1.0575\n",
      "ValLoss: 0.9877 MAE: 0.8233 RMSE: 0.9938\n",
      "Epoch 44: TrainLoss 0.9369 RecLoss: 0.0000 (left: 0:01:05)\n",
      "TestLoss: 1.1258 MAE: 0.8461 RMSE: 1.0611\n",
      "ValLoss: 0.9905 MAE: 0.8285 RMSE: 0.9952\n",
      "Epoch 45: TrainLoss 0.9363 RecLoss: 0.0000 (left: 0:01:04)\n",
      "TestLoss: 1.1154 MAE: 0.8330 RMSE: 1.0561\n",
      "ValLoss: 0.9957 MAE: 0.8261 RMSE: 0.9978\n",
      "Epoch 46: TrainLoss 0.9358 RecLoss: 0.0000 (left: 0:01:03)\n",
      "TestLoss: 1.1270 MAE: 0.8470 RMSE: 1.0616\n",
      "ValLoss: 0.9945 MAE: 0.8308 RMSE: 0.9972\n",
      "Epoch 47: TrainLoss 0.9360 RecLoss: 0.0000 (left: 0:01:02)\n",
      "TestLoss: 1.1151 MAE: 0.8318 RMSE: 1.0560\n",
      "ValLoss: 0.9964 MAE: 0.8262 RMSE: 0.9982\n",
      "Epoch 48: TrainLoss 0.9348 RecLoss: 0.0000 (left: 0:01:00)\n",
      "TestLoss: 1.1214 MAE: 0.8397 RMSE: 1.0590\n",
      "ValLoss: 0.9883 MAE: 0.8238 RMSE: 0.9941\n",
      "Epoch 49: TrainLoss 0.9346 RecLoss: 0.0000 (left: 0:00:59)\n",
      "TestLoss: 1.1240 MAE: 0.8425 RMSE: 1.0602\n",
      "ValLoss: 0.9903 MAE: 0.8262 RMSE: 0.9951\n",
      "Epoch 50: TrainLoss 0.9357 RecLoss: 0.0000 (left: 0:00:58)\n",
      "TestLoss: 1.1167 MAE: 0.8255 RMSE: 1.0568\n",
      "ValLoss: 1.0064 MAE: 0.8264 RMSE: 1.0032\n",
      "Epoch 51: TrainLoss 0.9384 RecLoss: 0.0000 (left: 0:00:56)\n",
      "TestLoss: 1.1470 MAE: 0.8601 RMSE: 1.0710\n",
      "ValLoss: 1.0113 MAE: 0.8412 RMSE: 1.0057\n",
      "Epoch 52: TrainLoss 0.9404 RecLoss: 0.0000 (left: 0:00:55)\n",
      "TestLoss: 1.1214 MAE: 0.8223 RMSE: 1.0590\n",
      "ValLoss: 1.0192 MAE: 0.8277 RMSE: 1.0096\n",
      "Epoch 53: TrainLoss 0.9437 RecLoss: 0.0000 (left: 0:00:54)\n",
      "TestLoss: 1.1369 MAE: 0.8534 RMSE: 1.0663\n",
      "ValLoss: 1.0028 MAE: 0.8355 RMSE: 1.0014\n",
      "Epoch 54: TrainLoss 0.9398 RecLoss: 0.0000 (left: 0:00:53)\n",
      "TestLoss: 1.1151 MAE: 0.8245 RMSE: 1.0560\n",
      "ValLoss: 1.0122 MAE: 0.8288 RMSE: 1.0061\n",
      "Epoch 55: TrainLoss 0.9405 RecLoss: 0.0000 (left: 0:00:52)\n",
      "TestLoss: 1.1225 MAE: 0.8427 RMSE: 1.0595\n",
      "ValLoss: 1.0003 MAE: 0.8313 RMSE: 1.0002\n",
      "Epoch 56: TrainLoss 0.9340 RecLoss: 0.0000 (left: 0:00:51)\n",
      "TestLoss: 1.1143 MAE: 0.8300 RMSE: 1.0556\n",
      "ValLoss: 0.9962 MAE: 0.8239 RMSE: 0.9981\n",
      "Epoch 57: TrainLoss 0.9337 RecLoss: 0.0000 (left: 0:00:49)\n",
      "TestLoss: 1.1193 MAE: 0.8373 RMSE: 1.0580\n",
      "ValLoss: 0.9891 MAE: 0.8226 RMSE: 0.9945\n",
      "Epoch 58: TrainLoss 0.9338 RecLoss: 0.0000 (left: 0:00:48)\n",
      "TestLoss: 1.1143 MAE: 0.8279 RMSE: 1.0556\n",
      "ValLoss: 0.9982 MAE: 0.8247 RMSE: 0.9991\n",
      "Epoch 59: TrainLoss 0.9335 RecLoss: 0.0000 (left: 0:00:47)\n",
      "TestLoss: 1.1328 MAE: 0.8497 RMSE: 1.0643\n",
      "ValLoss: 0.9979 MAE: 0.8325 RMSE: 0.9990\n",
      "Epoch 60: TrainLoss 0.9353 RecLoss: 0.0000 (left: 0:00:46)\n",
      "TestLoss: 1.1185 MAE: 0.8230 RMSE: 1.0576\n",
      "ValLoss: 1.0108 MAE: 0.8261 RMSE: 1.0054\n",
      "Epoch 61: TrainLoss 0.9367 RecLoss: 0.0000 (left: 0:00:45)\n",
      "TestLoss: 1.1442 MAE: 0.8577 RMSE: 1.0697\n",
      "ValLoss: 1.0098 MAE: 0.8395 RMSE: 1.0049\n",
      "Epoch 62: TrainLoss 0.9410 RecLoss: 0.0000 (left: 0:00:44)\n",
      "TestLoss: 1.1191 MAE: 0.8217 RMSE: 1.0579\n",
      "ValLoss: 1.0165 MAE: 0.8273 RMSE: 1.0082\n",
      "Epoch 63: TrainLoss 0.9416 RecLoss: 0.0000 (left: 0:00:42)\n",
      "TestLoss: 1.1356 MAE: 0.8518 RMSE: 1.0656\n",
      "ValLoss: 1.0011 MAE: 0.8338 RMSE: 1.0005\n",
      "Epoch 64: TrainLoss 0.9385 RecLoss: 0.0000 (left: 0:00:41)\n",
      "TestLoss: 1.1142 MAE: 0.8247 RMSE: 1.0555\n",
      "ValLoss: 1.0044 MAE: 0.8256 RMSE: 1.0022\n",
      "Epoch 65: TrainLoss 0.9333 RecLoss: 0.0000 (left: 0:00:40)\n",
      "TestLoss: 1.1301 MAE: 0.8477 RMSE: 1.0631\n",
      "ValLoss: 0.9987 MAE: 0.8319 RMSE: 0.9993\n",
      "Epoch 66: TrainLoss 0.9335 RecLoss: 0.0000 (left: 0:00:39)\n",
      "TestLoss: 1.1150 MAE: 0.8252 RMSE: 1.0559\n",
      "ValLoss: 1.0011 MAE: 0.8238 RMSE: 1.0006\n",
      "Epoch 67: TrainLoss 0.9348 RecLoss: 0.0000 (left: 0:00:37)\n",
      "TestLoss: 1.1255 MAE: 0.8439 RMSE: 1.0609\n",
      "ValLoss: 0.9969 MAE: 0.8301 RMSE: 0.9984\n",
      "Epoch 68: TrainLoss 0.9341 RecLoss: 0.0000 (left: 0:00:36)\n",
      "TestLoss: 1.1148 MAE: 0.8267 RMSE: 1.0558\n",
      "ValLoss: 0.9991 MAE: 0.8241 RMSE: 0.9995\n",
      "Epoch 69: TrainLoss 0.9354 RecLoss: 0.0000 (left: 0:00:35)\n",
      "TestLoss: 1.1276 MAE: 0.8453 RMSE: 1.0619\n",
      "ValLoss: 0.9966 MAE: 0.8302 RMSE: 0.9983\n",
      "Epoch 70: TrainLoss 0.9348 RecLoss: 0.0000 (left: 0:00:34)\n",
      "TestLoss: 1.1155 MAE: 0.8288 RMSE: 1.0562\n",
      "ValLoss: 0.9938 MAE: 0.8222 RMSE: 0.9969\n",
      "Epoch 71: TrainLoss 0.9319 RecLoss: 0.0000 (left: 0:00:33)\n",
      "TestLoss: 1.1217 MAE: 0.8396 RMSE: 1.0591\n",
      "ValLoss: 0.9947 MAE: 0.8275 RMSE: 0.9973\n",
      "Epoch 72: TrainLoss 0.9322 RecLoss: 0.0000 (left: 0:00:31)\n",
      "TestLoss: 1.1152 MAE: 0.8303 RMSE: 1.0561\n",
      "ValLoss: 0.9971 MAE: 0.8256 RMSE: 0.9986\n",
      "Epoch 73: TrainLoss 0.9325 RecLoss: 0.0000 (left: 0:00:30)\n",
      "TestLoss: 1.1182 MAE: 0.8340 RMSE: 1.0574\n",
      "ValLoss: 0.9935 MAE: 0.8244 RMSE: 0.9967\n",
      "Epoch 74: TrainLoss 0.9336 RecLoss: 0.0000 (left: 0:00:29)\n",
      "TestLoss: 1.1196 MAE: 0.8347 RMSE: 1.0581\n",
      "ValLoss: 0.9919 MAE: 0.8235 RMSE: 0.9959\n",
      "Epoch 75: TrainLoss 0.9313 RecLoss: 0.0000 (left: 0:00:28)\n",
      "TestLoss: 1.1179 MAE: 0.8322 RMSE: 1.0573\n",
      "ValLoss: 0.9936 MAE: 0.8239 RMSE: 0.9968\n",
      "Epoch 76: TrainLoss 0.9322 RecLoss: 0.0000 (left: 0:00:27)\n",
      "TestLoss: 1.1207 MAE: 0.8371 RMSE: 1.0586\n",
      "ValLoss: 0.9951 MAE: 0.8270 RMSE: 0.9976\n",
      "Epoch 77: TrainLoss 0.9327 RecLoss: 0.0000 (left: 0:00:26)\n",
      "TestLoss: 1.1187 MAE: 0.8343 RMSE: 1.0577\n",
      "ValLoss: 0.9968 MAE: 0.8269 RMSE: 0.9984\n",
      "Epoch 78: TrainLoss 0.9317 RecLoss: 0.0000 (left: 0:00:25)\n",
      "TestLoss: 1.1187 MAE: 0.8324 RMSE: 1.0577\n",
      "ValLoss: 0.9930 MAE: 0.8236 RMSE: 0.9965\n",
      "Epoch 79: TrainLoss 0.9324 RecLoss: 0.0000 (left: 0:00:23)\n",
      "TestLoss: 1.1274 MAE: 0.8427 RMSE: 1.0618\n",
      "ValLoss: 0.9954 MAE: 0.8288 RMSE: 0.9977\n",
      "Epoch 80: TrainLoss 0.9331 RecLoss: 0.0000 (left: 0:00:22)\n",
      "TestLoss: 1.1177 MAE: 0.8246 RMSE: 1.0572\n",
      "ValLoss: 1.0031 MAE: 0.8249 RMSE: 1.0016\n",
      "Epoch 81: TrainLoss 0.9376 RecLoss: 0.0000 (left: 0:00:21)\n",
      "TestLoss: 1.1326 MAE: 0.8474 RMSE: 1.0642\n",
      "ValLoss: 1.0015 MAE: 0.8332 RMSE: 1.0008\n",
      "Epoch 82: TrainLoss 0.9320 RecLoss: 0.0000 (left: 0:00:20)\n",
      "TestLoss: 1.1173 MAE: 0.8229 RMSE: 1.0570\n",
      "ValLoss: 1.0075 MAE: 0.8262 RMSE: 1.0037\n",
      "Epoch 83: TrainLoss 0.9373 RecLoss: 0.0000 (left: 0:00:19)\n",
      "TestLoss: 1.1296 MAE: 0.8456 RMSE: 1.0628\n",
      "ValLoss: 1.0032 MAE: 0.8335 RMSE: 1.0016\n",
      "Epoch 84: TrainLoss 0.9359 RecLoss: 0.0000 (left: 0:00:18)\n",
      "TestLoss: 1.1162 MAE: 0.8264 RMSE: 1.0565\n",
      "ValLoss: 1.0015 MAE: 0.8256 RMSE: 1.0008\n",
      "Epoch 85: TrainLoss 0.9341 RecLoss: 0.0000 (left: 0:00:17)\n",
      "TestLoss: 1.1254 MAE: 0.8403 RMSE: 1.0608\n",
      "ValLoss: 0.9945 MAE: 0.8270 RMSE: 0.9972\n",
      "Epoch 86: TrainLoss 0.9325 RecLoss: 0.0000 (left: 0:00:16)\n",
      "TestLoss: 1.1169 MAE: 0.8276 RMSE: 1.0569\n",
      "ValLoss: 0.9982 MAE: 0.8244 RMSE: 0.9991\n",
      "Epoch 87: TrainLoss 0.9334 RecLoss: 0.0000 (left: 0:00:14)\n",
      "TestLoss: 1.1217 MAE: 0.8377 RMSE: 1.0591\n",
      "ValLoss: 0.9950 MAE: 0.8268 RMSE: 0.9975\n",
      "Epoch 88: TrainLoss 0.9318 RecLoss: 0.0000 (left: 0:00:13)\n",
      "TestLoss: 1.1173 MAE: 0.8310 RMSE: 1.0570\n",
      "ValLoss: 0.9956 MAE: 0.8247 RMSE: 0.9978\n",
      "Epoch 89: TrainLoss 0.9323 RecLoss: 0.0000 (left: 0:00:12)\n",
      "TestLoss: 1.1224 MAE: 0.8375 RMSE: 1.0594\n",
      "ValLoss: 0.9942 MAE: 0.8262 RMSE: 0.9971\n",
      "Epoch 90: TrainLoss 0.9317 RecLoss: 0.0000 (left: 0:00:11)\n",
      "TestLoss: 1.1180 MAE: 0.8304 RMSE: 1.0573\n",
      "ValLoss: 0.9944 MAE: 0.8237 RMSE: 0.9972\n",
      "Epoch 91: TrainLoss 0.9310 RecLoss: 0.0000 (left: 0:00:10)\n",
      "TestLoss: 1.1198 MAE: 0.8336 RMSE: 1.0582\n",
      "ValLoss: 0.9940 MAE: 0.8247 RMSE: 0.9970\n",
      "Epoch 92: TrainLoss 0.9309 RecLoss: 0.0000 (left: 0:00:09)\n",
      "TestLoss: 1.1221 MAE: 0.8366 RMSE: 1.0593\n",
      "ValLoss: 0.9939 MAE: 0.8260 RMSE: 0.9970\n",
      "Epoch 93: TrainLoss 0.9302 RecLoss: 0.0000 (left: 0:00:08)\n",
      "TestLoss: 1.1195 MAE: 0.8321 RMSE: 1.0581\n",
      "ValLoss: 0.9942 MAE: 0.8244 RMSE: 0.9971\n",
      "Epoch 94: TrainLoss 0.9304 RecLoss: 0.0000 (left: 0:00:06)\n",
      "TestLoss: 1.1205 MAE: 0.8337 RMSE: 1.0586\n",
      "ValLoss: 0.9934 MAE: 0.8244 RMSE: 0.9967\n",
      "Epoch 95: TrainLoss 0.9299 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 1.1217 MAE: 0.8354 RMSE: 1.0591\n",
      "ValLoss: 0.9953 MAE: 0.8261 RMSE: 0.9976\n",
      "Epoch 96: TrainLoss 0.9302 RecLoss: 0.0000 (left: 0:00:04)\n",
      "TestLoss: 1.1204 MAE: 0.8336 RMSE: 1.0585\n",
      "ValLoss: 0.9958 MAE: 0.8259 RMSE: 0.9979\n",
      "Epoch 97: TrainLoss 0.9304 RecLoss: 0.0000 (left: 0:00:03)\n",
      "TestLoss: 1.1206 MAE: 0.8339 RMSE: 1.0586\n",
      "ValLoss: 0.9961 MAE: 0.8261 RMSE: 0.9980\n",
      "Epoch 98: TrainLoss 0.9327 RecLoss: 0.0000 (left: 0:00:02)\n",
      "TestLoss: 1.1190 MAE: 0.8287 RMSE: 1.0578\n",
      "ValLoss: 0.9971 MAE: 0.8247 RMSE: 0.9986\n",
      "Epoch 99: TrainLoss 0.9316 RecLoss: 0.0000 (left: 0:00:01)\n",
      "TestLoss: 1.1249 MAE: 0.8384 RMSE: 1.0606\n",
      "ValLoss: 0.9962 MAE: 0.8277 RMSE: 0.9981\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 21136/4938\n",
      "test set size: support/query 73/213\n",
      "USER HIS DICT: 943\n",
      "NUM IS: 943\n",
      "Key Test Result: MAE: 0.7714 RMSE: 0.9523 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 943\n",
      "NUM IS: 943\n",
      "Que Test Result: MAE: 0.8373 RMSE: 1.0572 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.8205 RMSE: 1.0315 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 20% cos as input to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 35161/4938\n",
      "test set size: support/query 146/213\n",
      "Epoch 0 Step 33: Train 11.4273 Reg: 0.4319\n",
      "Test: 8.3260 MAE: 2.6473 RMSE: 2.8855\n",
      "Val: 8.1389 MAE: 2.6386 RMSE: 2.8529\n",
      "Epoch 1 Step 66: Train 3.7433 Reg: 0.3295\n",
      "Test: 1.2741 MAE: 0.9554 RMSE: 1.1287\n",
      "Val: 1.1385 MAE: 0.8960 RMSE: 1.0670\n",
      "Epoch 2 Step 99: Train 1.0736 Reg: 0.3249\n",
      "Test: 1.1345 MAE: 0.9037 RMSE: 1.0651\n",
      "Val: 1.0117 MAE: 0.8268 RMSE: 1.0058\n",
      "Epoch 3 Step 132: Train 0.9606 Reg: 0.3070\n",
      "Test: 1.0206 MAE: 0.8558 RMSE: 1.0103\n",
      "Val: 0.9216 MAE: 0.7891 RMSE: 0.9600\n",
      "Epoch 4 Step 165: Train 0.8713 Reg: 0.2983\n",
      "Test: 0.9550 MAE: 0.8218 RMSE: 0.9772\n",
      "Val: 0.8640 MAE: 0.7507 RMSE: 0.9295\n",
      "Epoch 5 Step 198: Train 0.8172 Reg: 0.2949\n",
      "Test: 0.9244 MAE: 0.7956 RMSE: 0.9614\n",
      "Val: 0.8343 MAE: 0.7232 RMSE: 0.9134\n",
      "Epoch 6 Step 231: Train 0.7864 Reg: 0.2913\n",
      "Test: 0.9102 MAE: 0.7910 RMSE: 0.9540\n",
      "Val: 0.8206 MAE: 0.7115 RMSE: 0.9059\n",
      "Epoch 7 Step 264: Train 0.7682 Reg: 0.2873\n",
      "Test: 0.8984 MAE: 0.7863 RMSE: 0.9479\n",
      "Val: 0.8124 MAE: 0.7050 RMSE: 0.9013\n",
      "Epoch 8 Step 297: Train 0.7567 Reg: 0.2832\n",
      "Test: 0.8873 MAE: 0.7812 RMSE: 0.9420\n",
      "Val: 0.8094 MAE: 0.7032 RMSE: 0.8997\n",
      "Epoch 9 Step 330: Train 0.7489 Reg: 0.2801\n",
      "Test: 0.8894 MAE: 0.7831 RMSE: 0.9431\n",
      "Val: 0.8063 MAE: 0.7002 RMSE: 0.8980\n",
      "Epoch 10 Step 363: Train 0.7435 Reg: 0.2768\n",
      "Test: 0.8821 MAE: 0.7778 RMSE: 0.9392\n",
      "Val: 0.8066 MAE: 0.7015 RMSE: 0.8981\n",
      "Epoch 11 Step 396: Train 0.7397 Reg: 0.2740\n",
      "Test: 0.8915 MAE: 0.7824 RMSE: 0.9442\n",
      "Val: 0.8081 MAE: 0.7021 RMSE: 0.8990\n",
      "Epoch 12 Step 429: Train 0.7363 Reg: 0.2714\n",
      "Test: 0.8834 MAE: 0.7774 RMSE: 0.9399\n",
      "Val: 0.8045 MAE: 0.7003 RMSE: 0.8969\n",
      "Epoch 13 Step 462: Train 0.7336 Reg: 0.2687\n",
      "Test: 0.8771 MAE: 0.7738 RMSE: 0.9366\n",
      "Val: 0.8038 MAE: 0.7004 RMSE: 0.8966\n",
      "Epoch 14 Step 495: Train 0.7319 Reg: 0.2658\n",
      "Test: 0.8846 MAE: 0.7768 RMSE: 0.9405\n",
      "Val: 0.8035 MAE: 0.7008 RMSE: 0.8964\n",
      "Epoch 15 Step 528: Train 0.7303 Reg: 0.2634\n",
      "Test: 0.8770 MAE: 0.7736 RMSE: 0.9365\n",
      "Val: 0.8039 MAE: 0.7011 RMSE: 0.8966\n",
      "Epoch 16 Step 561: Train 0.7286 Reg: 0.2612\n",
      "Test: 0.8788 MAE: 0.7758 RMSE: 0.9375\n",
      "Val: 0.8029 MAE: 0.7006 RMSE: 0.8961\n",
      "Epoch 17 Step 594: Train 0.7275 Reg: 0.2588\n",
      "Test: 0.8761 MAE: 0.7718 RMSE: 0.9360\n",
      "Val: 0.8034 MAE: 0.7002 RMSE: 0.8963\n",
      "Epoch 18 Step 627: Train 0.7259 Reg: 0.2569\n",
      "Test: 0.8779 MAE: 0.7725 RMSE: 0.9369\n",
      "Val: 0.8006 MAE: 0.6994 RMSE: 0.8947\n",
      "Epoch 19 Step 660: Train 0.7249 Reg: 0.2547\n",
      "Test: 0.8722 MAE: 0.7707 RMSE: 0.9339\n",
      "Val: 0.8007 MAE: 0.6995 RMSE: 0.8948\n",
      "Epoch 20 Step 693: Train 0.7236 Reg: 0.2529\n",
      "Test: 0.8750 MAE: 0.7719 RMSE: 0.9354\n",
      "Val: 0.8022 MAE: 0.6999 RMSE: 0.8957\n",
      "Epoch 21 Step 726: Train 0.7226 Reg: 0.2514\n",
      "Test: 0.8738 MAE: 0.7714 RMSE: 0.9348\n",
      "Val: 0.8007 MAE: 0.6995 RMSE: 0.8948\n",
      "Epoch 22 Step 759: Train 0.7219 Reg: 0.2495\n",
      "Test: 0.8738 MAE: 0.7694 RMSE: 0.9348\n",
      "Val: 0.8003 MAE: 0.6992 RMSE: 0.8946\n",
      "Epoch 23 Step 792: Train 0.7209 Reg: 0.2479\n",
      "Test: 0.8729 MAE: 0.7689 RMSE: 0.9343\n",
      "Val: 0.8011 MAE: 0.6995 RMSE: 0.8951\n",
      "Epoch 24 Step 825: Train 0.7200 Reg: 0.2467\n",
      "Test: 0.8711 MAE: 0.7681 RMSE: 0.9333\n",
      "Val: 0.7998 MAE: 0.6990 RMSE: 0.8943\n",
      "Epoch 25 Step 858: Train 0.7191 Reg: 0.2451\n",
      "Test: 0.8734 MAE: 0.7675 RMSE: 0.9346\n",
      "Val: 0.8003 MAE: 0.6984 RMSE: 0.8946\n",
      "Epoch 26 Step 891: Train 0.7184 Reg: 0.2439\n",
      "Test: 0.8738 MAE: 0.7700 RMSE: 0.9348\n",
      "Val: 0.8001 MAE: 0.6989 RMSE: 0.8945\n",
      "Epoch 27 Step 924: Train 0.7178 Reg: 0.2426\n",
      "Test: 0.8714 MAE: 0.7690 RMSE: 0.9335\n",
      "Val: 0.8001 MAE: 0.6993 RMSE: 0.8945\n",
      "Epoch 28 Step 957: Train 0.7170 Reg: 0.2414\n",
      "Test: 0.8719 MAE: 0.7680 RMSE: 0.9338\n",
      "Val: 0.7997 MAE: 0.6991 RMSE: 0.8943\n",
      "Epoch 29 Step 990: Train 0.7162 Reg: 0.2403\n",
      "Test: 0.8716 MAE: 0.7683 RMSE: 0.9336\n",
      "Val: 0.7993 MAE: 0.6991 RMSE: 0.8940\n",
      "Epoch 30 Step 1023: Train 0.7155 Reg: 0.2393\n",
      "Test: 0.8742 MAE: 0.7691 RMSE: 0.9350\n",
      "Val: 0.7991 MAE: 0.6981 RMSE: 0.8939\n",
      "Epoch 31 Step 1056: Train 0.7149 Reg: 0.2383\n",
      "Test: 0.8706 MAE: 0.7665 RMSE: 0.9330\n",
      "Val: 0.7987 MAE: 0.6980 RMSE: 0.8937\n",
      "Epoch 32 Step 1089: Train 0.7143 Reg: 0.2374\n",
      "Test: 0.8708 MAE: 0.7671 RMSE: 0.9332\n",
      "Val: 0.7985 MAE: 0.6981 RMSE: 0.8936\n",
      "Epoch 33 Step 1122: Train 0.7135 Reg: 0.2365\n",
      "Test: 0.8713 MAE: 0.7666 RMSE: 0.9334\n",
      "Val: 0.7989 MAE: 0.6983 RMSE: 0.8938\n",
      "Epoch 34 Step 1155: Train 0.7131 Reg: 0.2357\n",
      "Test: 0.8716 MAE: 0.7672 RMSE: 0.9336\n",
      "Val: 0.7987 MAE: 0.6985 RMSE: 0.8937\n",
      "Epoch 35 Step 1188: Train 0.7124 Reg: 0.2349\n",
      "Test: 0.8697 MAE: 0.7667 RMSE: 0.9326\n",
      "Val: 0.7979 MAE: 0.6983 RMSE: 0.8933\n",
      "Epoch 36 Step 1221: Train 0.7119 Reg: 0.2342\n",
      "Test: 0.8710 MAE: 0.7668 RMSE: 0.9333\n",
      "Val: 0.7978 MAE: 0.6980 RMSE: 0.8932\n",
      "Epoch 37 Step 1254: Train 0.7114 Reg: 0.2335\n",
      "Test: 0.8701 MAE: 0.7660 RMSE: 0.9328\n",
      "Val: 0.7971 MAE: 0.6977 RMSE: 0.8928\n",
      "Epoch 38 Step 1287: Train 0.7109 Reg: 0.2328\n",
      "Test: 0.8719 MAE: 0.7665 RMSE: 0.9338\n",
      "Val: 0.7973 MAE: 0.6979 RMSE: 0.8929\n",
      "Epoch 39 Step 1320: Train 0.7103 Reg: 0.2322\n",
      "Test: 0.8700 MAE: 0.7656 RMSE: 0.9327\n",
      "Val: 0.7976 MAE: 0.6981 RMSE: 0.8931\n",
      "Epoch 40 Step 1353: Train 0.7099 Reg: 0.2316\n",
      "Test: 0.8682 MAE: 0.7650 RMSE: 0.9318\n",
      "Val: 0.7976 MAE: 0.6980 RMSE: 0.8931\n",
      "Epoch 41 Step 1386: Train 0.7094 Reg: 0.2311\n",
      "Test: 0.8691 MAE: 0.7653 RMSE: 0.9323\n",
      "Val: 0.7968 MAE: 0.6975 RMSE: 0.8927\n",
      "Epoch 42 Step 1419: Train 0.7088 Reg: 0.2306\n",
      "Test: 0.8694 MAE: 0.7654 RMSE: 0.9324\n",
      "Val: 0.7968 MAE: 0.6975 RMSE: 0.8927\n",
      "Epoch 43 Step 1452: Train 0.7086 Reg: 0.2301\n",
      "Test: 0.8683 MAE: 0.7651 RMSE: 0.9318\n",
      "Val: 0.7968 MAE: 0.6979 RMSE: 0.8926\n",
      "Epoch 44 Step 1485: Train 0.7081 Reg: 0.2297\n",
      "Test: 0.8710 MAE: 0.7654 RMSE: 0.9333\n",
      "Val: 0.7966 MAE: 0.6974 RMSE: 0.8925\n",
      "Epoch 45 Step 1518: Train 0.7076 Reg: 0.2293\n",
      "Test: 0.8678 MAE: 0.7649 RMSE: 0.9316\n",
      "Val: 0.7969 MAE: 0.6979 RMSE: 0.8927\n",
      "Epoch 46 Step 1551: Train 0.7072 Reg: 0.2289\n",
      "Test: 0.8681 MAE: 0.7644 RMSE: 0.9317\n",
      "Val: 0.7967 MAE: 0.6978 RMSE: 0.8926\n",
      "Epoch 47 Step 1584: Train 0.7068 Reg: 0.2285\n",
      "Test: 0.8681 MAE: 0.7654 RMSE: 0.9317\n",
      "Val: 0.7965 MAE: 0.6979 RMSE: 0.8925\n",
      "Epoch 48 Step 1617: Train 0.7064 Reg: 0.2282\n",
      "Test: 0.8676 MAE: 0.7642 RMSE: 0.9315\n",
      "Val: 0.7961 MAE: 0.6975 RMSE: 0.8922\n",
      "Epoch 49 Step 1650: Train 0.7061 Reg: 0.2278\n",
      "Test: 0.8678 MAE: 0.7640 RMSE: 0.9316\n",
      "Val: 0.7958 MAE: 0.6973 RMSE: 0.8921\n",
      "Epoch 50 Step 1683: Train 0.7058 Reg: 0.2275\n",
      "Test: 0.8683 MAE: 0.7648 RMSE: 0.9318\n",
      "Val: 0.7959 MAE: 0.6974 RMSE: 0.8921\n",
      "Epoch 51 Step 1716: Train 0.7054 Reg: 0.2272\n",
      "Test: 0.8692 MAE: 0.7648 RMSE: 0.9323\n",
      "Val: 0.7960 MAE: 0.6974 RMSE: 0.8922\n",
      "Epoch 52 Step 1749: Train 0.7052 Reg: 0.2269\n",
      "Test: 0.8671 MAE: 0.7640 RMSE: 0.9312\n",
      "Val: 0.7958 MAE: 0.6976 RMSE: 0.8921\n",
      "Epoch 53 Step 1782: Train 0.7048 Reg: 0.2266\n",
      "Test: 0.8676 MAE: 0.7642 RMSE: 0.9314\n",
      "Val: 0.7958 MAE: 0.6973 RMSE: 0.8921\n",
      "Epoch 54 Step 1815: Train 0.7045 Reg: 0.2264\n",
      "Test: 0.8682 MAE: 0.7644 RMSE: 0.9318\n",
      "Val: 0.7955 MAE: 0.6971 RMSE: 0.8919\n",
      "Epoch 55 Step 1848: Train 0.7042 Reg: 0.2262\n",
      "Test: 0.8671 MAE: 0.7637 RMSE: 0.9312\n",
      "Val: 0.7958 MAE: 0.6972 RMSE: 0.8921\n",
      "Epoch 56 Step 1881: Train 0.7039 Reg: 0.2260\n",
      "Test: 0.8674 MAE: 0.7638 RMSE: 0.9313\n",
      "Val: 0.7956 MAE: 0.6974 RMSE: 0.8919\n",
      "Epoch 57 Step 1914: Train 0.7036 Reg: 0.2257\n",
      "Test: 0.8669 MAE: 0.7636 RMSE: 0.9311\n",
      "Val: 0.7955 MAE: 0.6973 RMSE: 0.8919\n",
      "Epoch 58 Step 1947: Train 0.7034 Reg: 0.2255\n",
      "Test: 0.8673 MAE: 0.7637 RMSE: 0.9313\n",
      "Val: 0.7957 MAE: 0.6975 RMSE: 0.8920\n",
      "Epoch 59 Step 1980: Train 0.7032 Reg: 0.2253\n",
      "Test: 0.8674 MAE: 0.7638 RMSE: 0.9314\n",
      "Val: 0.7954 MAE: 0.6971 RMSE: 0.8918\n",
      "Epoch 60 Step 2013: Train 0.7030 Reg: 0.2252\n",
      "Test: 0.8665 MAE: 0.7636 RMSE: 0.9309\n",
      "Val: 0.7954 MAE: 0.6975 RMSE: 0.8918\n",
      "Epoch 61 Step 2046: Train 0.7027 Reg: 0.2250\n",
      "Test: 0.8667 MAE: 0.7634 RMSE: 0.9309\n",
      "Val: 0.7952 MAE: 0.6971 RMSE: 0.8917\n",
      "Epoch 62 Step 2079: Train 0.7025 Reg: 0.2248\n",
      "Test: 0.8667 MAE: 0.7634 RMSE: 0.9310\n",
      "Val: 0.7954 MAE: 0.6973 RMSE: 0.8918\n",
      "Epoch 63 Step 2112: Train 0.7023 Reg: 0.2247\n",
      "Test: 0.8665 MAE: 0.7633 RMSE: 0.9308\n",
      "Val: 0.7952 MAE: 0.6972 RMSE: 0.8917\n",
      "Epoch 64 Step 2145: Train 0.7021 Reg: 0.2245\n",
      "Test: 0.8670 MAE: 0.7634 RMSE: 0.9311\n",
      "Val: 0.7950 MAE: 0.6971 RMSE: 0.8916\n",
      "Epoch 65 Step 2178: Train 0.7019 Reg: 0.2244\n",
      "Test: 0.8660 MAE: 0.7630 RMSE: 0.9306\n",
      "Val: 0.7950 MAE: 0.6971 RMSE: 0.8916\n",
      "Epoch 66 Step 2211: Train 0.7017 Reg: 0.2243\n",
      "Test: 0.8662 MAE: 0.7630 RMSE: 0.9307\n",
      "Val: 0.7950 MAE: 0.6971 RMSE: 0.8916\n",
      "Epoch 67 Step 2244: Train 0.7015 Reg: 0.2241\n",
      "Test: 0.8663 MAE: 0.7629 RMSE: 0.9307\n",
      "Val: 0.7949 MAE: 0.6970 RMSE: 0.8916\n",
      "Epoch 68 Step 2277: Train 0.7014 Reg: 0.2240\n",
      "Test: 0.8661 MAE: 0.7628 RMSE: 0.9306\n",
      "Val: 0.7949 MAE: 0.6970 RMSE: 0.8916\n",
      "Epoch 69 Step 2310: Train 0.7012 Reg: 0.2239\n",
      "Test: 0.8657 MAE: 0.7627 RMSE: 0.9305\n",
      "Val: 0.7948 MAE: 0.6971 RMSE: 0.8915\n",
      "Epoch 70 Step 2343: Train 0.7011 Reg: 0.2238\n",
      "Test: 0.8661 MAE: 0.7630 RMSE: 0.9306\n",
      "Val: 0.7948 MAE: 0.6971 RMSE: 0.8915\n",
      "Epoch 71 Step 2376: Train 0.7009 Reg: 0.2237\n",
      "Test: 0.8660 MAE: 0.7628 RMSE: 0.9306\n",
      "Val: 0.7949 MAE: 0.6970 RMSE: 0.8915\n",
      "Epoch 72 Step 2409: Train 0.7008 Reg: 0.2237\n",
      "Test: 0.8658 MAE: 0.7627 RMSE: 0.9305\n",
      "Val: 0.7948 MAE: 0.6970 RMSE: 0.8915\n",
      "Epoch 73 Step 2442: Train 0.7006 Reg: 0.2236\n",
      "Test: 0.8661 MAE: 0.7629 RMSE: 0.9306\n",
      "Val: 0.7947 MAE: 0.6970 RMSE: 0.8915\n",
      "Epoch 74 Step 2475: Train 0.7005 Reg: 0.2235\n",
      "Test: 0.8659 MAE: 0.7626 RMSE: 0.9306\n",
      "Val: 0.7947 MAE: 0.6969 RMSE: 0.8915\n",
      "Epoch 75 Step 2508: Train 0.7004 Reg: 0.2234\n",
      "Test: 0.8655 MAE: 0.7626 RMSE: 0.9303\n",
      "Val: 0.7946 MAE: 0.6970 RMSE: 0.8914\n",
      "Epoch 76 Step 2541: Train 0.7003 Reg: 0.2233\n",
      "Test: 0.8659 MAE: 0.7625 RMSE: 0.9305\n",
      "Val: 0.7946 MAE: 0.6969 RMSE: 0.8914\n",
      "Epoch 77 Step 2574: Train 0.7002 Reg: 0.2233\n",
      "Test: 0.8654 MAE: 0.7624 RMSE: 0.9303\n",
      "Val: 0.7946 MAE: 0.6969 RMSE: 0.8914\n",
      "Epoch 78 Step 2607: Train 0.7001 Reg: 0.2232\n",
      "Test: 0.8653 MAE: 0.7624 RMSE: 0.9302\n",
      "Val: 0.7946 MAE: 0.6970 RMSE: 0.8914\n",
      "Epoch 79 Step 2640: Train 0.7000 Reg: 0.2231\n",
      "Test: 0.8655 MAE: 0.7625 RMSE: 0.9303\n",
      "Val: 0.7946 MAE: 0.6970 RMSE: 0.8914\n",
      "Epoch 80 Step 2673: Train 0.6999 Reg: 0.2231\n",
      "Test: 0.8654 MAE: 0.7623 RMSE: 0.9302\n",
      "Val: 0.7945 MAE: 0.6969 RMSE: 0.8913\n",
      "Epoch 81 Step 2706: Train 0.6998 Reg: 0.2230\n",
      "Test: 0.8654 MAE: 0.7623 RMSE: 0.9303\n",
      "Val: 0.7945 MAE: 0.6969 RMSE: 0.8913\n",
      "Epoch 82 Step 2739: Train 0.6997 Reg: 0.2230\n",
      "Test: 0.8654 MAE: 0.7623 RMSE: 0.9303\n",
      "Val: 0.7945 MAE: 0.6969 RMSE: 0.8913\n",
      "Epoch 83 Step 2772: Train 0.6996 Reg: 0.2229\n",
      "Test: 0.8652 MAE: 0.7623 RMSE: 0.9302\n",
      "Val: 0.7944 MAE: 0.6969 RMSE: 0.8913\n",
      "Epoch 84 Step 2805: Train 0.6995 Reg: 0.2229\n",
      "Test: 0.8652 MAE: 0.7622 RMSE: 0.9302\n",
      "Val: 0.7944 MAE: 0.6969 RMSE: 0.8913\n",
      "Epoch 85 Step 2838: Train 0.6994 Reg: 0.2228\n",
      "Test: 0.8654 MAE: 0.7623 RMSE: 0.9303\n",
      "Val: 0.7944 MAE: 0.6969 RMSE: 0.8913\n",
      "Epoch 86 Step 2871: Train 0.6994 Reg: 0.2228\n",
      "Test: 0.8652 MAE: 0.7622 RMSE: 0.9301\n",
      "Val: 0.7944 MAE: 0.6968 RMSE: 0.8913\n",
      "Epoch 87 Step 2904: Train 0.6993 Reg: 0.2228\n",
      "Test: 0.8651 MAE: 0.7622 RMSE: 0.9301\n",
      "Val: 0.7944 MAE: 0.6968 RMSE: 0.8913\n",
      "Epoch 88 Step 2937: Train 0.6992 Reg: 0.2227\n",
      "Test: 0.8651 MAE: 0.7622 RMSE: 0.9301\n",
      "Val: 0.7944 MAE: 0.6969 RMSE: 0.8913\n",
      "Epoch 89 Step 2970: Train 0.6992 Reg: 0.2227\n",
      "Test: 0.8651 MAE: 0.7621 RMSE: 0.9301\n",
      "Val: 0.7943 MAE: 0.6968 RMSE: 0.8913\n",
      "Epoch 90 Step 3003: Train 0.6991 Reg: 0.2226\n",
      "Test: 0.8652 MAE: 0.7622 RMSE: 0.9302\n",
      "Val: 0.7944 MAE: 0.6969 RMSE: 0.8913\n",
      "Epoch 91 Step 3036: Train 0.6991 Reg: 0.2226\n",
      "Test: 0.8651 MAE: 0.7620 RMSE: 0.9301\n",
      "Val: 0.7943 MAE: 0.6968 RMSE: 0.8913\n",
      "Epoch 92 Step 3069: Train 0.6990 Reg: 0.2226\n",
      "Test: 0.8650 MAE: 0.7621 RMSE: 0.9301\n",
      "Val: 0.7943 MAE: 0.6969 RMSE: 0.8913\n",
      "Epoch 93 Step 3102: Train 0.6989 Reg: 0.2226\n",
      "Test: 0.8650 MAE: 0.7620 RMSE: 0.9301\n",
      "Val: 0.7943 MAE: 0.6968 RMSE: 0.8912\n",
      "Epoch 94 Step 3135: Train 0.6989 Reg: 0.2225\n",
      "Test: 0.8649 MAE: 0.7621 RMSE: 0.9300\n",
      "Val: 0.7943 MAE: 0.6969 RMSE: 0.8912\n",
      "Epoch 95 Step 3168: Train 0.6988 Reg: 0.2225\n",
      "Test: 0.8650 MAE: 0.7620 RMSE: 0.9300\n",
      "Val: 0.7943 MAE: 0.6968 RMSE: 0.8912\n",
      "Epoch 96 Step 3201: Train 0.6988 Reg: 0.2225\n",
      "Test: 0.8650 MAE: 0.7620 RMSE: 0.9300\n",
      "Val: 0.7943 MAE: 0.6968 RMSE: 0.8912\n",
      "Epoch 97 Step 3234: Train 0.6988 Reg: 0.2224\n",
      "Test: 0.8648 MAE: 0.7620 RMSE: 0.9300\n",
      "Val: 0.7943 MAE: 0.6969 RMSE: 0.8912\n",
      "Epoch 98 Step 3267: Train 0.6987 Reg: 0.2224\n",
      "Test: 0.8648 MAE: 0.7619 RMSE: 0.9299\n",
      "Val: 0.7943 MAE: 0.6968 RMSE: 0.8912\n",
      "Epoch 99 Step 3300: Train 0.6987 Reg: 0.2224\n",
      "Test: 0.8649 MAE: 0.7619 RMSE: 0.9300\n",
      "Val: 0.7943 MAE: 0.6968 RMSE: 0.8912\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 35161/4938\n",
      "test set size: support/query 146/213\n",
      "Epoch 0: TrainLoss 1.9609 RecLoss: 0.0000 (left: 0:02:30)\n",
      "TestLoss: 1.8989 MAE: 1.1463 RMSE: 1.3780\n",
      "ValLoss: 1.5150 MAE: 1.0234 RMSE: 1.2309\n",
      "Epoch 1: TrainLoss 1.3359 RecLoss: 0.0000 (left: 0:02:07)\n",
      "TestLoss: 1.3687 MAE: 0.9260 RMSE: 1.1699\n",
      "ValLoss: 1.1451 MAE: 0.8641 RMSE: 1.0701\n",
      "Epoch 2: TrainLoss 1.1792 RecLoss: 0.0000 (left: 0:01:54)\n",
      "TestLoss: 1.3237 MAE: 0.9573 RMSE: 1.1505\n",
      "ValLoss: 1.1101 MAE: 0.8949 RMSE: 1.0536\n",
      "Epoch 3: TrainLoss 1.1402 RecLoss: 0.0000 (left: 0:01:48)\n",
      "TestLoss: 1.2909 MAE: 0.9424 RMSE: 1.1362\n",
      "ValLoss: 1.1096 MAE: 0.8956 RMSE: 1.0534\n",
      "Epoch 4: TrainLoss 1.0979 RecLoss: 0.0000 (left: 0:01:58)\n",
      "TestLoss: 1.2690 MAE: 0.9121 RMSE: 1.1265\n",
      "ValLoss: 1.1069 MAE: 0.8782 RMSE: 1.0521\n",
      "Epoch 5: TrainLoss 1.0796 RecLoss: 0.0000 (left: 0:01:55)\n",
      "TestLoss: 1.2773 MAE: 0.9339 RMSE: 1.1302\n",
      "ValLoss: 1.0759 MAE: 0.8797 RMSE: 1.0372\n",
      "Epoch 6: TrainLoss 1.0635 RecLoss: 0.0000 (left: 0:01:52)\n",
      "TestLoss: 1.2380 MAE: 0.9035 RMSE: 1.1126\n",
      "ValLoss: 1.0521 MAE: 0.8592 RMSE: 1.0257\n",
      "Epoch 7: TrainLoss 1.0473 RecLoss: 0.0000 (left: 0:01:50)\n",
      "TestLoss: 1.2344 MAE: 0.9061 RMSE: 1.1111\n",
      "ValLoss: 1.0360 MAE: 0.8563 RMSE: 1.0179\n",
      "Epoch 8: TrainLoss 1.0351 RecLoss: 0.0000 (left: 0:01:46)\n",
      "TestLoss: 1.2176 MAE: 0.8971 RMSE: 1.1034\n",
      "ValLoss: 1.0315 MAE: 0.8543 RMSE: 1.0156\n",
      "Epoch 9: TrainLoss 1.0221 RecLoss: 0.0000 (left: 0:01:43)\n",
      "TestLoss: 1.2070 MAE: 0.8931 RMSE: 1.0986\n",
      "ValLoss: 1.0289 MAE: 0.8549 RMSE: 1.0144\n",
      "Epoch 10: TrainLoss 1.0136 RecLoss: 0.0000 (left: 0:01:41)\n",
      "TestLoss: 1.2012 MAE: 0.8909 RMSE: 1.0960\n",
      "ValLoss: 1.0203 MAE: 0.8523 RMSE: 1.0101\n",
      "Epoch 11: TrainLoss 1.0052 RecLoss: 0.0000 (left: 0:01:42)\n",
      "TestLoss: 1.1884 MAE: 0.8811 RMSE: 1.0901\n",
      "ValLoss: 1.0135 MAE: 0.8457 RMSE: 1.0067\n",
      "Epoch 12: TrainLoss 0.9993 RecLoss: 0.0000 (left: 0:01:41)\n",
      "TestLoss: 1.1897 MAE: 0.8854 RMSE: 1.0907\n",
      "ValLoss: 1.0061 MAE: 0.8460 RMSE: 1.0030\n",
      "Epoch 13: TrainLoss 0.9919 RecLoss: 0.0000 (left: 0:01:40)\n",
      "TestLoss: 1.1748 MAE: 0.8748 RMSE: 1.0839\n",
      "ValLoss: 1.0056 MAE: 0.8434 RMSE: 1.0028\n",
      "Epoch 14: TrainLoss 0.9832 RecLoss: 0.0000 (left: 0:01:38)\n",
      "TestLoss: 1.1776 MAE: 0.8801 RMSE: 1.0852\n",
      "ValLoss: 0.9997 MAE: 0.8441 RMSE: 0.9999\n",
      "Epoch 15: TrainLoss 0.9769 RecLoss: 0.0000 (left: 0:01:38)\n",
      "TestLoss: 1.1647 MAE: 0.8697 RMSE: 1.0792\n",
      "ValLoss: 0.9965 MAE: 0.8392 RMSE: 0.9982\n",
      "Epoch 16: TrainLoss 0.9728 RecLoss: 0.0000 (left: 0:01:38)\n",
      "TestLoss: 1.1673 MAE: 0.8741 RMSE: 1.0804\n",
      "ValLoss: 0.9929 MAE: 0.8405 RMSE: 0.9964\n",
      "Epoch 17: TrainLoss 0.9669 RecLoss: 0.0000 (left: 0:01:36)\n",
      "TestLoss: 1.1552 MAE: 0.8644 RMSE: 1.0748\n",
      "ValLoss: 0.9928 MAE: 0.8355 RMSE: 0.9964\n",
      "Epoch 18: TrainLoss 0.9633 RecLoss: 0.0000 (left: 0:01:35)\n",
      "TestLoss: 1.1661 MAE: 0.8748 RMSE: 1.0799\n",
      "ValLoss: 0.9934 MAE: 0.8421 RMSE: 0.9967\n",
      "Epoch 19: TrainLoss 0.9626 RecLoss: 0.0000 (left: 0:01:34)\n",
      "TestLoss: 1.1488 MAE: 0.8579 RMSE: 1.0718\n",
      "ValLoss: 0.9970 MAE: 0.8326 RMSE: 0.9985\n",
      "Epoch 20: TrainLoss 0.9585 RecLoss: 0.0000 (left: 0:01:33)\n",
      "TestLoss: 1.1705 MAE: 0.8789 RMSE: 1.0819\n",
      "ValLoss: 0.9958 MAE: 0.8429 RMSE: 0.9979\n",
      "Epoch 21: TrainLoss 0.9594 RecLoss: 0.0000 (left: 0:01:31)\n",
      "TestLoss: 1.1417 MAE: 0.8550 RMSE: 1.0685\n",
      "ValLoss: 0.9966 MAE: 0.8329 RMSE: 0.9983\n",
      "Epoch 22: TrainLoss 0.9566 RecLoss: 0.0000 (left: 0:01:30)\n",
      "TestLoss: 1.1533 MAE: 0.8684 RMSE: 1.0739\n",
      "ValLoss: 0.9851 MAE: 0.8360 RMSE: 0.9925\n",
      "Epoch 23: TrainLoss 0.9482 RecLoss: 0.0000 (left: 0:01:29)\n",
      "TestLoss: 1.1379 MAE: 0.8530 RMSE: 1.0667\n",
      "ValLoss: 0.9913 MAE: 0.8286 RMSE: 0.9956\n",
      "Epoch 24: TrainLoss 0.9486 RecLoss: 0.0000 (left: 0:01:29)\n",
      "TestLoss: 1.1525 MAE: 0.8694 RMSE: 1.0735\n",
      "ValLoss: 0.9900 MAE: 0.8383 RMSE: 0.9950\n",
      "Epoch 25: TrainLoss 0.9493 RecLoss: 0.0000 (left: 0:01:28)\n",
      "TestLoss: 1.1364 MAE: 0.8515 RMSE: 1.0660\n",
      "ValLoss: 0.9884 MAE: 0.8253 RMSE: 0.9942\n",
      "Epoch 26: TrainLoss 0.9486 RecLoss: 0.0000 (left: 0:01:26)\n",
      "TestLoss: 1.1618 MAE: 0.8749 RMSE: 1.0778\n",
      "ValLoss: 0.9898 MAE: 0.8374 RMSE: 0.9949\n",
      "Epoch 27: TrainLoss 0.9486 RecLoss: 0.0000 (left: 0:01:25)\n",
      "TestLoss: 1.1307 MAE: 0.8495 RMSE: 1.0634\n",
      "ValLoss: 0.9892 MAE: 0.8264 RMSE: 0.9946\n",
      "Epoch 28: TrainLoss 0.9429 RecLoss: 0.0000 (left: 0:01:23)\n",
      "TestLoss: 1.1413 MAE: 0.8632 RMSE: 1.0683\n",
      "ValLoss: 0.9892 MAE: 0.8360 RMSE: 0.9946\n",
      "Epoch 29: TrainLoss 0.9421 RecLoss: 0.0000 (left: 0:01:22)\n",
      "TestLoss: 1.1292 MAE: 0.8519 RMSE: 1.0626\n",
      "ValLoss: 0.9824 MAE: 0.8248 RMSE: 0.9912\n",
      "Epoch 30: TrainLoss 0.9410 RecLoss: 0.0000 (left: 0:01:20)\n",
      "TestLoss: 1.1331 MAE: 0.8567 RMSE: 1.0645\n",
      "ValLoss: 0.9762 MAE: 0.8250 RMSE: 0.9880\n",
      "Epoch 31: TrainLoss 0.9414 RecLoss: 0.0000 (left: 0:01:19)\n",
      "TestLoss: 1.1331 MAE: 0.8579 RMSE: 1.0645\n",
      "ValLoss: 0.9868 MAE: 0.8328 RMSE: 0.9934\n",
      "Epoch 32: TrainLoss 0.9380 RecLoss: 0.0000 (left: 0:01:17)\n",
      "TestLoss: 1.1286 MAE: 0.8542 RMSE: 1.0624\n",
      "ValLoss: 0.9806 MAE: 0.8267 RMSE: 0.9903\n",
      "Epoch 33: TrainLoss 0.9361 RecLoss: 0.0000 (left: 0:01:16)\n",
      "TestLoss: 1.1281 MAE: 0.8525 RMSE: 1.0621\n",
      "ValLoss: 0.9777 MAE: 0.8229 RMSE: 0.9888\n",
      "Epoch 34: TrainLoss 0.9354 RecLoss: 0.0000 (left: 0:01:16)\n",
      "TestLoss: 1.1300 MAE: 0.8555 RMSE: 1.0630\n",
      "ValLoss: 0.9772 MAE: 0.8252 RMSE: 0.9885\n",
      "Epoch 35: TrainLoss 0.9348 RecLoss: 0.0000 (left: 0:01:16)\n",
      "TestLoss: 1.1257 MAE: 0.8506 RMSE: 1.0610\n",
      "ValLoss: 0.9790 MAE: 0.8220 RMSE: 0.9894\n",
      "Epoch 36: TrainLoss 0.9346 RecLoss: 0.0000 (left: 0:01:15)\n",
      "TestLoss: 1.1241 MAE: 0.8506 RMSE: 1.0602\n",
      "ValLoss: 0.9831 MAE: 0.8255 RMSE: 0.9915\n",
      "Epoch 37: TrainLoss 0.9330 RecLoss: 0.0000 (left: 0:01:13)\n",
      "TestLoss: 1.1293 MAE: 0.8560 RMSE: 1.0627\n",
      "ValLoss: 0.9817 MAE: 0.8278 RMSE: 0.9908\n",
      "Epoch 38: TrainLoss 0.9322 RecLoss: 0.0000 (left: 0:01:12)\n",
      "TestLoss: 1.1248 MAE: 0.8504 RMSE: 1.0606\n",
      "ValLoss: 0.9791 MAE: 0.8214 RMSE: 0.9895\n",
      "Epoch 39: TrainLoss 0.9321 RecLoss: 0.0000 (left: 0:01:10)\n",
      "TestLoss: 1.1310 MAE: 0.8575 RMSE: 1.0635\n",
      "ValLoss: 0.9790 MAE: 0.8260 RMSE: 0.9894\n",
      "Epoch 40: TrainLoss 0.9329 RecLoss: 0.0000 (left: 0:01:09)\n",
      "TestLoss: 1.1225 MAE: 0.8497 RMSE: 1.0595\n",
      "ValLoss: 0.9823 MAE: 0.8237 RMSE: 0.9911\n",
      "Epoch 41: TrainLoss 0.9309 RecLoss: 0.0000 (left: 0:01:07)\n",
      "TestLoss: 1.1286 MAE: 0.8560 RMSE: 1.0624\n",
      "ValLoss: 0.9793 MAE: 0.8255 RMSE: 0.9896\n",
      "Epoch 42: TrainLoss 0.9309 RecLoss: 0.0000 (left: 0:01:06)\n",
      "TestLoss: 1.1230 MAE: 0.8496 RMSE: 1.0597\n",
      "ValLoss: 0.9789 MAE: 0.8209 RMSE: 0.9894\n",
      "Epoch 43: TrainLoss 0.9306 RecLoss: 0.0000 (left: 0:01:05)\n",
      "TestLoss: 1.1265 MAE: 0.8540 RMSE: 1.0614\n",
      "ValLoss: 0.9787 MAE: 0.8238 RMSE: 0.9893\n",
      "Epoch 44: TrainLoss 0.9310 RecLoss: 0.0000 (left: 0:01:04)\n",
      "TestLoss: 1.1240 MAE: 0.8519 RMSE: 1.0602\n",
      "ValLoss: 0.9806 MAE: 0.8238 RMSE: 0.9903\n",
      "Epoch 45: TrainLoss 0.9296 RecLoss: 0.0000 (left: 0:01:03)\n",
      "TestLoss: 1.1248 MAE: 0.8523 RMSE: 1.0606\n",
      "ValLoss: 0.9813 MAE: 0.8241 RMSE: 0.9906\n",
      "Epoch 46: TrainLoss 0.9300 RecLoss: 0.0000 (left: 0:01:01)\n",
      "TestLoss: 1.1251 MAE: 0.8527 RMSE: 1.0607\n",
      "ValLoss: 0.9811 MAE: 0.8239 RMSE: 0.9905\n",
      "Epoch 47: TrainLoss 0.9297 RecLoss: 0.0000 (left: 0:01:00)\n",
      "TestLoss: 1.1212 MAE: 0.8486 RMSE: 1.0589\n",
      "ValLoss: 0.9824 MAE: 0.8217 RMSE: 0.9912\n",
      "Epoch 48: TrainLoss 0.9293 RecLoss: 0.0000 (left: 0:01:00)\n",
      "TestLoss: 1.1264 MAE: 0.8539 RMSE: 1.0613\n",
      "ValLoss: 0.9791 MAE: 0.8226 RMSE: 0.9895\n",
      "Epoch 49: TrainLoss 0.9288 RecLoss: 0.0000 (left: 0:00:59)\n",
      "TestLoss: 1.1242 MAE: 0.8517 RMSE: 1.0603\n",
      "ValLoss: 0.9796 MAE: 0.8217 RMSE: 0.9898\n",
      "Epoch 50: TrainLoss 0.9286 RecLoss: 0.0000 (left: 0:00:58)\n",
      "TestLoss: 1.1212 MAE: 0.8477 RMSE: 1.0589\n",
      "ValLoss: 0.9811 MAE: 0.8190 RMSE: 0.9905\n",
      "Epoch 51: TrainLoss 0.9305 RecLoss: 0.0000 (left: 0:00:57)\n",
      "TestLoss: 1.1307 MAE: 0.8577 RMSE: 1.0634\n",
      "ValLoss: 0.9884 MAE: 0.8293 RMSE: 0.9942\n",
      "Epoch 52: TrainLoss 0.9315 RecLoss: 0.0000 (left: 0:00:56)\n",
      "TestLoss: 1.1214 MAE: 0.8421 RMSE: 1.0590\n",
      "ValLoss: 0.9876 MAE: 0.8171 RMSE: 0.9938\n",
      "Epoch 53: TrainLoss 0.9330 RecLoss: 0.0000 (left: 0:00:55)\n",
      "TestLoss: 1.1404 MAE: 0.8634 RMSE: 1.0679\n",
      "ValLoss: 0.9868 MAE: 0.8287 RMSE: 0.9934\n",
      "Epoch 54: TrainLoss 0.9331 RecLoss: 0.0000 (left: 0:00:53)\n",
      "TestLoss: 1.1203 MAE: 0.8405 RMSE: 1.0585\n",
      "ValLoss: 0.9902 MAE: 0.8181 RMSE: 0.9951\n",
      "Epoch 55: TrainLoss 0.9322 RecLoss: 0.0000 (left: 0:00:52)\n",
      "TestLoss: 1.1273 MAE: 0.8546 RMSE: 1.0618\n",
      "ValLoss: 0.9887 MAE: 0.8286 RMSE: 0.9943\n",
      "Epoch 56: TrainLoss 0.9288 RecLoss: 0.0000 (left: 0:00:51)\n",
      "TestLoss: 1.1196 MAE: 0.8440 RMSE: 1.0581\n",
      "ValLoss: 0.9832 MAE: 0.8177 RMSE: 0.9916\n",
      "Epoch 57: TrainLoss 0.9286 RecLoss: 0.0000 (left: 0:00:50)\n",
      "TestLoss: 1.1259 MAE: 0.8529 RMSE: 1.0611\n",
      "ValLoss: 0.9787 MAE: 0.8218 RMSE: 0.9893\n",
      "Epoch 58: TrainLoss 0.9305 RecLoss: 0.0000 (left: 0:00:48)\n",
      "TestLoss: 1.1201 MAE: 0.8446 RMSE: 1.0583\n",
      "ValLoss: 0.9818 MAE: 0.8172 RMSE: 0.9908\n",
      "Epoch 59: TrainLoss 0.9305 RecLoss: 0.0000 (left: 0:00:47)\n",
      "TestLoss: 1.1273 MAE: 0.8539 RMSE: 1.0618\n",
      "ValLoss: 0.9849 MAE: 0.8260 RMSE: 0.9924\n",
      "Epoch 60: TrainLoss 0.9312 RecLoss: 0.0000 (left: 0:00:46)\n",
      "TestLoss: 1.1199 MAE: 0.8457 RMSE: 1.0583\n",
      "ValLoss: 0.9836 MAE: 0.8197 RMSE: 0.9918\n",
      "Epoch 61: TrainLoss 0.9313 RecLoss: 0.0000 (left: 0:00:45)\n",
      "TestLoss: 1.1209 MAE: 0.8480 RMSE: 1.0587\n",
      "ValLoss: 0.9864 MAE: 0.8242 RMSE: 0.9932\n",
      "Epoch 62: TrainLoss 0.9298 RecLoss: 0.0000 (left: 0:00:43)\n",
      "TestLoss: 1.1226 MAE: 0.8494 RMSE: 1.0596\n",
      "ValLoss: 0.9823 MAE: 0.8222 RMSE: 0.9911\n",
      "Epoch 63: TrainLoss 0.9281 RecLoss: 0.0000 (left: 0:00:42)\n",
      "TestLoss: 1.1235 MAE: 0.8482 RMSE: 1.0599\n",
      "ValLoss: 0.9763 MAE: 0.8158 RMSE: 0.9881\n",
      "Epoch 64: TrainLoss 0.9268 RecLoss: 0.0000 (left: 0:00:41)\n",
      "TestLoss: 1.1250 MAE: 0.8515 RMSE: 1.0607\n",
      "ValLoss: 0.9825 MAE: 0.8235 RMSE: 0.9912\n",
      "Epoch 65: TrainLoss 0.9271 RecLoss: 0.0000 (left: 0:00:39)\n",
      "TestLoss: 1.1204 MAE: 0.8463 RMSE: 1.0585\n",
      "ValLoss: 0.9836 MAE: 0.8202 RMSE: 0.9918\n",
      "Epoch 66: TrainLoss 0.9272 RecLoss: 0.0000 (left: 0:00:38)\n",
      "TestLoss: 1.1242 MAE: 0.8507 RMSE: 1.0603\n",
      "ValLoss: 0.9835 MAE: 0.8236 RMSE: 0.9917\n",
      "Epoch 67: TrainLoss 0.9266 RecLoss: 0.0000 (left: 0:00:37)\n",
      "TestLoss: 1.1203 MAE: 0.8456 RMSE: 1.0584\n",
      "ValLoss: 0.9829 MAE: 0.8187 RMSE: 0.9914\n",
      "Epoch 68: TrainLoss 0.9267 RecLoss: 0.0000 (left: 0:00:36)\n",
      "TestLoss: 1.1242 MAE: 0.8503 RMSE: 1.0603\n",
      "ValLoss: 0.9828 MAE: 0.8226 RMSE: 0.9914\n",
      "Epoch 69: TrainLoss 0.9268 RecLoss: 0.0000 (left: 0:00:34)\n",
      "TestLoss: 1.1219 MAE: 0.8478 RMSE: 1.0592\n",
      "ValLoss: 0.9815 MAE: 0.8199 RMSE: 0.9907\n",
      "Epoch 70: TrainLoss 0.9264 RecLoss: 0.0000 (left: 0:00:33)\n",
      "TestLoss: 1.1260 MAE: 0.8520 RMSE: 1.0612\n",
      "ValLoss: 0.9808 MAE: 0.8217 RMSE: 0.9903\n",
      "Epoch 71: TrainLoss 0.9264 RecLoss: 0.0000 (left: 0:00:32)\n",
      "TestLoss: 1.1208 MAE: 0.8466 RMSE: 1.0587\n",
      "ValLoss: 0.9836 MAE: 0.8202 RMSE: 0.9918\n",
      "Epoch 72: TrainLoss 0.9261 RecLoss: 0.0000 (left: 0:00:31)\n",
      "TestLoss: 1.1228 MAE: 0.8490 RMSE: 1.0596\n",
      "ValLoss: 0.9861 MAE: 0.8239 RMSE: 0.9930\n",
      "Epoch 73: TrainLoss 0.9270 RecLoss: 0.0000 (left: 0:00:30)\n",
      "TestLoss: 1.1212 MAE: 0.8458 RMSE: 1.0589\n",
      "ValLoss: 0.9829 MAE: 0.8184 RMSE: 0.9914\n",
      "Epoch 74: TrainLoss 0.9283 RecLoss: 0.0000 (left: 0:00:29)\n",
      "TestLoss: 1.1243 MAE: 0.8499 RMSE: 1.0603\n",
      "ValLoss: 0.9827 MAE: 0.8215 RMSE: 0.9913\n",
      "Epoch 75: TrainLoss 0.9261 RecLoss: 0.0000 (left: 0:00:27)\n",
      "TestLoss: 1.1226 MAE: 0.8478 RMSE: 1.0595\n",
      "ValLoss: 0.9822 MAE: 0.8197 RMSE: 0.9911\n",
      "Epoch 76: TrainLoss 0.9263 RecLoss: 0.0000 (left: 0:00:26)\n",
      "TestLoss: 1.1244 MAE: 0.8503 RMSE: 1.0604\n",
      "ValLoss: 0.9846 MAE: 0.8233 RMSE: 0.9923\n",
      "Epoch 77: TrainLoss 0.9262 RecLoss: 0.0000 (left: 0:00:26)\n",
      "TestLoss: 1.1210 MAE: 0.8467 RMSE: 1.0588\n",
      "ValLoss: 0.9856 MAE: 0.8214 RMSE: 0.9928\n",
      "Epoch 78: TrainLoss 0.9261 RecLoss: 0.0000 (left: 0:00:24)\n",
      "TestLoss: 1.1232 MAE: 0.8485 RMSE: 1.0598\n",
      "ValLoss: 0.9814 MAE: 0.8192 RMSE: 0.9906\n",
      "Epoch 79: TrainLoss 0.9262 RecLoss: 0.0000 (left: 0:00:23)\n",
      "TestLoss: 1.1265 MAE: 0.8518 RMSE: 1.0613\n",
      "ValLoss: 0.9831 MAE: 0.8227 RMSE: 0.9915\n",
      "Epoch 80: TrainLoss 0.9272 RecLoss: 0.0000 (left: 0:00:22)\n",
      "TestLoss: 1.1231 MAE: 0.8475 RMSE: 1.0598\n",
      "ValLoss: 0.9811 MAE: 0.8180 RMSE: 0.9905\n",
      "Epoch 81: TrainLoss 0.9277 RecLoss: 0.0000 (left: 0:00:21)\n",
      "TestLoss: 1.1252 MAE: 0.8502 RMSE: 1.0607\n",
      "ValLoss: 0.9821 MAE: 0.8211 RMSE: 0.9910\n",
      "Epoch 82: TrainLoss 0.9267 RecLoss: 0.0000 (left: 0:00:20)\n",
      "TestLoss: 1.1218 MAE: 0.8472 RMSE: 1.0592\n",
      "ValLoss: 0.9857 MAE: 0.8217 RMSE: 0.9928\n",
      "Epoch 83: TrainLoss 0.9274 RecLoss: 0.0000 (left: 0:00:19)\n",
      "TestLoss: 1.1200 MAE: 0.8450 RMSE: 1.0583\n",
      "ValLoss: 0.9872 MAE: 0.8210 RMSE: 0.9936\n",
      "Epoch 84: TrainLoss 0.9263 RecLoss: 0.0000 (left: 0:00:17)\n",
      "TestLoss: 1.1275 MAE: 0.8523 RMSE: 1.0618\n",
      "ValLoss: 0.9847 MAE: 0.8237 RMSE: 0.9923\n",
      "Epoch 85: TrainLoss 0.9256 RecLoss: 0.0000 (left: 0:00:16)\n",
      "TestLoss: 1.1240 MAE: 0.8465 RMSE: 1.0602\n",
      "ValLoss: 0.9803 MAE: 0.8159 RMSE: 0.9901\n",
      "Epoch 86: TrainLoss 0.9268 RecLoss: 0.0000 (left: 0:00:15)\n",
      "TestLoss: 1.1263 MAE: 0.8509 RMSE: 1.0613\n",
      "ValLoss: 0.9826 MAE: 0.8216 RMSE: 0.9913\n",
      "Epoch 87: TrainLoss 0.9255 RecLoss: 0.0000 (left: 0:00:14)\n",
      "TestLoss: 1.1218 MAE: 0.8457 RMSE: 1.0592\n",
      "ValLoss: 0.9844 MAE: 0.8189 RMSE: 0.9922\n",
      "Epoch 88: TrainLoss 0.9256 RecLoss: 0.0000 (left: 0:00:13)\n",
      "TestLoss: 1.1244 MAE: 0.8495 RMSE: 1.0604\n",
      "ValLoss: 0.9873 MAE: 0.8242 RMSE: 0.9936\n",
      "Epoch 89: TrainLoss 0.9256 RecLoss: 0.0000 (left: 0:00:12)\n",
      "TestLoss: 1.1237 MAE: 0.8483 RMSE: 1.0600\n",
      "ValLoss: 0.9840 MAE: 0.8208 RMSE: 0.9920\n",
      "Epoch 90: TrainLoss 0.9255 RecLoss: 0.0000 (left: 0:00:11)\n",
      "TestLoss: 1.1238 MAE: 0.8480 RMSE: 1.0601\n",
      "ValLoss: 0.9833 MAE: 0.8199 RMSE: 0.9916\n",
      "Epoch 91: TrainLoss 0.9263 RecLoss: 0.0000 (left: 0:00:09)\n",
      "TestLoss: 1.1246 MAE: 0.8486 RMSE: 1.0605\n",
      "ValLoss: 0.9830 MAE: 0.8201 RMSE: 0.9915\n",
      "Epoch 92: TrainLoss 0.9259 RecLoss: 0.0000 (left: 0:00:08)\n",
      "TestLoss: 1.1243 MAE: 0.8485 RMSE: 1.0603\n",
      "ValLoss: 0.9842 MAE: 0.8209 RMSE: 0.9921\n",
      "Epoch 93: TrainLoss 0.9256 RecLoss: 0.0000 (left: 0:00:07)\n",
      "TestLoss: 1.1248 MAE: 0.8493 RMSE: 1.0605\n",
      "ValLoss: 0.9864 MAE: 0.8233 RMSE: 0.9932\n",
      "Epoch 94: TrainLoss 0.9253 RecLoss: 0.0000 (left: 0:00:06)\n",
      "TestLoss: 1.1226 MAE: 0.8462 RMSE: 1.0595\n",
      "ValLoss: 0.9845 MAE: 0.8192 RMSE: 0.9922\n",
      "Epoch 95: TrainLoss 0.9251 RecLoss: 0.0000 (left: 0:00:05)\n",
      "TestLoss: 1.1267 MAE: 0.8510 RMSE: 1.0615\n",
      "ValLoss: 0.9847 MAE: 0.8227 RMSE: 0.9923\n",
      "Epoch 96: TrainLoss 0.9256 RecLoss: 0.0000 (left: 0:00:04)\n",
      "TestLoss: 1.1235 MAE: 0.8476 RMSE: 1.0600\n",
      "ValLoss: 0.9854 MAE: 0.8210 RMSE: 0.9927\n",
      "Epoch 97: TrainLoss 0.9254 RecLoss: 0.0000 (left: 0:00:03)\n",
      "TestLoss: 1.1225 MAE: 0.8467 RMSE: 1.0595\n",
      "ValLoss: 0.9868 MAE: 0.8214 RMSE: 0.9934\n",
      "Epoch 98: TrainLoss 0.9266 RecLoss: 0.0000 (left: 0:00:02)\n",
      "TestLoss: 1.1253 MAE: 0.8491 RMSE: 1.0608\n",
      "ValLoss: 0.9834 MAE: 0.8204 RMSE: 0.9917\n",
      "Epoch 99: TrainLoss 0.9254 RecLoss: 0.0000 (left: 0:00:01)\n",
      "TestLoss: 1.1242 MAE: 0.8476 RMSE: 1.0603\n",
      "ValLoss: 0.9839 MAE: 0.8196 RMSE: 0.9919\n",
      "Extra : False\n",
      "-------Dataset Info--------\n",
      "split way [threshold] with threshold 30 training_ratio 1.0\n",
      "train set size: support/query 35161/4938\n",
      "test set size: support/query 146/213\n",
      "USER HIS DICT: 943\n",
      "NUM IS: 943\n",
      "Key Test Result: MAE: 0.7619 RMSE: 0.9300 NDCG: 0.0000\n",
      "CORE IS SELECTED:\n",
      "USER HIS DICT: 943\n",
      "NUM IS: 943\n",
      "Que Test Result: MAE: 0.8567 RMSE: 1.0645 NDCG: 0.0000\n",
      "All Test Result: MAE: 0.8182 RMSE: 1.0119 NDCG: 0.0000\n"
     ]
    }
   ],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 40% cos coreuser as input to IDCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python pretrain-1m.py\n",
    "!python train-1m.py\n",
    "!python test-1m.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = [10, 20, 40, 60]\n",
    "y_axis = [1.0013,0.9986,0.9933, 0.9923]\n",
    "x1_axis = [10, 20, 40, 60]\n",
    "y1_axis = [0.9859, 0.9859, 0.9859, 0.9859]\n",
    "x2_axis = [10, 20, 40, 60]\n",
    "y2_axis = [0.9990, 0.9935, 0.9906, 0.9883]\n",
    "\n",
    "plt.plot(x1_axis, y1_axis, label=\"Base-Line 100% SUPPORT USERS ARE USED AS CORE USERS\")\n",
    "plt.plot(x_axis, y_axis, label=\"CORE USER CALCULATED USING COSINE SIMILARITY\")\n",
    "plt.plot(x2_axis, y2_axis, label=\"CORE USER CALCULATED USING CUR DECOMPOSITION\")\n",
    "\n",
    "plt.title('RMSE VS % of core user in support')\n",
    "plt.xlabel('% of core users in support')\n",
    "plt.ylabel('RMSE')\n",
    "plt.grid()\n",
    "plt.legend(fontsize=7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
